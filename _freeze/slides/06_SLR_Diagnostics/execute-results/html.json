{
  "hash": "2aa9ba939d7b7f7d11e1adef03569e56",
  "result": {
    "markdown": "---\ntitle: \"SLR: Model Diagnostics\"\nauthor: \"Nicky Wakim\"\ntitle-slide-attributes:\n    data-background-color: \"#213c96\"\ndate: \"01/17/2023\"\ncategories: [\"Week 1\"]\nformat: \n  revealjs:\n    theme: [default, simple_NW.scss]\n    toc: true\n    toc-depth: 1\n    toc-title: Class Overview\n    chalkboard: true\n    slide-number: true\n    show-slide-number: all\n    width: 1955\n    height: 1100\n    footer: SLR 1\n    html-math-method: mathjax\n    highlight-style: ayu\nexecute:\n  echo: true\n  freeze: auto  # re-render only when source changes\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapm <- read_csv(\"data/lifeexp_femlit_2011.csv\")\n```\n:::\n\n\n# Learning Objectives\n\n1.  Identify the aims of your research and see how they align with the\n    intended purpose of simple linear regression\n\n2.  Identify the simple linear regression model and define statistics\n    language for key notation\n\n3.  Illustrate how ordinary least squares (OLS) finds the best model\n    parameter estimates\n\n4.  Solve the optimal coefficient estimates for simple linear regression\n    using OLS\n\n5.  Apply OLS in R for simple linear regression of real data\n\n## Topics\n\n\n-   LINE assumptions\n\n-   checking assumptions\n-   residual analysis\n-   outlier detection \n\n# Learning Objectives\n\n1.  Identify different sources of variation in an Analysis of Variance\n    (ANOVA) table\n\n2.  Using the F-test, determine if there is enough evidence that\n    population slope $\\beta_1$ is not 0\n\n3.  Calculate and interpret the coefficient of determination\n\n::: lob\n4.  Describe the model assumptions made in linear regression using\n    ordinary least squares\n:::\n\n## Least-squares model assumptions: eLINE\n\nThese are the model assumptions made in ordinary least squares:\n\n \n\n-   **e** xistence: For any $X$, there exists a distribution for $Y$\n\n \n\n-   **L** inearity of relationship between variables\n\n \n\n-   **I** ndependence of the $Y$ values\n\n \n\n-   **N** ormality of the $Y$'s given $X$ (residuals)\n\n \n\n-   **E** quality of variance of the residuals (homoscedasticity)\n\n## e: Existence of Y’s distribution\n\n-   For any fixed value of the variable $X$, $Y$ is a\n    -   random variable with a certain probability distribution\n    -   having finite\n        -   mean and\n        -   variance\n-   This leads to the normality assumption\n-   Note: This is not about $Y$ alone, but $Y|X$\n\n## L: Linearity\n\n-   The relationship between the variables is linear (a straight line):\n    -   The mean value of $Y$ given $X$, $\\mu_{y|x}$ or $E[Y|X]$, is a\n        straight-line function of $X$\n\n$$\\mu_{y|x} = \\beta_0 + \\beta_1 \\cdot X$$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## I: Independence of observations\n\n-   The $Y$-values are statistically independent of one another\n\n \n\n-   Examples of when they are *not* independent, include\n\n     \n\n    -   repeated measures (such as baseline, 3 months, 6 months)\n\n     \n\n    -   data from clusters, such as different hospitals or families\n\n \n\n-   This condition is checked by reviewing the study *design* and not by\n    inspecting the data\n\n \n\n-   How to analyze data using regression models when the $Y$-values are\n    not independent is covered in BSTA 519 (Longitudinal data)\n\n## Poll Everywhere Question\n\n## N: Normality\n\n-   For any fixed value of $X$, $Y$ has normal distribution.\n    -   Note: This is not about $Y$ alone, but $Y|X$\n-   Equivalently, the measurement (random) errors $\\epsilon_i$ ’s\n    normally distributed\n    -   This is more often what we check\n-   We will discuss how to assess this in practice in Chapter 14\n    (Regression Diagnostics)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=1056}\n:::\n:::\n\n\n## E: Equality of variance of the residuals\n\n-   The variance of $Y$ given $X$ ($\\sigma_{Y|X}^2$), is the same for\n    any $X$\n\n    -   We use just $\\sigma^2$ to denote the common variance\n\n-   This is also called **homoscedasticity**\n\n-   We will discuss how to assess this in practice in Chapter 14\n    (Regression Diagnostics)\n\n![](05_SLR_Eval/homosced.webp){fig-align=\"center\"}\n\n## Summary of eLINE model assumptions\n\n-   $Y$ values are independent (check study design!)\n\n<br>\n\n::: columns\n::: column\n-   The distribution of $Y$ given $X$ is\n    -   normal\n    -   with mean $\\mu_{y|x} = \\beta_0 + \\beta_1 \\cdot X$\n    -   and common variance $\\sigma^2$\n:::\n\n::: column\n-   This means that the residuals are\n    -   normal\n    -   with mean = 0\n    -   and common variance $\\sigma^2$\n:::\n:::\n\n## Anscombe's Quartet\n\n![](05_SLR_Eval/anscombe.png){fig-align=\"center\"}\n\n\n## What are the LINE conditions?\n\nFor \"good\" model fit and to be able to make inferences and predictions\nbased on our models, 4 conditions need to be satisfied.\n\nBriefly:\n\n-   **L** inearity of relationship between variables\n-   **I** ndependence of the Y values\n-   **N** ormality of the residuals\n-   **E** quality of variance of the residuals (homoscedasticity)\n\n[More in\ndepth](https://bookdown.org/roback/bookdown-bysh/ch-MLRreview.html#ordinary-least-squares-ols-assumptions):\n\n-   **L** : there is a linear relationship between the mean response (Y)\n    and the explanatory variable (X),\n-   **I** : the errors are independent—there’s no connection between how\n    far any two points lie from the regression line,\n-   **N** : the responses are normally distributed at each level of X,\n    and\n-   **E** : the variance or, equivalently, the standard deviation of the\n    responses is equal for all levels of X.\n\n## L: Linearity of relationship between variables\n\nIs the association between the variables linear?\n\n-   Diagnostic tools:\n    -   Scatterplot\n    -   Residual plot (see later section for E : Equality of variance of\n        the residuals)\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-5-1.png){width=1152}\n:::\n:::\n\n\n## I: Independence of the residuals ($Y$ values)\n\n-   **Are the data points independent of each other?**\n\n-   Examples of when they are *not* independent, include\n\n    -   repeated measures (such as baseline, 3 months, 6 months)\n    -   data from clusters, such as different hospitals or families\n\n-   This condition is checked by reviewing the study *design* and not by\n    inspecting the data\n\n-   How to analyze data using regression models when the $Y$-values are\n    not independent is covered in BSTA 519 (Longitudinal data)\n\n# N: Normality of the residuals\n\n-   Extract residuals from regression model in R\n-   Diagnostic tools:\n    -   Distribution plots of residuals\n    -   QQ plots\n\n## N: Normality of the residuals\n\n-   The responses Y are normally distributed at each level of x\n\n![](/img_slides/OLSassumptions-1.png){fig-align=\"center\"}\n\n::: {style=\"font-size: 60%;\"}\n<https://bookdown.org/roback/bookdown-bysh/ch-MLRreview.html#ordinary-least-squares-ols-assumptions>\n:::\n\n## Extract model's residuals in R\n\n-   First extract the residuals' values from the model output using the\n    `augment()` function from the `broom` package.\n-   Get a tibble with the orginal data, as well as the residuals and\n    some other important values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- lm(life_expectancy_years_2011 ~ female_literacy_rate_2011, \n                data = gapm)\naug1 <- augment(model1) \n\nglimpse(aug1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 80\nColumns: 9\n$ .rownames                  <chr> \"1\", \"2\", \"5\", \"6\", \"7\", \"8\", \"14\", \"22\", \"…\n$ life_expectancy_years_2011 <dbl> 56.7, 76.7, 60.9, 76.9, 76.0, 73.8, 71.0, 7…\n$ female_literacy_rate_2011  <dbl> 13.0, 95.7, 58.6, 99.4, 97.9, 99.5, 53.4, 9…\n$ .fitted                    <dbl> 53.94643, 73.14897, 64.53453, 74.00809, 73.…\n$ .resid                     <dbl> 2.7535654, 3.5510294, -3.6345319, 2.8919074…\n$ .hat                       <dbl> 0.13628996, 0.01768176, 0.02645854, 0.02077…\n$ .sigma                     <dbl> 6.172684, 6.168414, 6.167643, 6.172935, 6.1…\n$ .cooksd                    <dbl> 1.835891e-02, 3.062372e-03, 4.887448e-03, 2…\n$ .std.resid                 <dbl> 0.48238134, 0.58332052, -0.59972251, 0.4757…\n```\n:::\n:::\n\n\n## Check normality with \"usual\" distribution plots\n\nNote that below I save each figure, and then combine them together in\none row of output using `grid.arrange()` from the `gridExtra` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist1 <- ggplot(aug1, aes(x = .resid)) +\n  geom_histogram()\n\ndensity1 <- ggplot(aug1, aes(x = .resid)) +\n  geom_density()\n\nbox1 <- ggplot(aug1, aes(x = .resid)) +\n  geom_boxplot()\n\nlibrary(gridExtra) # NEW!!!\ngrid.arrange(hist1, density1, box1, nrow = 1)\n```\n\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-7-1.png){width=1152}\n:::\n:::\n\n\n## Normal QQ plots (QQ = quantile-quantile)\n\n-   It can be tricky to eyeball with a histogram or density plot whether\n    the residuals are normal or not\n-   QQ plots are often used to help with this\n\n::: columns\n::: {.column width=\"60%\"}\n-   *Vertical axis*: **data quantiles**\n    -   data points are sorted in order and\n    -   assigned quantiles based on how many data points there are\n-   *Horizontal axis*: **theoretical quantiles**\n    -   mean and standard deviation (SD) calculated from the data points\n    -   theoretical quantiles are calculated for each point, assuming\n        the data are modeled by a normal distribution with the mean and\n        SD of the data\n:::\n\n::: {.column width=\"40%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-8-1.png){width=480}\n:::\n:::\n\n:::\n:::\n\n-   **Data are approximately normal if points fall on a line.**\n\nSee more info at\n<https://data.library.virginia.edu/understanding-QQ-plots/>\n\n## Examples of Normal QQ plots (1/5)\n\n-   **Data**:\n    -   Body measurements from 507 physically active individuals\n    -   in their 20's or early 30's\n    -   within normal weight range.\n\n![](/img_slides/qq_wristdiam.png){fig-align=\"center\"}\n\n## Examples of Normal QQ plots (2/5)\n\nSkewed right distribution\n\n<br>\n\n![](/img_slides/qq_weights.png){fig-align=\"center\"}\n\n## Examples of Normal QQ plots (3/5)\n\nLong tails in distribution\n\n<br>\n\n![](/img_slides/qq_biliac.png){fig-align=\"center\"}\n\n## Examples of Normal QQ plots (4/5)\n\nBimodal distribution\n\n<br>\n\n![](/img_slides/qq_forearm.png){fig-align=\"center\"}\n\n## Examples of Normal QQ plots (5/5)\n\n![](/img_slides/qq_forearm_gender.png){fig-align=\"center\"}\n\n## QQ plot of residuals of `model1`\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-9-1.png){width=1152}\n:::\n:::\n\n\n::: columns\n::: {.column width=\"50%\"}\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(aug1, aes(sample = .resid)) + \n  stat_qq() +     # points\n  stat_qq_line()  # line\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-11-1.png){width=480}\n:::\n:::\n\n:::\n:::\n\n## Compare to randomly generated Normal QQ plots\n\nHow \"*good*\" we can expect a QQ plot to look depends on the sample size.\n\n-   The QQ plots on the next slides are randomly generated\n\n    -   using random samples from actual standard normal distributions\n        $N(0,1)$.\n\n-   Thus, all the points in the QQ plots **should theoretically** fall\n    in a line\n\n-   However, there is sampling variability...\n\n## Randomly generated Normal QQ plots: n=100\n\n-   Note that `stat_qq_line()` doesn't work with randomly generated\n    samples, and thus the code below manually creates the line that the\n    points should be on (which is $y=x$ in this case.)\n\n::: columns\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 90%;\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nsamplesize <- 100\n\nrand_qq1 <- ggplot() +\n  stat_qq(aes(sample = rnorm(samplesize))) + \n  # line y=x\n  geom_abline(intercept = 0, slope = 1, \n              color = \"blue\") \n\nrand_qq2 <- ggplot() +\n  stat_qq(aes(sample = rnorm(samplesize))) + \n  geom_abline(intercept = 0, slope = 1, \n              color = \"blue\")\n\nrand_qq3 <- ggplot() +\n  stat_qq(aes(sample = rnorm(samplesize))) + \n  geom_abline(intercept = 0, slope = 1, \n              color = \"blue\")\n\nrand_qq4 <- ggplot() +\n  stat_qq(aes(sample = rnorm(samplesize))) + \n  geom_abline(intercept = 0, slope = 1, \n              color = \"blue\")\n```\n:::\n\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid.arrange(rand_qq1, rand_qq2, \n             rand_qq3, rand_qq4, ncol =2)\n```\n\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-13-1.png){width=768}\n:::\n:::\n\n:::\n:::\n\n## Examples of simulated Normal QQ plots: n=10\n\nWith fewer data points,\n\n-   simulated QQ plots are more likely to look \"less normal\"\n-   even though the data points were sampled from normal distributions.\n\n::: columns\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 90%;\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nsamplesize <- 10  # only change made to code!\n\nrand_qq1 <- ggplot() +\n  stat_qq(aes(sample = rnorm(samplesize))) + \n  # line y=x\n  geom_abline(intercept = 0, slope = 1, \n              color = \"blue\") \n\nrand_qq2 <- ggplot() +\n  stat_qq(aes(sample = rnorm(samplesize))) + \n  geom_abline(intercept = 0, slope = 1, \n              color = \"blue\")\n\nrand_qq3 <- ggplot() +\n  stat_qq(aes(sample = rnorm(samplesize))) + \n  geom_abline(intercept = 0, slope = 1, \n              color = \"blue\")\n\nrand_qq4 <- ggplot() +\n  stat_qq(aes(sample = rnorm(samplesize))) + \n  geom_abline(intercept = 0, slope = 1, \n              color = \"blue\")\n```\n:::\n\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid.arrange(rand_qq1, rand_qq2, \n             rand_qq3, rand_qq4, ncol =2)\n```\n\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-15-1.png){width=768}\n:::\n:::\n\n:::\n:::\n\n## Examples of simulated Normal QQ plots: n=1,000\n\nWith more data points,\n\n-   simulated QQ plots are more likely to look \"more normal\"\n\n::: columns\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 90%;\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nsamplesize <- 1000 # only change made to code!\n\nrand_qq1 <- ggplot() +\n  stat_qq(aes(sample = rnorm(samplesize))) + \n  # line y=x\n  geom_abline(intercept = 0, slope = 1, \n              color = \"blue\") \n\nrand_qq2 <- ggplot() +\n  stat_qq(aes(sample = rnorm(samplesize))) + \n  geom_abline(intercept = 0, slope = 1, \n              color = \"blue\")\n\nrand_qq3 <- ggplot() +\n  stat_qq(aes(sample = rnorm(samplesize))) + \n  geom_abline(intercept = 0, slope = 1, \n              color = \"blue\")\n\nrand_qq4 <- ggplot() +\n  stat_qq(aes(sample = rnorm(samplesize))) + \n  geom_abline(intercept = 0, slope = 1, \n              color = \"blue\")\n```\n:::\n\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid.arrange(rand_qq1, rand_qq2, \n             rand_qq3, rand_qq4, ncol =2)\n```\n\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-17-1.png){width=768}\n:::\n:::\n\n:::\n:::\n\n## Back to our example\n\n::: columns\n::: {.column width=\"40%\"}\nResiduals from Life Expectancy vs. Female Literacy Rate Regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(aug1, \n      aes(sample = .resid)) + \n  stat_qq() + \n  stat_qq_line() \n```\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\nSimulated QQ plot of Normal Residuals with n = 80\n\n::: columns\n::: {.column width=\"40%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# number of observations \n# in fitted model\nnobs(model1) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 80\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  stat_qq(aes(\n    sample = rnorm(80))) + \n  geom_abline(\n    intercept = 0, slope = 1, \n    color = \"blue\")\n```\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n# E: Equality of variance of the residuals {.nostretch}\n\n-   Homoscedasticity\n-   Diagnostic tool: **residual plot**\n\n![](/img_slides/OLSassumptions-1.png){fig-align=\"center\" width=\"60%\"}\n\n::: {style=\"font-size: 60%;\"}\n<https://bookdown.org/roback/bookdown-bysh/ch-MLRreview.html#ordinary-least-squares-ols-assumptions>\n:::\n\n## Residual plot\n\n-   $x$ = explanatory variable from regression model\n    -   (or the fitted values for a multiple regression)\n-   $y$ = residuals from regression model\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(aug1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \".rownames\"                  \"life_expectancy_years_2011\"\n[3] \"female_literacy_rate_2011\"  \".fitted\"                   \n[5] \".resid\"                     \".hat\"                      \n[7] \".sigma\"                     \".cooksd\"                   \n[9] \".std.resid\"                \n```\n:::\n:::\n\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(aug1, \n       aes(x = female_literacy_rate_2011, \n           y = .resid)) + \n  geom_point() +\n  geom_abline(\n    intercept = 0, \n    slope = 0, \n    color = \"orange\") +\n  labs(title = \"Residual plot\")\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_SLR_Diagnostics_files/figure-revealjs/unnamed-chunk-25-1.png){width=576}\n:::\n:::\n\n:::\n:::\n\n## E: Equality of variance of the residuals (Homoscedasticity)\n\n-   The **variance** or, equivalently, the standard deviation of the\n    responses is **equal for all values of x**.\n-   This is called **homoskedasticity** (top row)\n-   If there is **heteroskedasticity** (bottom row), then the assumption\n    is not met.\n\n![](/img_slides/heteroskedastic.png){fig-align=\"center\"}\n",
    "supporting": [
      "06_SLR_Diagnostics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}