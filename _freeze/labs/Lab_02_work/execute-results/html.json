{
  "hash": "07f7568816fee127957f617461cb10ca",
  "result": {
    "markdown": "---\ntitle: \"Lab 2 Work\"\nsubtitle: \"BSTA 512/612\"\ndescription: \"Due: Thursday February 8, 2024 at 11pm\"\ndate-modified: \"1/17/2024\"\ndate: \"2/8/2024\"\ncategories: [\"\"]\nformat: \n  html:\n    link-external-newwindow: true\n    toc: true\n  pdf: default \neditor_options: \n  chunk_output_type: console\n---\n\n\n## Directions\n\nPlease turn in your `.html` file [on Sakai.](https://sakai.ohsu.edu/portal/site/BSTA-512-1-AB-W24/tool/961ec5ef-d7f9-4518-be16-25f7af3d6be4?panel=Main) Please let me know if you greatly prefer to submit a physical copy.\n\n[You can download the `.qmd` file for this lab here.](https://github.com/nwakim/W2024_BSTA_512/blob/main/labs/Lab_02.qmd)\n\nThe rest of this lab's instructions are embedded into the lab activities.\n\n### Purpose\n\nThe main purpose of this lab is to introduce our dataset, codebook, and variables. We will continue to think about the context of our research question, but our main focus is to become familiar with the data.\n\n### Grading\n\nThis lab is graded out of 12 points. Nicky will use the following rubric to assign grades.\n\n#### Rubric\n\n|            | 4 points                                                                                                                                                                                                        | 3 points                                                                                                                                                                                       | 2 points                                                                                                                                                                                                   | 1 point                                                                                                                                 | 0 points                                                                                                |\n|------------|------------|------------|------------|------------|------------|\n| Answers    | Answers demonstrate completion and understanding of the needed activity\\*. Answers are thoughtful and can be easily integrated into the final report.                                                           | Answers demonstrate completion and understanding of the needed activity\\*. Answers are thoughtful, but lack the clarity needed to easily integrate into the final report.                      | Answers demonstrate completion and minimal understanding of the needed activity\\*. Answers are fairly thoughtful, but lack connection to the research.                                                     | Answers demonstrate completion of needed activities\\*, although evidently rushed through. Answers seem rushed and with minimal thought. | It is evident that the needed activities\\* were not completed. Answers seem rushed and without thought. |\n| Formatting | Lab submitted on Sakai with `.html` file. Answers are written in complete sentences with no major grammatical nor spelling errors. With little editing, the answer can be incorporated into the project report. | Lab submitted on Sakai with `.html` file. Answers are written in complete sentences with grammatical or spelling errors. With editing, the answer can be incorporated into the project report. | Lab submitted on Sakai with `.html` file. Answers are written in complete sentences with major grammatical or spelling errors. With major editing, the answer can be incorporated into the project report. | Lab submitted on Sakai with `.html` file. Answers are bulletted or do not use complete sentences.                                       | Lab *not* submitted on Sakai with `.html` file.                                                         |\n| Code       |                                                                                                                                                                                                                 |                                                                                                                                                                                                |                                                                                                                                                                                                            |                                                                                                                                         |                                                                                                         |\n| Reasoning  |                                                                                                                                                                                                                 |                                                                                                                                                                                                |                                                                                                                                                                                                            |                                                                                                                                         |                                                                                                         |\n\n## Lab activities\n\n### 1. Access and download the data\n\nThis serves as good practice for accessing data that is online or needs to be downloaded from a collaborator.\n\nData can be accessed [here](https://osf.io/iay3x/). Under \"Weight IAT 2004-2022\" there are several drop down menus:\n\n![](images/data_access_1.png)\n\nI opened the first \"Datasets & Codebooks,\" then selected \"OSF Storage (United States).\" Once selected, the \"Download as zip\" option pops up in the top right part of the Files section.\n\n![](images/data_access_2.png)\n\nWe will be working with the `Weight_IAT.public.2021.csv` dataset. Please locate the `zip` file called `Weight IAT.public.2021-CSV.zip` . T0 download, you need to click the row of the zip file, but you can't click the name of the zip file. If a link opens, then you clicked the name. If the row is highlighted blue and clickable \"Download\" and \"View\" buttons appear on the top right, then you selected it correctly! (See below image for what it should look like.)\n\n![](images/data_access_3.png)\n\nThen click the \"Download\" button to download! Note that the name does not have an underscore between \"Weight\" and \"IAT.\" I like to have my datasets named without spaces, so I will replace the space with an underscore.\n\nFor the codebook, perform the same process for the file named: `Weight_IAT_public_2021_codebook.xlsx`\n\nYou will need to unzip the actual data.\n\nMove the data to a folder that you can easily access as you work from this document. I like to have a folder named `data` to house my data.\n\n### 2. Load data and needed packages\n\nFirst, load the packages that you will need in the remainder of this lab. You can add to this as you need to. At the top of your R code chunk, you can add the following option to repress the messages from the loading packages:\n\n![](images/r_message.png)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(gtsummary)\nlibrary(here)\n```\n:::\n\n\nUsing R, load the data (`csv` file) into this document. Note that this is a `csv` file that we can load with basic R packages. Name your dataset something that feels intuitive to you and will distinguish it from other datasets that you work with.\n\n\n::: {.cell}\n\n```{.r .cell-code}\niat_2021_raw = read.csv(file = here(\"../TA_files/Project/data/Weight_IAT.public.2021.csv\"))\n```\n:::\n\n\nLoading the `csv` file every time you render will take a long time. One way to speed this up is by saving the data as an `rda` file (R data file). Change the following R code to save the `rda` file. You will also need to remove the `#| eval: false` at the top of the code chunk once you have corrected the code. If you are confused on the syntax, don't forget that you can use `?save` for more information.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsave(<whatever you called the read csv file>, file = \"Where you would like to save the file with its name\")\n```\n:::\n\n\nCheck that you have an `rda` file where you save it. Now use `load()` with the file path to load the `rda` data here.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nload(file = \"Where you would like to save the file with its name\")\n```\n:::\n\n\nAt this point, if you think you loaded the file correctly, add `#| eval: false` to the code chunk where you loaded the `csv` file and back to the chunk where you saved the `rda` file.\n\nTake a glimpse at the data to make sure you loaded it correctly. This should be able to run with just the code chunk with your `load()` command.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(iat_2021_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 465,886\nColumns: 92\n$ session_id              <dbl> 2653543637, 2653543649, 2653543656, 2653543718…\n$ session_status          <chr> \" \", \" \", \"C\", \" \", \"C\", \"C\", \"C\", \" \", \" \", \"…\n$ study_name              <chr> \"Demo.Weight.0004\", \"Demo.Weight.0004\", \"Demo.…\n$ date                    <chr> \"1/1/2021 0:00:49\", \"1/1/2021 0:02:36\", \"1/1/2…\n$ month                   <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day                     <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ year                    <int> 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021…\n$ hour                    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1…\n$ weekday                 <int> 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6…\n$ birthmonth              <int> NA, 3, 1, NA, 1, 3, 5, NA, NA, 11, 4, 1, 4, 1,…\n$ birthyear               <int> NA, 1975, 1979, NA, 1972, 2002, 1943, NA, NA, …\n$ birthSex                <int> NA, 2, 2, NA, 2, 1, 2, NA, NA, 1, 2, 2, 1, 2, …\n$ genderIdentity          <chr> \" \", \"[2]\", \"[2]\", \" \", \"[2]\", \"[1]\", \"[2]\", \"…\n$ num_002                 <int> NA, 1, 1, NA, 1, 1, 2, NA, NA, 1, 1, 1, 4, 4, …\n$ ethnicityomb            <int> NA, 2, 2, NA, 2, 3, 2, NA, NA, 1, 2, 2, 2, 2, …\n$ raceomb_002             <int> NA, 6, 6, -999, 6, 5, 6, NA, NA, 6, 7, 5, 6, 5…\n$ raceombmulti            <chr> \" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \"…\n$ D_biep.Thin_Good_all    <dbl> NA, NA, -0.40210378, 0.51834547, 0.67850537, 0…\n$ Mn_RT_all_3467          <dbl> NA, NA, 864.4333, 911.1250, 1088.9833, 655.941…\n$ N_3467                  <int> NA, NA, 120, 120, 120, 120, 120, NA, NA, 120, …\n$ PCT_error_3467          <dbl> NA, NA, 7.500000, 5.000000, 2.500000, 7.500000…\n$ Order                   <int> NA, NA, 2, 1, 1, 2, 1, NA, NA, 2, 2, NA, 2, 1,…\n$ Side_Thin_34            <int> NA, NA, 1, 2, 2, 1, 2, NA, NA, 1, 1, NA, 1, 2,…\n$ Side_Good_34            <int> NA, NA, 2, 2, 2, 2, 2, NA, NA, 2, 2, NA, 2, 2,…\n$ Stimuli                 <int> NA, NA, 3, 3, 3, 3, 3, NA, NA, 3, 3, NA, 3, 3,…\n$ pct_300                 <dbl> NA, NA, 0.000000, 0.000000, 0.000000, 8.333333…\n$ pct_400                 <dbl> NA, NA, 0.8333333, 0.0000000, 0.0000000, 14.16…\n$ pct_2K                  <dbl> NA, NA, 0.8333333, 4.1666667, 7.5000000, 3.333…\n$ pct_3K                  <dbl> NA, NA, 0.8333333, 0.0000000, 0.8333333, 1.666…\n$ pct_4K                  <dbl> NA, NA, 0.0000000, 0.0000000, 0.0000000, 0.000…\n$ att7                    <int> NA, NA, 4, 4, 5, 4, 5, NA, NA, 6, 5, NA, 5, NA…\n$ tfat                    <int> NA, NA, 7, NA, 5, 5, 3, NA, NA, 6, 5, NA, 3, N…\n$ tthin                   <int> NA, NA, 7, NA, 5, 5, 5, NA, NA, 6, 7, NA, 7, N…\n$ comptomost_001          <int> NA, NA, 5, NA, 3, 4, 4, NA, NA, 5, 4, NA, 5, N…\n$ controlyou_001          <int> NA, NA, 3, NA, 2, 3, 3, NA, NA, 3, 2, NA, 2, N…\n$ controlother_001        <int> NA, NA, 3, NA, 3, 3, 3, NA, NA, 2, 2, NA, 3, N…\n$ easytolose_001          <int> NA, NA, 4, NA, 3, 3, 4, NA, NA, 3, 4, NA, 3, N…\n$ iam_001                 <int> NA, NA, 5, NA, 4, 4, 4, NA, NA, 6, 5, NA, 5, N…\n$ identfat_001            <int> NA, NA, 3, NA, 2, 3, 3, NA, NA, 2, 1, NA, 2, N…\n$ identthin_001           <int> NA, NA, 3, NA, 3, 3, 2, NA, NA, 2, 1, NA, 2, N…\n$ important_001           <int> NA, NA, 4, NA, 3, 3, 2, NA, NA, 4, 4, NA, 3, N…\n$ mostpref_001            <int> NA, NA, 6, NA, 4, 4, 6, NA, NA, 6, 6, NA, 6, N…\n$ othersay_001            <int> NA, NA, 4, NA, 4, 4, 4, NA, NA, 4, 4, NA, 5, N…\n$ D_biep.Thin_Good_36     <dbl> NA, NA, -0.65922173, 0.25492457, 0.85758482, 0…\n$ D_biep.Thin_Good_47     <dbl> NA, NA, -0.1449858, 0.7817664, 0.4994259, 0.36…\n$ Mn_RT_all_3             <dbl> NA, NA, 708.40, 773.70, 978.90, 911.90, 1192.6…\n$ Mn_RT_all_4             <dbl> NA, NA, 864.9500, 758.3750, 888.8000, 623.8250…\n$ Mn_RT_all_6             <dbl> NA, NA, 890.550, 860.350, 1510.250, 717.200, 2…\n$ Mn_RT_all_7             <dbl> NA, NA, 928.875, 1157.975, 1133.575, 529.450, …\n$ SD_all_3                <dbl> NA, NA, 262.0541, 303.0142, 472.6722, 805.6804…\n$ SD_all_4                <dbl> NA, NA, 537.2739, 317.2618, 569.8885, 296.7929…\n$ SD_all_6                <dbl> NA, NA, 265.6665, 376.0075, 644.9575, 438.7512…\n$ SD_all_7                <dbl> NA, NA, 320.9680, 588.8174, 362.0522, 213.2356…\n$ N_3                     <int> NA, NA, 20, 20, 20, 20, 20, NA, NA, 20, 20, NA…\n$ N_4                     <int> NA, NA, 20, 20, 20, 20, 20, NA, NA, 20, 20, NA…\n$ N_5                     <int> NA, NA, 28, 28, 28, 28, 28, NA, NA, 28, 28, NA…\n$ N_6                     <int> NA, NA, 20, 20, 20, 20, 20, NA, NA, 20, 20, NA…\n$ N_7                     <int> NA, NA, 40, 40, 40, 40, 40, NA, NA, 40, 40, NA…\n$ Mn_RT_correct_3         <dbl> NA, NA, 708.4000, 773.7000, 978.9000, 791.0526…\n$ Mn_RT_correct_4         <dbl> NA, NA, 708.8235, 745.5385, 809.2051, 601.8421…\n$ Mn_RT_correct_6         <dbl> NA, NA, 890.5500, 840.8947, 1487.1053, 661.176…\n$ Mn_RT_correct_7         <dbl> NA, NA, 872.3243, 1121.3333, 1114.1282, 501.05…\n$ SD_correct_3            <dbl> NA, NA, 262.0541, 303.0142, 472.6722, 613.9011…\n$ SD_correct_4            <dbl> NA, NA, 253.1620, 310.7078, 270.6234, 286.9534…\n$ SD_correct_6            <dbl> NA, NA, 265.6665, 375.8263, 654.0420, 446.9360…\n$ SD_correct_7            <dbl> NA, NA, 258.7414, 597.8491, 344.9726, 185.6936…\n$ N_ERROR_3               <int> NA, NA, 0, 0, 0, 1, 0, NA, NA, 1, 0, NA, 2, 0,…\n$ N_ERROR_4               <int> NA, NA, 6, 1, 1, 2, 0, NA, NA, 10, 3, NA, 1, 0…\n$ N_ERROR_6               <int> NA, NA, 0, 1, 1, 3, 1, NA, NA, 1, 2, NA, 2, 1,…\n$ N_ERROR_7               <int> NA, NA, 3, 4, 1, 3, 1, NA, NA, 5, 4, NA, 6, 4,…\n$ myweight_002            <int> NA, NA, 24, NA, 20, 32, 19, NA, NA, 34, 18, NA…\n$ myheight_002            <int> NA, NA, 36, NA, 34, 38, 33, NA, NA, 33, 30, NA…\n$ countrycit_num          <int> NA, 1, 85, NA, 1, 1, 1, NA, NA, 1, 105, 1, 1, …\n$ countryres_num          <int> NA, 1, 85, NA, 1, 1, 1, NA, NA, 1, 105, 1, 1, …\n$ edu                     <int> NA, 7, 7, NA, 9, 4, 11, NA, NA, 5, 11, 5, 13, …\n$ edu_14                  <int> NA, 7, 7, NA, 9, 4, 11, NA, NA, 5, 11, 5, 13, …\n$ occuSelf                <chr> \" \", \"11-\", \"43-\", \" \", \"2931\", \"15-\", \"2931\",…\n$ occuSelfDetail          <chr> \" \", \"1\", \"43-6000\", \" \", \"29-1000\", \"15-1000\"…\n$ politicalid_7           <int> NA, 6, 4, NA, 5, 4, 6, NA, NA, 5, 4, 5, 6, NA,…\n$ STATE                   <chr> \" \", \"NC\", \" \", \" \", \"NY\", \"NC\", \" \", \" \", \" \"…\n$ CountyNo                <int> NA, 129, NA, NA, 55, 105, NA, NA, NA, 37, NA, …\n$ MSANo                   <int> NA, 48900, NA, NA, 40380, 99032, NA, NA, NA, 3…\n$ MSAName                 <chr> \" \", \"Wilmington, NC MSA\", \" \", \" \", \"Rocheste…\n$ religion2014            <int> NA, 7, 2, NA, 7, 2, 1, NA, NA, 2, 6, 7, 7, 3, …\n$ religionid              <int> NA, 1, 2, NA, 1, 3, 2, NA, NA, 2, 3, 4, 2, 4, …\n$ iatevaluations001       <int> NA, NA, 4, NA, 3, 3, 3, NA, NA, 4, NA, NA, 3, …\n$ iatevaluations002       <int> NA, NA, 3, NA, 1, 3, 2, NA, NA, 2, NA, NA, 2, …\n$ iatevaluations003       <int> NA, NA, 3, NA, 3, 3, 2, NA, NA, 1, NA, NA, 2, …\n$ broughtwebsite          <chr> \" \", \" \", \"Mention or link at a non-news Inter…\n$ user_id                 <int> -1, -1, -1, -1, -1, -1, 11555672, -1, -1, -1, …\n$ previous_session_id     <dbl> NA, 2653543637, NA, 2653543685, NA, NA, 265354…\n$ previous_session_schema <chr> \" \", \"s\", \" \", \"s\", \" \", \" \", \"s\", \" \", \"s\", \"…\n```\n:::\n:::\n\n\nHow many rows and columns are in the dataset? Do you think we will need all these variables for our analysis?\n\n### 3. Data wrangling\n\nAs you go through this process, it is important that you look at the codebook for more information on each variable.\n\n#### 3.1 What's our target population?\n\nAs many of you mentioned in Lab 1, individuals taking the IAT test are not necessarily representative of the world population. I want you to articulate the target population that you think our analysis can give information about. To what population can we generalize our analysis results? We can get very specific with this population, but try to restrict your population to 3-5 characteristics.\n\nAfter you articulate the population, I want to add one more restriction to our population: US residency. The sample includes individuals residing in many different countries. Since we are discussing attitudes and beliefs that are connected to our society, I think it is important that we restrict our analysis and discussion to a country that we have some social experience in. Thus, let's restrict our data to the US only by filtering the variable `countryres` to category 1 (corresponding to the US).\n\n#### 3.1 Restrict your analysis to 1 outcome and 10 possible covariates/predictors\n\nWe are going to restrict our analysis to the single outcome, IAT score, which is named `D_biep.Thin_Good_all`.\n\nWe will also restrict our analysis to the following 10 potential variables so our work is a little more manageable.\n\nFrom the following 7 attitudes and beliefs, please select 3 that you think will be the most important variables related to your research question. In 1-2 lines, briefly explain why you chose each variable. This can be informal and bulleted.\n\n(Make sure you chose the variable that is part of your research question!)\n\n1.  Self-perception of weight (`iam_001`)\n2.  Fat group identity (`identfat_001` )\n3.  Thin group identity (`identthen_001` )\n4.  Controllability of weight of others (`controlother_001`)\n5.  Controllability of weight of yourself (`controlyou_001`)\n6.  Awareness of societal standards (`mostpref_001` )\n7.  Internalization of societal standards (`important_001`)\n\nWe will start our data exploration with the following 4 demographic variables:\n\n1.  Age\n2.  Race\n3.  Ethnicity\n4.  Gender\n\nYou may pick 3 additional variables to include in your analysis:\n\n1.  Education\n2.  Sex assigned at birth\n3.  Self-reported BMI\n4.  Political identity\n5.  Religion\n\nI have chosen these variables for a mixture of reasons. For example, I have left out variables about residence and occuptation because those variables have hundreds of categories that would be overwhelming in linear regression. For the 4 required demographic variables, I chose age because I really want us to get practice with a continuous variable. I chose race and ethnicity because of the intertwined history of racism and anti-fat bias in the Western countries (including the U.S. where most participants reside). Finally, I chose gender because diet culture has historically targeted genders in different ways.\n\nIf you would like to investigate a variable outside the list, please let me know by emailing or chatting with me.\n\nUsing R, select your identified variables from your dataset. Your new dataset should have 11 columns for the 11 variables.\n\n#### 3.1 Manipulating variables that are coded as numeric variables\n\n#### 3.2 Converting categorical variables to continuous variables\n\n#### 3.3 Make a new dataset with only complete cases\n\nQuickly make sure that we are not introducing bias by using complete cases\n\n### 4. Some exploratory data analysis\n\n4.1 Peek at your outcome\n\nThis serves as a check to make sure we are all looking at the correct outcome: IAT score. Please plot a histogram of the IAT scores.\n\n#### 4.1 Univariate exploratory data analysis\n\n#### 4.2 Bivariate exploratory data analysis\n\n#### 4.3 Multivariate exploratory data analysis\n\n### 5. Revisit your research question\n\nPlease restate the research question that you proposed in Lab 1. What are your thoughts on the research question now that we looked at the data?\n\n### 5. Make a Table 1\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}