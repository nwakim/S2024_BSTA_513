{
  "hash": "eea0a31ac266dfc3aeea4dbbc236d049",
  "result": {
    "markdown": "---\ntitle: \"Lesson 14: Model Building\"\nsubtitle: \"With an emphasis on prediction\"\nauthor: \"Nicky Wakim\"\ntitle-slide-attributes:\n    data-background-color: \"#C2352F\"\ndate: \"05/20/2024\"\nformat: \n  revealjs:\n    theme: \"../simple_NW.scss\"\n    chalkboard: true\n    slide-number: true\n    show-slide-number: all\n    width: 1955\n    height: 1100\n    footer: \"Lesson 14: Model Building\"\n    html-math-method: mathjax\n    highlight-style: ayu\nexecute:\n  echo: true\n  freeze: auto  # re-render only when source changes\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.5      ✔ rsample      1.2.1 \n✔ dials        1.2.1      ✔ tune         1.2.1 \n✔ infer        1.0.7      ✔ workflows    1.1.4 \n✔ modeldata    1.3.0      ✔ workflowsets 1.1.0 \n✔ parsnip      1.2.1      ✔ yardstick    1.3.1 \n✔ recipes      1.0.10     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidytext)\n#library(textrecipes)\nlibrary(here)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nhere() starts at /Users/wakim/Library/CloudStorage/OneDrive-OregonHealth&ScienceUniversity/Teaching/Classes/S2024_BSTA_513_613/S2024_BSTA_513\n```\n:::\n\n```{.r .cell-code}\nlibrary(aplore3)\n\ntheme_set(theme_minimal())\n\n\nmean_age = mean(glow500$age) %>% round()\nglow1 = glow500 %>% mutate(age_c = age - mean_age)\n```\n:::\n\n\n\n\n# Learning Objectives\n\n\n## Some important definitions\n\n-   **Model selection**: picking the \"best\" model from a set of possible models\n\n    -   Models will have the same outcome, but typically differ by the covariates that are included, their transformations, and their interactions\n\n \n\n-   **Model selection strategies**: a process or framework that helps us pick our \"best\" model\n\n    -   These strategies often differ by the approach and criteria used to the determine the \"best\" model\n\n \n\n-   **Overfitting**: result of fitting a model so closely to our *particular* sample data that it cannot be generalized to other samples (or the population)\n\n## Bias-variance trade off\n\n::: columns\n::: {.column width=\"50%\"}\n\n-   Recall from 512/612: MSE can be written as a function of the bias and variance\n\n    $$\n    MSE = \\text{bias}\\big(\\widehat\\beta\\big)^2 + \\text{variance}\\big(\\widehat\\beta\\big)\n    $$\n    \n    -   **We no longer use MSE in logistic regression to find the best fit model, BUT the idea between the bias and variance trade off holds!**\n\n-   For the same data:\n\n    -   More covariates in model: less bias, more variance\n    \n        -   Potential overfitting: with new data does our model still hold?\n\n    -   Less covariates in model: more bias, less variance\n\n:::\n\n::: {.column width=\"50%\"}\n[![Source: http://scott.fortmann-roe.com/docs/BiasVariance.html](images/biasvariance_tradeoff.png){width=\"1000\"}](http://scott.fortmann-roe.com/docs/BiasVariance.html)\n:::\n:::\n\n## The goals of association vs. prediction\n\n::: columns\n::: column\n::: definition\n::: def-title\nAssociation / Explanatory / One variable's effect\n:::\n\n::: def-cont\n-   **Goal:** Understand one variable's (or a group of variable's) effect on the response after adjusting for other factors\n\n-   Mainly interpret odds ratios of the variable that is the focus of the study\n\n:::\n:::\n:::\n\n::: column\n::: proposition\n::: prop-title\nPrediction\n:::\n\n::: prop-cont\n-   **Goal:** to calculate the most precise prediction of the response variable\n\n-   Interpreting coefficients is not important\n\n-   Choose only the variables that are strong predictors of the response variable\n\n    -   Excluding irrelevant variables can help reduce widths of the prediction intervals\n\n:::\n:::\n:::\n:::\n\n## Model selection strategies for *categorical* outcomes\n\n::: columns\n::: column\n::: definition\n::: def-title\nAssociation / Explanatory / One variable's effect\n:::\n\n::: def-cont\n-   Selection of potential models is tied more with the research context with some incorporation of prediction scores\n\n \n\n-   Pre-specification of multivariable model\n\n-   Purposeful model selection\n\n    -   \"Risk factor modeling\"\n\n-   Change in Estimate (CIE) approaches\n\n    -   Will learn in Survival Analysis (BSTA 514)\n:::\n:::\n:::\n\n::: column\n::: proposition\n::: prop-title\nPrediction\n:::\n\n::: prop-cont\n-   Selection of potential models is fully dependent on prediction scores\n\n \n\n-   Logistic regression with more refined model selection\n    \n    -   Regularization techniques (LASSO, Ridge, Elastic net)\n    \n-   Machine learning realm\n    \n    -   Decision trees, random forest, k-nearest neighbors, Neural networks\n:::\n:::\n:::\n:::\n\n## Before I move on...\n\n-   We CAN use purposeful selection from last quarter in **any** type of generalized linear model (GLM)\n\n    -   This includes logistic regression!\n    \n \n    \n-   The best documented information on purposeful selection is in the Hosmer-Lemeshow textbook on logistic regression\n\n    -   [Textbook in student files is linked here](https://ohsuitg-my.sharepoint.com/:b:/r/personal/wakim_ohsu_edu/Documents/Teaching/Classes/S2024_BSTA_513_613/Student_files/Textbooks/Hosmer_Applied_Logistic_Regression.pdf?csf=1&web=1&e=3tVxMV)\n    \n    -   Purposeful selection starts on page 89 (or page 101 in the pdf)\n\n \n\n-   I will not discuss purposeful selection in this course \n\n    -   Be aware that this is a tool that you can use in any regression!\n\n## Okay, so prediction of categorical outcomes\n\n-   **Classification:** process of predicting categorical responses/outcomes\n\n    -   Assigning a category outcome based on an observation's predictors\n    \n-   Common classification methods ([good site on brief explanation of each](https://www.mathworks.com/campaigns/offers/next/choosing-the-best-machine-learning-classification-model-and-avoiding-overfitting.html))\n\n    -   Logistic regression\n    -   Naive Bayes\n    -   k-Nearest Neighbor (KNN)\n    -   Decision Trees\n    -   Support Vector Machines (SVMs)\n    -   Neural Networks\n\n## Logistic regression is a classification method\n\n-   But to be a good classifier, our model needs to built a certain way\n     \n-   Prediction depends on type of variable/model selection! \n\n    -   This is when it can become machine learning\n    \n-   So the big question is: how do we select this model??\n    \n## Poll Everywhere Question 1\n\n## Overview of the process\n\n-   \n\n## Splitting data\n\n-   Let's keep this in context of the outcome\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(glow1, aes(x = fracture)) + geom_bar()\n```\n\n::: {.cell-output-display}\n![](15_Model_Building_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nglow = glow1 %>%\n    dplyr::select(-sub_id, -site_id, -phy_id, -age)\n```\n:::\n\n\n\n## Splitting data\n\n-   Want to split our data into training and testing sets\n-   Stratify by fracture: because we have imbalanced data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_split = initial_split(glow, strata = fracture)\nglow_split\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<Training/Testing/Total>\n<374/126/500>\n```\n:::\n\n```{.r .cell-code}\nglow_train = training(glow_split)\nglow_test = testing(glow_split)\n```\n:::\n\n\n\n## Fitting the logistic regression model\n\n-   Use Lasso\n\n[Lasso with interactions!!](https://strakaps.github.io/post/glinternet/) Using interactions??\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_mod = logistic_reg(penalty = 0.001, mixture = 1) %>%\n            set_engine(\"glmnet\")\n```\n:::\n\n\n\n## build recipe??\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_rec = recipe(fracture ~ ., data = glow_train) %>%\n  step_dummy(priorfrac, premeno, momfrac, armassist, smoke, raterisk) \n\nglow_workflow = workflow() %>%\n      add_model(lasso_mod) %>% add_recipe(glow_rec)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_folds = vfold_cv(glow_train, v = 5, strata = fracture)\n\nglow_fit_rs = glow_workflow %>% \n      fit_resamples(glow_folds, control = control_resamples(save_pred=T))\n\nglow_train_metrics = collect_metrics(glow_fit_rs)\nglow_train_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 6\n  .metric     .estimator  mean     n std_err .config             \n  <chr>       <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy    binary     0.733     5 0.00744 Preprocessor1_Model1\n2 brier_class binary     0.185     5 0.00380 Preprocessor1_Model1\n3 roc_auc     binary     0.639     5 0.0220  Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\nglow_train_pred = collect_predictions(glow_fit_rs)\n\nglow_train_pred %>%\n    group_by(id) %>%\n    roc_curve(truth = fracture, .pred_No) %>%\n    autoplot()\n```\n\n::: {.cell-output-display}\n![](15_Model_Building_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nglow_fit = glow_workflow %>% fit(data = glow_train)\n\nglow_test_pred = predict(glow_fit, new_data = glow_test, type = \"prob\") %>%\n    bind_cols(glow_test)\n\nglow_test_pred %>% \n    roc_curve(truth = fracture, .pred_No) %>%\n    autoplot()\n```\n\n::: {.cell-output-display}\n![](15_Model_Building_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n\n```{.r .cell-code}\nglow_test_pred %>% \n    roc_auc(truth = fracture, .pred_No)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.690\n```\n:::\n\n```{.r .cell-code}\nglow_test_pred %>% filter(fracture == \"No\", .pred_Yes > 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 14\n  .pred_No .pred_Yes priorfrac weight height   bmi premeno momfrac armassist\n     <dbl>     <dbl> <fct>      <dbl>  <int> <dbl> <fct>   <fct>   <fct>    \n1    0.429     0.571 Yes         79.4    163  29.9 No      No      Yes      \n2    0.379     0.621 Yes         59      153  25.2 No      No      Yes      \n3    0.393     0.607 Yes         55.3    152  23.9 No      No      Yes      \n# ℹ 5 more variables: smoke <fct>, raterisk <fct>, fracscore <int>,\n#   fracture <fct>, age_c <dbl>\n```\n:::\n\n```{.r .cell-code}\nglow_test_pred %>% filter(fracture == \"Yes\", .pred_No > 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 24 × 14\n   .pred_No .pred_Yes priorfrac weight height   bmi premeno momfrac armassist\n      <dbl>     <dbl> <fct>      <dbl>  <int> <dbl> <fct>   <fct>   <fct>    \n 1    0.816     0.184 Yes         94.3    173  31.5 No      No      Yes      \n 2    0.596     0.404 No          60.3    148  27.5 Yes     No      Yes      \n 3    0.792     0.208 No          64.9    160  25.4 No      No      Yes      \n 4    0.844     0.156 No          55.3    158  22.2 No      No      No       \n 5    0.708     0.292 No          46.3    158  18.5 No      No      No       \n 6    0.676     0.324 No          59.9    160  23.4 Yes     No      Yes      \n 7    0.722     0.278 No          63.5    155  26.4 Yes     Yes     No       \n 8    0.866     0.134 No          59      160  23.0 No      No      No       \n 9    0.521     0.479 Yes         68      160  26.6 Yes     Yes     No       \n10    0.627     0.373 No          50.8    152  22.0 No      No      Yes      \n# ℹ 14 more rows\n# ℹ 5 more variables: smoke <fct>, raterisk <fct>, fracscore <int>,\n#   fracture <fct>, age_c <dbl>\n```\n:::\n:::\n\n\n\n\n## Other stufs\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vip)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'vip'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:utils':\n\n    vi\n```\n:::\n\n```{.r .cell-code}\nvi_data = glow_workflow %>% \n    fit(glow_train) %>%\n    pull_workflow_fit() %>%\n    vi(lambda = 0.001) %>%\n    filter(Importance != 0)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `pull_workflow_fit()` was deprecated in workflows 0.2.3.\nℹ Please use `extract_fit_parsnip()` instead.\n```\n:::\n:::\n\n\n\n\n\n\n## hfnekl\n\nhttps://github.com/tidyverse/datascience-box/tree/main/course-materials/_slides/u4-d07-prediction-overfitting\n\nhttps://datasciencebox.org/02-making-rigorous-conclusions",
    "supporting": [
      "15_Model_Building_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}