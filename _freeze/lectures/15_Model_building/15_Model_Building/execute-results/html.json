{
  "hash": "78d428c1a8e8195555a0801d02efb481",
  "result": {
    "markdown": "---\ntitle: \"Lesson 15: Model Building\"\nsubtitle: \"With an emphasis on prediction\"\nauthor: \"Nicky Wakim\"\ntitle-slide-attributes:\n    data-background-color: \"#C2352F\"\ndate: \"05/22/2024\"\nformat: \n  revealjs:\n    theme: \"../simple_NW.scss\"\n    chalkboard: true\n    slide-number: true\n    show-slide-number: all\n    width: 1955\n    height: 1100\n    footer: \"Lesson 15: Model Building\"\n    html-math-method: mathjax\n    highlight-style: ayu\nexecute:\n  echo: true\n  freeze: auto  # re-render only when source changes\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n:::\n\n\n# Learning Objectives\n\n1. Understand the place of LASSO regression within association and prediction modeling for binary outcomes.\n\n2. Recognize the process for `tidymodels`\n\n3. Understand how penalized regression is a form of model/variable selection.\n\n4. Perform LASSO regression on a dataset using R and the general process for classification methods.\n\n\n::: {.cell}\n<style type=\"text/css\">\n.reveal code {\n  max-height: 80% !important;\n}\n</style>\n:::\n\n\n# Learning Objectives\n\n::: lob\n1. Understand the place of LASSO regression within association and prediction modeling for binary outcomes.\n:::\n\n2. Recognize the process for `tidymodels`\n\n3. Understand how penalized regression is a form of model/variable selection.\n\n4. Perform LASSO regression on a dataset using R and the general process for classification methods.\n\n## Some important definitions\n\n-   **Model selection**: picking the \"best\" model from a set of possible models\n\n    -   Models will have the same outcome, but typically differ by the covariates that are included, their transformations, and their interactions\n\n    -   \"Best\" model is defined by the research question and by how you want to answer it!\n\n \n\n-   **Model selection strategies**: a process or framework that helps us pick our \"best\" model\n\n    -   These strategies often differ by the approach and criteria used to the determine the \"best\" model\n\n \n\n-   **Overfitting**: result of fitting a model so closely to our *particular* sample data that it cannot be generalized to other samples (or the population)\n\n## Bias-variance trade off\n\n::: columns\n::: {.column width=\"50%\"}\n-   Recall from 512/612: MSE can be written as a function of the bias and variance\n\n    $$\n    MSE = \\text{bias}\\big(\\widehat\\beta\\big)^2 + \\text{variance}\\big(\\widehat\\beta\\big)\n    $$\n\n    -   **We no longer use MSE in logistic regression to find the best fit model, BUT the idea between the bias and variance trade off holds!**\n\n-   For the same data:\n\n    -   More covariates in model: less bias, more variance\n\n        -   Potential overfitting: with new data does our model still hold?\n\n    -   Less covariates in model: more bias, less variance\n\n        -   More bias bc more likely that were are not capturing the true underlying relationship with less variables\n:::\n\n::: {.column width=\"50%\"}\n[![Source: http://scott.fortmann-roe.com/docs/BiasVariance.html](images/biasvariance_tradeoff.png){width=\"1000\"}](http://scott.fortmann-roe.com/docs/BiasVariance.html)\n:::\n:::\n\n## The goals of association vs. prediction\n\n::: columns\n::: column\n::: definition\n::: def-title\nAssociation / Explanatory / One variable's effect\n:::\n\n::: def-cont\n-   **Goal:** Understand one variable's (or a group of variable's) effect on the response after adjusting for other factors\n\n-   Mainly interpret odds ratios of the variable that is the focus of the study\n:::\n:::\n:::\n\n::: column\n::: proposition\n::: prop-title\nPrediction\n:::\n\n::: prop-cont\n-   **Goal:** to calculate the most precise prediction of the response variable\n\n-   Interpreting coefficients is not important\n\n-   Choose only the variables that are strong predictors of the response variable\n\n    -   Excluding irrelevant variables can help reduce widths of the prediction intervals\n:::\n:::\n:::\n:::\n\n## Model selection strategies for *categorical* outcomes\n\n::: columns\n::: column\n::: definition\n::: def-title\nAssociation / Explanatory / One variable's effect\n:::\n\n::: def-cont\n-   Selection of potential models is tied more with the research context with some incorporation of prediction scores\n\n \n\n-   Pre-specification of multivariable model\n\n-   Purposeful model selection\n\n    -   \"Risk factor modeling\"\n\n-   Change in Estimate (CIE) approaches\n\n    -   Will learn in Survival Analysis (BSTA 514)\n:::\n:::\n:::\n\n::: column\n::: proposition\n::: prop-title\nPrediction\n:::\n\n::: prop-cont\n-   Selection of potential models is fully dependent on prediction scores\n\n \n\n-   Logistic regression with more refined model selection\n\n    -   Regularization techniques (LASSO, Ridge, Elastic net)\n\n-   Machine learning realm\n\n    -   Decision trees, random forest, k-nearest neighbors, Neural networks\n:::\n:::\n:::\n:::\n\n## Before I move on...\n\n-   We CAN use purposeful selection from last quarter in **any** type of generalized linear model (GLM)\n\n    -   This includes logistic regression!\n\n \n\n-   The best documented information on purposeful selection is in the Hosmer-Lemeshow textbook on logistic regression\n\n    -   [Textbook in student files is linked here](https://ohsuitg-my.sharepoint.com/:b:/r/personal/wakim_ohsu_edu/Documents/Teaching/Classes/S2024_BSTA_513_613/Student_files/Textbooks/Hosmer_Applied_Logistic_Regression.pdf?csf=1&web=1&e=3tVxMV)\n\n    -   Purposeful selection starts on page 89 (or page 101 in the pdf)\n\n \n\n-   I will not discuss purposeful selection in this course\n\n    -   Be aware that this is a tool that you can use in any regression!\n\n## Okay, so prediction of categorical outcomes\n\n-   **Classification:** process of predicting categorical responses/outcomes\n\n    -   Assigning a category outcome based on an observation's predictors\n\n \n\n-   Note: we've already done a lot of work around predicting probabilities within logistic regression\n\n    -   Can we take those predicted probabilities one step further to predict the binary outcome??\n\n \n\n-   Common classification methods ([good site on brief explanation of each](https://www.mathworks.com/campaigns/offers/next/choosing-the-best-machine-learning-classification-model-and-avoiding-overfitting.html))\n\n    -   Logistic regression\n    -   Naive Bayes\n    -   k-Nearest Neighbor (KNN)\n    -   Decision Trees\n    -   Support Vector Machines (SVMs)\n    -   Neural Networks\n\n## Logistic regression is a classification method\n\n-   But to be a good classifier, our logistic regression model needs to built a certain way\n\n \n\n-   Prediction depends on type of variable/model selection!\n\n    -   This is when it can become machine learning\n\n \n\n-   So the big question is: how do we select this model??\n\n    -   Regularized techniques, aka penalized regression\n\n## Poll Everywhere Question 1\n\n# Learning Objectives\n\n1. Understand the place of LASSO regression within association and prediction modeling for binary outcomes.\n\n::: lob\n2. Recognize the process for `tidymodels`\n:::\n\n3. Understand how penalized regression is a form of model/variable selection.\n\n4. Perform LASSO regression on a dataset using R and the general process for classification methods.\n\n## Before I get really into things!!\n\n-   `tidymodels` is a great package when we are performing prediction\n\n-   One problem: it uses very different syntax for model fitting than we are used to...\n\n-   `tidymodels` syntax dictates that we need to define:\n\n    -   A model \n    -   A recipe\n    -   A workflow\n\n## `tidymodels` with GLOW\n\nTo fit our logistic regression model with the interaction between age and prior fracture, we use:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model\nmodel = logistic_reg()\n# recipe\nrecipe = recipe(fracture ~ priorfrac + age_c, data = glow1) %>%\n            step_dummy(priorfrac) %>%\n            step_interact(terms = ~ age_c:starts_with(\"priorfrac\"))\n# workflow\nworkflow = workflow() %>% add_model(model) %>% add_recipe(recipe)\n\nfit = workflow %>% fit(data = glow1)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div id=\"acjsoapsxa\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#acjsoapsxa table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#acjsoapsxa thead, #acjsoapsxa tbody, #acjsoapsxa tfoot, #acjsoapsxa tr, #acjsoapsxa td, #acjsoapsxa th {\n  border-style: none;\n}\n\n#acjsoapsxa p {\n  margin: 0;\n  padding: 0;\n}\n\n#acjsoapsxa .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 35px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#acjsoapsxa .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#acjsoapsxa .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#acjsoapsxa .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#acjsoapsxa .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#acjsoapsxa .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#acjsoapsxa .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#acjsoapsxa .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#acjsoapsxa .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#acjsoapsxa .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#acjsoapsxa .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#acjsoapsxa .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#acjsoapsxa .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#acjsoapsxa .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#acjsoapsxa .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#acjsoapsxa .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#acjsoapsxa .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#acjsoapsxa .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#acjsoapsxa .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#acjsoapsxa .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#acjsoapsxa .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#acjsoapsxa .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#acjsoapsxa .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#acjsoapsxa .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#acjsoapsxa .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#acjsoapsxa .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#acjsoapsxa .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#acjsoapsxa .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#acjsoapsxa .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#acjsoapsxa .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#acjsoapsxa .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#acjsoapsxa .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#acjsoapsxa .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#acjsoapsxa .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#acjsoapsxa .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#acjsoapsxa .gt_left {\n  text-align: left;\n}\n\n#acjsoapsxa .gt_center {\n  text-align: center;\n}\n\n#acjsoapsxa .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#acjsoapsxa .gt_font_normal {\n  font-weight: normal;\n}\n\n#acjsoapsxa .gt_font_bold {\n  font-weight: bold;\n}\n\n#acjsoapsxa .gt_font_italic {\n  font-style: italic;\n}\n\n#acjsoapsxa .gt_super {\n  font-size: 65%;\n}\n\n#acjsoapsxa .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#acjsoapsxa .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#acjsoapsxa .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#acjsoapsxa .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#acjsoapsxa .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#acjsoapsxa .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#acjsoapsxa .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"term\">term</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"estimate\">estimate</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"std.error\">std.error</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"statistic\">statistic</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"p.value\">p.value</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"conf.low\">conf.low</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"conf.high\">conf.high</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">(Intercept)</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">−1.376</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">0.134</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">−10.270</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.000</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">−1.646</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">−1.120</td></tr>\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">age_c</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">0.063</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">0.015</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">4.043</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.000</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">0.032</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">0.093</td></tr>\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">priorfrac_Yes</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">1.002</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">0.240</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">4.184</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.000</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">0.530</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">1.471</td></tr>\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">age_c_x_priorfrac_Yes</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">−0.057</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">0.025</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">−2.294</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.022</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">−0.107</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">−0.008</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n## Same as results from previous lessons\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_m3 = glm(fracture ~ priorfrac + age_c + priorfrac*age_c, \n              data = glow1, family = binomial)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(glow_m3, conf.int = T) %>% gt() %>% \n  tab_options(table.font.size = 35) %>%\n  fmt_number(decimals = 3)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"uufcqkxros\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#uufcqkxros table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#uufcqkxros thead, #uufcqkxros tbody, #uufcqkxros tfoot, #uufcqkxros tr, #uufcqkxros td, #uufcqkxros th {\n  border-style: none;\n}\n\n#uufcqkxros p {\n  margin: 0;\n  padding: 0;\n}\n\n#uufcqkxros .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 35px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#uufcqkxros .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#uufcqkxros .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#uufcqkxros .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#uufcqkxros .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#uufcqkxros .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#uufcqkxros .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#uufcqkxros .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#uufcqkxros .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#uufcqkxros .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#uufcqkxros .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#uufcqkxros .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#uufcqkxros .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#uufcqkxros .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#uufcqkxros .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#uufcqkxros .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#uufcqkxros .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#uufcqkxros .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#uufcqkxros .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#uufcqkxros .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#uufcqkxros .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#uufcqkxros .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#uufcqkxros .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#uufcqkxros .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#uufcqkxros .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#uufcqkxros .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#uufcqkxros .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#uufcqkxros .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#uufcqkxros .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#uufcqkxros .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#uufcqkxros .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#uufcqkxros .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#uufcqkxros .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#uufcqkxros .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#uufcqkxros .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#uufcqkxros .gt_left {\n  text-align: left;\n}\n\n#uufcqkxros .gt_center {\n  text-align: center;\n}\n\n#uufcqkxros .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#uufcqkxros .gt_font_normal {\n  font-weight: normal;\n}\n\n#uufcqkxros .gt_font_bold {\n  font-weight: bold;\n}\n\n#uufcqkxros .gt_font_italic {\n  font-style: italic;\n}\n\n#uufcqkxros .gt_super {\n  font-size: 65%;\n}\n\n#uufcqkxros .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#uufcqkxros .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#uufcqkxros .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#uufcqkxros .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#uufcqkxros .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#uufcqkxros .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#uufcqkxros .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"term\">term</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"estimate\">estimate</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"std.error\">std.error</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"statistic\">statistic</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"p.value\">p.value</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"conf.low\">conf.low</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"conf.high\">conf.high</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">(Intercept)</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">−1.376</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">0.134</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">−10.270</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.000</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">−1.646</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">−1.120</td></tr>\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">priorfracYes</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">1.002</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">0.240</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">4.184</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.000</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">0.530</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">1.471</td></tr>\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">age_c</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">0.063</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">0.015</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">4.043</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.000</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">0.032</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">0.093</td></tr>\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">priorfracYes:age_c</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">−0.057</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">0.025</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">−2.294</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.022</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">−0.107</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">−0.008</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n[**Interaction model: **]{style=\"color:#70AD47\"} $$\\begin{aligned} \\text{logit}\\left(\\widehat\\pi(\\mathbf{X})\\right) & = \\widehat\\beta_0 &+ &\\widehat\\beta_1\\cdot I(\\text{PF}) & + &\\widehat\\beta_2\\cdot Age& + &\\widehat\\beta_3 \\cdot I(\\text{PF}) \\cdot Age \\\\  \n\\text{logit}\\left(\\widehat\\pi(\\mathbf{X})\\right) & = -1.376 &+ &1.002\\cdot I(\\text{PF})& + &0.063\\cdot Age& -&0.057 \\cdot I(\\text{PF}) \\cdot Age\n\\end{aligned}$$\n\n-   Reminder of main effects and interactions\n\n# Learning Objectives\n\n1. Understand the place of LASSO regression within association and prediction modeling for binary outcomes.\n\n2. Recognize the process for `tidymodels`\n\n::: lob\n3. Understand how penalized regression is a form of model/variable selection.\n:::\n\n4. Perform LASSO regression on a dataset using R and the general process for classification methods.\n\n## Penalized regression\n\n-   **Basic idea:** We are running regression, but now we want to **incentivize our model fit to have less predictors**\n\n    -   Include a **penalty to discourage too many predictors** in the model\n\n \n\n-   Also known as *shrinkage* or *regularization* methods\n\n \n\n-   Penalty will reduce coefficient values to zero (or close to zero) if the predictor does not contribute much information to predicting our outcome\n\n \n\n-   We need a tuning parameter that determines the amount of shrinkage called lambda/$\\lambda$\n\n    -   How much do we want to penalize additional predictors?\n\n## Poll Everywhere Question 2\n\n\n## Three types of penalized regression\n\nMain difference is the type of penalty used\n\n::: columns\n\n::: {.column width=\"33%\"}\n\n::: proposition\n::: prop-title\nRidge regression\n:::\n::: prop-cont\n- Penalty called L2 norm, uses sqaured values\n\n- Pros\n  - Reduces overfitting\n  - Handles $p>n$\n  - Handles collinearity\n\n- Cons\n  - Does not shrink coefficients to 0\n  - Difficult to interpret\n\n:::\n\n:::\n\n:::\n\n::: {.column width=\"33%\"}\n\n::: axiom\n::: axiom-title\nLasso regression\n:::\n::: axiom-cont\n- Penalty called L1 norm, uses absolute values\n\n \n\n- Pros\n  - Reduces overfitting\n  - Shrinks coefficients to 0\n\n- Cons\n  - Cannot handle $p>n$\n  - Does not handle multicollinearity well\n\n:::\n:::\n\n:::\n\n::: {.column width=\"33%\"}\n\n::: proof1\n::: proof-title\nElastic net regression\n:::\n::: proof-cont\n- L1 and L2 used, best of both worlds\n\n- Pros\n  - Reduces overfitting\n  - Handles $p>n$\n  - Handles collinearity\n  - Shrinks coefficients to 0\n  \n- Cons \n  - More difficult to do than other two\n:::\n:::\n\n:::\n\n:::\n\n# Learning Objectives\n\n1. Understand the place of LASSO regression within association and prediction modeling for binary outcomes.\n\n2. Recognize the process for `tidymodels`\n\n3. Understand how penalized regression is a form of model/variable selection.\n\n::: lob\n4. Perform LASSO regression on a dataset using R and the general process for classification methods.\n:::\n\n## Overview of the process\n\n1.  Split data into training and testing datasets\n\n \n\n2.  Perform our classification method on training set\n\n    -   This is where we will use penalized regression!\n\n \n\n3.  Measure predictive accuracy on testing set\n\n\n\n## Example to be used: GLOW Study\n\n-   From GLOW (Global Longitudinal Study of Osteoporosis in Women) study\n\n \n\n-   **Outcome variable:** any fracture in the first year of follow up (FRACTURE: 0 or 1)\n\n \n\n-   ~~**Risk factor/variable of interest:** history of prior fracture (PRIORFRAC: 0 or 1)~~\n\n-   ~~**Potential confounder or effect modifier:** age (AGE, a continuous variable)~~\n\n    -   ~~Center age will be used! We will center around the rounded mean age of 69 years old~~\n\n \n   \n-   Crossed out because we are no longer attached to specific predictors and their association with fracture\n\n    -   Focused on **predicting fracture with whatever variables we can!**\n\n\n\n## Step 1: Splitting data\n\n-   **Training:** act of creating our prediction model based on our observed data\n\n    -   Supervised: Means we keep information on our outcome while training\n\n \n\n-   **Testing:** act of measuring the predictive accuracy of our model by trying it out on *new* data\n\n \n\n-   When we use data to create a prediction model, we want to test our prediction model on *new* data\n\n    -   Helps make sure prediction model can be applied to other data **outside of the data that was used to create it!**\n\n \n\n-   So an important first step in prediction modeling is to *split our data* into a **training set** and a **testing set**!\n\n## Step 1: Splitting data\n\n::: columns\n::: column\n::: definition\n::: def-title\nTraining set\n:::\n\n::: def-cont\n-   Sandbox for model building\n-   Spend most of your time using the training set to develop the model\n-   Majority of the data (usually 80%)\n:::\n:::\n:::\n\n::: column\n::: theorem\n::: thm-title\nTesting set\n:::\n\n::: thm-cont\n-   Held in reserve to determine efficacy of one or two chosen models\n-   Critical to look at it once at the end, otherwise it becomes part of the modeling process\n-   Remainder of the data (usually 20%)\n:::\n:::\n:::\n:::\n\n     \n\n \n\n-   Slide content from [Data Science in a Box](https://datasciencebox.org/02-making-rigorous-conclusions)\n\n## Poll Everywhere Question 3\n\n## Step 1: Splitting data\n\n-   When splitting data, we need to be conscious of the proportions of our outcomes\n\n    -   Is there imbalance within our outcome?\n\n    -   We want to randomly select observations but make sure the proportions of No and Yes stay the same\n    -   We **stratify** by the outcome, meaning we pick Yes's and No's separately for the training set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(glow1, aes(x = fracture)) + geom_bar()\n```\n\n::: {.cell-output-display}\n![](15_Model_Building_files/figure-revealjs/unnamed-chunk-7-1.png){width=288}\n:::\n:::\n\n\n-   Side note: took out `bmi` and `weight` bc we have multicollinearity issues\n\n    -   Combo of I hate these variables and my previous work in the LASSO identified these as not important\n    \n\n::: {.cell}\n\n```{.r .cell-code}\nglow = glow1 %>%\n    dplyr::select(-sub_id, -site_id, -phy_id, -age, -bmi, -weight)\n```\n:::\n\n\n## Step 1: Splitting data\n\n-   From package `rsample` within `tidyverse`, we can use `initial_split()` to create training and testing data\n\n    -   Use `strata` to stratify by fracture\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_split = initial_split(glow, strata = fracture, prop = 0.8)\nglow_split\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<Training/Testing/Total>\n<400/100/500>\n```\n:::\n:::\n\n\n-   Then we can pull the training and testing data into their own datasets\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_train = training(glow_split)\nglow_test = testing(glow_split)\n```\n:::\n\n\n## Step 1: Splitting data: peek at the split {.smaller}\n\n::: columns\n::: column\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(glow_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 400\nColumns: 10\n$ priorfrac <fct> No, No, Yes, No, No, Yes, No, Yes, Yes, No, No, No, No, No, …\n$ height    <int> 158, 160, 157, 160, 152, 161, 150, 153, 156, 166, 153, 160, …\n$ premeno   <fct> No, No, No, No, No, No, No, No, No, No, No, Yes, No, No, No,…\n$ momfrac   <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, No, No, No, No…\n$ armassist <fct> No, No, Yes, No, No, No, No, No, No, No, No, No, Yes, No, No…\n$ smoke     <fct> No, No, No, No, No, Yes, No, No, No, No, Yes, No, No, No, No…\n$ raterisk  <fct> Same, Same, Less, Less, Same, Same, Less, Same, Same, Less, …\n$ fracscore <int> 1, 2, 11, 5, 1, 4, 6, 7, 7, 0, 4, 1, 4, 2, 2, 7, 2, 1, 4, 5,…\n$ fracture  <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ age_c     <dbl> -7, -4, 19, 13, -8, -2, 15, 13, 17, -11, -2, -5, -1, -2, 0, …\n```\n:::\n:::\n\n\n:::\n::: column\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(glow_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 100\nColumns: 10\n$ priorfrac <fct> No, No, No, No, No, No, No, No, Yes, Yes, No, No, No, No, No…\n$ height    <int> 167, 162, 165, 158, 153, 170, 154, 171, 142, 152, 166, 154, …\n$ premeno   <fct> No, No, No, Yes, No, Yes, Yes, Yes, Yes, No, No, No, No, No,…\n$ momfrac   <fct> No, No, No, No, No, Yes, No, No, Yes, No, No, No, No, No, No…\n$ armassist <fct> Yes, No, Yes, No, Yes, No, Yes, No, No, No, No, No, No, No, …\n$ smoke     <fct> Yes, Yes, No, No, No, No, No, No, No, No, No, No, No, No, No…\n$ raterisk  <fct> Same, Less, Less, Greater, Same, Same, Same, Same, Same, Sam…\n$ fracscore <int> 3, 1, 5, 1, 8, 3, 7, 1, 6, 7, 0, 2, 0, 0, 1, 2, 2, 8, 4, 3, …\n$ fracture  <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ age_c     <dbl> -13, -10, 3, -8, 17, 0, 6, -5, 1, 17, -11, -6, -10, -12, -6,…\n```\n:::\n:::\n\n:::\n:::\n\n## Step 2: Fit LASSO penalized logistic regression model\n\n-   Using Lasso penalized regression!\n\n-   We can simply set up a penalized regression model\n\n \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_mod = logistic_reg(penalty = 0.001, mixture = 1) %>%\n\n            set_engine(\"glmnet\")\n```\n:::\n\n\n-   `glmnet` takes the basic fitting of `glm` and adds penalties! \n\n    -   In `tidymodels` we set an engine that will fit the model\n    \n-   `mixture` option let's us pick the penalty\n\n    -   `mixture = 0` for Ridge regression\n    -   `mixture = 1` for Lasso regression\n    -   `0 < mixture < 1` for Elastic net regression\n\n## Step 2: Fit LASSO: Main effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_rec_main = recipe(fracture ~ ., data = glow_train) %>%\n\n  step_dummy(priorfrac, premeno, momfrac, armassist, smoke, raterisk)\n\nglow_workflow_main = workflow() %>%\n\n      add_model(lasso_mod) %>% add_recipe(glow_rec_main)\n  \nglow_fit_main = glow_workflow_main %>% fit(glow_train)\n```\n:::\n\n\n## Step 2: Fit LASSO: Main effects: Identify variables\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vip)  \nvi_data_main = glow_fit_main %>% \n    pull_workflow_fit() %>%\n    vi(lambda = 0.001) %>%\n    filter(Importance != 0)\nvi_data_main\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 × 3\n  Variable         Importance Sign \n  <chr>                 <dbl> <chr>\n1 raterisk_Greater     0.559  POS  \n2 momfrac_Yes          0.542  POS  \n3 priorfrac_Yes        0.493  POS  \n4 raterisk_Same        0.438  POS  \n5 smoke_Yes            0.376  NEG  \n6 premeno_Yes          0.285  POS  \n7 fracscore            0.197  POS  \n8 armassist_Yes        0.146  POS  \n9 height               0.0382 NEG  \n```\n:::\n:::\n\n\n- Looks like age is removed!\n\n## Step 2: Fit LASSO: Main effects + interactions\n\n-   We want to include interactions in our regression \n-   The main effect model will be our starting point\n    -   Otherwise, we may drop main effects but not their interactions\n    -   Cannot do that: see [hierarchy principle](http://www.feat.engineering/interactions-guiding-principles)\n    \n-   I remove `age_c` from this section because main effects did not include it\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_rec_int = recipe(fracture ~ ., data = glow_train) %>%\n  update_role(age_c, new_role = \"dont_use\") %>%\n\n  step_dummy(priorfrac, premeno, momfrac, armassist, smoke, raterisk) %>%\n\n  step_interact(terms = ~ all_predictors():all_predictors())\n\nglow_workflow_int = workflow() %>%\n      add_model(lasso_mod) %>% add_recipe(glow_rec_int)\n  \nglow_fit_int = glow_workflow_int %>% fit(glow_train)\n```\n:::\n\n\n## Step 2: Fit LASSO: Identify interactions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvi_data_int = glow_fit_int %>%\n    pull_workflow_fit() %>%\n    vi(lambda = 0.001) %>%\n    filter(Importance != 0)\nvi_data_int\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 34 × 3\n   Variable                       Importance Sign \n   <chr>                               <dbl> <chr>\n 1 smoke_Yes                            4.29 NEG  \n 2 smoke_Yes_x_raterisk_Greater         3.89 POS  \n 3 smoke_Yes_x_raterisk_Same            3.14 POS  \n 4 premeno_Yes_x_smoke_Yes              3.00 NEG  \n 5 momfrac_Yes_x_armassist_Yes          2.82 NEG  \n 6 priorfrac_Yes_x_premeno_Yes          2.50 NEG  \n 7 priorfrac_Yes                        1.82 POS  \n 8 armassist_Yes_x_smoke_Yes            1.44 POS  \n 9 premeno_Yes_x_raterisk_Greater       1.31 POS  \n10 momfrac_Yes_x_smoke_Yes              1.17 POS  \n# ℹ 24 more rows\n```\n:::\n:::\n\n\n- This is where things got a little annoying for me...\n\n## Step 2: Fit LASSO: Identify interactions\n\n- I combed through the column names of the results to find the interactions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvi_data_int$Variable\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"smoke_Yes\"                        \"smoke_Yes_x_raterisk_Greater\"    \n [3] \"smoke_Yes_x_raterisk_Same\"        \"premeno_Yes_x_smoke_Yes\"         \n [5] \"momfrac_Yes_x_armassist_Yes\"      \"priorfrac_Yes_x_premeno_Yes\"     \n [7] \"priorfrac_Yes\"                    \"armassist_Yes_x_smoke_Yes\"       \n [9] \"premeno_Yes_x_raterisk_Greater\"   \"momfrac_Yes_x_smoke_Yes\"         \n[11] \"priorfrac_Yes_x_momfrac_Yes\"      \"priorfrac_Yes_x_armassist_Yes\"   \n[13] \"premeno_Yes_x_armassist_Yes\"      \"momfrac_Yes_x_raterisk_Same\"     \n[15] \"priorfrac_Yes_x_raterisk_Greater\" \"armassist_Yes_x_raterisk_Greater\"\n[17] \"fracscore_x_momfrac_Yes\"          \"priorfrac_Yes_x_smoke_Yes\"       \n[19] \"premeno_Yes_x_raterisk_Same\"      \"fracscore_x_priorfrac_Yes\"       \n[21] \"fracscore_x_premeno_Yes\"          \"raterisk_Same\"                   \n[23] \"fracscore\"                        \"fracscore_x_raterisk_Greater\"    \n[25] \"armassist_Yes_x_raterisk_Same\"    \"fracscore_x_smoke_Yes\"           \n[27] \"height\"                           \"momfrac_Yes_x_raterisk_Greater\"  \n[29] \"priorfrac_Yes_x_raterisk_Same\"    \"fracscore_x_raterisk_Same\"       \n[31] \"height_x_raterisk_Greater\"        \"height_x_premeno_Yes\"            \n[33] \"height_x_fracscore\"               \"height_x_armassist_Yes\"          \n```\n:::\n:::\n\n\n## Step 2: Fit LASSO: Identify interactions\n\n- I combed through the column names of the results to find the interactions\n  - I used ChatGPT to help me because I'm pretty new to `tidymodels`: [let's view what I asked](https://chatgpt.com/c/506e4235-52fc-46b9-a9ad-6edf425818d5)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninteractions = vi_data_int %>% filter(grepl(\"_x_\", Variable))\n\ninteraction_terms = ~ (all_predictors()^2) - #Makes interactions b/w all predictors\n                      fracscore:starts_with(\"premeno\") - # Removes this interaction\n                      height:starts_with(\"premeno\") - \n                      height:starts_with(\"smoke\") - \n                      height:starts_with(\"momfrac\")\n```\n:::\n\n\n## Step 2: Fit LASSO: Create recipe and fit model (from LASSO)\n\n- This is not the typical procedure for LASSO, but the `tidymodels` framework for interactions did not let me keep all main effects when looking at my interactions\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_rec_int2 = recipe(fracture ~ ., data = glow_train) %>%\n  update_role(age_c, new_role = \"dont_use\") %>%\n\n  step_dummy(priorfrac, premeno, momfrac, armassist, smoke, raterisk) %>%\n\n  step_interact(terms = interaction_terms)\n  \nlog_model = logistic_reg()\n\nglow_workflow_int2 = workflow() %>%\n      add_model(log_model) %>% add_recipe(glow_rec_int2)\n  \nglow_fit_int2 = glow_workflow_int2 %>% fit(glow_train)\n```\n:::\n\n\n## Step 2: Fit LASSO: Look at model fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(tidy(glow_fit_int2), n=60)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 42 × 5\n   term                              estimate std.error statistic p.value\n   <chr>                                <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)                        3.09      10.3       0.300   0.764 \n 2 height                            -0.0415     0.0637   -0.652   0.515 \n 3 fracscore                         -2.92       2.15     -1.36    0.175 \n 4 priorfrac_Yes                     15.1        8.61      1.75    0.0793\n 5 premeno_Yes                       -0.805      1.14     -0.709   0.478 \n 6 momfrac_Yes                       -1.71       1.74     -0.984   0.325 \n 7 armassist_Yes                     18.5       10.7       1.73    0.0838\n 8 smoke_Yes                        -22.8      838.       -0.0272  0.978 \n 9 raterisk_Same                     16.0       10.1       1.59    0.112 \n10 raterisk_Greater                   1.13       9.16      0.123   0.902 \n11 height_x_fracscore                 0.0215     0.0136    1.58    0.113 \n12 height_x_priorfrac_Yes            -0.0825     0.0531   -1.55    0.120 \n13 height_x_armassist_Yes            -0.114      0.0645   -1.77    0.0762\n14 height_x_raterisk_Same            -0.0940     0.0623   -1.51    0.131 \n15 height_x_raterisk_Greater          0.00238    0.0563    0.0423  0.966 \n16 fracscore_x_priorfrac_Yes         -0.373      0.177    -2.10    0.0353\n17 fracscore_x_momfrac_Yes            0.608      0.313     1.94    0.0520\n18 fracscore_x_armassist_Yes         -0.111      0.178    -0.626   0.531 \n19 fracscore_x_smoke_Yes              0.604      0.564     1.07    0.284 \n20 fracscore_x_raterisk_Same         -0.257      0.209    -1.23    0.217 \n21 fracscore_x_raterisk_Greater      -0.318      0.212    -1.50    0.133 \n22 priorfrac_Yes_x_premeno_Yes       -2.72       1.06     -2.56    0.0104\n23 priorfrac_Yes_x_momfrac_Yes       -1.35       1.35     -1.00    0.317 \n24 priorfrac_Yes_x_armassist_Yes      1.45       0.820     1.76    0.0779\n25 priorfrac_Yes_x_smoke_Yes         -0.329      1.68     -0.196   0.845 \n26 priorfrac_Yes_x_raterisk_Same      0.122      0.837     0.146   0.884 \n27 priorfrac_Yes_x_raterisk_Greater   0.838      0.916     0.915   0.360 \n28 premeno_Yes_x_momfrac_Yes          0.304      1.58      0.192   0.848 \n29 premeno_Yes_x_armassist_Yes        1.73       0.923     1.87    0.0615\n30 premeno_Yes_x_smoke_Yes           -3.98       1.84     -2.17    0.0300\n31 premeno_Yes_x_raterisk_Same        0.716      1.16      0.620   0.535 \n32 premeno_Yes_x_raterisk_Greater     1.71       1.19      1.44    0.150 \n33 momfrac_Yes_x_armassist_Yes       -3.60       1.43     -2.52    0.0118\n34 momfrac_Yes_x_smoke_Yes            2.73       2.67      1.02    0.307 \n35 momfrac_Yes_x_raterisk_Same        1.87       1.33      1.41    0.160 \n36 momfrac_Yes_x_raterisk_Greater     0.730      1.33      0.548   0.583 \n37 armassist_Yes_x_smoke_Yes          1.58       1.67      0.948   0.343 \n38 armassist_Yes_x_raterisk_Same      0.690      0.893     0.774   0.439 \n39 armassist_Yes_x_raterisk_Greater  -0.247      0.975    -0.253   0.800 \n40 smoke_Yes_x_raterisk_Same         19.5      838.        0.0232  0.981 \n41 smoke_Yes_x_raterisk_Greater      20.0      838.        0.0239  0.981 \n42 raterisk_Same_x_raterisk_Greater  NA         NA        NA      NA     \n```\n:::\n:::\n\n\n## Poll Everywhere Question 4\n\n\n## Step 3: Prediction on testing set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_test_pred = predict(glow_fit_int2, new_data = glow_test, type = \"prob\") %>%\n    bind_cols(glow_test)\n```\n:::\n\n\n::: columns\n::: {.column width=\"45%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_test_pred %>% \n  roc_auc(truth = fracture, \n                  .pred_No)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.644\n```\n:::\n:::\n\n:::\n\n::: {.column width=\"55%\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglow_test_pred %>% \n  roc_curve(truth = fracture, .pred_No) %>%\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](15_Model_Building_files/figure-revealjs/unnamed-chunk-24-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n:::\n:::\n\n## Step 3: Prediction on testing set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_test_pred = predict(glow_fit_int2, new_data = glow_test, type = \"prob\") %>%\n    bind_cols(glow_test)\n```\n:::\n\n\n::: columns\n::: {.column width=\"45%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nglow_test_pred %>% \n  roc_auc(truth = fracture, \n                  .pred_No)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.644\n```\n:::\n:::\n\n\n \n\n::: box2\nWhy is this AUC worse than the one we saw with prior fracture, age, and their interaction?\n\n- Only 1 training and testing set: can overfit training and perform poorly on testing\n- We did not tune our penalty\n- Our testing set only has 100 observations!\n:::\n:::\n\n::: {.column width=\"55%\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglow_test_pred %>% \n  roc_curve(truth = fracture, .pred_No) %>%\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](15_Model_Building_files/figure-revealjs/unnamed-chunk-27-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n:::\n:::\n\n\n## Cross-validation (specifically k-fold)\n\n-   Prevents overfitting to one set of training data\n\n-   Split data into folds that train and validate model selection\n\n-   Basically subsection of training and testing (called validating) before truly testing on our original testing set\n\n![](images/cross_val.png)\n\n## Solutions / Resources (beyond our class right now)\n\n-   Use a tuning parameter for our penalty\n\n    -   Basically, we need to figure out what the best penalty is for our model\n    -   We use the training set to determine the best penality\n    -   Videos that includes tuning parameter with LASSO\n        \n        -   [TidyTuesday video on LASSO with interactions](https://www.youtube.com/watch?v=a7VTTQovUGU&ab_channel=AndrewCouch)\n        \n\n-   Cross-validation\n\n    -   Under [Cross validation within Data Science in a Box](https://datasciencebox.org/02-making-rigorous-conclusions#model-validation)\n\n    \n-   For complete video of machine learning with **LASSO**, **cross-validation**, and **tuning parameters**\n\n    -   See \"Unit 5 - Deck 4: Machine learning\" on [this Data Science in a Box page](https://datasciencebox.org/02-looking-further#slides-videos-and-application-exercises)\n    \n        -   Video goes through an example with more complicated data, but can be followed with our work!\n        \n## Summary\n\n- Revisited model selection techniques and discussed how a binary outcome can be treated differently than a continuous outcome\n- Discussed association vs prediction modeling\n- Discussed classification: a type of machine learning!\n- Introduced penalized regression as a classification method\n- Performed penalized regression (specifically LASSO) to select a prediction model\n- Process presented today has major flaws\n  - We did not tune our parameter\n  - We did not perform cross validation\n  \n## For your Lab 4\n\n-   You can use purposeful selection, like we did last quarter\n\n    -   If you want to focus on **association** modeling!\n\n    -   A good way to practice this again if you struggled with it previously\n\n \n\n-   You can try out LASSO regression \n\n    -   If you want to focus on **prediction** modeling!\n    -   And if you want to stretch your R coding skills\n",
    "supporting": [
      "15_Model_Building_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}