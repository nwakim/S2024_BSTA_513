---
title: "Review"
author: "Nicky Wakim"
title-slide-attributes:
    data-background-color: "#213c96"
date: "01/12/2023"
categories: ["Week 1"]
format: 
  revealjs:
    theme: [default, simple_NW.scss]
    toc: true
    toc-depth: 1
    toc-title: Class Overview
    chalkboard: true
    slide-number: true
    show-slide-number: all
    width: 1955
    height: 1100
    footer: Review
    mermaid: 
      theme: neutral
---

## What did we learn in 511?

-   In 511, we talked about *categorical* and *continuous* outcomes (dependent variables)
-   We also talked about their relationship with 1-2 *continuous* or *categorical* exposure (independent variables or predictor)
-   We had many good ways to assess the relationship between an outcome and exposure:

|                      |                                                  |                                                                                                                  |
|------------------|------------------|-------------------------------------|
|                      | Continuous Outcome                               | Categorical Outcome                                                                                              |
| Continuous Exposure  | Correlation, simple linear regression            | ??                                                                                                               |
| Categorical Exposure | t-tests, paired t-tests, 2 sample t-tests, ANOVA | proportion t-test, Chi-squared goodness of fit test, Fisher's Exact test, Chi-squared test of independence, etc. |

: {tbl-colwidths="\[15, 35,35\]"}

## What did we learn in 511?

-   You set up a really important foundation

    -   Including distributions, mathematical definitions, hypothesis testing, and more!

-   Tests and statistical approaches learned are incredibly helpful!

-   While you had to learn a lot of different tests and approaches for each combination of categorical/continuous exposure with categorical/continuous outcome

    -   Those tests cannot handle more complicated data

-   What happens when other variables influence the relationship between your exposure and outcome?

    -   Do we just ignore them?

## What will we learn in this class?

-   We will be building towards models that can handle many variables!

    -   **Regression** is the building block for modeling multivariable relationships

-   In Linear Models we will *build, interpret, and evaluate* linear regression models

## Process of regression data analysis

![](01_Review/Reg_analysis_process.png){fig-align="center"}

## Main sections of the course

-   Review

-   Intro to SLR: estimation and testing

    -   <span style="color:#34AC8B;">Model fitting</span>

-   Intro to MLR: estimation and testing

    -   <span style="color:#34AC8B;">Model fitting</span>

-   Diving into our predictors: categorical variables, interactions between variable

    -   <span style="color:#34AC8B;">Model fitting</span>

-   Key ingredients: model evaluation, diagnostics, selection, and building

    -   <span style="color:#A7EA52;">Model evaluation </span> and <span style="color:#FF8021;">Model selection</span>

```{r}
library(ggplot2)
```

```{css}
code.sourceCode {
  font-size: 1.4em;
  /* or try font-size: xx-large; */
}
```

## Main sections of the course

::: lob
-   Review
:::

-   Intro to SLR: estimation and testing

    -   <span style="color:#34AC8B;">Model fitting</span>

-   Intro to MLR: estimation and testing

    -   <span style="color:#34AC8B;">Model fitting</span>

-   Diving into our predictors: categorical variables, interactions between variable

    -   <span style="color:#34AC8B;">Model fitting</span>

-   Key ingredients: model evaluation, diagnostics, selection, and building

    -   <span style="color:#A7EA52;">Model evaluation </span> and <span style="color:#FF8021;">Model selection</span>

## Before we begin

-   Meike has some really good online notes, code, and work on [her BSTA 511 page](https://niederhausen.github.io/BSTA_511_F23/)

# Quick basics

## Some Basic Statistics "Talk"

::: columns
::: column
-   Random variable $Y$

    -   Sample $Y_i, i=1,\dots, n$

-   Summation:

    $\sum_{i=1}^n Y_i =Y_1 + Y_2 + \ldots + Y_n$

-   Product:

    $\prod_{i=1}^n Y_i = Y_1 \times Y_2 \times \ldots \times Y_n$
:::

::: column
:::
:::

## Descriptive Statistics: continuous variables

::: columns
::: {.column width="40%"}
**Measures of central tendency**

-   Sample mean

    $$
    \bar{x} = \dfrac{x_1+x_2+...+x_n}{n}=\dfrac{\sum_{i=1}^nx_i}{n}
    $$

-   Median
:::

::: column
**Measures of variability (or dispersion)**

-   Sample variance

    -   Average of the squared deviations from the sample mean

-   Sample standard deviation

    $$
    s = \sqrt{\dfrac{(x_1-\bar{x})^2+(x_2-\bar{x})^2+...+(x_n-\bar{x})^2}{n-1}}=\sqrt{\dfrac{\sum_{i=1}^n(x_i-\bar{x})^2}{n-1}}
    $$

-   IQR
:::
:::

## Descriptive Statistics: continuous variables (R code)

::: columns
::: {.column width="40%"}
**Measures of central tendency**

-   Sample mean

    ```{r}
    #| eval: false
    #| echo: true

    mean( sample )
    ```

-   Median

    ```{r}
    #| eval: false
    #| echo: true

    median( sample )
    ```
:::

::: column
**Measures of variability (or dispersion)**

-   Sample variance

    ```{r}
    #| eval: false
    #| echo: true

    var( sample )
    ```

-   Sample standard deviation

    ```{r}
    #| eval: false
    #| echo: true

    sd( sample )
    ```

-   IQR

    ```{r}
    #| eval: false
    #| echo: true

    IQR( sample )
    ```
:::
:::

## Data visualization

-   Using the library `ggplot2` to visualize data

-   We will load the package:

```{r}
#| echo: true

library(ggplot2)
```

## Histogram using `ggplot2`

We can make a basic graph for a continuous variable:

::: columns
```{r}
data("dds.discr")
```

::: {.column width="50%"}
```{r}
#| echo: true
#| fig-align: center

ggplot(data = dds.discr, 
       aes(x = age)) +
  geom_histogram()
```
:::

::: {.column width="50%"}
```{r}
#| echo: true
#| fig-align: center

ggplot() +
  geom_histogram(data = dds.discr, 
       aes(x = age))
```
:::
:::

[Some more information](https://www.sharpsightlabs.com/blog/histogram-r-ggplot2/) on histograms using `ggplot2`

## Spruced up histogram using `ggplot2`

We can make a more formal, presentable graph:

```{r}
#| echo: true
#| fig-align: center

ggplot(data = dds.discr, 
       aes(x = age)) +
  geom_histogram() +
  theme(text = element_text(size=20)) +
  labs(x = "Age", 
       y = "Count", 
       title = "Distribution of Age in Sample")
```

I would like you to turn in homework, labs, and project reports with graphs like these.

## Other basic plots from `ggplot2`

We can also make a density and boxplot for the continuous variable with `ggplot2`

::: columns
::: {.column width="50%"}
```{r}
#| echo: true

ggplot(data = dds.discr, 
       aes(x = age)) +
  geom_density()
```
:::

::: {.column width="50%"}
```{r}
#| echo: true

ggplot(data = dds.discr, 
       aes(x = age)) +
  geom_boxplot()
```
:::
:::

# Important Distributions

## Distributions that will be used in this class

-   Normal distribution

-   Chi-square distribution

-   t distribution

-   F distribution

## Normal Distribution

-   Notation: $Y\sim N(\mu,\sigma^2)$

-   If we know $E(Y)=\mu$, $Var(Y)=\sigma^2$ then

    -   2/3 of $Y$'s distribution lies within 1 $\sigma$ of $\mu$

    -   95% $\ldots$ $\ldots$ is within $\mu\pm 2\sigma$

    -   $>99$% $\ldots$ $\ldots$ lies within $\mu\pm 3\sigma$

-   Arguably, the most important distribution in statistics

-   Linear combinations of Normals are Normal\
    e.g., $(aY+b)\sim \mbox{N}(a\mu+b,\;a^2\sigma^2)$

-   Standard normal:

```{=tex}
\begin{aligned}
        Z=\frac{Y-\mu}{\sigma} \sim \mbox{N}(0,1) \nonumber
        
\end{aligned}
```
## Chi-square Distribution

-   Notation: $X \sim \chi^2_{df}$

    -   $df=$ degrees of freedom

    -   $E[X]=df$

    -   $X$ takes on only positive values

-   If $Z_i\sim \mbox{N}(0,1)$, then $Z_i^2\sim \chi^2_1$

-   If $Z_1,\ldots,Z_n$ are independent, with $Z_i\sim\mbox{N}(0,1)$, then

```{=tex}
\begin{aligned}
        \sum_{i=1}^n Z_i^2 & \sim & \chi^2_n \nonumber
        
\end{aligned}
```
-   Used in hypothesis testing and CI's involving variance

## t Distribution

-   If $Z\sim \mbox{N}(0,1)$ and $S^2\sim \chi^2_{df}$ and $Z$ and $S^2$ are independent,

    ```{=tex}
    \begin{aligned}        \frac{Z}{S/\sqrt{df}} & \sim & t_{df} \nonumber            \end{aligned}
    ```
    -   Symmetric, bell-shaped; tails heavier than Normal

    -   $E[t_{df}]=0$; $Var(t_{df})$ greater than 1

    -   $\lim_{df\rightarrow \infty}t_{df} \rightarrow \mbox{N}(0,1)$

    -   for $df>30$, the $t_{df}$ closely resembles the $\mbox{N}(0,1)$ distribution

-   In linear modeling, used for inference on individual regression parameters

## F Distribution

-   Model ratio of sample variances

    -   Ratio of variances is important for hypothesis testing of regression and ANOVA models

-   If $X_1^2\sim \chi^2_{df1}$ and $X_2^2\sim \chi^2_{df2}$, where $X_1^2\perp X_2^2$, then:

    ```{=tex}
    \begin{aligned}        \frac{X_1^2/df1}{X_2^2/df2} & \sim & F_{df1,df2} \nonumber        \end{aligned}
    ```
    -   only takes on positive values

-   Important relationship with $t$ distribution:

    -   The square of a t-distribution with $df=\nu$

    -   is an F-distrubtion with numerator df ($df1 = 1$) and denominator df ($df2 = \nu$)

```{=tex}
\begin{aligned}
             T^2  \stackrel{{D}}{\sim} & F_{1,\nu} \\
             \text{ if and only if } T \sim t_{\nu}
            
\end{aligned}
```
# Statistical inference: Estimation

## Confidence interval for one mean

## Confidence interval for two independent means

# Statistical inference: Hypothesis testing

## Steps in hypothesis testing

![](01_Review/hypothesis_test_steps.png){fig-align="center"}

## Example: one sample t-test using p-value approach

## Example: one sample t-test using critical values approach

# Error Rates and Power

## Type 1 and 2 errors

![](01_Review/Type_1_2_error.png){fig-align="center"}

## Power

-   Power is $1-\beta$

    -   The probability of correctly rejecting the null hypothesis

![](01_Review/Power.png){fig-align="center"}
