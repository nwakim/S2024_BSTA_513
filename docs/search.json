[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BSTA 512/612: Linear Models",
    "section": "",
    "text": "BSTA 512/612: Linear Models\n\nWinter 2024\n \nWelcome to BSTA 512/612! In this course, we will focus on linear models, and build our understanding of regression analysis. We will build some theoretical understanding in order to interpret and apply regression models appropriately. We will learn how to build a regression model, interpret the model, and diagnose potential issues with our model.  \n\n\n\n\n\n\n\nInstructor\n Dr. Nicky Wakim\n Vanport 622A\n wakim@ohsu.edu\n\n\nOffice Hours\nOH with Nicky\n Thursdays, 11:30am - 1pm\nOH with Antara\n Wednesdays, 4:30 - 6 pm\nOH with Ariel\n Tuesdays, 2:30 - 4 pm\n\n\nCourse details\n Mondays, Wednesdays\n Jan 8 - March 20\n 1:00 PM - 2:50 PM\n In-person\n\n\nContacting me\nE-mail or Slack is the best way to get in contact with me. I will try to respond to all course-related e-mails within 24 hours Monday-Friday.\n\n\n\n\n\n\n\n\n View the source on GitHub"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Weekly Pages",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\n1/8/24\n\n\nWeek 1\n\n\nIntroduction; Review; and Data Wrangling\n\n\n\n\n1/15/24\n\n\nWeek 2\n\n\nSimple Linear Regression\n\n\n\n\n1/22/24\n\n\nWeek 3\n\n\nSLR Hypothesis Testing\n\n\n\n\n1/29/24\n\n\nWeek 4\n\n\nMultiple Linear Regression (MLR)\n\n\n\n\n2/5/24\n\n\nWeek 5\n\n\nMLR Hypothesis Testing\n\n\n\n\n2/12/24\n\n\nWeek 6\n\n\nCategorical Covariates\n\n\n\n\n2/19/24\n\n\nWeek 7\n\n\nInteractions\n\n\n\n\n2/26/24\n\n\nWeek 8\n\n\nModel Evaluation and Diagnostics\n\n\n\n\n3/4/24\n\n\nWeek 9\n\n\nModel Diagnostics\n\n\n\n\n3/11/24\n\n\nWeek 10\n\n\nModel Selection and Building\n\n\n\n\n3/18/24\n\n\nWeek 11\n\n\nSpill-Over Week\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This course is designed to introduce history, concepts and distributions in probability, Monte Carlo simulation techniques, and Markov chains. Students will also learn how to write R codes for various statistical computations and plots. Previous experience in R is not required. R is free software available from http://www.r-project.org.\n\n\nAt the end of this course, students should be able to…\n\nUnderstand basic concepts in probability\nCompute probabilities for random variables\nCompute probabilities using basic distributions\nPerform statistical computations and simulations using R"
  },
  {
    "objectID": "syllabus.html#textbook",
    "href": "syllabus.html#textbook",
    "title": "Syllabus",
    "section": "Textbook",
    "text": "Textbook\n\nIntroduction to Probability\n\nAuthors: Mark Daniel Ward and Ellen Gundlach\nPublisher: W. H. Freeman\nEdition: 1st\nISBN-13: 978-0716771098\nTextbook in Sakai\n\n\n\nSupplemental Readings (Optional)\n\nStatistical Inference, Casella and Berger, 2nd ed. (This will be the textbook for BSTA 551-552 Math Stat.)\nIntroduction to Probability, Charles M. Grinstead and J. Laurie Snell, http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/pdf.html\nProbability With Applications and R, Robert P. Dobrow, Wiley 2013 (eBook available from OHSU library)\nAn Introduction to R (free pdf available from http://cran.r-project.org/manuals.html)"
  },
  {
    "objectID": "syllabus.html#online-resources",
    "href": "syllabus.html#online-resources",
    "title": "Syllabus",
    "section": "Online Resources",
    "text": "Online Resources\n\nSlack\nWe will use Slack as our main form of communication for the class. I will try to mirror the Slack Workspace that you had for 512/612. If you are unsure how to do a homework problem or have other questions, please ask myself or the TA’s either by email or posting your question(s) on Slack. Please know that Slack is not guarded by the OSHU firewall, so if you have a question about accommodations or any sensitive topics, you may wish to message me via email. You can still message me regarding sensitive information on Slack, but I will not initiate those conversations on Slack. Please continue to use the tips on asking for help that Meike laid out in the 512/612 syllabus. I will also add her tips to the Slack workspace.\n**Please use this invitation link for our Slack workspace!**\n\n\nSakai\nCourse materials will be delivered online through Sakai, OHSU’s course management system. This is where you’ll find all course materials (syllabus, videos, lectures, homework assignments, announcements, etc.). This is also where you’ll submit all course assignments.\nI will try to keep the structure of the Sakai page similar to that of BSTA 512/612. It’s always tough for you, the students, to spend two quarters with one faculty member then change to a new one. That is why I will try my best to keep the Sakai navigation similar. However, certain aspects will certainly be different. I hope we can work together to identify the things that are and are not working for our classroom. \n\n\nExplain Everything\nI plan to use Explain Everything on my iPad to deliver lectures. This application allows me to take real time notes, access Poll Everywhere, and record the lecture. I hope to use these features to allow you to follow me during lecture and have access to a recording for asynchronous viewing. While I will try to always make a recorded lecture available to you after class, I want you to try to attend class in person. I understand that life events get in the way on in-person attendance, but your attendance in-person brings me joy while I teach, and then further motivates me to be a great teacher. \nNote: I am new to this application so I ask you for some grace as I learn to navigate it. \n\n\nWebex\nWebex software will be used for office hours. To give everyone the best possible experience with Webex, we recommend the following best practices:\n\nPlease stay muted until you want to participate\nDuring office hours, please send a message in chat with your question or with a statement like “I have a question.” This makes sure I or the TA can address everyone’s questions in order. \nI encourage you to attend office hours with your video on. This helps me recognize you, and keep mental notes on what techniques/concepts I emphasize to facilitate your specific understanding. \n\n\n\nPoll Everywhere\nWe will use the Poll Everywhere tool as an interactive feature of the course. Poll Everywhere is a web-based application that allows students to participate by responding via text messages or by visiting a web page on an internet-enabled device (smartphone, tablet, laptop). Instructions will be displayed on-screen. The poll that is embedded within the presentation will update in real time. While there is no cost to use this software, standard text messaging rates will apply if you use your phone. Please make sure that you have a Poll Everywhere account before our first class. You are not required to use your OHSU/PSU email to make an account. \nDuring lectures I will pose questions to the class. These questions are designed to provide real-time feedback to both students and the instructor on how well students are grasping the material. This is meant to be an interactive, learning activity with NO contribution to your grade. Your identity will never be connected to your answers, so I encourage you to answer honestly.\n\n\nPennState STAT 414 Website\nPennState has a class offered to advanced undergraduates that has some overlap with our class. They have all their course notes posted on thispage. This is a great source if you would like to see class notes with different phrasing.\nNot all of our topics are covered in their notes, but the most important ones are. If you are having trouble finding our course’s concepts on their page, please make ask me at Office Hours, after class, or in a private meeting. I do not explicitly state corresponding sections under our schedule because I believe it is important for you to develop skills involving resources and learning key words that can help you find answers. \n\n\nR: Statistical Computing Software\nStudents will use statistical software to complete homework assignments. Students are required to use R/RStudio for this course. R can be freely downloaded. Helpful documentation on installing R is available. I encourage you to install R prior to attending our first lecture. Please email me if you need help installing R or RStudio.\nYou will need to download the following three things:\n\nR https://www.r-project.org/\nRstudio https://posit.co/download/rstudio-desktop/\nQuarto https://quarto.org/docs/get-started/\n\n\nAdditional R Resources\nYour learning and practicing of R will hopefully not be limited to this course. One of the best aspects of programming in R is that many resources are freely available online. Here are just a few additional resources you may explore beyond this class to continue your training in R.\n\n\nUseful online R resources\n\nR for the rest of us\nStatistical tools for high-throughput data analysis. ggplot2 essentials\nR-bloggers\nStack Overflow for troubleshooting\nR Graphical Manual\nQuick-R. Accessing the power of R\nR for SAS, STATA, and SPSS Users\nggplot2\nLearn R 4 free\nJoin a local R user groups\nLearning Machines\n\n\n\nOnline R courses to complement or refresh material from class\n\nR for the rest of us\nCoursera: R programming\nedX: R basics\nData Carpentry: For Biologists\nData Carpentry: For Ecologists\nPsychiatric R\nR coder"
  },
  {
    "objectID": "syllabus.html#types-of-assessments",
    "href": "syllabus.html#types-of-assessments",
    "title": "Syllabus",
    "section": "Types of assessments",
    "text": "Types of assessments\nThis class will use a combination of formative and summative assessments to build and test our knowledge. Below I define each of these types of assessments:\n\nFormative assessment: Activity or work meant to help students learn and practice. Grading of these assessments are meant to help the instructor and student identify gaps in knowledge and highlight accomplishments.\nSummative assessment: Work meant to test how well students have achieved learning objectives. Grading of these assessments are meant to gauge how well a student grasps the learning objectives and will be able to use their knowledge outside of the classroom.\n\nStudents will always have the opportunity to redo formative assessments until they are satisfied with their grade. That means students can redo homework and readings until they are satisfied with their grade. This is meant to emphasize the learning process, and reduce pressure for correctness. However, there are some limitations on “redoing” your work. In the homework grading scale (shown in Criteria), you might notice that certain grades correspond to a certain percentage of the homework completed. You can only redo problems that you have completely worked through. Thus, you can only increase your grade by increasing the amount of correct problems."
  },
  {
    "objectID": "syllabus.html#breakdown",
    "href": "syllabus.html#breakdown",
    "title": "Syllabus",
    "section": "Breakdown",
    "text": "Breakdown\n\nGrading & Requirements\nLetter grades will be assigned roughly according to the following scheme: A (&gt;=93%), A- (90-92%), B+ (88-89%), B(83-87%), B- (82-80%), C+(78-79%), C(73-77%), C- (70-72%), D (60 – 69%), F(&lt;60%).\nGrades will be based on homework assignments, midterm exam, class “attendance”, and final exam, as follows:\n\n\n\n\n\n\n\n\n\nCourse activity\nType of Assessment\nDue Date\nPercentage of final grade\n\n\nHomework\nFormative\nApprox. weekly\n35%\n\n\nPost-class survey\nN/A\nTwice Weekly\n5%\n\n\nMidterm Exam\nSummative\n5/12\n30%\n\n\nFinal Exam\nSummative\nPaper: 6/11\n30%\n\n\n\n\n\nCriteria\n\nHomework grading\nNo student has the same amount of time available to dedicate to homework. This class may not be a priority to you, you may be taking several other courses, or you may need to dedicate time to other activities. Homeworks are formative assessments, meaning its purpose is to help you learn and practice. To reduce the pressure on you to have perfect or complete homework, I have a very simple grading policy: Your homework will be given a check mark if you turn something in (whether it is incomplete, complete, correct, or wrong). I highly encourage you to stay up-to-date with the homeworks and put in as much effort as you can. This will be the most helpful work in this class!\nAfter the due date, either the TA or myself will post the solutions.\n\n\nViewing Grades in Sakai\nPoints you receive for graded activities will be posted to the Sakai Gradebook. Click on the Gradebook link on the left navigation to view your points.\n\n\nLate Work Policy\nI encourage you to make your best effort to submit all assignments on time, but I understand circumstances arise that are beyond our control. Please see this Swansea University’s page on extenuating circumstances for some examples. Not all circumstances are covered here, so please reach out if you have questions. \n\nEach of you will receive one “no questions asked” extension on any homework assignment. To request the extension, you can write an email with subject “Extension on Homework Assignment __” with body saying “I would like an extension on Homework Assignment __ for __ days.” I will grant you that extension with no questions asked.\n\nIf you have already used a “no questions asked” extension on homework, then homework grades will go down one point for every day it is late. For example, if your work is on par of a 5/5, but you turn it in homework 2 days late, then you will receive a 3/5. \n\nThe class will end on June 16, 2023. All coursework is expected to be completed by then. If you have extenuating circumstances, and need additional time to complete class assignments, please contact me. Together, we will come up with a plan for completion and to sort out registrar logistics.\nIf you have extenuating circumstances that may jeopardize your ability to do work for several weeks, please contact me. We will come up with a plan to keep you on track in the course and prevent any delay in your education.\nFor non-homework assignments, I ask you to email me directly. You can explain your circumstances and may ask me for an extension, but I won’t necessarily grant one.\nIf you have a emergency involving your self, family, pet, friend, classmate, or anything/one deemed important to you, please do not worry about immediately contacting me. We can work something out after your emergency. If I contact you during an emergency, it is only because I am worried, and you do NOT need to respond until you are able. \n\n\n\nRegrade Policy\nIf you think a question was incorrectly graded, first compare your answer to the answer key. If you believe a re-grade would be appropriate, write an email to me containing the question and a short explanation as to why the question(s) was/were incorrectly graded. Deadline: One week after assignments were returned to class (late requests will not be considered).\n\n\nAttendance Policy\nYou are expected to attend class and participate in class polls and the exit ticket. For students who miss class or need a review, I will make video and audio recordings of lectures available. There are no guarantees against technical or other challenges for the recording availability or quality. For students who are unable to attend the class in-person and synchronously, viewing the recording within 7 days is acceptable. Make sure to complete the exit ticket to demonstrate attendance."
  },
  {
    "objectID": "syllabus.html#ongoing-course-feedback",
    "href": "syllabus.html#ongoing-course-feedback",
    "title": "Syllabus",
    "section": "Ongoing Course Feedback",
    "text": "Ongoing Course Feedback\nThroughout the duration of the course, you are also welcome to informally and anonymously submit your feedback through this Microsoft Form or Class Exit Tickets. This form will be available on Sakai. Students can submit feedback at any time and this form will be reviewed regularly by me. Your responses will be anonymous unless you elect to leave your email address. If I have done anything to make you feel uncomfortable, please give me feedback so I can change my behavior. Ultimately, this class is for you, and my individual social identity/behavior should not inhibit your learning. Thank you for your help making BSTA 513/613 a more successful class! Examples of ongoing feedback are:\n\nNicky talks a little fast during lecture time. May you speak slower?\nDuring Office Hours, Dr. Wakim made a face when I asked a question. This face made me feel self-conscious about my question.\nDr. W asked me a question about my experience that made me feel like a monolith for my race. Please do not assume I can speak on behalf of my social identity groups.\nThe in-class examples do not make me more interested in the material."
  },
  {
    "objectID": "syllabus.html#midterm-feedback",
    "href": "syllabus.html#midterm-feedback",
    "title": "Syllabus",
    "section": "Midterm Feedback",
    "text": "Midterm Feedback\nDuring the middle of the quarter, I will ask you to submit guided, anonymous feedback. Completion of feedback will be count towards your midterm exam grade. To insure anonymity, I will ask you to sign a separate, written statement that you completed the feedback."
  },
  {
    "objectID": "syllabus.html#final-course-feedback",
    "href": "syllabus.html#final-course-feedback",
    "title": "Syllabus",
    "section": "Final Course Feedback",
    "text": "Final Course Feedback\nAt the conclusion of the course, you will be asked to complete a formal online review of the course and the instructor. Your feedback on this University evaluation is critical to improving future student learning in this course as well as providing metrics relevant to the instructor’s career advancement."
  },
  {
    "objectID": "syllabus.html#instructor-expectations",
    "href": "syllabus.html#instructor-expectations",
    "title": "Syllabus",
    "section": "Instructor Expectations",
    "text": "Instructor Expectations\nCommitment to your learning and your success\nI believe that everyone has the ability to be successful in this course and I have put a lot of effort into designing the course in a way that maximizes your learning to ensure your success. Please talk to me before or after class or stop by my office if there is anything you want to discuss or about which you are unclear. I want to be supportive of your learning and growth.\nInclusive & supportive learning community\nI believe that learning happens best when we all learn together, as a community. This means creating a space characterized by generous listening, civility, humility, patience, and hospitality. I will attempt to promote a safe climate where we examine content from multiple cultural perspectives, and I will strive to create and maintain a classroom atmosphere in which you feel free to both listen to others and express your views and ask questions to increase your learning.\nOpenness to feedback\nI appreciate straightforward feedback from you regarding how well the class is meeting your needs. Let me know if material is not clear or when its relevance to the student learning outcomes for the course is not apparent. In particular, let me know if you identify bias or stereotyping in my teaching materials as I will seek to continuously improve. Please also let me know if there’s an aspect of the class you find particularly interesting, helpful, or enjoyable!\nResponsiveness\nI will monitor email as well as the discussion board daily and try respond to all messages within 24 hours Monday-Friday.\nClear guidelines and prompt feedback on assignments\nI will provide clear instructions for all assignments, and a grading rubric when applicable. I will provide detailed feedback on your submissions and will update grades promptly in Sakai."
  },
  {
    "objectID": "syllabus.html#student-expectations-and-resources",
    "href": "syllabus.html#student-expectations-and-resources",
    "title": "Syllabus",
    "section": "Student Expectations and Resources",
    "text": "Student Expectations and Resources\nAttend class\nYou are expected to attend all scheduled class meetings synchronously or watch the recording within 7 days. Attendance is taken through exit tickets. If you have issues accessing the poll on a specific day, please let me know. \nParticipate\nI encourage you to participate actively in class and online discussions. I will expect all students, and all instructors, to be respectful of each other’s contributions, whether I agree with them or not. Professional interactions are expected.\nBuild rapport\nIf you find that you have any trouble keeping up with assignments or other aspects of the course, make sure you let me know as early as possible. As you will find, building rapport and effective relationships are key to becoming an effective professional. Make sure that you are proactive in informing me when difficulties arise during the semester so that I can help you find a solution.\nComplete assignments\nAll assignments for this course will be submitted electronically through Sakai unless otherwise instructed.  I encourage you to make your best effort to submit all assignments on time, but I understand that sometimes circumstances arise that are beyond our control. If you need an extension, please contact me in congruence with the Late Policy.\nSeek help if you need it\nI believe it is important to support the physical and emotional well‐being of my students. If you are experiencing physical or mental health issues, I encourage you to use the resources on campus such as those listed below. If you have a health issue that is affecting your performance or participation in the course, and/or if you need help connecting with these resources, please contact the instructor or any of the TAs.\n\nStudent Health and Wellness Center (SHW), Website, 503-494-8665 (OHSU Students only)\nStudent Health and Counseling (SHAC), Website, 503-725-2800\n\nInform your instructor of any accommodations needed\nYou should speak with or email me before or during the first week of classes regarding any special needs. Students seeking academic accommodations should register with the appropriate service under the School policies below.\nSome religious holidays may occur on regularly scheduled class days. Because available class hours are so limited in number, we will have to hold class on all such days. Class video recordings will be available and you are encouraged to engage with the material outside of the regular class time. You are also encouraged to come to office hours with questions from the session.\nCommit to integrity\nAs a student in this course (and at PSU or OHSU) you are expected to maintain high degrees of professionalism, commitment to active learning and participation in this class and also integrity in your behavior in and out of the classroom.\nCheating and other forms of academic misconduct will not be tolerated in this course and will be dealt with firmly. Student academic misconduct refers to behavior that includes plagiarism, cheating on assignments, fabrication of data, falsification of records or official documents, intentional misuse of equipment or materials (including library materials), or aiding and abetting the perpetration of such acts. Preparation of papers or homework, assigned on an individual basis, must represent each student’s own individual effort. When used, resource materials should be cited in conventional reference format."
  },
  {
    "objectID": "readings/Chapter_01.html",
    "href": "readings/Chapter_01.html",
    "title": "Outcomes, Events, and Sample Space",
    "section": "",
    "text": "Note that I will keep the example and definition numbering that is presented in the textbook, so it may seem like numbers are being skipped. This just means I may not have presented an example from the textbook here. Feel free to consult the textbook for more examples!"
  },
  {
    "objectID": "readings/Chapter_01.html#introduction",
    "href": "readings/Chapter_01.html#introduction",
    "title": "Outcomes, Events, and Sample Space",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nThe introduction in this chapter starts with the following quote:\n\n\n\n\n\n\n“Probability theory is the study of randomness and all things associated with randomness.”\n\n\n\nI couldn’t say it better myself. There are examples with obvious hints at randomness (i.e. dice rolls, coins flips) and there are examples with not-so-obvious randomness involved (i.e. time until any given traffic light turns green).\n\n\n\n\n\n\nDefinition 1.1\n\n\n\nWhen something happens at random there are several potential outcomes. Exactly one of the outcomes occurs. An event is defined to be a collection of some outcomes.\n\n\nOur goal in probability and statistics is to characterize randomness. Then as statisticians, we can use what we know about randomness to see if certain features of the world is within randomness or outside the randomness. For example, according to a New York Times article published on July 25, 2023, the Education Department is investigating Harvard University’s legacy admissions policy. Here is an excerpt from that article:\n\nHarvard gives preference to applicants who are recruited athletes, legacies, relatives of donors and children of faculty and staff. As a group, they make up less than 5 percent of applicants, but around 30 percent of those admitted each year. About 67.8 percent of these applicants are white, according to court papers.\n\nUsing probability, we can start to see why this practice might be inequitable. If these applicants make up 5% of the total applicant pool, and we completely, randomly chose applicants to admit, then we would expect 5% of admitted students to be this group of recruited athletes, legacies, relatives of donors, and children of faculty and staff. We could argue that recruited athletes are more likely to be admitted since they are, in fact, recruited, or that children of faculty and staff might “game” high school succesfully because they live in a home that subscribes to the academic world. If we want to compare the acceptance rate of 30% for this group to the average acceptance rate, the article actually fails to present a crucial peice of information: the average acceptance rate. I looked it up, and it is ~4%. So now we can start to think about questions like: With an average acceptance rate of 4%, does an acceptance of 30% of this group of recruited athletes, legacies, relatives of donors and children of faculty and staff make sense? We will explore this example further as we progress through our class.\nBaaack to our definitions: When we have several potential outcomes, and an event is a collection of outcomes, then we can start thinking of the set of potential outcomes. When there are no outcomes, then we have the empty set \\(\\emptyset\\). When we look at all outcomes, we call it the sample space \\(S\\). For now, when we look at a single event, we will focus on the sample space. When we start thinking of multiple events, the empty set might come into play. And just to reiterate: The empty set is an event. It is an impossible event, but it is still considered an event. So when you consider all possible events, the empty set is included. When you consider all possible outcomes, this is the sample space.\nNow let’s look at at an example with an obvious hint at randomness:\n\n\n\n\n\n\nExample 1.2\n\n\n\nYou roll a 6-sided die.\n\n\n\n\n\n\n\n\nExample 1.2 Explanation\n\n\n\n\n\nA 6-sided die has sides labelled 1-6. Thus, the sample space is \\(S=\\{1,2,3,4,5,6\\}\\) since we can land on any of the 6 sides. For every roll, only one of these outcomes occur, and that outcome is random.\nAn event can be any subgroup (more formally, subset) of the sample space, but not necessarily. Events can technically be outside of the sample space, but we often only consider events within the sample space.\nIf we can say our event is if we roll a 6, then our event is defined mathematically as \\(\\{6\\}\\). We can define a different event as rolling an odd numbered side, then our event is defined mathematically as \\(\\{1,3,5\\}\\). See TB pg 4 for more event examples.\n\n\n\nWe introduced subset, but here’s the definition:\n\n\n\n\n\n\nDefinition 1.3\n\n\n\nEvent A is a subset of event B, written \\(A \\subset B\\). if every outcome in A is also an outcome in B.\n\n\n\nLet’s work on defining different types of events within sample spaces:\n\n\n\n\n\n\nExample 1.4\n\n\n\nA student buys a book and opens it to a random page. They note the number of typographical errors on the page. Let’s define the sample space and discuss one potential event.\n\n\n\n\n\n\n\n\nExample 1.4 Explanation\n\n\n\n\n\nSince there must be 0 or more errors, and errors are counted with whole numbers, the sample space will be the set of nonnegative integers: \\(S=\\mathbb{Z}^{&gt;=0}\\). More plainly, \\(S=\\{0, 1, 2, 3, 4, ...\\}\\).\nHere are a few possible events we can consider: (I invite you to think of others if you’d like)\n\nevent that a page contains 4 errors\nevent that a page contains at most 3 errors\nevent that a page contains more than 3 errors\nevent that a page contains an odd number of errors.\n\n\n\n\nDefinitions:\n\n\n\n\n\n\nDefinition 1.11\n\n\n\nThe union of events \\(A\\) and \\(B\\), denoted by \\(A \\cup B\\), contains all outcomes that are in \\(A\\) or \\(B\\).\n\n\n\n\n\n\n\n\nDefinition 1.12\n\n\n\nThe intersection of events \\(A\\) and \\(B\\), denoted by \\(A \\cap B\\), contains all outcomes that are both in \\(A\\) and \\(B\\)."
  },
  {
    "objectID": "readings/Chapter_01.html#complements-and-demorgans-laws",
    "href": "readings/Chapter_01.html#complements-and-demorgans-laws",
    "title": "Outcomes, Events, and Sample Space",
    "section": "1.2 Complements and DeMorgan’s Laws",
    "text": "1.2 Complements and DeMorgan’s Laws"
  },
  {
    "objectID": "readings/Chapter_01.html#notes",
    "href": "readings/Chapter_01.html#notes",
    "title": "Outcomes, Events, and Sample Space",
    "section": "Notes",
    "text": "Notes\nThere are a few things I’d like to address from the book:\n\nThere is a set of examples, 1.5 and 1.6, that talk about the birth of a baby. While this example is helpful for considering potential sample spaces, there is an oversight on the biology of births. The examples refer to the event of the sex assigned at birth (SAB). There are two issues in this example. First, SAB is considered binary in this example (I will get back to this). Second, the binary SAB is written as “boy” or “girl.” These labels have gender identity inherently attached to their meaning, and thus, the more accurate binary versions of these are “male” or “female,” respectively (“Assigned Sex at Birth,” n.d.). These are often denoted as “assigned male at birth” (AMAB) or “assigned female at birth” (AFAB). Going back the first issue, a binary representation of SAB does not cover all possible events. People can also be intersex, meaning their genitals, chromosomes, and/or reproductive organs are not exclusively AMAB or AFAB (“Intersex: What Is Intersex, Gender Identity, Intersex Surgery,” n.d.).\n\n\n\n\n\n\nExtension to Example 1.5 and 1.6\n\n\n\nYou can go back to these examples (TB pg. 5) and work through them with the more accurate representation of sex at birth. Please use the possible outcomes of AFAB, AMAB, or intersex."
  },
  {
    "objectID": "homework/HW5.html",
    "href": "homework/HW5.html",
    "title": "Homework 5",
    "section": "",
    "text": "Important\n\n\n\nTHIS PAGE IS UNDER CONSTRUCTION!!"
  },
  {
    "objectID": "homework/HW8.html",
    "href": "homework/HW8.html",
    "title": "Homework 7",
    "section": "",
    "text": "Complete all of the problems listed below. Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nYou must show all of your work to receive credit. Don’t forget to define every r.v. you use! In particular, if a similar problem was done in class or an example in the book, make sure to still show every step in the solution and not just cite the examples’ results."
  },
  {
    "objectID": "homework/HW2.html",
    "href": "homework/HW2.html",
    "title": "Homework 2",
    "section": "",
    "text": "Important\n\n\n\nTHIS PAGE IS UNDER CONSTRUCTION!!"
  },
  {
    "objectID": "homework/HW7.html",
    "href": "homework/HW7.html",
    "title": "Homework 7",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n28\nTB # 18\nTB # 1, 10\n\n\n291\nTB # 26, NTB # 1, 3\nTB # 10, 14, 23, 11, 13, 32\n\n\n30\n\nTB # 4, 7-12\n\n\n31\nTB # 18\nTB # 13, 14, 17\n\n\n32\nTB # 8\nTB # 3, 5, 102, 15\n\n\n33\nNTB # 4\nTB # 3, 9, 10\n\n\n35\nTB # 10, NTB # 5\nTB # 6, 9, 24\n\n\n43\nTB # 93, 104, 11, 125, NTB # 6, 7, 8\nTB # 1-4, NTB # 9\n\n\n36\nTB # 126, 14\nTB # 4, 11, 13, 15, 16\n\n\n37\nTB # 24, 30\nTB # 2, 4, 13, 20, 29"
  },
  {
    "objectID": "class_slides.html",
    "href": "class_slides.html",
    "title": "Class Slides",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nCategories\n\n\n\n\n\n\n9/13/20\n\n\nModule_C\n\n\nundefined\n\n\n\n\n10/12/20\n\n\nModule_G\n\n\nundefined\n\n\n\n\n10/18/20\n\n\nModule_H\n\n\nundefined\n\n\n\n\n10/24/20\n\n\nModule_L\n\n\nundefined\n\n\n\n\n10/24/20\n\n\nModule_I\n\n\nundefined\n\n\n\n\n12/1/20\n\n\nModule_N\n\n\nundefined\n\n\n\n\n9/24/21\n\n\nModule_E\n\n\nundefined\n\n\n\n\n11/2/21\n\n\nModule_K\n\n\nundefined\n\n\n\n\n11/28/21\n\n\nModule M\n\n\nundefined\n\n\n\n\n11/28/22\n\n\nNHANES\n\n\nundefined\n\n\n\n\n1/8/23\n\n\nWelcome to BSTA 512/612!\n\n\nWeek 1\n\n\n\n\n1/8/23\n\n\nReview\n\n\nWeek 1\n\n\n\n\n1/10/23\n\n\nData Management with the tidyverse\n\n\nWeek 1\n\n\n\n\n1/12/23\n\n\nSimple Linear Regression (SLR)\n\n\nWeek 1\n\n\n\n\n1/12/23\n\n\nModule A\n\n\nWeek 1\n\n\n\n\n10/30/23\n\n\nModule_I\n\n\nundefined\n\n\n\n\nundefined\n\n\nundefined\n\n\nundefined\n\n\n\n\nundefined\n\n\nundefined\n\n\nundefined\n\n\n\n\nundefined\n\n\nundefined\n\n\nundefined\n\n\n\n\nundefined\n\n\nundefined\n\n\nundefined\n\n\n\n\nundefined\n\n\n{}\n\n\nundefined\n\n\n\n\nundefined\n\n\nundefined\n\n\nundefined\n\n\n\n\nundefined\n\n\nundefined\n\n\nundefined\n\n\n\n\nundefined\n\n\nundefined\n\n\nundefined\n\n\n\n\nundefined\n\n\nundefined\n\n\nundefined\n\n\n\n\nundefined\n\n\nundefined\n\n\nundefined\n\n\n\n\nundefined\n\n\n}$, where = = =&lt;/a&gt;\n\n\nundefined\n\n\n\n\nundefined\n\n\nundefined\n\n\nundefined\n\n\n\n\nundefined\n\n\nundefined\n\n\nundefined\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/12_Variance.html",
    "href": "slides/12_Variance.html",
    "title": "Chapter 12: Variance of Discrete r.v.’s - or, Expected Values of Functions of r.v.’s",
    "section": "",
    "text": "Question: What is \\(\\mathbb{E}[g(X)]\\) for a function \\(g\\) and discrete r.v. \\(X\\)?\n\n\nExample 1. Let \\(g(x) = ax+b\\), for real-valued constants \\(a\\) and \\(b\\). What is \\(\\mathbb{E}[g(X)]\\)?\n\nSolution:\n\n\nDefinition 2 (Expected value of a function of a r.v.).   For any function \\(g\\) and discrete r.v. \\(X\\), the expected value of \\(g(X)\\) is \\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\]\n\n\nExample 3. Suppose you draw 2 cards from a standard deck of cards with* replacement. Let \\(X\\) be the number of hearts you draw.*\n\nFind \\(\\mathbb{E}[X^2]\\).\nSolution:\nFind \\(\\mathbb{E}\\big[\\big(X-\\frac{1}{2}\\big)^2\\big]\\).\nSolution:\n\n\n\n\n\n\nDefinition 4 (Variance of a r.v.).   The variance of a r.v. \\(X\\), with (finite) expected value \\(\\mu_X=\\mathbb{E}[X]\\) is \\[\\sigma_X^2=Var(X)=\\mathbb{E}[(X-\\mu_X)^2] = \\mathbb{E}[(X-\\mathbb{E}[X])^2].\\]\n\n\nDefinition 5 (Standard deviation of a r.v.).   The standard deviation of a r.v. \\(X\\) is \\[\\sigma_X = SD(X) = \\sqrt{\\sigma_X^2}=\\sqrt{Var(X)}.\\]\n\n\nQuestions: Why do we square the difference in the variance definition? \\((X-\\mu_X)^2\\)\n\nWhy not define the measure of spread as \\(\\mathbb{E}[X-\\mu_X] = \\mathbb{E}[X-\\mathbb{E}[X]]\\)?\nWhy not use \\(\\mathbb{E}[|X-\\mu_X|]\\)?\n\n\nLemma 6 (\"Computation formula\" for Variance).   The variance of a r.v. \\(X\\), can be computed as \\[\\sigma_X^2=Var(X)=\\mathbb{E}[X^2]-\\mu_X^2 = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2.\\]\n\n\nProof. Proof. ◻\n\n\n\n\n\nLemma 7.   For a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), \\[Var(aX+b) = a^2Var(X).\\]\n\n\nProof. Proof. See homework. ◻\n\n\n\n\n\nTheorem 8.   For independent r.v.’s \\(X\\) and \\(Y\\), and functions \\(g\\) and \\(h\\), \\[\\mathbb{E}[g(X)h(Y)] = \\mathbb{E}[g(X)]\\mathbb{E}[h(Y)].\\]\n\n\nCorollary 1.   For independent r.v.’s \\(X\\) and \\(Y\\), \\[\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y].\\]\n\n\nProof. Proof of Theorem 8. ◻\n\n\nTheorem 9 (Variance of sum of independent discrete r.v.’s).   For independent discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Big(\\sum_{i=1}^n a_iX_i\\Big) = \\sum_{i=1}^n a_i^2Var(X_i).\\]\n\n\nCorollary 2.   For independent discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Big(\\sum_{i=1}^n X_i\\Big) = \\sum_{i=1}^n Var(X_i).\\]\n\n\nCorollary 3.   For independent identically (i.i.d.) discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Big(\\sum_{i=1}^n X_i\\Big) = n Var(X_1).\\]\n\n\nProof. Proof to Theorem 9. ◻\n\n\nExample 10. A tour group is planning a visit to the city of Landport and needs to book 30 hotel rooms. The average price of a room is $200 with standard deviation $10. In addition, there is a 10% tourism tax for each room. What is the standard deviation of the cost for the 30 hotel rooms?\n\nSolution:"
  },
  {
    "objectID": "slides/12_Variance.html#expected-values-of-functions-of-r.v.s",
    "href": "slides/12_Variance.html#expected-values-of-functions-of-r.v.s",
    "title": "Chapter 12: Variance of Discrete r.v.’s - or, Expected Values of Functions of r.v.’s",
    "section": "",
    "text": "Question: What is \\(\\mathbb{E}[g(X)]\\) for a function \\(g\\) and discrete r.v. \\(X\\)?\n\n\nExample 1. Let \\(g(x) = ax+b\\), for real-valued constants \\(a\\) and \\(b\\). What is \\(\\mathbb{E}[g(X)]\\)?\n\nSolution:\n\n\nDefinition 2 (Expected value of a function of a r.v.).   For any function \\(g\\) and discrete r.v. \\(X\\), the expected value of \\(g(X)\\) is \\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\]\n\n\nExample 3. Suppose you draw 2 cards from a standard deck of cards with* replacement. Let \\(X\\) be the number of hearts you draw.*\n\nFind \\(\\mathbb{E}[X^2]\\).\nSolution:\nFind \\(\\mathbb{E}\\big[\\big(X-\\frac{1}{2}\\big)^2\\big]\\).\nSolution:"
  },
  {
    "objectID": "slides/12_Variance.html#variance-of-a-r.v.",
    "href": "slides/12_Variance.html#variance-of-a-r.v.",
    "title": "Chapter 12: Variance of Discrete r.v.’s - or, Expected Values of Functions of r.v.’s",
    "section": "",
    "text": "Definition 4 (Variance of a r.v.).   The variance of a r.v. \\(X\\), with (finite) expected value \\(\\mu_X=\\mathbb{E}[X]\\) is \\[\\sigma_X^2=Var(X)=\\mathbb{E}[(X-\\mu_X)^2] = \\mathbb{E}[(X-\\mathbb{E}[X])^2].\\]\n\n\nDefinition 5 (Standard deviation of a r.v.).   The standard deviation of a r.v. \\(X\\) is \\[\\sigma_X = SD(X) = \\sqrt{\\sigma_X^2}=\\sqrt{Var(X)}.\\]\n\n\nQuestions: Why do we square the difference in the variance definition? \\((X-\\mu_X)^2\\)\n\nWhy not define the measure of spread as \\(\\mathbb{E}[X-\\mu_X] = \\mathbb{E}[X-\\mathbb{E}[X]]\\)?\nWhy not use \\(\\mathbb{E}[|X-\\mu_X|]\\)?\n\n\nLemma 6 (\"Computation formula\" for Variance).   The variance of a r.v. \\(X\\), can be computed as \\[\\sigma_X^2=Var(X)=\\mathbb{E}[X^2]-\\mu_X^2 = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2.\\]\n\n\nProof. Proof. ◻"
  },
  {
    "objectID": "slides/12_Variance.html#some-important-variance-and-expected-values-results",
    "href": "slides/12_Variance.html#some-important-variance-and-expected-values-results",
    "title": "Chapter 12: Variance of Discrete r.v.’s - or, Expected Values of Functions of r.v.’s",
    "section": "",
    "text": "Lemma 7.   For a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), \\[Var(aX+b) = a^2Var(X).\\]\n\n\nProof. Proof. See homework. ◻\n\n\n\n\n\nTheorem 8.   For independent r.v.’s \\(X\\) and \\(Y\\), and functions \\(g\\) and \\(h\\), \\[\\mathbb{E}[g(X)h(Y)] = \\mathbb{E}[g(X)]\\mathbb{E}[h(Y)].\\]\n\n\nCorollary 1.   For independent r.v.’s \\(X\\) and \\(Y\\), \\[\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y].\\]\n\n\nProof. Proof of Theorem 8. ◻\n\n\nTheorem 9 (Variance of sum of independent discrete r.v.’s).   For independent discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Big(\\sum_{i=1}^n a_iX_i\\Big) = \\sum_{i=1}^n a_i^2Var(X_i).\\]\n\n\nCorollary 2.   For independent discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Big(\\sum_{i=1}^n X_i\\Big) = \\sum_{i=1}^n Var(X_i).\\]\n\n\nCorollary 3.   For independent identically (i.i.d.) discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Big(\\sum_{i=1}^n X_i\\Big) = n Var(X_1).\\]\n\n\nProof. Proof to Theorem 9. ◻\n\n\nExample 10. A tour group is planning a visit to the city of Landport and needs to book 30 hotel rooms. The average price of a room is $200 with standard deviation $10. In addition, there is a 10% tourism tax for each room. What is the standard deviation of the cost for the 30 hotel rooms?\n\nSolution:"
  },
  {
    "objectID": "slides/37_Central_Limit_Theorem.html",
    "href": "slides/37_Central_Limit_Theorem.html",
    "title": "Ch 37: The Central Limit Theorem (CLT)",
    "section": "",
    "text": "Ch 37: The Central Limit Theorem (CLT)\n\nTheorem 1 (Central Limit Theorem (CLT)).  Let \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\hspace{-12cm} \\sum_{i=1}^n X_i \\rightarrow\\]\n\n\n\nCorollary 1.   Let \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\hspace{-12cm} \\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n}  \\rightarrow\\]\n\n\nExample 2.   According to a large US study, the mean resting heart rate of adult women is about 74 beats per minutes (bpm), with standard deviation 13 bpm (NHANES 2003-2004).\n\nFind the probability that the average resting heart rate for a random sample of 36 adult women is more than 3 bpm away from the mean.\nRepeat the previous question for a single adult woman.\n\n\n\nExample 3.   Let \\(X_i \\sim Exp(\\lambda)\\) be iid r.v.’s for \\(i=1,2,\\ldots,n\\). Then \\[\\hspace{-12cm} \\sum_{i=1}^n X_i \\rightarrow\\]\n\n\nCLT for Discrete rv’s\n\nBinomial rv’s: Let \\(X \\sim Bin(n,p)\\).\nPoisson rv’s: Let \\(X \\sim Poisson(\\lambda)\\).\n\n\nExample 4.   Suppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "slides/43_Moment_Generating_Functions_Part2.html",
    "href": "slides/43_Moment_Generating_Functions_Part2.html",
    "title": "Chapter 43: Moment Generating Functions Part 2",
    "section": "",
    "text": "Chapter 43: Moment Generating Functions Part 2\nRecap: What is an mgf?\n\nExample 1.   Let \\(X\\) be a random variable with mgf \\[M_X(t)= \\frac{1}{5}e^t + \\frac{3}{10}e^{2t} + \\frac{1}{2}e^{3t}.\\] Find the pmf or pdf of \\(X\\).\n\n\nExample 2.   Let \\(X\\) be a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), i.e. \\(X \\sim N(\\mu,\\sigma^2)\\).\n\nFind the mgf of \\(X\\).\nFind \\(\\mathbb{E}[X]\\).\nFind \\(Var(X)\\).\n\n\n\n\nTheorem 3.   Let \\(X\\) have mgf \\(M_X(t)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[M_Y(t)=\\]\n\n\nProof. Proof. ◻\n\nQuestion: Do linear transformations always preserve the distribution type?\nI.e., if \\(X\\) has a certain probability distribution, does \\(aX+b\\) always have the same distribution type?\n\n\nExample 4.   Let \\(X \\sim U[0,1]\\), and \\(Y = 2X+3\\). Is \\(Y\\) also a uniform rv? If so, what are its parameters?\n\n\nExample 5.   Let \\(X \\sim Exp(\\lambda=5)\\), and \\(Y = 2X+3\\). Is \\(Y\\) also an exponential rv? If so, what is its parameter?\n\nMgf’s of Sums of Independent rv’s\n\n\nTheorem 6.   Let \\(X_1, X_2, \\ldots, X_n\\) be independent rv’s with respective mgf’s \\(M_{X_i}(t)\\), for \\(i=1,2,\\ldots,n\\). Let \\(Y=\\sum_{i=1}^n a_iX_i\\), where \\(a_i\\) are constants. Then \\[M_Y(t)= %\\Pi_{i=1}^n M_{X_i}(a_it).\\]\n\n\nProof. Proof. ◻\n\n\n\nExample 7.   Let \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s. What is the distribution of  \\(Y=\\sum_{i=1}^n X_i\\)?\n\n\n\nExample 8.   Let \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). What is the distribution of  \\(\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n}\\)?\n\n\nExample 9.   Let \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\). Show that \\(Z^2 \\sim \\chi_1^2\\), i.e. is a chi-squared rv with 1 degree of freedom."
  },
  {
    "objectID": "slides/20_Discrete_Uniform_rv.html",
    "href": "slides/20_Discrete_Uniform_rv.html",
    "title": "Chapter 20: Discrete Uniform r.v.’s",
    "section": "",
    "text": "Chapter 20: Discrete Uniform r.v.’s\nScenario: There are \\(N\\) possible outcomes, which are all equally likely.\n\n\nExample 1. Examples of discrete uniform r.v.’s.\n\n\nProperties of discrete uniform r.v.’s"
  },
  {
    "objectID": "slides/24_Calculus_review.html",
    "href": "slides/24_Calculus_review.html",
    "title": "Calculus Review",
    "section": "",
    "text": "Example 1. Find the derivatives of the following functions.\n\n\\(f(x) = 2\\)\n\\(f(x) = 2x\\)\n\\(f(x) = 2x+2\\)\n\\(f(x) = x^2\\)\n\\(f(x) = 3\\sqrt{x}+\\frac2x+5\\)\n\\(f(x) = e^x\\)\n\\(f(x) = \\ln(x)\\)\n\\(f(x) = x^2 e^x\\)\n\\(f(x) = \\frac{x^5}{2x+7}\\)\n\\(f(x) = e^{-2x+7}\\)\n\\(f(x) = \\ln(x^2)\\)\n\n\n\n\n\n\n\n\nExample 2. Find the antiderivatives of the following functions.\n\n\\(f(x) = 2\\)\n\\(f(x) = x\\)\n\\(f(x) = \\frac1x\\)\n\\(f(x) = x^{3/2}\\)\n\\(f(x) = e^x\\)\n\\(f(x) = e^{-x}\\)\n\\(f(x) = e^{-2x}\\)\n\n\n\n\n\n\nExample 3. Solve the following integrals.\n\n\\(\\displaystyle\\int_0^1 (2x+x^5)dx\\)\n\\(\\displaystyle\\int_2^3 e^{-x}dx\\)\n\\(\\displaystyle\\int_2^3 x e^{x^2}dx\\)\n\\(\\displaystyle\\int_0^{\\infty} x e^{-x}dx\\)\n\\(\\displaystyle\\int_1^2 x^2 \\ln(x)dx\\)\n\\(\\displaystyle\\int_1^2 \\ln(x)dx\\)\n\\(\\displaystyle\\int_1^2 x^2 e^{x}dx\\)"
  },
  {
    "objectID": "slides/24_Calculus_review.html#differentiation",
    "href": "slides/24_Calculus_review.html#differentiation",
    "title": "Calculus Review",
    "section": "",
    "text": "Example 1. Find the derivatives of the following functions.\n\n\\(f(x) = 2\\)\n\\(f(x) = 2x\\)\n\\(f(x) = 2x+2\\)\n\\(f(x) = x^2\\)\n\\(f(x) = 3\\sqrt{x}+\\frac2x+5\\)\n\\(f(x) = e^x\\)\n\\(f(x) = \\ln(x)\\)\n\\(f(x) = x^2 e^x\\)\n\\(f(x) = \\frac{x^5}{2x+7}\\)\n\\(f(x) = e^{-2x+7}\\)\n\\(f(x) = \\ln(x^2)\\)"
  },
  {
    "objectID": "slides/24_Calculus_review.html#integration",
    "href": "slides/24_Calculus_review.html#integration",
    "title": "Calculus Review",
    "section": "",
    "text": "Example 2. Find the antiderivatives of the following functions.\n\n\\(f(x) = 2\\)\n\\(f(x) = x\\)\n\\(f(x) = \\frac1x\\)\n\\(f(x) = x^{3/2}\\)\n\\(f(x) = e^x\\)\n\\(f(x) = e^{-x}\\)\n\\(f(x) = e^{-2x}\\)\n\n\n\n\n\n\nExample 3. Solve the following integrals.\n\n\\(\\displaystyle\\int_0^1 (2x+x^5)dx\\)\n\\(\\displaystyle\\int_2^3 e^{-x}dx\\)\n\\(\\displaystyle\\int_2^3 x e^{x^2}dx\\)\n\\(\\displaystyle\\int_0^{\\infty} x e^{-x}dx\\)\n\\(\\displaystyle\\int_1^2 x^2 \\ln(x)dx\\)\n\\(\\displaystyle\\int_1^2 \\ln(x)dx\\)\n\\(\\displaystyle\\int_1^2 x^2 e^{x}dx\\)"
  },
  {
    "objectID": "slides/4_Conditional_Probability.html",
    "href": "slides/4_Conditional_Probability.html",
    "title": "Chapter 4: Conditional Probability",
    "section": "",
    "text": "Use set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "slides/4_Conditional_Probability.html#example",
    "href": "slides/4_Conditional_Probability.html#example",
    "title": "Chapter 4: Conditional Probability",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 4.2\n\n\nTwo dice (red and blue) are rolled. If the dice do not show the same face, what is the probability that one of the dice is a 1?\n\n\n\n\n\n\nChapter 4 Slides"
  },
  {
    "objectID": "slides/4_Conditional_Probability.html#conditional-probability-facts-12",
    "href": "slides/4_Conditional_Probability.html#conditional-probability-facts-12",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional Probability facts (1/2)",
    "text": "Conditional Probability facts (1/2)\n\n\n\n\nFact 1: General Multiplication Rule\n\n\n\\[\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\cdot\\mathbb{P}(B|A)\\]\n\n\n\n\n\nFact 2: Conditional Probability Definition\n\n\n\\[\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "slides/4_Conditional_Probability.html#conditional-probability-facts-22",
    "href": "slides/4_Conditional_Probability.html#conditional-probability-facts-22",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional Probability facts (2/2)",
    "text": "Conditional Probability facts (2/2)\n\n\n\n\nFact 3\n\n\nIf \\(A\\) and \\(B\\) are independent events (\\(A \\unicode{x2AEB}B\\)), then \\[\\mathbb{P}(A|B) = \\mathbb{P}(A)\\]\n\n\n\n\n\nFact 4\n\n\n\\(\\mathbb{P}(A|B)\\) is a probability, meaning that it satisfies the probability axioms. In particular, \\[\\mathbb{P}(A|B) + \\mathbb{P}(A^C|B) = 1\\]"
  },
  {
    "objectID": "slides/4_Conditional_Probability.html#example-1",
    "href": "slides/4_Conditional_Probability.html#example-1",
    "title": "Chapter 4: Conditional Probability",
    "section": "Example",
    "text": "Example\n\n\nExample 4.2\n\n\nTwo dice (red and blue) are rolled. If the dice do not show the same face, what is the probability that one of the dice is a 1?\n\n\nSolution:\n\n\nChapter 4 Slides"
  },
  {
    "objectID": "slides/14_Bernoulli_rv.html",
    "href": "slides/14_Bernoulli_rv.html",
    "title": "Chapter 14: Bernoulli r.v.’s",
    "section": "",
    "text": "Chapter 14: Bernoulli r.v.’s\nScenario: One trial, with outcome success or failure.\n\nProperties of Bernoulli r.v.’s\n\nExample 1.  \n\nWe roll a fair 6-sided die.\nWe get $1 if we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get.\nFind the mean and variance of \\(X\\).\n\n\nSolution:\n\n\nExample 2.  \n\nSuppose we roll a fair 6-sided die 50 times.\nWe get $1 every time we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get on the 50 rolls.\nFind the mean and variance of \\(X\\).\n\n\nSolution:"
  },
  {
    "objectID": "slides/36_Sums_of_Independent_Normal_rv.html",
    "href": "slides/36_Sums_of_Independent_Normal_rv.html",
    "title": "Chapter 36: Sums of Independent Normal Random Variables",
    "section": "",
    "text": "Chapter 36: Sums of Independent Normal Random Variables\n\nTheorem 1.   Let \\(X\\sim N(\\mu, \\sigma^2)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[\\hspace{-12cm} Y \\sim\\]\n\n\nProof. Proof. ◻\n\n\n\nTheorem 2.   Let \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\hspace{-12cm} \\sum_{i=1}^n X_i \\sim\\]\n\n\nProof. Proof. ◻\n\n\nSpecial Cases\n\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\hspace{-12cm} \\sum_{i=1}^n X_i \\sim\\]\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\hspace{-12cm} \\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n} \\sim\\]\nLet \\(X\\sim N(\\mu_X,\\sigma_X^2)\\), and \\(Y\\sim N(\\mu_Y,\\sigma_Y^2)\\). Then \\[\\hspace{-12cm} X-Y \\sim\\]\n\nProof. Proof. ◻\n\n\n\nExample 3.   Glaucoma is an eye disease that is manifested by high intraocular pressure (IOP). The distribution of IOP in the general population is approximately normal with mean 16 mmHg and standard deviation 3 mmHg.\n\nSuppose a patient has 40 IOP readings. What is the probability that their average reading is greater than 20.32 mmHg, assuming their eyes are healthy?\nRepeat the previous question for a patient with 10 IOP readings."
  },
  {
    "objectID": "slides/27_Conditional_distributions.html",
    "href": "slides/27_Conditional_distributions.html",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Chapter 27: Conditional Distributions\nWhat do we know about conditional probabilities and distributions for events and discrete r.v.’s?\n\n\nExample 1.   Let \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\).\n\n\n\n\nDefinition 2 (Conditional density). The conditional density of a r.v. \\(X\\) given \\(Y=y\\), is \\[f_{X|Y}(x|y)= \\frac{f_{X,Y}(x,y)}{f_Y(y)},\\] for \\(f_Y(y)&gt; 0\\).\n\nRemarks\n\nIt follows from the definition for the conditional density \\(f_{X|Y}(x|y)\\), that \\[f_{X,Y}(x,y)= f_{X|Y}(x|y)f_Y(y).\\]\nFor a fixed value of \\(Y=y\\), the conditional density \\(f_{X|Y}(x|y)\\) is an actual pdf, meaning\n\n\\(f_{X|Y}(x|y)\\geq 0\\) for all \\(x\\) and \\(y\\), and\n\\(\\displaystyle\\int_{-\\infty}^{\\infty} f_{X|Y}(x|y)dx =1\\).\n\n\nExample 1 cont’d Let \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\).\nFind \\(\\mathbb{P}(X&gt;20 |Y=5)\\).\n\n\nExample 3.   Randomly choose a point \\(X\\) from the interval \\([0,1]\\), and given \\(X=x\\), randomly choose a point \\(Y\\) from \\([0,x]\\). Find \\(\\mathbb{P}(0 &lt; Y &lt; \\frac14)\\).\n\n\nQuestion What is \\(f_{X|Y}(x|y)\\) if \\(X\\) and \\(Y\\) are independent?\n\nRemark If \\(f_{X|Y}(x|y)\\) does not depend on \\(y\\), then \\(X\\) and \\(Y\\) are independent."
  },
  {
    "objectID": "slides/7_Random_Variables.html",
    "href": "slides/7_Random_Variables.html",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "",
    "text": "Map the sample space to the set of real numbers using a discrete and continuous random variable\nDistinguish between discrete and continuous random variables from a written description"
  },
  {
    "objectID": "slides/7_Random_Variables.html#example",
    "href": "slides/7_Random_Variables.html#example",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Example",
    "text": "Example\n\nExample 1. Suppose we toss 3 fair coins.\n\nWhat is the sample space?\nWhat are the probabilities for each of the elements in the sample space?\n\n\nSolution:"
  },
  {
    "objectID": "slides/7_Random_Variables.html#definition",
    "href": "slides/7_Random_Variables.html#definition",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Definition",
    "text": "Definition\n\n\n\n\nExample 2\n\n\nWhat are some other random variables we could consider in Example 1?"
  },
  {
    "objectID": "slides/7_Random_Variables.html#slide-3",
    "href": "slides/7_Random_Variables.html#slide-3",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Slide 3",
    "text": "Slide 3\nRemarks:\n\nA random variable’s value is completely determined by the outcome \\(\\omega\\), where \\(\\omega \\in S\\). What is random is the outcome \\(\\omega\\).\nWe typically write \\(X\\) instead of \\(X(\\omega)\\)."
  },
  {
    "objectID": "slides/7_Random_Variables.html#slide-4",
    "href": "slides/7_Random_Variables.html#slide-4",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Slide 4",
    "text": "Slide 4\n\nExample 4. Let \\(X =\\) how many hours you slept last night.\n\nWhat is the sample space \\(S\\)?\nWhat is the range of possible values for \\(X\\)?\nWhat is \\(X(\\omega)\\)?\n\n\nSolution:"
  },
  {
    "objectID": "slides/7_Random_Variables.html#discrete-vs.-continuous-r.v.s",
    "href": "slides/7_Random_Variables.html#discrete-vs.-continuous-r.v.s",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Discrete vs. Continuous r.v.’s",
    "text": "Discrete vs. Continuous r.v.’s\n\nFor a discrete r.v., the set of possible values is either finite or can be put into a countably infinite list\n\nYou could theoretically list the specific possible outcomes that the variable can take\nIf you sum the rolls of three dice, you must get a whole number. For example, you can’t get any number between 3 and 4.\n\n\n   \n\nContinuous r.v.’s take on values from continuous intervals, or unions of continuous intervals\n\nVariable takes on a range of values, but there are infinitely possible values within the range\nIf you keep track of the time you sleep, you can sleep for 8 hours or 7.9 hours or 7.99 hours or 7.999 hours …\n\n\n\n\nChapter 7 Slides"
  },
  {
    "objectID": "slides/16_Geometric_rv.html",
    "href": "slides/16_Geometric_rv.html",
    "title": "Chapter 16: Geometric r.v.’s",
    "section": "",
    "text": "Chapter 16: Geometric r.v.’s\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the first success.\n\n\nExample 1.   We throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws until we hit the bullseye?\nSolution:\nWhat are the mean and variance for the number of throws until we hit the bullseye?\nSolution:\nFind the probability that our first bullseye:\n\nis on the fourth try\nSolution:\nis on one of the first four tries\nSolution:\nis after the fifth try\nSolution:\nis on one of the first fifty tries\nSolution:\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries.\nSolution:\n\nFind the expected number of misses until we hit the bullseye.\nSolution:"
  },
  {
    "objectID": "slides/9_joint_distributions.html",
    "href": "slides/9_joint_distributions.html",
    "title": "Chapter 9: Independence and Conditioning - or, Joint Distributions",
    "section": "",
    "text": "Definition 1. The joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]\n\n\nExample 2. Let \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\n\n\nSolution:\nRemarks: Some properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)\n\n\n\nDefinition 3. The joint cdf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]\n\n\n\nExample 4. Find the joint cdf \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\) in Example 2.\n\nSolution:\n\nExample 5. Find the marginal cdfs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\) for Example 4.\n\nSolution:\n\nRemark: Some properties of joint cdf’s:\nIndependence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]\n\nDefinition 6. The conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\).\n\nRemark: The following properties follow from the conditional pmf definition:\n\nExample 7. Using \\(X\\) and \\(Y\\) from Example 2:\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\nSolution:\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counterexample.\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\).\n\n\nExample 8. Hypothetical 4-sided die\n\nSuppose you have a 4-sided die, and you roll the 4-sided die until the first 4 appears.\nLet \\(X\\) be the number of rolls required until (and including) the first 4.\nAfter the first 4, you keep rolling it again until you roll a 3.\nLet \\(Y\\) be the number of rolls, after the first 4, required until (and including) the 3.\n\n\nFind \\(p_{X,Y}(x,y)\\).\nUsing \\(p_{X,Y}(x,y)\\), find \\(p_{Y}(y)\\).\nFind \\(p_{X}(x)\\).\nAre \\(X\\) and \\(Y\\) are independent? Why or why not?\nFind \\(F_{X,Y}(x,y)\\).\n\n\nSolution:\nExample 8 cont’d."
  },
  {
    "objectID": "slides/25_Joint_densities.html",
    "href": "slides/25_Joint_densities.html",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Chapter 25: Joint densities\nRecall from Chapter 24, that the probability distribution, or probability density function (pdf), of a continuous random variable \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx.\\]\n\nHow to define the joint pdf for continuous r.v.’s?\n\nRemarks:\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)\n\n\nDouble Integrals Mini Lesson\n\nExample 1.  Solve the following integrals.\n\n\\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)\n\\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)\n\\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)\n\n\n\nDefinition 2 (Joint cumulative distribution function).   The joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]\n\n\n\nDefinition 3 (Marginal pdf’s).   Suppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]\n\n\nExample 4.   Let \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\).\nFind \\(f_X(x)\\) and \\(f_Y(y)\\).\n\n\n\nExample 5.   Let \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\).\nFind \\(\\mathbb{P}(Y &lt; 3)\\).\n\n\n\nExample 6.   Let \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\).\nExample 6 continued.\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\).\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\).\n\n\n\nExample 7.   Let \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\).\n\nExample 7 solution continued."
  },
  {
    "objectID": "slides/22_Counting_Intro-solutions.html",
    "href": "slides/22_Counting_Intro-solutions.html",
    "title": "Chapter 22: Counting",
    "section": "",
    "text": "Example 1\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\nHow many possible ways are there to order them?\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\nHow many ways to order them if without replacements and only need 6?\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?\n\n\n\n\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\n\nExample 1.1\n\n\nHow many possible ways are there to order them?\n\n\n\\(10!\\)\n\n\nExample 1.2\n\n\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\n\n\n\nneed 10 total?\n\n\\(10^{10}\\)\n\nneed 6 total?\n\n\\(10^6\\)\n\n\n\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\n\nExample 1.3\n\n\nHow many ways to order them if without replacements and only need 6?\n\n\n\\[\\frac{10!}{4!}=151,200\\]\n\n\nExample 1.4\n\n\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?\n\n\n\\[\\frac{\\frac{10!}{4!}}{6!} = \\frac{10!}{4!6!}=210\\]\nThere are \\(6!\\) ways to order the 6 subjects."
  },
  {
    "objectID": "slides/22_Counting_Intro-solutions.html#basic-counting-examples-13",
    "href": "slides/22_Counting_Intro-solutions.html#basic-counting-examples-13",
    "title": "Chapter 22: Counting",
    "section": "Basic Counting Examples (1/3)",
    "text": "Basic Counting Examples (1/3)\n\n\nExample 1\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\nHow many possible ways are there to order them?\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\nHow many ways to order them if without replacements and only need 6?\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "slides/22_Counting_Intro-solutions.html#basic-counting-examples-23",
    "href": "slides/22_Counting_Intro-solutions.html#basic-counting-examples-23",
    "title": "Chapter 22: Counting",
    "section": "Basic Counting Examples (2/3)",
    "text": "Basic Counting Examples (2/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\nExample 1.1\n\n\nHow many possible ways are there to order them?\n\n\n\\(10!\\)\n\n\nExample 1.2\n\n\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\n\n\n\nneed 10 total?\n\n\\(10^{10}\\)\n\nneed 6 total?\n\n\\(10^6\\)"
  },
  {
    "objectID": "slides/22_Counting_Intro-solutions.html#basic-counting-examples-33",
    "href": "slides/22_Counting_Intro-solutions.html#basic-counting-examples-33",
    "title": "Chapter 22: Counting",
    "section": "Basic Counting Examples (3/3)",
    "text": "Basic Counting Examples (3/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\nExample 1.3\n\n\nHow many ways to order them if without replacements and only need 6?\n\n\n\\[\\frac{10!}{4!}=151,200\\]\n\n\nExample 1.4\n\n\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?\n\n\n\\[\\frac{\\frac{10!}{4!}}{6!} = \\frac{10!}{4!6!}=210\\]\nThere are \\(6!\\) ways to order the 6 subjects."
  },
  {
    "objectID": "slides/22_Counting_Intro-solutions.html#permutations-and-combinations-1",
    "href": "slides/22_Counting_Intro-solutions.html#permutations-and-combinations-1",
    "title": "Chapter 22: Counting",
    "section": "Permutations and Combinations",
    "text": "Permutations and Combinations\n\n\nDefinition: Permutations\n\n\nPermutations are the number of ways to arrange in order \\(r\\) distinct objects when there are \\(n\\) total.\n\\[nPr = \\frac{n!}{(n-r)!}\\]\n\n\n\n\nDefinition: Combinations\n\n\nCombinations are the number of ways to choose (order doesn’t matter) \\(r\\) objects from \\(n\\) without replacement.\n\\[nCr = \\textrm{\"n choose r\"} = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "slides/22_Counting_Intro-solutions.html#some-combinations-properties",
    "href": "slides/22_Counting_Intro-solutions.html#some-combinations-properties",
    "title": "Chapter 22: Counting",
    "section": "Some combinations properties",
    "text": "Some combinations properties\n\n\\[\\binom{n}{r} = \\binom{n}{n-r}\\]\n\\[\\binom{n}{1} = n\\]\n\\[\\binom{n}{0} = 1\\]"
  },
  {
    "objectID": "slides/22_Counting_Intro-solutions.html#more-examples-order-matters-vs.-not-12",
    "href": "slides/22_Counting_Intro-solutions.html#more-examples-order-matters-vs.-not-12",
    "title": "Chapter 22: Counting",
    "section": "More examples: order matters vs. not (1/2)",
    "text": "More examples: order matters vs. not (1/2)\n\n\nExample 2\n\n\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\norder doesn’t matter?"
  },
  {
    "objectID": "slides/22_Counting_Intro-solutions.html#more-examples-order-matters-vs.-not-22",
    "href": "slides/22_Counting_Intro-solutions.html#more-examples-order-matters-vs.-not-22",
    "title": "Chapter 22: Counting",
    "section": "More examples: order matters vs. not (2/2)",
    "text": "More examples: order matters vs. not (2/2)\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\n\n\\[\\frac{13P2}{52P2} = \\frac{\\frac{13!}{11!}}{\\frac{52!}{50!}} = \\frac{13\\cdot12}{52\\cdot51}\\]\n\norder doesn’t matter?\n\n\\[\\frac{\\binom{13}{2}}{\\binom{52}{2}} = \\frac{\\frac{13!}{2!11!}}{\\frac{52!}{2!50!}} = \\frac{13\\cdot12}{52\\cdot51}\\]"
  },
  {
    "objectID": "slides/22_Counting_Intro-solutions.html#table-of-different-cases",
    "href": "slides/22_Counting_Intro-solutions.html#table-of-different-cases",
    "title": "Chapter 22: Counting",
    "section": "Table of different cases",
    "text": "Table of different cases\nSee table on pg. 277 of textbook\n\n\\(n\\) = total number of objects\n\\(r\\) = number objects needed\n\n\n\n\n\n\n\n\n\nwith replacement\nwithout replacement\n\n\n\n\norder matters\n\\(n^r\\)\n\\(nPr = \\frac{n!}{(n-r)!}\\)\n\n\norder doesn’t matter\n\\(\\binom{n+r-1}{r}\\)\n\\(nCr = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\)\n\n\n\n\n\n\nChapter 22 Slides"
  },
  {
    "objectID": "slides/15_Binomial_rv.html",
    "href": "slides/15_Binomial_rv.html",
    "title": "Chapter 15: Binomial r.v.’s",
    "section": "",
    "text": "Chapter 15: Binomial r.v.’s\nScenario: There are \\(n\\) independent trials, each resulting in a success or failure, with constant probability in each trial. We are counting the number of successes (or failures).\n\nProperties of Binomial r.v.’s"
  },
  {
    "objectID": "slides/18_Poisson_rv.html",
    "href": "slides/18_Poisson_rv.html",
    "title": "Chapter 18: Poisson r.v.’s",
    "section": "",
    "text": "Chapter 18: Poisson r.v.’s\nScenario: We are counting the number of successes in a fixed time period, which has a constant rate of successes.\n\n\nRecall that if \\(X\\sim Binomial(n,p)\\), then\n\n\\(X\\) models the number of successes\nin \\(n\\) independent (Bernoulli) trials\nthat each have the same probability of success \\(p\\).\n\nPoisson r.v.’s are similar,\n\nexcept that instead of having \\(n\\) discrete independent trials,\nthere is a fixed time period during which the successes happen.\n\n\n\n\nExample 1.   Some examples of Poisson r.v.’s:\n\nNumber of visitors to an emergency room in an hour during a weekend night\nNumber of study participants enrolled in a study per week\nNumber of gun shootings in a square mile\n\n\n\nProperties of Poisson r.v.’s\n\nExample 2.   Suppose an emergency room has an average of 50 visitors per day. Find the following probabilities.\n\nProbability of 30 visitors in a day.\nSolution:\nProbability of 8 visitors in an hour.\nSolution:\nProbability of at least 8 visitors in an hour.\nSolution:\n\n\n\nExample 3.   Suppose emergency room 1 has an average of 50 visitors per day, and emergency room 2 has an average of 70 visitors per day, independently of each other. What is the probability distribution to model of the total number of visitors to both?\n\nSolution:\n\nTheorem 4.   If \\(X\\sim Poiss(\\lambda_1)\\) and \\(Y\\sim Poiss(\\lambda_2)\\) are independent of each other, then \\(Z=X+Y\\sim Poiss(\\lambda_1 + \\lambda_2)\\).\n\n\nPoisson vs. Binomial r.v.’s\nBoth Poisson and Binomial r.v.’s are counting the number of successes\n\nIf for a Binomial r.v.\n\nthe number of trials \\(n\\) is very large, and\nthe probability of success \\(p\\) is close to 0 or 1,\n\nthen the Poisson distribution can be used to approximate Binomial probabilities.\n\n\nExample 5.   Suppose that in the long run, errors in a medical testing lab are made 0.1% of the time. Find the probability that fewer than 4 mistakes are made in the next 2,000 tests.\n\nFind the probability using the Binomial distribution.\nApproximate the probability in part (1) using the Poisson distribution.\n\nSolution:"
  },
  {
    "objectID": "slides/19_Hypergeometric_rv.html",
    "href": "slides/19_Hypergeometric_rv.html",
    "title": "Chapter 19: Hypergeometric r.v.’s",
    "section": "",
    "text": "Chapter 19: Hypergeometric r.v.’s\nScenario: There are a fixed number of successes and failures (which are known in advance), from which we make \\(n\\) draws without replacement. We are counting the number of successes from the \\(n\\) trials.\n\n\nExample 1.   A wildlife biologist is using mark-recapture to research a wolf population. Suppose a specific study region is known to have 24 wolves, of which 11 have already been tagged. If 5 wolves are randomly captured, what is the probability that 3 of them have already been tagged?\nSolution:\n\n\nProperties of Hypergeometric r.v.’s\n\nThere is a finite population of \\(N\\) items.\nEach item in the population is either a success or a failure, and there are \\(M\\) successes total.\nWe randomly select (sample) \\(n\\) items from the population.\n\nHypergeometric vs. Binomial r.v.’s\nSuppose a hypergeometric r.v. \\(X\\) has the following properties:\n\nthe population size \\(N\\) is really big,\nthe number of successes \\(M\\) in the population is relatively large,\n\n\\(\\frac{M}{N}\\) shouldn’t be close to 0 or 1\n\nand the number of items \\(n\\) selected is small.\n\nThen, in this case, making \\(n\\) draws from the population doesn’t change the probability of success much, and the hypergeometric r.v. can be approximated by a binomial r.v.\n\nExample 2.   Suppose a specific study region is known to have 2400 wolves, of which 1100 have already been tagged.\n\nIf 50 wolves are randomly captured, what is the probability that 20 of them have already been tagged?\nApproximate the probability in part (1) using the binomial distribution.\n\nSolution:"
  },
  {
    "objectID": "instructors.html",
    "href": "instructors.html",
    "title": "Instructors",
    "section": "",
    "text": "Email: wakim@ohsu.edu\nOffice: VPT 622A\n\nPronouns: she/her/hers\nYou are welcome to address me as Nicky (pronounced “nik-EE”), Dr. Wakim (pronounced “wah-KEEM”), Dr. W, Dr. Nicky, Professor, Professor Wakim, or any combination of the prior.\nBest method to contact: Office hours or Slack for general course questions or E-mail/Calendly appointments for private communication.\n\n\n\n\n\n\n\n\n\n\nBrief professor statement: As a professor, my main goal is to instill a growth mindset into my students. Growth mindset means we are NOT stuck in our abilities or knowledge, and that we all can and will grow! This course aims to be as transparent as possible. I want you to understand my motivation for assessments, questions, and lessons. I also want those assessments to be clear, so please ask for clarification whenever needed.\n\n\nLink to Webex!!\n\nThursdays, 11:30am - 1pm\nExceptions:\n\nJanuary 25th: 10:30am - 12pm\nFebruary 22nd: 10:30am - 12pm"
  },
  {
    "objectID": "instructors.html#instructor-nicole-nicky-wakim-phd",
    "href": "instructors.html#instructor-nicole-nicky-wakim-phd",
    "title": "Instructors",
    "section": "",
    "text": "Email: wakim@ohsu.edu\nOffice: VPT 622A\n\nPronouns: she/her/hers\nYou are welcome to address me as Nicky (pronounced “nik-EE”), Dr. Wakim (pronounced “wah-KEEM”), Dr. W, Dr. Nicky, Professor, Professor Wakim, or any combination of the prior.\nBest method to contact: Office hours or Slack for general course questions or E-mail/Calendly appointments for private communication.\n\n\n\n\n\n\n\n\n\n\nBrief professor statement: As a professor, my main goal is to instill a growth mindset into my students. Growth mindset means we are NOT stuck in our abilities or knowledge, and that we all can and will grow! This course aims to be as transparent as possible. I want you to understand my motivation for assessments, questions, and lessons. I also want those assessments to be clear, so please ask for clarification whenever needed.\n\n\nLink to Webex!!\n\nThursdays, 11:30am - 1pm\nExceptions:\n\nJanuary 25th: 10:30am - 12pm\nFebruary 22nd: 10:30am - 12pm"
  },
  {
    "objectID": "instructors.html#teaching-assistants",
    "href": "instructors.html#teaching-assistants",
    "title": "Instructors",
    "section": "Teaching Assistants",
    "text": "Teaching Assistants\nAntara and Ariel were great students in my BSTA 513 class last year! They will have the following office hours and will help answer questions on Slack.\n\nAntara Vidyarthi\nLink to Zoom!!\n\nWednesdays, 4:30 - 6 pm\n\n\n\nAriel Weingarten\nLink to Webex!!\n\nTuesdays, 2:30 - 4 pm"
  },
  {
    "objectID": "schedule/week_02_sched.html",
    "href": "schedule/week_02_sched.html",
    "title": "Week 2",
    "section": "",
    "text": "```{css, echo=FALSE} .title{ font-size: 40px; color: #006a4e; background-color: #fff; padding: 10px; }\n.description{ font-size: 20px; color: #fff; background-color: #006a4e; padding: 10px; } ```"
  },
  {
    "objectID": "schedule/week_02_sched.html#resources",
    "href": "schedule/week_02_sched.html#resources",
    "title": "Week 2",
    "section": "Resources",
    "text": "Resources\nBelow is a table with links to resources. Icons in orange mean there is an available file link.\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n3\nIndependent Events\n\n\n\n\n\n4\nConditional Probability\n\n\n\n\n\n6\nBayes’ Theorem\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "schedule/week_02_sched.html#post-class",
    "href": "schedule/week_02_sched.html#post-class",
    "title": "Week 2",
    "section": "Post Class",
    "text": "Post Class\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_02_sched.html#muddiest-points",
    "href": "schedule/week_02_sched.html#muddiest-points",
    "title": "Week 2",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_02_sched.html#clearest-points",
    "href": "schedule/week_02_sched.html#clearest-points",
    "title": "Week 2",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_02_sched.html#additional-information",
    "href": "schedule/week_02_sched.html#additional-information",
    "title": "Week 2",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "schedule/week_04_sched.html",
    "href": "schedule/week_04_sched.html",
    "title": "Week 4",
    "section": "",
    "text": "Resource\nInformation and Links\n\n\n\n\nReadings and Code\nExpected values of discrete random variables (Chapter 10 and 11)\n\n\nSlides\n\n\n\nClass Notes\n\n\n\nData\n\n\n\nHomework"
  },
  {
    "objectID": "schedule/week_04_sched.html#resources",
    "href": "schedule/week_04_sched.html#resources",
    "title": "Week 4",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n10\nExpected Values of discrete RVs\n\n\n\n\n\n11\nExpected Values of sums of discrete RVs\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "schedule/week_04_sched.html#post-class",
    "href": "schedule/week_04_sched.html#post-class",
    "title": "Week 4",
    "section": "Post Class",
    "text": "Post Class\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_04_sched.html#muddiest-points",
    "href": "schedule/week_04_sched.html#muddiest-points",
    "title": "Week 4",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_04_sched.html#clearest-points",
    "href": "schedule/week_04_sched.html#clearest-points",
    "title": "Week 4",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_04_sched.html#additional-information",
    "href": "schedule/week_04_sched.html#additional-information",
    "title": "Week 4",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "schedule/week_03_sched.html",
    "href": "schedule/week_03_sched.html",
    "title": "Week 3",
    "section": "",
    "text": "Resource\nInformation and Links\n\n\n\n\nReadings and Code\nRandom Variables (Chapter 7)\nPMF and CDF (Chapter 8)\nIndependence and Conditioning (Chapter 9)\n\n\nSlides\n\n\n\nClass Notes\n\n\n\nData\n\n\n\nHomework"
  },
  {
    "objectID": "schedule/week_03_sched.html#resources",
    "href": "schedule/week_03_sched.html#resources",
    "title": "Week 3",
    "section": "Resources",
    "text": "Resources\nBelow is a table with links to resources. Icons in orange mean there is an available file link.\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n7\nRandom Variables\n\n\n\n\n\n8\nPMF and CDF\n\n\n\n\n\n9\nIndependence and Conditioning\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "schedule/week_03_sched.html#post-class",
    "href": "schedule/week_03_sched.html#post-class",
    "title": "Week 3",
    "section": "Post Class",
    "text": "Post Class\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_03_sched.html#muddiest-points",
    "href": "schedule/week_03_sched.html#muddiest-points",
    "title": "Week 3",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_03_sched.html#clearest-points",
    "href": "schedule/week_03_sched.html#clearest-points",
    "title": "Week 3",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_03_sched.html#additional-information",
    "href": "schedule/week_03_sched.html#additional-information",
    "title": "Week 3",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "schedule/week_11_sched.html",
    "href": "schedule/week_11_sched.html",
    "title": "Week 11",
    "section": "",
    "text": "Resource\nInformation and Links\n\n\n\n\nReadings and Code\nFinal Exam!! (12/6)\n\n\nSlides\n\n\n\nClass Notes\n\n\n\nData\n\n\n\nHomework"
  },
  {
    "objectID": "schedule/week_11_sched.html#resources",
    "href": "schedule/week_11_sched.html#resources",
    "title": "Week 11",
    "section": "Resources",
    "text": "Resources\nFinal exam week!"
  },
  {
    "objectID": "schedule/week_11_sched.html#post-class",
    "href": "schedule/week_11_sched.html#post-class",
    "title": "Week 11",
    "section": "Post Class",
    "text": "Post Class\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_11_sched.html#muddiest-points",
    "href": "schedule/week_11_sched.html#muddiest-points",
    "title": "Week 11",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_11_sched.html#clearest-points",
    "href": "schedule/week_11_sched.html#clearest-points",
    "title": "Week 11",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_11_sched.html#additional-information",
    "href": "schedule/week_11_sched.html#additional-information",
    "title": "Week 11",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "schedule/week_06_sched.html",
    "href": "schedule/week_06_sched.html",
    "title": "Week 6",
    "section": "",
    "text": "Resource\nInformation and Links\n\n\n\n\nReadings and Code\nCommon families of discrete distributions (Chapter 17 and 18)\n\n\nSlides\n\n\n\nClass Notes\n\n\n\nData\n\n\n\nHomework"
  },
  {
    "objectID": "schedule/week_06_sched.html#resources",
    "href": "schedule/week_06_sched.html#resources",
    "title": "Week 6",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n17\nNegative Binomial RV\n\n\n\n\n\n18\nPoisson RV\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "schedule/week_06_sched.html#post-class",
    "href": "schedule/week_06_sched.html#post-class",
    "title": "Week 6",
    "section": "Post Class",
    "text": "Post Class\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_06_sched.html#muddiest-points",
    "href": "schedule/week_06_sched.html#muddiest-points",
    "title": "Week 6",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_06_sched.html#clearest-points",
    "href": "schedule/week_06_sched.html#clearest-points",
    "title": "Week 6",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_06_sched.html#additional-information",
    "href": "schedule/week_06_sched.html#additional-information",
    "title": "Week 6",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "schedule/week_07_sched.html",
    "href": "schedule/week_07_sched.html",
    "title": "Week 7",
    "section": "",
    "text": "Resource\nInformation and Links\n\n\n\n\nReadings and Code\nContinuous random variables and PDFs (Chapter 24)\nJoint Densities (Chapter 25)\n\n\nSlides\n\n\n\nClass Notes\n\n\n\nData\n\n\n\nHomework"
  },
  {
    "objectID": "schedule/week_07_sched.html#resources",
    "href": "schedule/week_07_sched.html#resources",
    "title": "Week 7",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n24\nContinuous RVs and PDFs\n\n\n\n\n\n25\nJoint Densities\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "schedule/week_07_sched.html#post-class",
    "href": "schedule/week_07_sched.html#post-class",
    "title": "Week 7",
    "section": "Post Class",
    "text": "Post Class\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_07_sched.html#muddiest-points",
    "href": "schedule/week_07_sched.html#muddiest-points",
    "title": "Week 7",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_07_sched.html#clearest-points",
    "href": "schedule/week_07_sched.html#clearest-points",
    "title": "Week 7",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_07_sched.html#additional-information",
    "href": "schedule/week_07_sched.html#additional-information",
    "title": "Week 7",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "homeworks.html",
    "href": "homeworks.html",
    "title": "Homework Assignments and Solutions",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n1/11/24\n\n\nHomework 0\n\n\n4 min\n\n\n\n\n1/18/24\n\n\nHomework 1\n\n\n6 min\n\n\n\n\n2/1/24\n\n\nHomework 2\n\n\n7 min\n\n\n\n\n2/15/24\n\n\nHomework 3\n\n\n9 min\n\n\n\n\n2/22/24\n\n\nHomework 4\n\n\n4 min\n\n\n\n\n3/7/24\n\n\nHomework 5\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "readings.html",
    "href": "readings.html",
    "title": "612 Readings",
    "section": "",
    "text": "These reading assignments are for 612 students only. 612 students, you must complete all the readings by 3/22. I have included some recommended due dates that will keep you on track if you would like.\n\n\n\nReading\nRecommended Due Date\nLink to Sakai\nArticle\n\n\n\n\n1\n1/21 @ 11pm\n\n\n\n\n2\n2/4 @ 11pm\n\n\n\n\n3\n2/18 @ 11pm\n\n\n\n\n4\n2/25 @ 11pm\n\n\n\n\n5\n3/10 @ 11pm\n\n\n\n\n\n\nInstructions for each assignment\nFor each reading assignment, students will write a summary including:\n\nstudy background,\nwhy the author think the research important,\nstatistical methods used to address the research question,\nand a discussion/critique on whether you agree or disagree with the authors’  science and statistics.\n\nYou may write complete sentences under each bullet point. Please keep your summary to less than 1 page (margins are up to you). There are no requirements on formatting for references."
  },
  {
    "objectID": "schedule/week_01_sched.html#resources",
    "href": "schedule/week_01_sched.html#resources",
    "title": "Week 1",
    "section": "Resources",
    "text": "Resources\nBelow is a table with links to resources. Icons in orange mean there is an available file link.\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording(s)\n\n\n\n\n\nIntro\n\n\n\n\n\n1\nOutcomes, Events, and Sample Space\n\n\n\n\n\n2\nProbability\n\n\n\n\n\n22\nIntroduction to Counting\n\n\n\n\n\n23\nCase Study on Counting\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "schedule/week_01_sched.html#homework",
    "href": "schedule/week_01_sched.html#homework",
    "title": "Week 1",
    "section": "Homework",
    "text": "Homework\nHomework 1 due 10/5"
  },
  {
    "objectID": "schedule/week_01_sched.html#post-class",
    "href": "schedule/week_01_sched.html#post-class",
    "title": "Week 1",
    "section": "Post Class",
    "text": "Post Class\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_01_sched.html#statistician-of-the-week-regina-nuzzo",
    "href": "schedule/week_01_sched.html#statistician-of-the-week-regina-nuzzo",
    "title": "Week 1",
    "section": "Statistician of the Week: Regina Nuzzo",
    "text": "Statistician of the Week: Regina Nuzzo\n\n\n\n\n\n\n\nRegina Nuzzo\n\n\n\n\n\n\nDr. Nuzzo received her PhD in Statistics from Stanford University and is now Professor of Science, Technology, & Mathematics at Gallaudet University. Gallaudet University, federally funded and located in Washington, DC, is the only higher education institution where all programs are designed for the education of the deaf and hard of hearing. Dr. Nuzzo teaches statistics using American Sign Language.\nShe is the Senior Advisor for Statistics Communication and Media Innovation at the American Statistical Association and a freelance writer.\n\n\n\nTopics covered\nDr. Nuzzo is a statistician and a science journalist. Her work has appeared in Nature, Los Angeles Times, New York Times, Reader’s Digest, New Scientist, and Scientific American. Most of her work is in the “Health” or “Science” sections of the aforementioned outlets. Primarily, she works to help lay-audiences understand science and statistics in particular. She earned the American Statistical Association’s 2014 Excellence in Statistical Reporting Award for her article on p-values in Nature. Her work led to the ASA’s statement on p-values.\n\n\nRelevant work\n\nNuzzo, R. “Scientific method: Statistical errors.” Nature 506, 150–152 (2014).\nNuzzo, R. “Tips for Communicating Statistical Significance.” Science, Health, and Public Trust, National Institutes of Health, 2018.\nNuzzo, R. “Vying for a soul mate? Psych out the competition with science.” Health: Features. Los Angeles Times, 2008.\n\n\n\nOutside links\n\nWikipedia\nacademic\nLinkedin\npersonal\n\nPlease note the statisticians of the week are taken directly from the CURV project by Jo Hardin. I also invite you to check out this youtube video of her Women Rise Keynote address where she discusses her hearing impairment, career growth, and her work with p-values."
  },
  {
    "objectID": "schedule/week_01_sched.html#muddiest-points",
    "href": "schedule/week_01_sched.html#muddiest-points",
    "title": "Week 1",
    "section": "Muddiest Points",
    "text": "Muddiest Points\n\n1. Why is the number of possible events \\(2^{|S|}\\)?\nIn class, we were wondering why/if \\(2^{|S|}\\) is the general formula for calculating the total number of possible events. We were specifically wondering if the \\(2\\) came from the fact that we had two options (heads and tails) for our outcome. Let’s work through the example of a 6-sided die to explain this further. The sample space is \\(S=\\{1, 2, 3, 4, 5, 6\\}\\). So is the total number of possible events \\(2^6\\) or \\(6^6\\) or something else? We can actually think about an event by using an indicator variable for each outcome of the sample space. An indicator variable is just a way to give us a yes/no answer to a question. So in this case, we are wondering: is this outcome a part of our event? If our event is \\(\\{1\\}\\) then for the outcome \\(1\\), the answer is “yes, the outcome is part of the event. For outcomes \\(2-6\\), the answer is”no, the outcome is not apart of the event.”\n\nFor each outcome, we have a “yes” or “no” answer. We can look at another example of an event. Let’s say our event is rolling an even number:\n\nFor \\(2\\), \\(4\\), and \\(6\\), the answer is “yes.” We can define the indicator variable for whether an outcome is in an event or not. The indicator gives a 1 or 0 for yes and no respectively.\n\nAs stated above, the \\(2\\) in \\(2^6\\) comes from the \\(2\\) options from our indicator. Each side has two options, and there are \\(6\\) sides. Thus, \\(2^6\\) possible events.\n\n\n2. What is an event??\nI think this will become clearer when we start thinking about events in the context of probability. When we think of events outside of probability, we may think of something we actually do or something that happens, like going to a concert or coming to class or missing the streetcar. In this case, we think of the event as the single thing (out of all the options) that actually occured. For example, if I’m taking the streetcar to class, I can think of two definitive options of what might occur: I miss the streetcar or I get on the streetcar. Only one of these things can occur, which I may call an event colloquially.\nIt is important to make the distinction with events defined within probability. Events are not necessarily a single thing that occurred. Instead it can be a collection of things that may occur. In the example of the streetcar, I can define my event to include both options. Thus, my event is that I make the streetcar or I miss it. Both of these things cannot happen simultaneously, but if I want to calculate the probability that I miss or make the streetcar, then it is helpful to have the event defined."
  },
  {
    "objectID": "schedule/week_01_sched.html#clearest-points",
    "href": "schedule/week_01_sched.html#clearest-points",
    "title": "Week 1",
    "section": "Clearest Points",
    "text": "Clearest Points\nMostly: heads/tails example, sample space, how to draw a quarter, possible events for two coins."
  },
  {
    "objectID": "schedule/week_01_sched.html#additional-information",
    "href": "schedule/week_01_sched.html#additional-information",
    "title": "Week 1",
    "section": "Additional Information",
    "text": "Additional Information\nAs we start the course, here are some administrative items that we need to do:\n\nPlease join the Slack page\nPlease read the syllabus on your own time\n\n\nExtra Practice/Learning\n\nIf you would like a Calculus review, please see this page!\nCombinatorics practice problems\n\nhandout (& answers)\nTry to complete as many of these as you can before class on Wednesday.\nWe will discuss some of them Wednesday in class.\n\nPixar has a series of videos explaining how they use combinatorics in making animations\n\nThis is a great & fun introduction to the basic principles of counting\nI highly recommend looking at them, especially if you have not studied permutations and combinations before.\n\nThere is a table on p. 277 of the book with formulas for 4 different common counting cases (does order matter (y/n) vs. sampling with replacement (y/n).\n\nIn class we covered all cases except “order does not matter and sampling with replacement.”\n\nThis case is often referred to as the “stars and bars” problem.\nSee this page for a proof to the Stars and Bars Theorem.\n\nNote: Their notation is opposite of what our textbook uses. The website uses k instead of n and n instead of r."
  },
  {
    "objectID": "schedule/week_08_sched.html",
    "href": "schedule/week_08_sched.html",
    "title": "Week 8",
    "section": "",
    "text": "```{css, echo=FALSE} .title{ font-size: 40px; color: #006a4e; background-color: #fff; padding: 10px; }\n.description{ font-size: 20px; color: #fff; background-color: #006a4e; padding: 10px; } ```"
  },
  {
    "objectID": "schedule/week_08_sched.html#resources",
    "href": "schedule/week_08_sched.html#resources",
    "title": "Week 8",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n25\nJoint PDFs\n\n\n\n\n\n26\nIndependent continuous random variables\n\n\n\n\n\n27\nConditional distributions\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "schedule/week_08_sched.html#post-class",
    "href": "schedule/week_08_sched.html#post-class",
    "title": "Week 8",
    "section": "Post Class",
    "text": "Post Class\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_08_sched.html#muddiest-points",
    "href": "schedule/week_08_sched.html#muddiest-points",
    "title": "Week 8",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_08_sched.html#clearest-points",
    "href": "schedule/week_08_sched.html#clearest-points",
    "title": "Week 8",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_08_sched.html#additional-information",
    "href": "schedule/week_08_sched.html#additional-information",
    "title": "Week 8",
    "section": "Additional Information",
    "text": "Additional Information\n\nExtra Practice/Learning"
  },
  {
    "objectID": "schedule/week_05_sched.html",
    "href": "schedule/week_05_sched.html",
    "title": "Week 5",
    "section": "",
    "text": "Resource\nInformation and Links\n\n\n\n\nReadings and Code\nVariance of discrete random variables (Chapter 12-16)\nCommon families of discrete distributions (Chapter 19 and 20)\n\n\nSlides\n\n\n\nClass Notes\n\n\n\nData\n\n\n\nHomework"
  },
  {
    "objectID": "schedule/week_05_sched.html#resources",
    "href": "schedule/week_05_sched.html#resources",
    "title": "Week 5",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n12\nVariance of discrete RVs\n\n\n\n\n\n13\n\n\n\n\n\n\n14\nBernoulli RV\n\n\n\n\n\n15\nBinomial RV\n\n\n\n\n\n16\nGeometric RV\n\n\n\n\n\n19\nHypergeometric RV\n\n\n\n\n\n20\nDiscrete Uniform RV\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "schedule/week_05_sched.html#post-class",
    "href": "schedule/week_05_sched.html#post-class",
    "title": "Week 5",
    "section": "Post Class",
    "text": "Post Class\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_05_sched.html#muddiest-points",
    "href": "schedule/week_05_sched.html#muddiest-points",
    "title": "Week 5",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_05_sched.html#clearest-points",
    "href": "schedule/week_05_sched.html#clearest-points",
    "title": "Week 5",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_05_sched.html#additional-information",
    "href": "schedule/week_05_sched.html#additional-information",
    "title": "Week 5",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "schedule/week_09_sched.html",
    "href": "schedule/week_09_sched.html",
    "title": "Week 9",
    "section": "",
    "text": "Resource\nInformation and Links\n\n\n\n\nReadings and Code\nExpect value and variance of continuous random variables (Chapter 28-30)\nCommon families of continuous distributions (Chapter 31-33, 35)\n\n\nSlides\n\n\n\nClass Notes\n\n\n\nData\n\n\n\nHomework"
  },
  {
    "objectID": "schedule/week_09_sched.html#resources",
    "href": "schedule/week_09_sched.html#resources",
    "title": "Week 9",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n28\nExpected value of continuous RVs\n\n\n\n\n\n29\nVariance of continuous RVs\n\n\n\n\n\n31\nUniform RV\n\n\n\n\n\n32\nExponential RV\n\n\n\n\n\n33\nGamma RV\n\n\n\n\n\n35\nNormal RV\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "schedule/week_09_sched.html#post-class",
    "href": "schedule/week_09_sched.html#post-class",
    "title": "Week 9",
    "section": "Post Class",
    "text": "Post Class\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_09_sched.html#muddiest-points",
    "href": "schedule/week_09_sched.html#muddiest-points",
    "title": "Week 9",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_09_sched.html#clearest-points",
    "href": "schedule/week_09_sched.html#clearest-points",
    "title": "Week 9",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_09_sched.html#additional-information",
    "href": "schedule/week_09_sched.html#additional-information",
    "title": "Week 9",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "schedule/week_10_sched.html",
    "href": "schedule/week_10_sched.html",
    "title": "Week 10",
    "section": "",
    "text": "Resource\nInformation and Links\n\n\n\n\nReadings and Code\nMoment generating functions (Chapter 43)\nSums of independent normal random variables (Chapter 36)\nCentral limit theorem (Chapter 37)\n\n\nSlides\n\n\n\nClass Notes\n\n\n\nData\n\n\n\nHomework"
  },
  {
    "objectID": "schedule/week_10_sched.html#resources",
    "href": "schedule/week_10_sched.html#resources",
    "title": "Week 10",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n43\nMoment generating functions\n\n\n\n\n\n36\nSums of independent normal random variables\n\n\n\n\n\n37\nCentral limit theorem\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "schedule/week_10_sched.html#post-class",
    "href": "schedule/week_10_sched.html#post-class",
    "title": "Week 10",
    "section": "Post Class",
    "text": "Post Class\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_10_sched.html#muddiest-points",
    "href": "schedule/week_10_sched.html#muddiest-points",
    "title": "Week 10",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_10_sched.html#clearest-points",
    "href": "schedule/week_10_sched.html#clearest-points",
    "title": "Week 10",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "schedule/week_10_sched.html#additional-information",
    "href": "schedule/week_10_sched.html#additional-information",
    "title": "Week 10",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "slides/33_Gamma_rv.html",
    "href": "slides/33_Gamma_rv.html",
    "title": "Chapter 33: Gamma Random Variables",
    "section": "",
    "text": "Chapter 33: Gamma Random Variables\nScenario: Modeling the time until the \\(r^{th}\\) event.\n\nProperties of gamma r.v.’s\nRemarks\n\nThe parameter \\(r\\) in a Gamma(\\(r\\),\\(\\lambda\\)) distribution doesn’t have to be a positive integer (\\(\\mathbb{Z}^{+}\\)).\nWhen \\(r\\in \\mathbb{Z}^{+}\\), the distribution is sometimes called an Erlang(\\(r\\),\\(\\lambda\\)) distribution.\nWhen \\(r\\) is any positive real number, we have a general gamma distribution that is usually instead parameterized by \\(\\alpha&gt;0\\) and \\(\\beta&gt;0\\), where:\n\n= shape parameter\n= scale parameter"
  },
  {
    "objectID": "slides/43_Moment_Generating_Functions_Part1.html",
    "href": "slides/43_Moment_Generating_Functions_Part1.html",
    "title": "Chapter 43: Moment Generating Functions Part 1",
    "section": "",
    "text": "Chapter 43: Moment Generating Functions Part 1\n\nWhat are moments?\n\n\nDefinition 1.   The \\(j^{th}\\) moment of a r.v. \\(X\\) is \\(\\mathbb{E}[X^j]\\).\n\n\nExample 2.   \\(1^{st}-4^{th}\\) moments.\n\n\n\nWhat is a moment generating function (mgf)?\n\n\nDefinition 3.   If \\(X\\) is a r.v., then \\[M_X(t)= \\mathbb{E}[e^{tX}]\\] is the moment generating function (mgf) associated with \\(X\\).\n\nRemarks\n\nFor a discrete r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\sum_{all \\ x}e^{tx}p_X(x)\\]\nFor a continuous r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\int_{-\\infty}^{\\infty}e^{tx}f_X(x)dx\\]\nThe mgf \\(M_X(t)\\) is a function of \\(t\\), not of \\(X\\), and it might not be defined (i.e. finite) for all values of \\(t\\). We just need it to be defined for \\(t=0\\).\n\n\nExample 4.   What is \\(M_X(t)\\) for \\(t=0\\)?\n\n\n\nTheorem 5.   The moment generating function uniquely specifies a probability distribution.\n\n\nTheorem 6.   \\[\\mathbb{E}[X^r] = M_X^{(r)}(0)\\]\n\n\nProof. Proof. ◻\n\n\nExample 7.   Let \\(X \\sim Poisson(\\lambda)\\).\n\nFind the mgf of \\(X\\).\nFind \\(\\mathbb{E}[X]\\).\nFind \\(Var(X)\\).\n\n\nRemark\nFinding the mean and variance is sometimes easier with the following trick.\n\nTheorem 8. Let \\[R_X(t) = \\ln[M_X(t)]\\]\nThen,\n\\[\\mu = \\mathbb{E}[X] = R_X'(0)\\] and \\[\\sigma^2 = Var(X) = R_X''(0)\\]\n\n\nProof. Proof. ◻\n\n\n\nExample 9.   Let \\(X \\sim Poisson(\\lambda)\\).\n\nFind \\(\\mathbb{E}[X]\\) using \\(R_X(t)\\).\nFind \\(Var(X)\\) using \\(R_X(t)\\).\n\n\n\nExample 10.   Let \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\).\nFind \\(\\mathbb{E}[Z]\\).\nFind \\(Var(Z)\\)."
  },
  {
    "objectID": "slides/31_Uniform_rv.html",
    "href": "slides/31_Uniform_rv.html",
    "title": "Chapter 31: Continuous Uniform Random Variables",
    "section": "",
    "text": "Chapter 31: Continuous Uniform Random Variables\nScenario: Events are equally likely to happen anywhere or anytime in an interval of values.\n\nProperties of continuous uniform r.v.’s"
  },
  {
    "objectID": "slides/10_Expected_Values.html",
    "href": "slides/10_Expected_Values.html",
    "title": "Chapter 10 Expected Values of Discrete r.v.’s",
    "section": "",
    "text": "Chapter 10 Expected Values of Discrete r.v.’s\n::: {#Die expected outcome .example} Example 1. Suppose you roll a fair 6-sided die. What value do you expect to get? :::\nSolution:\n\n::: {#Die expected outcome .example} Example 2. Suppose the die is 6-sided, but not fair. What value do you expect to get on a roll? :::\nSolution:\nRemark: Expected vs. actual outcomes\n\n\nDefinition 3 (Expected value). The expected value of a discrete r.v. \\(X\\) that takes on values \\(x_1, x_2, \\ldots, x_n\\) is \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\nRemarks:\n\nThe definition holds if the r.v. \\(X\\) takes on countably infinitely many values \\(x_1, x_2, \\ldots\\), as well: \\[\\mathbb{E}[X] = \\sum_{i=1}^{\\infty} x_ip_X(x_i).\\]\nAnother way to define the expected value of a discrete r.v. is to do so at the \\(\\omega\\) level, where the \\(\\omega\\)’s are outcomes in the sample space:\n\nSuppose \\(\\omega_1, \\omega_2, \\ldots, \\omega_n\\) are the possible outcomes of a random phenomenon. If outcome \\(\\omega_i\\) causes the r.v. X to take on value \\(x_i\\) (meaning \\(X(\\omega_i)=x_i\\)), then \\[\\mathbb{E}[X] = \\sum_{i=1}^{\\infty} x_i\\mathbb{P}(\\{\\omega_i\\}).\\]\n\n\n\nExample 4. Suppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad\\mathrm{(success)}\\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\\mathrm{(failure)}\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\).\n\nSolution:\n\n\nExample 5. Suppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\\\\n            -1 & \\quad \\mathrm{with\\ probability}\\ 1-p\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\).\n\nSolution:\n\nExample 6. Suppose I throw darts at a dartboard until I hit the bullseye, and that my probability of hitting the bullseye is \\(p\\). Suppose further that all of my throws are independent, and that the probability of a bullseye never changes, no matter how many times I throw a dart. How many times should I expect to have to throw the dart until I hit the bullseye?\n\nSolution:\n\nExample 7. A ghost is trick-or-treating. It comes to a house where it is known that there are 30 candies in the bag and only one is a watermelon Jolly Rancher, which is the ghost’s favorite. The ghost takes pieces of candy without replacement until it gets the watermelon Jolly Rancher. How many pieces of candy do we expect the ghost to take?\n\nSolution:\nRemark: Both examples are repeated random processes. They are fundamentally different though:\n\nThe bullseye example (6) is \"with replacement\" since the probability of success remains constant.\nThe ghost trick-or-treating example (7) is without replacement, and thus the probability of success changes with each trial."
  },
  {
    "objectID": "slides/35_Normal_rv.html",
    "href": "slides/35_Normal_rv.html",
    "title": "Chapter 35: Normal Variables",
    "section": "",
    "text": "Chapter 35: Normal Variables\n\nI will not cover normal rv’s in detail here since I expect you have already learned about normal random variables and \\(z\\)-scores in statistics classes you have taken.\nMake sure you know how to use a normal distribution \\(z\\)-table if you will be taking the MS Biostatistics comprehensive exam, since that is what will be provided during the exam.\n\n\nSome remarks on normal rv’s"
  },
  {
    "objectID": "slides/29_Variance_and_Sums_of_rv.html",
    "href": "slides/29_Variance_and_Sums_of_rv.html",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "How do we calculate the expected value of a function of a discrete r.v. or joint r.v.’s?\n\nHow do we calculate the expected value of a function of a continuous r.v. or joint r.v.’s?\n\n::: {#29_EaX+b .example} Example 1.   What is \\(\\mathbb{E}[aX+b]\\)? :::\n\nExample 2.   Let \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\).\n\nRemark\nIf you are given \\(f_{X,Y}(x,y)\\) and want to calculate \\(\\mathbb{E}[X]\\), you have two options:\n\nFind \\(f_X(x)\\) and use it to calculate \\(\\mathbb{E}[X]\\).\nOr, calculate \\(\\mathbb{E}[X]\\) using the joint density: \\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x f_{X,Y}(x,y)dydx.\\]\n\n\n\n\n\n\\(\\mathbb{E}[X+Y] =\\)\nIf \\(X_1, X_2, \\ldots X_n\\) are continuous r.v.’s and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\(\\mathbb{E}[\\sum_{i=1}^{n} a_i X_i] =\\)\nIf \\(X\\) and \\(Y\\) are independent continuous r.v.’s, and \\(g\\) and \\(h\\) are functions, then \\(\\mathbb{E}[g(X)h(Y)] =\\)\nIf \\(X\\) and \\(Y\\) are independent continuous r.v.’s, then \\(\\mathbb{E}[XY] =\\)\n\n\n\n\nHow do we calculate the variance of a discrete r.v.?\n\nHow do we calculate the variance of a continuous r.v.?\n\nExample 3.   Let \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(Var[X]\\).\n\n\n\nExample 4.   Let \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(Var[X]\\).\n\n\n\n\n\n\\(Var[aX+b] =\\)\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous r.v.’s and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\(Var(\\sum_{i=1}^{n} a_i X_i) =\\)\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous r.v.’s, then \\(Var(\\sum_{i=1}^{n} X_i) =\\)\n\n\nExample 5.   A machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10per cubic inch, and 5for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes."
  },
  {
    "objectID": "slides/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-r.v.",
    "href": "slides/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-r.v.",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "How do we calculate the expected value of a function of a discrete r.v. or joint r.v.’s?\n\nHow do we calculate the expected value of a function of a continuous r.v. or joint r.v.’s?\n\n::: {#29_EaX+b .example} Example 1.   What is \\(\\mathbb{E}[aX+b]\\)? :::\n\nExample 2.   Let \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\).\n\nRemark\nIf you are given \\(f_{X,Y}(x,y)\\) and want to calculate \\(\\mathbb{E}[X]\\), you have two options:\n\nFind \\(f_X(x)\\) and use it to calculate \\(\\mathbb{E}[X]\\).\nOr, calculate \\(\\mathbb{E}[X]\\) using the joint density: \\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x f_{X,Y}(x,y)dydx.\\]"
  },
  {
    "objectID": "slides/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-r.v.s",
    "href": "slides/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-r.v.s",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "\\(\\mathbb{E}[X+Y] =\\)\nIf \\(X_1, X_2, \\ldots X_n\\) are continuous r.v.’s and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\(\\mathbb{E}[\\sum_{i=1}^{n} a_i X_i] =\\)\nIf \\(X\\) and \\(Y\\) are independent continuous r.v.’s, and \\(g\\) and \\(h\\) are functions, then \\(\\mathbb{E}[g(X)h(Y)] =\\)\nIf \\(X\\) and \\(Y\\) are independent continuous r.v.’s, then \\(\\mathbb{E}[XY] =\\)"
  },
  {
    "objectID": "slides/29_Variance_and_Sums_of_rv.html#variance-of-continuous-r.v.s",
    "href": "slides/29_Variance_and_Sums_of_rv.html#variance-of-continuous-r.v.s",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "How do we calculate the variance of a discrete r.v.?\n\nHow do we calculate the variance of a continuous r.v.?\n\nExample 3.   Let \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(Var[X]\\).\n\n\n\nExample 4.   Let \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "slides/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-r.v.s",
    "href": "slides/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-r.v.s",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "\\(Var[aX+b] =\\)\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous r.v.’s and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\(Var(\\sum_{i=1}^{n} a_i X_i) =\\)\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous r.v.’s, then \\(Var(\\sum_{i=1}^{n} X_i) =\\)\n\n\nExample 5.   A machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10per cubic inch, and 5for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes."
  },
  {
    "objectID": "slides/26_Independent_rv.html",
    "href": "slides/26_Independent_rv.html",
    "title": "Chapter 26: Independent Continuous Random Variables",
    "section": "",
    "text": "Chapter 26: Independent Continuous Random Variables\nWhat do we know about independence for events and discrete r.v.’s?\n\nWhat does it mean for continuous r.v.’s to be independent?\n\nExample 1.   Let \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(f_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\).\n\n\n\nExample 2.   Let \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nAre \\(X\\) and \\(Y\\) independent?\nFind \\(F_{X,Y}(x,y)\\).\n\n\n\nExample 3.   Let \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Are \\(X\\) and \\(Y\\) independent?\n\n\nRemarks\n\nIf \\(f_{X,Y}(x,y)= g(x)h(y)\\), where \\(g(x)\\) and \\(h(y)\\) are pdf’s, then \\(X\\) and \\(Y\\) are independent.\nIf \\(F_{X,Y}(x,y)= G(x)H(y)\\), where \\(G(x)\\) and \\(H(y)\\) are cdf’s, then \\(X\\) and \\(Y\\) are independent."
  },
  {
    "objectID": "slides/17_Negative_Binomial_rv.html",
    "href": "slides/17_Negative_Binomial_rv.html",
    "title": "Chapter 17: Negative Binomial r.v.’s",
    "section": "",
    "text": "Chapter 17: Negative Binomial r.v.’s\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the \\(r^{th}\\) success.\n\n\nExample 1.   Consider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the probability that the \\(5^{th}\\) bullseye is on the \\(20^{th}\\) throw?\nSolution:\n\n\n\nProperties of Negative Binomial r.v.’s"
  },
  {
    "objectID": "slides/28_Expected_Values.html",
    "href": "slides/28_Expected_Values.html",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "",
    "text": "Chapter 28: Expected Values of Continuous Random Variables\nHow do we calculate expected values of discrete r.v.’s?\n\nHow do we calculate expected values of continuous r.v.’s?\n\n\nExample 1.   Let \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(\\mathbb{E}[X]\\).\n\n\nExample 2.   Let \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(\\mathbb{E}[X]\\).\n\n\nExample 3.   Let \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "slides/32_Exponential_rv.html",
    "href": "slides/32_Exponential_rv.html",
    "title": "Chapter 32: Exponential Random Variables",
    "section": "",
    "text": "Chapter 32: Exponential Random Variables\nScenario: Modeling the time until the next (first) event.\n\nProperties of exponential r.v.’s\nMemoryless Property\n\nExample 1.   Let \\(X_i \\sim \\textrm{Exp}(\\lambda_i)\\) be independent r.v.’s, for \\(i=1 \\ldots n\\). Find the pdf for the first of the arrival times."
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html",
    "href": "slides/5_Bayes_Theorem.html",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "",
    "text": "So we learned about conditional probabilities\n\nWe learned how the occurrence of event A affects event B (B conditional on A)\n\nCan we figure out information on how the occurrence of event B affects event A?\nWe can use the conditional probability (\\(\\mathbb{P}(A|B)\\)) to get information on the flipped conditional probability (\\(\\mathbb{P}(B|A)\\))"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#introduction",
    "href": "slides/5_Bayes_Theorem.html#introduction",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Introduction",
    "text": "Introduction\n\nSo we learned about conditional probabilities\n\nWe learned how the occurrence of event A affects event B (B conditional on A)\n\nCan we figure out information on how the occurrence of event B affects event A?\nWe can use the conditional probability (\\(\\mathbb{P}(A|B)\\)) to get information on the flipped conditional probability (\\(\\mathbb{P}(B|A)\\))"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#bayes-rule-for-two-events",
    "href": "slides/5_Bayes_Theorem.html#bayes-rule-for-two-events",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Bayes’ Rule for two events",
    "text": "Bayes’ Rule for two events\n\n\n\n\nTheorem: Bayes’ Rule (for two events)\n\n\nFor any two events \\(A\\) and \\(B\\) with nonzero probabilties,\n\\[\\mathbb{P}(A| B) =\n\\frac{\\mathbb{P}(A) \\cdot \\mathbb{P}(B|A)}\n{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#example",
    "href": "slides/5_Bayes_Theorem.html#example",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Example",
    "text": "Example\n\n\nExample 4\n\n\nRecall the color-blind example (Example 2), where\n\na person is AMAB with probability 0.5,\nAMAB people are color-blind with probability 0.05, and\nall people are color-blind with probability 0.03.\n\nAssuming people are AMAB or AFAB, find the probability that a color-blind person is AMAB."
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#example-1",
    "href": "slides/5_Bayes_Theorem.html#example-1",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Example",
    "text": "Example\n\n\nExample 5\n\n\nSuppose\n\n1% of women aged 40-50 years have breast cancer,\na woman with breast cancer has a 90% chance of a positive test from a mammogram, and\na woman has a 10% chance of a false-positive result from a mammogram.\n\nWhat is the probability that a woman has breast cancer given that she just had a positive test?"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#example-2",
    "href": "slides/5_Bayes_Theorem.html#example-2",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Example",
    "text": "Example\n\n\nExample 5.3\n\n\nIndividuals are diagnosed with a particular type of cancer that can take on three different disease forms,* \\(D_1\\), \\(D_2\\), and \\(D_3\\). It is known that amongst people diagnosed with this particular type of cancer,\n\n20% of people will eventually be diagnosed with form \\(D_1\\),\n30% with form \\(D_2\\), and\n50% with form \\(D_3\\).\n\nThe probability of requiring chemotherapy (\\(C\\)) differs among the three forms of disease:\n\n80% with \\(D_1\\),\n30% with \\(D_2\\), and\n10% with \\(D_3\\).\n\nBased solely on the preliminary test of being diagnosed with the cancer, what is the probability of requiring chemotherapy (the event C)?\n\n\nSolution:\n\n\nLaw of Total Probability (general)\n\n\nIf \\(\\{A_i\\}_{i=1}^{n} = \\{A_1, A_2, \\ldots, A_n\\}\\) form a partition of the sample space, then for event \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=& \\sum_{i=1}^{n} \\mathbb{P}(B \\cap A_i)\\\\\n           &=& \\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#example-3",
    "href": "slides/5_Bayes_Theorem.html#example-3",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Example",
    "text": "Example\n\n\nExample 5.4\n\n\nRecall the color-blind example (Example 2), where\n\na person is male with probability 0.5,\nmales are color-blind with probability 0.05, and\nall people are color-blind with probability 0.03.\n\nFind the probability that a color-blind person is male.\n\n\nSolution:"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#example-4",
    "href": "slides/5_Bayes_Theorem.html#example-4",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Example",
    "text": "Example\n\n\nExample 5.5\n\n\nSuppose\n\n1% of women aged 40-50 years have breast cancer,\na woman with breast cancer has a 90% chance of a positive test from a mammogram, and\na woman has a 10% chance of a false-positive result from a mammogram.\n\nWhat is the probability that a woman has breast cancer given that she just had a positive test?\n\n\nSolution:"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#bayes-rule",
    "href": "slides/5_Bayes_Theorem.html#bayes-rule",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\n\nTheorem: Bayes’ Rule\n\n\nIf \\(\\{A_i\\}_{i=1}^{n}\\) form a partition of the sample space \\(S\\), with \\(\\mathbb{P}(A_i)&gt;0\\) for \\(i=1\\ldots n\\) and \\(\\mathbb{P}(B)&gt;0\\), then\n\\[\\mathbb{P}(A_j | B) =\n\\frac{\\mathbb{P}(B|A_j) \\cdot \\mathbb{P}(A_j)}\n{\\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)}\\]\n\n\n\n\nChapter 5 Slides"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "",
    "text": "Suppose you toss one coin.\n\nWhat are the possible outcomes?\n \nWhat is the sample space?\n \nWhat are the possible events?\n\n\n\n\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n\nHeads (\\(H\\))\nTails (\\(T\\))\n\nNote: When something happens at random, such as a coin toss, there are several possible outcomes, and exactly one of the outcomes will occur.\n\n\n\n\n\n\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all possible outcomes.\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some possible outcomes.\n\n\n\n\nWhat is the sample space?\n\n\\(S = \\{H, T\\}\\)\n\nWhat are the possible events?\n\n\\(\\{H\\}\\)\n\\(\\{T\\}\\)\n\\(\\{H, T\\}\\)\n\\(\\emptyset\\)\n\n \nWhen thinking about events, think about outcomes that you might be asking the probability of."
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#overview",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#overview",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Overview",
    "text": "Overview\n\nOutcomes, Events, and Sample Space\n\nTossing one coin\nTossing two coins\n\nSet Theory"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-1-coin-13",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-1-coin-13",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "",
    "text": "Suppose you toss one coin.\n\nWhat are the possible outcomes?\n \nWhat is the sample space?\n \nWhat are the possible events?"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-1-coin-23",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-1-coin-23",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "",
    "text": "Suppose you toss one coin.\n\nWhat are the possible outcomes?\n\nHeads (\\(H\\))\nTails (\\(T\\))\n\nNote: When something happens at random, such as a coin toss, there are several possible outcomes, and exactly one of the outcomes will occur."
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-1-coin-33",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-1-coin-33",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "",
    "text": "Definition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all possible outcomes.\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some possible outcomes.\n\n\n\n\nWhat is the sample space?\n\n\\(S = \\{H, T\\}\\)\n\nWhat are the possible events?\n\n\\(\\{H\\}\\)\n\\(\\{T\\}\\)\n\\(\\{H, T\\}\\)\n\\(\\emptyset\\)\n\n \nWhen thinking about events, think about outcomes that you might be asking the probability of."
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#tossing-two-coins",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#tossing-two-coins",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Tossing two coins",
    "text": "Tossing two coins"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-2-coins",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-2-coins",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Coin Toss Example: 2 coins",
    "text": "Coin Toss Example: 2 coins\nSuppose you toss two coins.\n\nWhat is the sample space? Assume the coins are distinguishable\n\n\\(S =\\) \\[S = \\{HH, TT, HT, TH\\}\\]\n\nWhat are some possible events?\n\n\\(A\\) = exactly one \\(H\\) = \\(\\{HT, TH\\}\\)\n\\(B\\) = at least one \\(H\\) = \\(\\{HH, HT, TH\\}\\)"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#more-info-on-events-and-sample-spaces",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#more-info-on-events-and-sample-spaces",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "More info on events and sample spaces",
    "text": "More info on events and sample spaces\n\nWe usually use capital letters from the beginning of the alphabet to denote events. However, other letters might be chosen to be more descriptive.\nWe use the notation \\(|S|\\) to denote the size of the sample space.\nThe total number of possible events is \\(2^{|S|}\\), which is the total number of possible subsets of \\(S\\). We will prove this later in the course.\nThe empty set, denoted by \\(\\emptyset\\), is the set containing no outcomes."
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#example-keep-sampling-until",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#example-keep-sampling-until",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Example: Keep sampling until…",
    "text": "Example: Keep sampling until…\nSuppose you keep sampling people until you have someone with high blood pressure (BP). What is the sample space?\n\nLet \\(H =\\) denote someone with high BP.\nLet \\(H^C =\\) denote someone with not high blood pressure, such as low or regular BP.\nThen, \\(S =\\)\n\n\\[S = \\{H, (H, H^C), (H, H, H^C), (H, H, H, H^C), \\ldots\\]"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#set-theory-12",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#set-theory-12",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Set Theory (1/2)",
    "text": "Set Theory (1/2)\n\n\n\n\nDefinition: Union\n\n\nThe union of events \\(A\\) and \\(B\\), denoted by \\(A \\cup B\\), contains all outcomes that are in \\(A\\) or \\(B\\).\n\n\n\n\nDefinition: Intersection\n\n\nThe intersection of events \\(A\\) and \\(B\\), denoted by \\(A \\cap B\\), contains all outcomes that are both in \\(A\\) and \\(B\\).\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#set-theory-22",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#set-theory-22",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Set Theory (2/2)",
    "text": "Set Theory (2/2)\n\n\n\n\nDefinition: Complement\n\n\nThe complement of event \\(A\\), denoted by \\(A^C\\) or \\(A'\\), contains all outcomes in the sample space \\(S\\) that are not in \\(A\\) .\n\n\n\n\nDefinition: Mutually Exclusive\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive, or disjoint, if they have no outcomes in common. In this case \\(A \\cap B = \\emptyset\\), where \\(\\emptyset\\) is the empty set.\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#bp-example-variation-13",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#bp-example-variation-13",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "BP example variation (1/3)",
    "text": "BP example variation (1/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\nEvent all \\(n\\) subjects have high BP\nEvent at least one subject has high BP\nEvent all of them do not have high BP\nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#bp-example-variation-23",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#bp-example-variation-23",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "BP example variation (2/3)",
    "text": "BP example variation (2/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\n\\[H_i^C\\]\nEvent all \\(n\\) subjects have high BP\n\\[H_1 \\textrm{ and } H_2 \\textrm{ and } \\ldots = \\bigcap\\limits_{i=1}^{n}H_i\\]\nEvent at least one subject has high BP\n\\[H_1 \\textrm{ or } H_2 \\textrm{ or } \\ldots = \\bigcup\\limits_{i=1}^{n}H_i\\]"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#bp-example-variation-33",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#bp-example-variation-33",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "BP example variation (3/3)",
    "text": "BP example variation (3/3)\n\nEvent all of them do not have high BP\n\\(H_1^C\\) and \\(H_2^C\\) and... \\[\\bigcap\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcup\\limits_{i=1}^{n}H_i\\Big)^C\\] = complement of at least one person having high BP\nEvent at least one subject does not have high BP\n\\(H_1^C\\) or \\(H_2^C\\) or... \\[\\bigcup\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}H_i\\Big)^C\\] = complement of all having high BP"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#de-morgans-laws",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#de-morgans-laws",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "De Morgan’s Laws",
    "text": "De Morgan’s Laws\n\n\nTheorem: De Morgan’s 1st Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcap\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcup\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“all not A = \\((\\)at least one event A\\()^C\\)”\n\n\nTheorem: De Morgan’s 2nd Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcup\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“at least one event not A = \\((\\)all A\\()^C\\)”"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample_space-solutions.html#remarks-on-de-morgans-laws",
    "href": "slides/1_Outcomes_Events_Sample_space-solutions.html#remarks-on-de-morgans-laws",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Remarks on De Morgan’s Laws",
    "text": "Remarks on De Morgan’s Laws\n\nThese laws also hold for infinite collections of events.\nDraw Venn diagrams to convince yourself that these are true!\nThese laws are very useful when calculating probabilities.\n\nThis is because calculating the probability of the intersection of events is often much easier than the union of events.\nThis is not obvious right now, but we will see in the coming chapters why."
  },
  {
    "objectID": "slides/2_Probability-solutions.html#what-do-you-know-about-probabilities",
    "href": "slides/2_Probability-solutions.html#what-do-you-know-about-probabilities",
    "title": "Chapter 2: Probability",
    "section": "What do you know about probabilities?",
    "text": "What do you know about probabilities?"
  },
  {
    "objectID": "slides/2_Probability-solutions.html#probabilities-of-equally-likely-events-12",
    "href": "slides/2_Probability-solutions.html#probabilities-of-equally-likely-events-12",
    "title": "Chapter 2: Probability",
    "section": "Probabilities of equally likely events (1/2)",
    "text": "Probabilities of equally likely events (1/2)\n\n\nExample 1\n\n\nSuppose you have a regular well-shuffled deck of cards. What’s the probability of drawing:\n\nany heart\nthe queen of hearts\nany queen\n\nSolution:\n\nany heart = 13/52 = 1/4\nthe queen of hearts = 1/52\nany queen = 4/52 = 1/13"
  },
  {
    "objectID": "slides/2_Probability-solutions.html#probabilities-of-equally-likely-events-22",
    "href": "slides/2_Probability-solutions.html#probabilities-of-equally-likely-events-22",
    "title": "Chapter 2: Probability",
    "section": "Probabilities of equally likely events (2/2)",
    "text": "Probabilities of equally likely events (2/2)\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}.\\]"
  },
  {
    "objectID": "slides/2_Probability-solutions.html#a-probability-is-a-function",
    "href": "slides/2_Probability-solutions.html#a-probability-is-a-function",
    "title": "Chapter 2: Probability",
    "section": "A probability is a function…",
    "text": "A probability is a function…\n\\(\\mathbb{P}(A)\\) is a function with\n\ninput: event \\(A\\) from the sample space \\(S\\), (\\(A \\subseteq S\\))\noutput: a number between 0 and 1 (inclusive)\n\n\\[\\mathbb{P}(A): S \\rightarrow [0,1]\\]\nA function that follows some specific rules though!\nSee Probability Axioms on next slide."
  },
  {
    "objectID": "slides/2_Probability-solutions.html#probability-axioms-1",
    "href": "slides/2_Probability-solutions.html#probability-axioms-1",
    "title": "Chapter 2: Probability",
    "section": "Probability Axioms",
    "text": "Probability Axioms\n\n\nAxiom 1\n\n\nFor every event \\(A\\), \\(0\\leq\\mathbb{P}(A)\\leq 1\\).\n\n\n\n\nAxiom 2\n\n\nFor the sample space \\(S\\), \\(\\mathbb{P}(S)=1\\).\n\n\n\n\nAxiom 3\n\n\nIf \\(A_1, A_2, A_3, \\ldots\\), is a collection of disjoint events, then \\[\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i).\\]"
  },
  {
    "objectID": "slides/2_Probability-solutions.html#some-probability-properties-1",
    "href": "slides/2_Probability-solutions.html#some-probability-properties-1",
    "title": "Chapter 2: Probability",
    "section": "Some probability properties",
    "text": "Some probability properties\nUsing the Axioms, we can prove all other probability properties!\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nProposition 4\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\n\n\nProposition 5\n\n\n\\(\\mathbb{P}(A \\cup B \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\\\ \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\\\ \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C)\\)"
  },
  {
    "objectID": "slides/2_Probability-solutions.html#proposition-1-proof",
    "href": "slides/2_Probability-solutions.html#proposition-1-proof",
    "title": "Chapter 2: Probability",
    "section": "Proposition 1 Proof",
    "text": "Proposition 1 Proof\n\n\n\n−+\n01:00\n\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\nProposition 1 Proof\n\n\nSince \\(A\\) and \\(A^C\\) are disjoint, we know from Axiom 3 that \\(\\mathbb{P}(A \\cup A^C) = \\mathbb{P}(A) + \\mathbb{P}(A^C)\\).\nHowever, \\(S = A \\cup A^C\\), and by Axiom 2, \\(\\mathbb{P}(S) = 1\\), implying \\(\\mathbb{P}(A \\cup A^C) = \\mathbb{P}(S) = 1\\).\nThus, \\(\\mathbb{P}(A) + \\mathbb{P}(A^C) = 1\\), or \\(\\mathbb{P}(A) = 1 - \\mathbb{P}(A^C)\\)"
  },
  {
    "objectID": "slides/2_Probability-solutions.html#proposition-2-proof",
    "href": "slides/2_Probability-solutions.html#proposition-2-proof",
    "title": "Chapter 2: Probability",
    "section": "Proposition 2 Proof",
    "text": "Proposition 2 Proof\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\nProposition 2 Proof (different from book)\n\n\nWe know \\(\\emptyset = S^C\\).\nThus by Prop 1,\n\\[\\mathbb{P}(\\emptyset) = \\mathbb{P}(S^C) = 1- \\mathbb{P}(S) = 1-1 =0\n.\\]"
  },
  {
    "objectID": "slides/2_Probability-solutions.html#proposition-3-proof",
    "href": "slides/2_Probability-solutions.html#proposition-3-proof",
    "title": "Chapter 2: Probability",
    "section": "Proposition 3 Proof",
    "text": "Proposition 3 Proof\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\nProposition 3 Proof\n\n\nCreate a partition! Make a Venn diagram.\n\\[%\\left(\n\\begin{array}{ccl}\nB &=& A \\cup (B \\cap A^C) \\\\\n\\mathbb{P}(B) &=& \\mathbb{P}(A) + \\mathbb{P}(B \\cap A^C) \\\\\n\\mathbb{P}(B)  & \\geq &   \\mathbb{P}(A),\n\\end{array}\n%\\right)\\] since \\(\\mathbb{P}(B \\cap A^C) \\geq 0\\)."
  },
  {
    "objectID": "slides/2_Probability-solutions.html#partitions-1",
    "href": "slides/2_Probability-solutions.html#partitions-1",
    "title": "Chapter 2: Probability",
    "section": "Partitions",
    "text": "Partitions\n\n\nDefinition: Partition\n\n\nA set of events \\(\\{A_i\\}_{i=1}^{n}\\) create a partition of \\(A\\), if\n\nthe \\(A_i\\)’s are disjoint (mutually exclusive) and\n\\(\\bigcup \\limits_{i=1}^n A_i = A\\)\n\n\n\n\n\nExample 2\n\n\n\nIf \\(A \\subset B\\), then \\(\\{A, B \\cap A^C\\}\\) is a partition of \\(B\\).\nIf \\(S = \\bigcup \\limits_{i=1}^n A_i\\), then the \\(A_i\\)’s are a partition of the sample space.\n\n\n\nCreating partitions is sometimes used to help calculate probabilities, since by Axiom 3 we can add the probabilities of disjoint events."
  },
  {
    "objectID": "slides/2_Probability-solutions.html#venn-diagram-probabilities-1",
    "href": "slides/2_Probability-solutions.html#venn-diagram-probabilities-1",
    "title": "Chapter 2: Probability",
    "section": "Venn Diagram Probabilities",
    "text": "Venn Diagram Probabilities\n\n\n\nExample 3\n\n\nIf a subject has an\n\n80% chance of taking their medication this week,\n70% chance of taking their medication next week, and\n10% chance of not taking their medication either week,\n\nthen find the probability of them taking their medication exactly one of the two weeks.\n\nHint: Draw a Venn diagram labelling each of the parts to find the probability.Answer: \\(\\mathbb{P}(A \\cap B) = 0.6\\).\n\n\n\nChapter 2 Slides"
  },
  {
    "objectID": "slides/11_Expected_Values_of_Sums_of_rvs.html",
    "href": "slides/11_Expected_Values_of_Sums_of_rvs.html",
    "title": "Chapter 11 Expected Values of Sums of Discrete r.v.’s",
    "section": "",
    "text": "Chapter 11 Expected Values of Sums of Discrete r.v.’s\n\nExample 1. Suppose you draw 2 cards from a standard deck of cards with* replacement. Let \\(X\\) be the number of hearts you draw. Find \\(\\mathbb{E}[X]\\).*\n\nSolution:\n\n\nExample 2. What is the expected number of hearts in Example 1 if you draw 200 cards?\n\nSolution:\n\nTheorem 3 (Sums of discrete r.v.’s). For discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[\\mathbb{E}[\\sum_{i=1}^n a_iX_i] = \\sum_{i=1}^n a_i\\mathbb{E}[X_i] .\\]\n\nRemark: The theorem holds for infinitely r.v.’s \\(X_i\\) as well.\n\n\nCorollary 1. For a discrete r.v. \\(X\\), and constants \\(a\\) and \\(b\\), \\[\\mathbb{E}[aX+b] = a\\mathbb{E}[X] + b.\\]\n\n\nCorollary 2. If \\(X_i\\), \\(i=1,2,\\dots, n\\), are i.i.d. r.v.’s, then \\[\\mathbb{E}[\\sum_{i=1}^n X_i] = n\\mathbb{E}[X_1] .\\]\n\n\nProof. Proof to Theorem 3. ◻\n\n\nProof. Proof to Corollary 1. ◻\n\n\nExample 4. The ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 [insert your favorite candy]. The ghost takes five pieces of candy without replacement. How many pieces of chocolate do we expect the ghost to take?\n\nSolution:\n\nExample 5. A tour group is planning a visit to the city of Landport and needs to book 30 hotel rooms. The average price of a room is $200. In addition, there is a 10% tourism tax for each room. What is the expected cost for the 30 hotel rooms?\n\nSolution:"
  },
  {
    "objectID": "slides/3_IndependentEvents.html",
    "href": "slides/3_IndependentEvents.html",
    "title": "Chapter 3: Independent Events",
    "section": "",
    "text": "Define independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "slides/3_IndependentEvents.html#slide-1",
    "href": "slides/3_IndependentEvents.html#slide-1",
    "title": "Chapter 3: Independent Events",
    "section": "Slide 1",
    "text": "Slide 1\nQuestion: Which of the following sequences of coin tosses of heads (\\(H\\)) and tails (\\(T\\)) is more likely to happen, assuming the coin is fair?\n\\[HTTHHHTHTHHTTTH\\] or \\[HTTTTTTTTHTTTTT\\]"
  },
  {
    "objectID": "slides/3_IndependentEvents.html#slide-2",
    "href": "slides/3_IndependentEvents.html#slide-2",
    "title": "Chapter 3: Independent Events",
    "section": "Slide 2",
    "text": "Slide 2\n\n\nDefinition: Independence\n\n\nEvents \\(A\\) and \\(B\\) are independent if \\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B).\\]\n\n\nNotation: For shorthand, we sometimes write \\[A \\mathrel{\\unicode{x2AEB}} B,\\] to denote that \\(A\\) and \\(B\\) are independent events."
  },
  {
    "objectID": "slides/3_IndependentEvents.html#da",
    "href": "slides/3_IndependentEvents.html#da",
    "title": "Chapter 3: Independent Events",
    "section": "da",
    "text": "da\n\n\nExample 1\n\n\nTwo dice (red and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event first die is a six. Are events \\(A\\) and \\(B\\) independent?"
  },
  {
    "objectID": "slides/3_IndependentEvents.html#fsf",
    "href": "slides/3_IndependentEvents.html#fsf",
    "title": "Chapter 3: Independent Events",
    "section": "fsf",
    "text": "fsf\n\n\nDefinition: Independence of 3 Events\n\n\nEvents \\(A\\), \\(B\\), and \\(C\\) are independent if\n\n\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B)\\)\n\\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(C)\\)\n\\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\\(\\mathbb{P}(A \\cap B \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\n\nRemark:\nOn your homework you will show that \\((1) \\not \\Rightarrow (2)\\) and \\((2) \\not \\Rightarrow (1)\\)."
  },
  {
    "objectID": "slides/3_IndependentEvents.html#fafs",
    "href": "slides/3_IndependentEvents.html#fafs",
    "title": "Chapter 3: Independent Events",
    "section": "fafs",
    "text": "fafs\n\n\nExample 2\n\n\nSuppose you take a random sample of \\(n\\) people, of which people are smokers and non-smokers independently of each other. Let\n\n\\(A_i =\\) event person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\), and\n\\(p_i =\\) probability person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\).\n\nFind the probability that at least one person in the random sample is a smoker."
  },
  {
    "objectID": "slides/3_IndependentEvents.html#faf",
    "href": "slides/3_IndependentEvents.html#faf",
    "title": "Chapter 3: Independent Events",
    "section": "faf",
    "text": "faf\n\n\nExample 3\n\n\n\\(A, B,\\) and \\(C\\) toss a fair coin in order. The first to throw heads wins. What are their respective chances of winning?\n\n\nLet\n\n\\(A_H\\) and \\(A_T\\) be the events player A tosses heads and tails, respectively.\nSimilarly define \\(B_H\\), \\(B_T\\), \\(C_H\\), and \\(C_T\\).\n\n\n\nChapter 3 Slides"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html",
    "href": "slides/8_pmfs_and_cdfs.html",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "",
    "text": "Example 1. Suppose we toss 3 coins with probability of heads \\(p\\). If \\(X\\) is the random variable counting the number of heads, what are the probabilities of each value of \\(X\\)?\n\nSolution:\n\nDefinition 2. The probability distribution or probability mass function (pmf) of a discrete r.v. \\(X\\) is defined for every number \\(x\\) by \\[p_X(x) = \\mathbb{P}(X=x) = \\mathbb{P}(\\mathrm{all }\\ \\omega\\in S:X(\\omega) = x)\\]"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#slide-1",
    "href": "slides/8_pmfs_and_cdfs.html#slide-1",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Slide 1",
    "text": "Slide 1\n\n\n\n\nExample 1\n\n\nSuppose we toss 3 coins with probability of heads \\(p\\). If \\(X\\) is the random variable counting the number of heads, what are the probabilities of each value of \\(X\\)?\n\n\n\n\n\nDefinition 2. The probability distribution or probability mass function (pmf) of a discrete r.v. \\(X\\) is defined for every number \\(x\\) by \\[p_X(x) = \\mathbb{P}(X=x) = \\mathbb{P}(\\mathrm{all }\\ \\omega\\in S:X(\\omega) = x)\\]"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#slide-2",
    "href": "slides/8_pmfs_and_cdfs.html#slide-2",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Slide 2",
    "text": "Slide 2\nRemarks:\n\nA pmf \\(p_X(x)\\) must satisfy the following properties:\n\n\\(p_X(x)\\geq 0\\) for all \\(x\\).\n\\(\\sum \\limits_{\\{all\\ x\\}}p_X(x)=1\\).\n\nSome distributions depend on parameters.\n\nEach value of a parameter gives a different pmf.\nThe collection of all pmf’s for different values of the parameters is called a family of pmf’s."
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#slide-3",
    "href": "slides/8_pmfs_and_cdfs.html#slide-3",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Slide 3",
    "text": "Slide 3\n\n\n\n\nExample 2: Binomial family of RVs\n\n\nSuppose you toss \\(n\\) coins, each with probability of heads \\(p\\). If \\(X\\) is the number of heads, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#slide-4",
    "href": "slides/8_pmfs_and_cdfs.html#slide-4",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Slide 4",
    "text": "Slide 4\n\n\n\n\nExample 3: Bernoulli family of RVs\n\n\nSuppose you toss 1 coin, with probability of heads \\(p\\). If \\(X\\) is the number of heads, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#slide-5",
    "href": "slides/8_pmfs_and_cdfs.html#slide-5",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Slide 5",
    "text": "Slide 5\n\nExample 5 (Household size). The table below shows household sizes in 2019. Data are from https://www.census.gov/data/tables/time-series/demo/families/households.html.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes.\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf.\n\n\nSolution:"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#slide-6",
    "href": "slides/8_pmfs_and_cdfs.html#slide-6",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Slide 6",
    "text": "Slide 6\n\nDefinition 6. The cumulative distribution function (cdf) of a discrete r.v. \\(X\\) with pmf \\(p_X(x)\\), is defined for every value \\(x\\) by \\[F_X(x) = \\mathbb{P}(X \\leq x) = \\sum \\limits_{\\{all\\ y:\\ y\\leq x\\}}p_X(y)\\]"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#slide-7",
    "href": "slides/8_pmfs_and_cdfs.html#slide-7",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Slide 7",
    "text": "Slide 7\n\nExample 7 (Household size cont’d).\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\n\nGraph the cdf of household sizes in 2019.\nWrite the cdf as a function.\n\n\nSolution:"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#slide-8",
    "href": "slides/8_pmfs_and_cdfs.html#slide-8",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Slide 8",
    "text": "Slide 8\nProperties of discrete cdf’s:\n\n\nChapter 8 Slides"
  },
  {
    "objectID": "slides/24_Continuous_rv.html",
    "href": "slides/24_Continuous_rv.html",
    "title": "Chapter 24: Continuous r.v.’s and pdf’s",
    "section": "",
    "text": "Chapter 24: Continuous r.v.’s and pdf’s\nRecall from Chapter 7:\nDiscrete vs. Continuous r.v.’s\n\nFor a discrete r.v., the set of possible values is either finite or can be put into a countably infinite list.\nContinuous r.v.’s take on values from continuous intervals, or unions of continuous intervals.\n\n\nHow to define probabilities for continuous r.v.’s?\n\nDefinition 1 (Probability density function).   The probability distribution, or probability density function (pdf), of a continuous random variable \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\),\n\\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\n\nRemarks:\n\nNote that \\(f_X(x) \\neq \\mathbb{P}(X=x)\\)!!!\nIn order for \\(f_X(x)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_X(x) \\geq 0\\) for all \\(x\\)\n\\(\\int_{-\\infty}^{\\infty} f_X(x)dx=1\\)\n\n\n\nExample 2.   Let \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind the value of \\(a\\) so that \\(f_X(x)\\) is a pdf.\nFind \\(\\mathbb{P}(2.7 \\leq X \\leq 2.9)\\).\nFind \\(\\mathbb{P}(2.7 &lt; X \\leq 2.9)\\).\nFind \\(\\mathbb{P}(X = 2.9)\\).\nFind \\(\\mathbb{P}(X \\leq 2.8)\\).\n\n\n\nDefinition 3 (Cumulative distribution function).   The cumulative distribution function (cdf) of a continuous random variable \\(X\\), is the function \\(F_X(x)\\), such that for all real values of \\(x\\), \\[F_X(x)= \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^x f_X(s)ds\\]\n\n\n\nExample 4.   Let \\(f_X(x)= 2\\), for \\(2.5 \\leq x \\leq 3\\). Find \\(F_X(x)\\).\n\n\nRemarks: In general, \\(F_X(x)\\) is increasing and\n\n\\(\\lim_{x\\rightarrow -\\infty} F_X(x)= 0\\)\n\\(\\lim_{x\\rightarrow \\infty} F_X(x)= 1\\)\n\n\nTheorem 5.   If \\(X\\) is a continuous random variable with pdf \\(f_X(x)\\) and cdf \\(F_X(x)\\), then for all real values of \\(x\\) at which \\(F'_X(x)\\) exists, \\[\\frac{d}{dx} F_X(x)= F'_X(x) = f_X(x)\\]\n\n\nExample 6.   Let \\(X\\) be a r.v. with cdf \\[F_X(x)= \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt; 2.5 \\\\\n            2x-5 & \\quad 2.5 \\leq x \\leq 3 \\\\\n            1 & \\quad x &gt; 3\n        \\end{array}\n    \\right.\\] Find the pdf \\(f_X(x)\\).\n\nSolution:\n\nExample 7.   Let \\(X\\) be a r.v. with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nShow \\(f_X(x)\\) is a pdf.\nFind \\(\\mathbb{P}(1 \\leq X \\leq 3)\\).\nFind \\(F_X(x)\\).\nGiven \\(F_X(x)\\), find \\(f_X(x)\\).\nFind \\(\\mathbb{P}(X \\geq 1 | X \\leq 3)\\).\nFind the median of the distribution of \\(X\\)."
  },
  {
    "objectID": "homework/HW3.html",
    "href": "homework/HW3.html",
    "title": "Homework 3",
    "section": "",
    "text": "Important\n\n\n\nTHIS PAGE IS UNDER CONSTRUCTION!!"
  },
  {
    "objectID": "homework/HW6.html",
    "href": "homework/HW6.html",
    "title": "Homework 6",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n19\nTB # 6\n# 1, 18, 19\n\n\n18\nTB # 24\n# 1, 26, 27\n\n\nCalculus Review\n\nNTB # 1\n\n\n24\nTB # 19, 20*\n# 2, 3, 7, 17, 18, 22, 23\n\n\n25\nTB # 18, NTB # 2\n# 1, 4, 8, 17, 23, 24\n\n\n26**\nTB # 12, NTB # 3, 4\n# 7, 9, 19, 20\n\n\n27\nTB # 12***\n# 6, 8, 13, 17\n\n\n\n\n* (Ch 24) Also find the cdf \\(F_X(x)\\)\n** Although within Chapter 26, these exercises are primarily practicing the material from Chapter 25.\n** For Ch 27 # 12, in order to find the conditional densities in parts (a) and (b), you will need to calculate \\(f_Y(y)\\) for the specific regions of \\(y\\) specified. After finding the conditional densities in parts (a) and (b), also calculate the conditional probabilities below. Please submit these together with your other work in parts (a) and (b):\n\nFind \\(\\mathbb{P}[0.5 &lt; X &lt; 3 | Y = 4]\\).\nFind \\(\\mathbb{P}[0.5 &lt; X &lt; 3 | Y = 7]\\).\n\n\nNon-textbook problems (NTB):\n\nCalculus Review\n\n\\[\\int_0^yc(x+y)dx\\]\n\\[\\frac{d}{dx}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\frac{d}{dy}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\int_0^y2e^{-x}e^{-y}dx\\]\n\\[\\int_0^\\infty xye^{-(x+y)}dy\\]\n\\[\\int_x^{2x} 2e^{-(x+3y)}dy\\]\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(y\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(y\\).\n\nLet \\(X_1, X_2, \\ldots, X_n\\) be i.i.d. random variables with common pdf \\(f_X(x)\\) and cdf \\(F_X(x)\\). Find the pdf for the random variable \\(Z\\), where \\(Z = max(X_1, X_2, \\ldots, X_n)\\).\nLet \\(X\\) and \\(Y\\) be independent random variables with respective pdf’s \\(f_X(x)=\\frac{1}{5}\\), for \\(0\\leq x\\leq 5\\), and \\(f_Y(y)=2e^{-2y}\\), for \\(y&gt;0\\).\n\nFind the joint distribution \\(f_{X,Y}(x,y)\\).\nFind the probability that \\(X\\) is less than \\(Y\\).\nLet \\(Z\\) be the random variable that is the smaller of \\(X\\) and \\(Y\\). Find the cumulative distribution function for \\(Z\\).\nFind the pdf for Z.\n\nSuppose that the random variables \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)\\), for \\(0&lt;x&lt;1\\), and \\(\\frac{1}{2}&lt;y&lt;1\\). Set up the equation for the cdf of \\(Z\\), where \\(Z=X/Y\\).\nHint: First determine what the possible values for \\(Z\\) are. Then make a sketch of the domain of the joint pdf and shade in the region representing the cdf of Z for different values of \\(z\\). Make sure to pay close attention to how the region we need to integrate over changes as \\(z\\) changes. The cdf has two different cases depending on the value of \\(z\\). Plug in specific values of \\(z\\) and shade in the region representing the cdf to see why two different cases are needed."
  },
  {
    "objectID": "homework/HW9.html",
    "href": "homework/HW9.html",
    "title": "Homework 9",
    "section": "",
    "text": "Complete all of the problems listed below. Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nYou must show all of your work to receive credit. Don’t forget to define every r.v. you use! In particular, if a similar problem was done in class or an example in the book, make sure to still show every step in the solution and not just cite the examples’ results.\n\n\n\n* Include in your answer an explanation as to why we need the condition that \\(t&lt;\\lambda\\).\n** Do parts (a)-(c) below for #10 and #12:\n\nAnswer the question using the mgf \\(M_X(t)\\) as instructed in the book.\nAnswer the question using \\(R_X(t)\\) (as defined in class, and NTB [Ch43_R_Var] below).\nWhich method did you prefer? Why?\n\n*** Assume the distances between the cars are independent.\n\nNon-textbook problems (NTB):\n\nLet \\(R_X(t)=\\ln(M_X(t))\\). Show that Var\\((X)=R''_X(0)\\).\nThe mgf for a Gamma distribution is \\(M_X(t)=\\frac{1}{(1-t/\\lambda)^r}\\). Use the mgf of an Exponential distribution (from #43.9), to show that the sum of \\(n\\) i.i.d. Exponential(\\(\\lambda)\\) random variables has a Gamma(\\(r,\\lambda\\)) distribution.\nUse the mgf of a Poisson distribution to find the mgf of the following distributions. If the mgf is that of a common named distribution, then name the distribution and state its parameter(s).\n\n1.  The distribution of $\\sum_{i=1}^nX_i$, if $X_i\\sim$Poisson$(\\lambda_i)$ and are independent.\n\n2.  The distribution of $\\sum_{i=1}^3X_i$, if $X_i\\sim$Poisson$(\\lambda)$ and are independent (i.i.d. in this case).\n\n3.  The distribution of $3X$, if $X\\sim$Poisson$(\\lambda)$.\n\n4.  Why are the answers to (b) and (c) different?\n\nUsing mgf’s, show that the sum of \\(n\\) i.i.d. Chi Square random variables with one degree of freedom (\\(\\chi^2_{(1)}\\)) r.v.’s has a Chi Square with \\(n\\) degrees of freedom (\\(\\chi^2_{(n)}\\)) distribution.\n\n*Hint:* First, look up the pdf of a $\\chi^2_{(n)}$. This is a special case of the Gamma distribution with what parameters? Based on that and the information from \\# [\\[Ch43_SumExpGamma\\]](#Ch43_SumExpGamma){reference-type=\"ref\" reference=\"Ch43_SumExpGamma\"} above, you can determine what the mgf of a $\\chi^2_{(n)}$ is, which will help you determine whether the mgf of the sum of $n$ i.i.d. $\\chi^2_{(1)}$ r.v.'s has a $\\chi^2_{(n)}$ distribution.\n\nSelected answers (or hints) not provided at the end the book:\n\n\n\n(a) Poisson\\((\\sum_{i=1}^n \\lambda_i)\\)     (b) Poisson\\((3\\lambda)\\)      (c) \\(M_{3X}(t)=e{\\lambda(e^{3t}-1)}\\) This is not an mgf of a common probability distribution.      (d) In (b) we are adding independent r.v.’s \\(X_i\\), while in (c) we are adding dependent r.v.’s (\\(3X=X+X+X\\); \\(X\\) is dependent with itself).\n\n\n0.0044\n(a) 0.9525     (b) 0.7939     (c) 0.7939\n0.5911\n(a) \\(R=8.225\\sigma+25\\mu\\)     (b) \\(R=16.45\\sigma+100\\mu\\)     (c) \\(R=164.5\\sigma+10,000\\mu\\)     (d) \\(R=1.645\\sqrt{n}\\sigma+n\\mu\\)\n\n\n0.8869\n0.0023\n0.3936\n0.4562\n(b) 0.0022     (c) \\(478.696\\approx 479\\)"
  },
  {
    "objectID": "homework/HW1.html",
    "href": "homework/HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Important\n\n\n\nTHIS PAGE IS UNDER CONSTRUCTION!!"
  },
  {
    "objectID": "homework/HW1.html#homework-structure",
    "href": "homework/HW1.html#homework-structure",
    "title": "Homework 1",
    "section": "",
    "text": "Complete all of the problems listed below. Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nYou must show all of your work to receive credit.\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n1\n\n# 3, 7, 9, 11\n\n\n2\nNTB # 1, TB # 30\n# 1, 4, 8, 16, 19, 23\n\n\n22*\nTB # 42, NTB # 2\n# 3, 5, 7, 25, 27, 30, 31, 39-41, 43-48\n\n\n\n\n* Please note the following for Chapter 22:\n\nSee the table on pg. 277, which summarizes some key combinatorics concepts.\nProblems 39-48 are a set that build on one another and more advanced than the other problems. It’ll be much easier to do #42 after doing 39-41.\nI highly recommend reading Chapter 23, which is a series of case studies in counting: poker hands and Yahtzee."
  },
  {
    "objectID": "homework/HW1.html#non-textbook-problems-ntb",
    "href": "homework/HW1.html#non-textbook-problems-ntb",
    "title": "Homework 1",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nSuppose the following are the percentage of US adults with the following conditions:\n\n\\(A\\): Hypertension 33%\n\\(B\\): Diabetes 9%\n\\(C\\): Metabolic syndrome 24%\n\\(A\\) or \\(B\\): 39%\n\\(A\\) or \\(C\\): 45%\n\\(B\\) or \\(C\\): 28%\n\\(A\\) or \\(B\\) or \\(C\\): 48%\n\n\nMake a Venn diagram of the 3 conditions labeling the percentage (or probability) for ALL of the 8 “sections”. Hint: Start from the last condition and work your way up!\nFor each of the following (1. - 7. below), (\\(i\\)) write out the event using unions, intersections, and/or complements of the events \\(A\\), \\(B\\), and \\(C\\) (this is NOT finding the probability, that’s in \\(ii\\)); (\\(ii\\)) find the probability of the event; and (\\(iii\\)) write a sentence explaining what the probability is of in terms of the context of the problem.\n\n\\(\\mathbb{P}\\)(event at least one of the 3)\n\\(\\mathbb{P}\\)(event none)\n\\(\\mathbb{P}\\)(event \\(A\\) only)\n\\(\\mathbb{P}\\)(event exactly one)\n\\(\\mathbb{P}\\)(event \\(A\\) and \\(B\\))\n\\(\\mathbb{P}\\)(event \\(A\\) and \\(B\\) but not \\(C\\))\n\\(\\mathbb{P}\\)(event all 3)"
  },
  {
    "objectID": "homework/HW1.html#some-select-answers",
    "href": "homework/HW1.html#some-select-answers",
    "title": "Homework 1",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 2\n\n# 4: 0.35\n# 8: 0.03125\n# 16: 0.48\n# 30: (a) 0.189     (b) 0.811     (c) 0.189"
  },
  {
    "objectID": "homework/HW4.html",
    "href": "homework/HW4.html",
    "title": "Homework 4",
    "section": "",
    "text": "Important\n\n\n\nTHIS PAGE IS UNDER CONSTRUCTION!!"
  },
  {
    "objectID": "readings/Calc_review.html",
    "href": "readings/Calc_review.html",
    "title": "Calculus Review",
    "section": "",
    "text": "Calculus will be used in probability throughout the quarter, as well as in the following math stat classes. Below are topics and links from Paul’s Online Math Notes to help you review algebra and calculus skills that are essential to BSTA 550.\n\nYou can ignore all examples that use trigonometry.\nI listed the sections that you should be familiar with. The webpages have both notes and exercises for you to practice.\nI recommend first reviewing the italicized sections since we will be using series early in the course.\nWe will not use differentiation and integration until the second half of the course (Week 6), so you have some time to review."
  },
  {
    "objectID": "readings/Calc_review.html#introduction",
    "href": "readings/Calc_review.html#introduction",
    "title": "Calculus Review",
    "section": "",
    "text": "Calculus will be used in probability throughout the quarter, as well as in the following math stat classes. Below are topics and links from Paul’s Online Math Notes to help you review algebra and calculus skills that are essential to BSTA 550.\n\nYou can ignore all examples that use trigonometry.\nI listed the sections that you should be familiar with. The webpages have both notes and exercises for you to practice.\nI recommend first reviewing the italicized sections since we will be using series early in the course.\nWe will not use differentiation and integration until the second half of the course (Week 6), so you have some time to review."
  },
  {
    "objectID": "readings/Calc_review.html#topics",
    "href": "readings/Calc_review.html#topics",
    "title": "Calculus Review",
    "section": "Topics",
    "text": "Topics\n\nAlgebra\n\nPreliminaries\nSolving Equations And Inequalities\nGraphing And Functions\nExponential And Logarithm Functions\n\nCalculus 1   [Notes]   [Practice Problems]\n\nDerivatives\n\nDifferentiation Formulas\nProduct and Quotient Rule\nDerivatives of Exponential and Logarithm Functions (Only need exponential functions, and in particular only ex)\nChain Rule\n\nIntegrals\n\nIndefinite Integrals\nComputing Indefinite Integrals\nSubstitution Rule for Indefinite Integrals\nMore Substitution Rule\nArea Problem\n\nDon’t worry about the computations. Read through as a review for how integrals calculate area under the curve as the limit of areas of rectangles.\n\nThe Definition of the Definite Integral\nComputing Definite Integrals\nSubstitution Rule for Definite Integrals\n\nApplications of Integrals\n\nArea Between Curves\n\nExtras\n\nSummation Notation\n\n\nCalculus 2   [Notes]   [Practice Problems]\n\nIntegration Techniques\n\nIntegration by Parts\n\nSequences and Series\n\nSeries - The Basics\nSeries - Special Series (just Geometric Series)"
  },
  {
    "objectID": "schedule1.html",
    "href": "schedule1.html",
    "title": "Schedule",
    "section": "",
    "text": "ScheduleImportant timesCredit to\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJanuary\n\n\n\n\n\nMON\n\n\nTUE\n\n\nWED\n\n\nTHU\n\n\nFRI\n\n\n\n\n\n\n\n\n\n8\n\n\n\n\n\n\n9\n\n\n\n\n\n\n10\n\n\n\n\n\n\n11\n\n\n\n\n\n\n12\n\n\n\n\n\n\n\n\nWeek 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 0 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n15\n\n\n\n\n\n\n16\n\n\n\n\n\n\n17\n\n\n\n\n\n\n18\n\n\n\n\n\n\n19\n\n\n\n\n\n\n\n\nNo Class: MLKJ Day\n\n\n\n\n\n\n\n\n\n\n\nWeek 2\n\n\n\n\n\n\nLab 1 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n22\n\n\n\n\n\n\n23\n\n\n\n\n\n\n24\n\n\n\n\n\n\n25\n\n\n\n\n\n\n26\n\n\n\n\n\n\n\n\nWeek 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 1 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n29\n\n\n\n\n\n\n30\n\n\n\n\n\n\n31\n\n\n\n\n\n\n1\n\n\n\n\n\n\n2\n\n\n\n\n\n\n\n\nWeek 4Quiz 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 2 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFebruary\n\n\n\n\n\nMON\n\n\nTUE\n\n\nWED\n\n\nTHU\n\n\nFRI\n\n\n\n\n\n\n\n\n\n29\n\n\n\n\n\n\n30\n\n\n\n\n\n\n31\n\n\n\n\n\n\n1\n\n\n\n\n\n\n2\n\n\n\n\n\n\n\n\nWeek 4Quiz 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 2 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\n\n\n\n\n\n\n6\n\n\n\n\n\n\n7\n\n\n\n\n\n\n8\n\n\n\n\n\n\n9\n\n\n\n\n\n\n\n\nWeek 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 2 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n12\n\n\n\n\n\n\n13\n\n\n\n\n\n\n14\n\n\n\n\n\n\n15\n\n\n\n\n\n\n16\n\n\n\n\n\n\n\n\nWeek 6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 3 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n19\n\n\n\n\n\n\n20\n\n\n\n\n\n\n21\n\n\n\n\n\n\n22\n\n\n\n\n\n\n23\n\n\n\n\n\n\n\n\nNo Class: Pres Day\n\n\n\n\n\n\n\n\n\n\n\nWeek 7Quiz 2\n\n\n\n\n\n\nHW 4 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n26\n\n\n\n\n\n\n27\n\n\n\n\n\n\n28\n\n\n\n\n\n\n29\n\n\n\n\n\n\n1\n\n\n\n\n\n\n\n\nWeek 8Virtual Class\n\n\n\n\n\n\n\n\n\n\n\nVirtual Class\n\n\n\n\n\n\nLab 3 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarch\n\n\n\n\n\nMON\n\n\nTUE\n\n\nWED\n\n\nTHU\n\n\nFRI\n\n\n\n\n\n\n\n\n\n26\n\n\n\n\n\n\n27\n\n\n\n\n\n\n28\n\n\n\n\n\n\n29\n\n\n\n\n\n\n1\n\n\n\n\n\n\n\n\nWeek 8Virtual Class\n\n\n\n\n\n\n\n\n\n\n\nVirtual Class\n\n\n\n\n\n\nLab 3 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\n\n\n\n\n\n\n5\n\n\n\n\n\n\n6\n\n\n\n\n\n\n7\n\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\nWeek 9\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 5 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n11\n\n\n\n\n\n\n12\n\n\n\n\n\n\n13\n\n\n\n\n\n\n14\n\n\n\n\n\n\n15\n\n\n\n\n\n\n\n\nWeek 10Quiz 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 4 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n18\n\n\n\n\n\n\n19\n\n\n\n\n\n\n20\n\n\n\n\n\n\n21\n\n\n\n\n\n\n22\n\n\n\n\n\n\n\n\nWeek 11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinal Project Due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere is a tentative list of important, recurring times:\n\nHomeworks are always due at 11pm on the specified day (usually Thursday)\nLabs are always due at 11pm on the specified day (usually Thursday)\nExit tickets are due at 11pm 7 days after class\n\nSo for Monday classes, they are due the following Monday at 11pm\nFor Wednesday classes, they are due the following Wednesday at 11pm\n\nOffice hours with Nicky: Link to Webex\n\nThursdays, 11:30am - 1pm\nExceptions:\n\nJanuary 25th: 10:30am - 12pm\nFebruary 22nd: 10:30am - 12pm\n\n\nClass meets on Mondays and Wednesdays at 1 - 2:50 pm\n\n\n\nSpecial thank you to Andrew Bray, who taught the Quarto workshop I attended. This schedule page was mostly taken from the Schedule on his STAT 20 course page. You can find the .qmd file for Andrew’s schedule page on his Github."
  },
  {
    "objectID": "slides/2_Probability-solutions.html#overview",
    "href": "slides/2_Probability-solutions.html#overview",
    "title": "Chapter 2: Probability",
    "section": "Overview",
    "text": "Overview"
  },
  {
    "objectID": "schedule/week_01_sched.html#post-class-surveys",
    "href": "schedule/week_01_sched.html#post-class-surveys",
    "title": "Week 1",
    "section": "Post-Class Surveys",
    "text": "Post-Class Surveys\nSurvey link!!"
  },
  {
    "objectID": "homework/HW2.html#non-textbook-problems-ntb",
    "href": "homework/HW2.html#non-textbook-problems-ntb",
    "title": "Homework 2",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nRecall from class, that we defined events \\(A,B,\\) and \\(C\\) to mutually independent if both (1) and (2) below hold. This point of this exercise is to show that \\((1)\\nRightarrow (2),\\) and \\((2)\\nRightarrow (1).\\) \\[\\begin{array}{cc}\n    (1) & \\mathbb{P}(A\\cap B\\cap C)=\\mathbb{P}(A)\\mathbb{P(}B)\\mathbb{P(}C) \\\\\n    (2) & \\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\mathbb{P(}B) \\\\\n    & \\mathbb{P}(A\\cap C)=\\mathbb{P}(A)\\mathbb{P(}C) \\\\\n    & \\mathbb{P}(B\\cap C)=\\mathbb{P}(B)\\mathbb{P(}C)%\n    \\end{array}%\\]\n\nSuppose two different fair dice are rolled. Let events \\(A,B,\\) and \\(C\\) be defined in the following way: \\[\\begin{array}{cl}\nA: & \\text{Roll a total of 7} \\\\\nB: & \\text{First die is a 6} \\\\\nC: & \\text{Second die is a 2}%\n\\end{array}%\\]\nShow that condition \\((2)\\) holds, but that condition \\((1)\\) does not.\nSuppose two different fair dice are rolled. Let events \\(A,B,\\) and \\(C\\) be defined in the following way: \\[\\begin{array}{cl}\nA: & \\text{Roll a 1 or 2 on the first die} \\\\\nB: & \\text{Roll a 3, 4, or 5 on the second die} \\\\\nC: & \\text{Roll a total of 4, 11, or 12}%\n\\end{array}%\\]\nShow that condition \\((1)\\) holds, but that condition \\((2)\\) does not."
  },
  {
    "objectID": "homework/HW2.html#some-select-answershints",
    "href": "homework/HW2.html#some-select-answershints",
    "title": "Homework 2",
    "section": "Some select answers/hints",
    "text": "Some select answers/hints\n\nChapter 3\n\n# 4: (a) 0.111328    (b) 0.004872    0.995128\n# 10: (c) 0.384 If you have the right answer to (c), then you should be able to figure out the rest (see (e)).\n# 12: No.\nNTB #1: (a) 0.0799     (b) 0.07553     (c) 0.0655\n\nChapter 4\n\n#4: 0.25\n# 12: (a) 0.4285714     (b) 0.4285714     (c) 0.1428571\n\nChapter 5\n\nNTB #3: 0.392\nNTB #4: 11.89 (rounds to about 12)"
  },
  {
    "objectID": "homework/HW2.html#some-select-answers",
    "href": "homework/HW2.html#some-select-answers",
    "title": "Homework 2",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 22\n\n# 30: (a) 2,835     (b) 405     (c) 10,780     (d) 7,980\n# 40: 0.6666667\n# 42: 0.002116402 (This is the answer when \\(n=5\\). Your answer needs to be in terms of \\(n\\).)\n# 44: 0.3\n# 46: 0.3333333\n# 48: 0.007936508 (This is the answer when \\(n=5\\). Your answer needs to be in terms of \\(n\\).)\n\nChapter 3\n\n# 4: (a) 0.111328    (b) 0.004872    0.995128\n# 10: (c) 0.384 If you have the right answer to (c), then you should be able to figure out the rest (see (e)).\n# 12: No.\nNTB #1: (a) 0.0799     (b) 0.07553     (c) 0.0655\n\nChapter 4\n\n#4: 0.25\n# 12: (a) 0.4285714     (b) 0.4285714     (c) 0.1428571"
  },
  {
    "objectID": "homework/HW3.html#non-textbook-problems-ntb",
    "href": "homework/HW3.html#non-textbook-problems-ntb",
    "title": "Homework 3",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nA new drug is packaged to contain 30 pills in a bottle. Suppose that 98% of all bottles contain no defective pills, 1.5% contain one defective pill, and 0.5% contain two defective pills. Two pills from a bottle are randomly selected and tested. What is the probability that there are 2 defective pills in the bottle given that one of the two tested pills is defective?"
  },
  {
    "objectID": "homework/HW3.html#some-select-answers",
    "href": "homework/HW3.html#some-select-answers",
    "title": "Homework 3",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 5\n\nNTB #1: 0.392\n\nChapter 7\n\n# 2: \\(X\\in(0,\\infty)\\), continuous; \\(Y\\in\\{0,1,2,\\ldots\\}\\), discrete\n# 10: \\(X_j\\in[0,\\infty),j=1,\\ldots,100\\); \\(Y\\in[0,\\infty)\\); both continuous\n# 16: \\(Y\\) could be 0\n# 18: Yes, a r.v. can be both. Give an example!\n\nChapter 8\n\n# 2: (a) \\(p(x)=\\binom{7}{x}(.5)^7\\) for \\(x=0,1,2,\\ldots,7\\)\n# 9: (a) \\(c = \\frac{1}{8}\\)\n# 10:\n\n\n\n\n\\(x\\)\n2\n4\n6\n8\n\n\n\n\n\\(p(x)\\)\n3/10\n1/2\n3/20\n1/20"
  },
  {
    "objectID": "homework/HW4.html#non-textbook-problems-ntb",
    "href": "homework/HW4.html#non-textbook-problems-ntb",
    "title": "Homework 4",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nThe following table shows the results of a survey in which the subjects were a sample of 300 adults residing in a certain metropolitan area. Each subject was asked to indicate which of three policies they favored with respect to smoking in public places. (Table is from Biostatistics: A Foundation for Analysis in the Health Sciences, 10th Edition, Daniel, Wayne W.; Cross, Chad L., pg. 630)\n\n\n\n\n\nLet \\(X=\\) highest education level and \\(Y=\\) policy favored. We can let \\(X=1\\) for college graduate, \\(X=2\\) for high-school graduate, etc., and similarly for \\(Y\\), or just keep the category names for the different levels of \\(X\\) and \\(Y\\)\n\nMake a table for the joint pmf \\(p_{X,Y}(x,y)\\) and briefly describe in words what the values are the probability of.\nFind the marginal pmf \\(p_{X}(x)\\) and briefly describe in words what the values are the probability of.\nFind the marginal pmf \\(p_{Y}(y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the joint cdf \\(F_{X,Y}(x,y)\\) and briefly describe in words what the values are the probability of.\nFind the marginal cdf \\(F_{X}(x)\\) and briefly describe in words what the values are the probability of.\nFind the marginal cdf \\(F_{Y}(y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the conditional pmf \\(p_{X|Y}(x|y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the conditional pmf \\(p_{Y|X}(y|x)\\) and briefly describe in words what the values are the probability of.\n\nForgetful mornings revisited. Using the joint pmf you found in Chapter 9 #2, complete the following questions:\n\nFind the joint cdf of \\(X\\) and \\(Y\\) and briefly explain what \\(F_{X,Y}(x,y)\\) represents in the context of the problem.\nFind the conditional pmf \\(p_{Y|X}(y|x)\\).\n\nForgetful mornings revisited again. Recall from Chapter 9 #2, that \\(X\\) is the number of days until Maude loses her cell phone and each day she has a 1% chance of losing her phone (her behavior on different days being independent). For this problem, ignore the r.v. \\(Y\\), and consider the r.v. \\(X\\) on its own.\n\nWhat is the pmf of \\(X\\)?\nUse the pmf of \\(X\\) to find \\(\\mathbb{E}[X]\\).\n\nApproximately 10% of U.S. Veterans are women. Suppose an investigator plans a study with 4500 participants that are Veterans. How many women can they expect to be included? Your answer must be calculated by defining a random variable and showing how to calculate the expected value.\nCashews revisited. Recall from Chapter 10 #8, that a bowl contains 30 cashews, 20 pecans, 25 almonds, and 25 walnuts, and 3 nuts are randomly selected to eat (without replacement). Again, find the expected value of the number of cashews, but this time by defining the number of cashews as a sum of random variables."
  },
  {
    "objectID": "homework/HW4.html#some-select-answers",
    "href": "homework/HW4.html#some-select-answers",
    "title": "Homework 4",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 9\n\nNTB # 1 Partial answers:\n\n\n\\(p_{X|Y}(X=\\text{high school}| Y=\\text{no smoking at all}) = 0.476\\)\n\n\n\\(p_{Y|X}( Y=\\text{no smoking at all}|X=\\text{high school}) = 0.200\\)\n\n\n\nChapter 10\n\n# 6:  750.5\n# 8:  0.9\n# 10:   201\n# 14:   (a) 1.875     (b) 3.125     \n\nChapter 11\n\n# 2:  1.6\n# 18:  a) 48.5     (b) 96     \n# 20:  \\(\\approx\\) 23.077"
  },
  {
    "objectID": "homework/HW5.html#non-textbook-problems-ntb",
    "href": "homework/HW5.html#non-textbook-problems-ntb",
    "title": "Homework 5",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nProve that for a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), that \\[\\mathrm{Var}[aX+b]=a^2\\mathrm{Var}[X].\\] Note: you will not earn credit for citing this as a special case of a more general result.\nLet \\(\\bar{X}\\) be the random variable for the sample mean, \\(\\bar{X}=\\frac{\\sum_{i=1}^nX_i}{n}\\), where the \\(X_i\\) are i.i.d. random variables with common mean \\(\\mu\\) and variance \\(\\sigma^2\\).\n\nFind \\(\\mathbb{E}[\\bar{X}]\\).\nFind \\(Var[\\bar{X}]\\).\n\nLet \\(\\hat{p}\\) be the random variable for the sample proportion, \\(\\hat{p}=\\frac{X}{n}\\), where \\(X\\) is the number of successes in a random sample of size \\(n\\). Assume the probability of success is \\(p\\).\n\nFind \\(\\mathbb{E}[\\hat{p}]\\).\nFind \\(Var[\\hat{p}]\\).\n\nLet \\(X_i\\sim\\) Binomial(\\(n_i,p\\)) be independent r.v.’s for \\(i=1,\\ldots,m\\). What does the r.v. \\(X=\\sum_{i=1}^mX_i\\) count, and what is the distribution of \\(X\\)? Make sure to specify the parameters of \\(X\\)’s distribution.Find \\(\\mathbb{E}[X]\\). Make sure to show your work for (b) and (c). However, you may use without proof what you know about the mean and variance of each \\(X_i\\).Find \\(Var[X]\\).\nRead the Washington Post article The amazing woman who can smell Parkinson’s disease - before symptoms appear (http://www.washingtonpost.com/news/morning-mix/wp/2015/10/23/scottish-woman-detects-a-musky-smell-that-could-radically-improve-how-parkinsons-disease-is-diagnosed/)\nAssuming Joy Milne does not have the ability to detect Parkinson’s disease via smell, answer the following questions:\n\nWhat is the probability of her correctly detecting Parkinson’s by smelling one t-shirt?\nWhat is the probability of her correctly detecting Parkinson’s in 12 out of 12 t-shirts?\n\nLet \\(X_i\\sim\\) Negative Binomial(\\(r_i,p\\)) be independent r.v.’s for \\(i=1,\\ldots,m\\).\n\nWhat does the r.v. \\(X=\\sum_{i=1}^mX_i\\) count, and what is the distribution of \\(X\\)? Make sure to specify the parameters of \\(X\\)’s distribution.\nFind \\(\\mathbb{E}[X]\\). Make sure to show your work for (b) and (c). However, you may use without proof what you know about the mean and variance of each \\(X_i\\).\nFind \\(Var[X]\\)."
  },
  {
    "objectID": "homework/HW5.html#some-select-answers",
    "href": "homework/HW5.html#some-select-answers",
    "title": "Homework 5",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 12\n\n# 2:  64.8\n# 12:  1,096,357\n\nChapter 13\n\n# 4:  (a) 260/9     (b) 2.833     (c) \\(2.679\\times 10^{-5}\\)     (d) Same idea as (c) Replace 10’s with 100.     \n# 6:  (a) \\(p_X(x)=\\binom{4}{x}.3^x .7^{4-x}\\), for \\(x=0,1,\\ldots,4\\)     (d) 0.3483     (e) 0.9163     (f) 0.0233     (g) 1\n# 8:  (a) T     (b) F     (c) F     (d) F     (e) T     (f) T    (g) T\n# 10:  (a) T     (b) T    (c) F     (d) T    (e) T     (f) F    (g) T     (h) T (nonnegative instead of positive)     (i) F\n\nChapter 20\n\n# 2:  (a) 0.0001     (b) Discrete since \\(X\\) has a finite number of possible values. Uniform since each outcome is equally likely.     (c) \\(X\\) = randomly selected 4-digit ID#; \\(X=0000,0001,\\ldots,9999\\)     (d) 5000.5     (e) 8,333,333.25\n\nChapter 15\n\n# 18  (a) Bin(21,0.65)     (b) 4.78     \n\nChapter 16\n\n# 8  (c) \\(1.03\\times 10^{-6}\\)    (d) 10 questions: 91.43 minutes    \n\nChapter 17\n\n# 6   (a) 400, 87.18     (b) No     \n# 12   (c) 0.8000"
  },
  {
    "objectID": "homework/HW6.html#some-select-answers",
    "href": "homework/HW6.html#some-select-answers",
    "title": "Homework 6",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 19\n\n# 6:  (c) 15.625     (d) 0.0486     (f) 0.0488\n# 18:   100\n\nChapter 18\n\n# 24  (c) 0.8571\n# 26  162,754.8\n\nCalculus Review\n\n(a)  \\(c(\\frac{y^{2}}{2}+y^{2})\\)\n(b)  \\(\\frac{8}{9}xy^{2}+\\frac{5}{9}y^{4}\\)\n(c)  \\(\\frac{8}{9}x^{2}y+\\frac{20}{9}xy^{3}\\)\n(d)  \\(-2e^{-2y}+2e^{-y}\\)\n(e)  \\(xe^{-x}\\)\n(f)  \\(-\\frac{2}{3}(e^{-7x}-e^{-4x})\\)\n(g)  \\(\\frac{9}{2}\\)\n(h)  \\(\\frac{9}{2}\\)\n(i)  \\(\\frac{9}{2}\\)\n(j)  \\(\\frac{9}{2}\\)\n\nChapter 24\n\n# 2: (a) Discrete     (b) Discrete     (c) Continuous\n# 22: \\[f_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt;0 \\\\\n            \\frac{7x}{4} & \\quad 0\\leq x\\leq 1 \\\\\n            0 & \\quad 1&lt; x&lt; 7 \\\\\n            \\frac{1}{8} & \\quad 7\\leq x\\leq 8 \\\\\n            0 & \\quad  x&gt;8 \\\\\n        \\end{array}\n    \\right.\\]\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?\n\nChapter 27\n\n# 6: \\(f_{X|Y}(x|y)=\\frac{e^{-x/4-y/5}}{4(e^{-y/5}-e^{-9y/20})}\\), for \\(0&lt; x&lt; y\\)\n# 8: \\(f_{X|Y}(x|y)=\\frac{1-x^2}{1-y-\\frac{(1-y)^3}{3}}\\), for \\(0\\leq x, 0\\leq y, x+y\\leq 1\\)\n# 12: (a) \\(f_{X|Y}(x|y)=\\frac{1}{2}\\)    (c) \\(\\frac{4}{7}\\)"
  },
  {
    "objectID": "homework/HW8.html#non-textbook-problems-ntb",
    "href": "homework/HW8.html#non-textbook-problems-ntb",
    "title": "Homework 7",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nLet \\(f_X(x)=\\lambda e^{-\\lambda x}\\) for \\(x&gt;0\\), where \\(\\lambda&gt;0\\).\n\nShow \\(Var[X]=\\frac{1}{\\lambda^2}\\). You may use the result from class for \\(\\mathbb{E}[X]\\) without first proving it.\n\nA shipping company handles containers in three different sizes: (1) 27 \\(ft^3\\) (3 x 3 x 3), (2) 125 \\(ft^3\\), and (3) 512 \\(ft^3\\). Let \\(X_i\\) (\\(i = 1, 2, 3\\)) denote the number of type \\(i\\) containers shipped during a given week. Suppose that \\(\\mu_1 =200,\\sigma_1=10,\\mu_2 =250,\\sigma_2=12,\\mu_3 =100,\\sigma_3=8\\).\n\nAssuming that \\(X_1,X_2,X_3\\) are independent, calculate the expected value and variance of the total volume shipped.\nWould your calculations necessarily be correct if the \\(X_i\\)’s were not independent? Explain.\n\nSuppose your waiting time for a bus in the morning is uniformly distributed on [0, 8] (minutes), whereas waiting time in the evening is uniformly distributed on [0, 10] (minutes) independent of morning waiting time. Make sure to FIRST set up an equation for calculating the total waiting time in each question before calculating the mean and variance of the total waiting time. You may use results from class for the expected value and variance of uniform r.v.’s without proving them.\n\nIf you take the bus each morning and evening for a week (7 days), what is your total expected waiting time?\nWhat is the variance of your total waiting time?\nWhat are the expected value and variance of the difference between morning and evening waiting times on a given day?\nWhat are the expected value and variance of the difference between total morning waiting time and total evening waiting time for a particular week?\n\nSuppose that voters arrive at a polling station at the rate of 120 per hour.For each of the following parts, give the name and parameter(s) of the distribution to be used to model the event and set up the expression to find the specified probability.You do not need to compute the probability.\n\nThe probability that the next voter will arrive in less than 30 seconds.\nThe probability that 200 voters will arrive within two hours of each other.\nThe probability that the \\(50^{th}\\) voter will arrive in between 15 and 30 minutes.\n\nThe automatic opening device of a military cargo parachute has been designed to open when the parachute is 200 m above the ground. Suppose opening altitude actually has a normal distribution with mean value 200 m and standard deviation 30 m. Equipment damage will occur if the parachute opens at an altitude of less than 100 m. What is the probability that there is equipment damage to the payload of at least one of the five independentIy dropped parachutes?\nLet \\(R_X(t)=\\ln(M_X(t))\\). Show that Var\\((X)=R''_X(0)\\).\nThe mgf for a Gamma distribution is \\(M_X(t)=\\frac{1}{(1-t/\\lambda)^r}\\). Use the mgf of an Exponential distribution (from #43.9), to show that the sum of \\(n\\) i.i.d. Exponential(\\(\\lambda)\\) random variables has a Gamma(\\(r,\\lambda\\)) distribution.\nUse the mgf of a Poisson distribution to find the mgf of the following distributions. If the mgf is that of a common named distribution, then name the distribution and state its parameter(s).\n\nThe distribution of \\(\\sum_{i=1}^nX_i\\), if \\(X_i\\sim\\)Poisson\\((\\lambda_i)\\) and are independent.\nThe distribution of \\(\\sum_{i=1}^3X_i\\), if \\(X_i\\sim\\)Poisson\\((\\lambda)\\) and are independent (i.i.d. in this case).\nThe distribution of \\(3X\\), if \\(X\\sim\\)Poisson\\((\\lambda)\\).\nWhy are the answers to (b) and (c) different?\n\nUsing mgf’s, show that the sum of \\(n\\) i.i.d. Chi Square random variables with one degree of freedom (\\(\\chi^2_{(1)}\\)) r.v.’s has a Chi Square with \\(n\\) degrees of freedom (\\(\\chi^2_{(n)}\\)) distribution.\nHint: First, look up the pdf of a \\(\\chi^2_{(n)}\\). This is a special case of the Gamma distribution with what parameters? Based on that and the information from # 7 above, you can determine what the mgf of a \\(\\chi^2_{(n)}\\) is, which will help you determine whether the mgf of the sum of \\(n\\) i.i.d. \\(\\chi^2_{(1)}\\) r.v.’s has a \\(\\chi^2_{(n)}\\) distribution."
  },
  {
    "objectID": "homework/HW8.html#some-select-answers",
    "href": "homework/HW8.html#some-select-answers",
    "title": "Homework 7",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 28\n\n# 10: (a) 8/9     (b) 14/3     \n# 18: 4/5\n\nChapter 29\n\n# 10: (a) 26/81     (b) 74/9\n# 14: (a) 67/3     (b) 1/14     (c) 25/12     (d) \\(\\sqrt{25/12}\\)\n# 26: 250\n# 32: See notes (or book) for the proof from the discrete random variables case. The proof doesn’t depend on what type of random variable (discrete vs. continuous) is being used.\nNTB # 3: (a) 63     (b) 287/3     (c) -1, 41/3     (d) -7, 287/3\n\nChapter 30\n\n# 4: \\(f_x(x)=1/2\\) for \\(2\\leq x\\leq 4\\)\n# 8: (a) T     (b) T     (c) F\n# 10: (a) F     (b) T\n# 12: (a) T     (b) T     (c) F     (d) T\n\nChapter 31\n\n# 14: (a) 0.25     (b) 0.02887     (c) 0.063     (d) 0.0145     (e) 0.01625     (f) 0.0055     (f) 6.195    (g) 0.00433     (h) 61.95     (i) 0.0433\n# 17: 2.25\n# 18: 7/15\n\nChapter 32\n\n# 8: 0.2526\n# 5: 0.8047\n# 10: 0.4323\n\nChapter 33\n\n#10: (a) \\(f_x(x)=\\frac{x}{9}e^{-x/3}\\) for \\(x&gt; 0\\)     (b) 0.4963\n\nChapter 35\n\n# 6: (a) 0     (b) -1.13     (c) \\(\\pm 0.32\\)\n# 10: (a) 0.0475     (b) 0.0475     (c) 0.2283     (d) 68.97 to 81.03     (e) 48 to 102     (f) 68.97\n# 24: (a) 0.2119     (b) 0.0011\nNTB # 5:   0.002\n\nChapter 43\n\nNTB # __: (a) Poisson\\((\\sum_{i=1}^n \\lambda_i)\\)     (b) Poisson\\((3\\lambda)\\)      (c) \\(M_{3X}(t)=e{\\lambda(e^{3t}-1)}\\) This is not an mgf of a common probability distribution.      (d) In (b) we are adding independent r.v.’s \\(X_i\\), while in (c) we are adding dependent r.v.’s (\\(3X=X+X+X\\); \\(X\\) is dependent with itself).\n\nChapter 36\n\n# 4: 0.0044\n# 12: (a) 0.9525     (b) 0.7939     (c) 0.7939\n# 14: 0.5911\n# 16: (a) \\(R=8.225\\sigma+25\\mu\\)     (b) \\(R=16.45\\sigma+100\\mu\\)     (c) \\(R=164.5\\sigma+10,000\\mu\\)     (d) \\(R=1.645\\sqrt{n}\\sigma+n\\mu\\)\n\nChapter 37\n\n# 2: 0.8869\n# 4: 0.0023\n# 20: 0.3936\n# 24: 0.4562\n# 30: (b) 0.0022     (c) \\(478.696\\approx 479\\)"
  },
  {
    "objectID": "homework/HW8.html#footnotes",
    "href": "homework/HW8.html#footnotes",
    "title": "Homework 7",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI recommend doing the Chapter 29 Extra Problems in the order listed.↩︎\nAssume \\(X\\) and \\(Y\\) are independent.↩︎\nInclude in your answer an explanation as to why we need the condition that \\(t&lt;\\lambda\\).↩︎\nDo parts (a)-(c) below for #10 and #12:\n\nAnswer the question using the mgf \\(M_X(t)\\) as instructed in the book.\nAnswer the question using \\(R_X(t)\\) (as defined in class, and NTB # 6below).\nWhich method did you prefer? Why?\n\n↩︎\nDo parts (a)-(c) below for #10 and #12:\n\nAnswer the question using the mgf \\(M_X(t)\\) as instructed in the book.\nAnswer the question using \\(R_X(t)\\) (as defined in class, and NTB # 6 below).\nWhich method did you prefer? Why?\n\n↩︎\nAssume the distances between the cars are independent.↩︎"
  },
  {
    "objectID": "homework/HW7.html#non-textbook-problems-ntb",
    "href": "homework/HW7.html#non-textbook-problems-ntb",
    "title": "Homework 7",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nLet \\(f_X(x)=\\lambda e^{-\\lambda x}\\) for \\(x&gt;0\\), where \\(\\lambda&gt;0\\).\n\nShow \\(Var[X]=\\frac{1}{\\lambda^2}\\). You may use the result from class for \\(\\mathbb{E}[X]\\) without first proving it.\n\nA shipping company handles containers in three different sizes: (1) 27 \\(ft^3\\) (3 x 3 x 3), (2) 125 \\(ft^3\\), and (3) 512 \\(ft^3\\). Let \\(X_i\\) (\\(i = 1, 2, 3\\)) denote the number of type \\(i\\) containers shipped during a given week. Suppose that \\(\\mu_1 =200,\\sigma_1=10,\\mu_2 =250,\\sigma_2=12,\\mu_3 =100,\\sigma_3=8\\).\n\nAssuming that \\(X_1,X_2,X_3\\) are independent, calculate the expected value and variance of the total volume shipped.\nWould your calculations necessarily be correct if the \\(X_i\\)’s were not independent? Explain.\n\nSuppose your waiting time for a bus in the morning is uniformly distributed on [0, 8] (minutes), whereas waiting time in the evening is uniformly distributed on [0, 10] (minutes) independent of morning waiting time. Make sure to FIRST set up an equation for calculating the total waiting time in each question before calculating the mean and variance of the total waiting time. You may use results from class for the expected value and variance of uniform r.v.’s without proving them.\n\nIf you take the bus each morning and evening for a week (7 days), what is your total expected waiting time?\nWhat is the variance of your total waiting time?\nWhat are the expected value and variance of the difference between morning and evening waiting times on a given day?\nWhat are the expected value and variance of the difference between total morning waiting time and total evening waiting time for a particular week?\n\nSuppose that voters arrive at a polling station at the rate of 120 per hour.For each of the following parts, give the name and parameter(s) of the distribution to be used to model the event and set up the expression to find the specified probability.You do not need to compute the probability.\n\nThe probability that the next voter will arrive in less than 30 seconds.\nThe probability that 200 voters will arrive within two hours of each other.\nThe probability that the \\(50^{th}\\) voter will arrive in between 15 and 30 minutes.\n\nThe automatic opening device of a military cargo parachute has been designed to open when the parachute is 200 m above the ground. Suppose opening altitude actually has a normal distribution with mean value 200 m and standard deviation 30 m. Equipment damage will occur if the parachute opens at an altitude of less than 100 m. What is the probability that there is equipment damage to the payload of at least one of the five independentIy dropped parachutes?\nLet \\(R_X(t)=\\ln(M_X(t))\\). Show that Var\\((X)=R''_X(0)\\).\nThe mgf for a Gamma distribution is \\(M_X(t)=\\frac{1}{(1-t/\\lambda)^r}\\). Use the mgf of an Exponential distribution (from #43.9), to show that the sum of \\(n\\) i.i.d. Exponential(\\(\\lambda)\\) random variables has a Gamma(\\(r,\\lambda\\)) distribution.\nUse the mgf of a Poisson distribution to find the mgf of the following distributions. If the mgf is that of a common named distribution, then name the distribution and state its parameter(s).\n\nThe distribution of \\(\\sum_{i=1}^nX_i\\), if \\(X_i\\sim\\)Poisson\\((\\lambda_i)\\) and are independent.\nThe distribution of \\(\\sum_{i=1}^3X_i\\), if \\(X_i\\sim\\)Poisson\\((\\lambda)\\) and are independent (i.i.d. in this case).\nThe distribution of \\(3X\\), if \\(X\\sim\\)Poisson\\((\\lambda)\\).\nWhy are the answers to (b) and (c) different?\n\nUsing mgf’s, show that the sum of \\(n\\) i.i.d. Chi Square random variables with one degree of freedom (\\(\\chi^2_{(1)}\\)) r.v.’s has a Chi Square with \\(n\\) degrees of freedom (\\(\\chi^2_{(n)}\\)) distribution.\nHint: First, look up the pdf of a \\(\\chi^2_{(n)}\\). This is a special case of the Gamma distribution with what parameters? Based on that and the information from # 7 above, you can determine what the mgf of a \\(\\chi^2_{(n)}\\) is, which will help you determine whether the mgf of the sum of \\(n\\) i.i.d. \\(\\chi^2_{(1)}\\) r.v.’s has a \\(\\chi^2_{(n)}\\) distribution."
  },
  {
    "objectID": "homework/HW7.html#some-select-answers",
    "href": "homework/HW7.html#some-select-answers",
    "title": "Homework 7",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 28\n\n# 10: (a) 8/9     (b) 14/3     \n# 18: 4/5\n\nChapter 29\n\n# 10: (a) 26/81     (b) 74/9\n# 14: (a) 67/3     (b) 1/14     (c) 25/12     (d) \\(\\sqrt{25/12}\\)\n# 26: 250\n# 32: See notes (or book) for the proof from the discrete random variables case. The proof doesn’t depend on what type of random variable (discrete vs. continuous) is being used.\nNTB # 3: (a) 63     (b) 287/3     (c) -1, 41/3     (d) -7, 287/3\n\nChapter 30\n\n# 4: \\(f_x(x)=1/2\\) for \\(2\\leq x\\leq 4\\)\n# 8: (a) T     (b) T     (c) F\n# 10: (a) F     (b) T\n# 12: (a) T     (b) T     (c) F     (d) T\n\nChapter 31\n\n# 14: (a) 0.25     (b) 0.02887     (c) 0.063     (d) 0.0145     (e) 0.01625     (f) 0.0055     (f) 6.195    (g) 0.00433     (h) 61.95     (i) 0.0433\n# 17: 2.25\n# 18: 7/15\n\nChapter 32\n\n# 8: 0.2526\n# 5: 0.8047\n# 10: 0.4323\n\nChapter 33\n\n#10: (a) \\(f_x(x)=\\frac{x}{9}e^{-x/3}\\) for \\(x&gt; 0\\)     (b) 0.4963\n\nChapter 35\n\n# 6: (a) 0     (b) -1.13     (c) \\(\\pm 0.32\\)\n# 10: (a) 0.0475     (b) 0.0475     (c) 0.2283     (d) 68.97 to 81.03     (e) 48 to 102     (f) 68.97\n# 24: (a) 0.2119     (b) 0.0011\nNTB # 5:   0.002\n\nChapter 43\n\nNTB # __: (a) Poisson\\((\\sum_{i=1}^n \\lambda_i)\\)     (b) Poisson\\((3\\lambda)\\)      (c) \\(M_{3X}(t)=e{\\lambda(e^{3t}-1)}\\) This is not an mgf of a common probability distribution.      (d) In (b) we are adding independent r.v.’s \\(X_i\\), while in (c) we are adding dependent r.v.’s (\\(3X=X+X+X\\); \\(X\\) is dependent with itself).\n\nChapter 36\n\n# 4: 0.0044\n# 12: (a) 0.9525     (b) 0.7939     (c) 0.7939\n# 14: 0.5911\n# 16: (a) \\(R=8.225\\sigma+25\\mu\\)     (b) \\(R=16.45\\sigma+100\\mu\\)     (c) \\(R=164.5\\sigma+10,000\\mu\\)     (d) \\(R=1.645\\sqrt{n}\\sigma+n\\mu\\)\n\nChapter 37\n\n# 2: 0.8869\n# 4: 0.0023\n# 20: 0.3936\n# 24: 0.4562\n# 30: (b) 0.0022     (c) \\(478.696\\approx 479\\)"
  },
  {
    "objectID": "homework/HW7.html#footnotes",
    "href": "homework/HW7.html#footnotes",
    "title": "Homework 7",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI recommend doing the Chapter 29 Extra Problems in the order listed.↩︎\nAssume \\(X\\) and \\(Y\\) are independent.↩︎\nInclude in your answer an explanation as to why we need the condition that \\(t&lt;\\lambda\\).↩︎\nDo parts (a)-(c) below for #10 and #12:\n\nAnswer the question using the mgf \\(M_X(t)\\) as instructed in the book.\nAnswer the question using \\(R_X(t)\\) (as defined in class, and NTB # 6below).\nWhich method did you prefer? Why?\n\n↩︎\nDo parts (a)-(c) below for #10 and #12:\n\nAnswer the question using the mgf \\(M_X(t)\\) as instructed in the book.\nAnswer the question using \\(R_X(t)\\) (as defined in class, and NTB # 6 below).\nWhich method did you prefer? Why?\n\n↩︎\nAssume the distances between the cars are independent.↩︎"
  },
  {
    "objectID": "homeworks.html#homework",
    "href": "homeworks.html#homework",
    "title": "Homework and Solutions",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n10/5/23\n\n\nHomework 1\n\n\n4 min\n\n\n\n\n10/12/23\n\n\nHomework 2\n\n\n5 min\n\n\n\n\n10/19/23\n\n\nHomework 3\n\n\n5 min\n\n\n\n\n10/26/23\n\n\nHomework 4\n\n\n3 min\n\n\n\n\n11/2/23\n\n\nHomework 5\n\n\n5 min\n\n\n\n\n11/16/23\n\n\nHomework 6\n\n\n7 min\n\n\n\n\n11/30/23\n\n\nHomework 7\n\n\n11 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homeworks.html#homework-solutions",
    "href": "homeworks.html#homework-solutions",
    "title": "Homework and Solutions",
    "section": "Homework Solutions",
    "text": "Homework Solutions\n\n\n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homeworks.html#assignments",
    "href": "homeworks.html#assignments",
    "title": "Homework Assignments and Solutions",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n1/11/24\n\n\nHomework 0\n\n\n4 min\n\n\n\n\n1/18/24\n\n\nHomework 1\n\n\n6 min\n\n\n\n\n2/1/24\n\n\nHomework 2\n\n\n7 min\n\n\n\n\n2/15/24\n\n\nHomework 3\n\n\n9 min\n\n\n\n\n2/22/24\n\n\nHomework 4\n\n\n4 min\n\n\n\n\n3/7/24\n\n\nHomework 5\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homeworks.html#solutions",
    "href": "homeworks.html#solutions",
    "title": "Homework Assignments and Solutions",
    "section": "Solutions",
    "text": "Solutions\n\n\n\nHomework\nWritten Solutions\nVideos\n\n\n\n\n0\n\n\n\n\n1\n\n NTB 1a\n NTB 1b\n TB 2.30\n\n\n2\n\n\n\n\n3\n\n\n\n\n4\n\n\n\n\n5\n\n\n\n\n6\n\n\n\n\n7"
  },
  {
    "objectID": "schedule/week_02_sched.html#homework",
    "href": "schedule/week_02_sched.html#homework",
    "title": "Week 2",
    "section": "Homework",
    "text": "Homework\nHomework 1 due 10/5"
  },
  {
    "objectID": "schedule/week_02_sched.html#post-class-surveys",
    "href": "schedule/week_02_sched.html#post-class-surveys",
    "title": "Week 2",
    "section": "Post-Class Surveys",
    "text": "Post-Class Surveys\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_02_sched.html#statistician-of-the-week-regina-nuzzo",
    "href": "schedule/week_02_sched.html#statistician-of-the-week-regina-nuzzo",
    "title": "Week 2",
    "section": "Statistician of the Week: Regina Nuzzo",
    "text": "Statistician of the Week: Regina Nuzzo"
  },
  {
    "objectID": "schedule/syllabus.html",
    "href": "schedule/syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This course is designed to introduce history, concepts and distributions in probability, Monte Carlo simulation techniques, and Markov chains. Students will also learn how to write R codes for various statistical computations and plots. Previous experience in R is not required. R is free software available from http://www.r-project.org.\n\n\nAt the end of this course, students should be able to…\n\nUnderstand basic concepts in probability\nCompute probabilities for random variables\nCompute probabilities using basic distributions\nPerform statistical computations and simulations using R"
  },
  {
    "objectID": "schedule/syllabus.html#textbook",
    "href": "schedule/syllabus.html#textbook",
    "title": "Syllabus",
    "section": "Textbook",
    "text": "Textbook\n\nIntroduction to Probability\n\nAuthors: Mark Daniel Ward and Ellen Gundlach\nPublisher: W. H. Freeman\nEdition: 1st\nISBN-13: 978-0716771098\nTextbook in Sakai\n\n\n\nSupplemental Readings (Optional)\n\nStatistical Inference, Casella and Berger, 2nd ed. (This will be the textbook for BSTA 551-552 Math Stat.)\nIntroduction to Probability, Charles M. Grinstead and J. Laurie Snell, http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/pdf.html\nProbability With Applications and R, Robert P. Dobrow, Wiley 2013 (eBook available from OHSU library)\nAn Introduction to R (free pdf available from http://cran.r-project.org/manuals.html)"
  },
  {
    "objectID": "schedule/syllabus.html#online-resources",
    "href": "schedule/syllabus.html#online-resources",
    "title": "Syllabus",
    "section": "Online Resources",
    "text": "Online Resources\n\nSlack\nWe will use Slack as our main form of communication for the class. If you are unsure how to do a homework problem or have other questions, please ask myself or the TAs either by email or posting your question(s) on Slack. Please know that Slack is not guarded by the OSHU firewall, so if you have a question about accommodations or any sensitive topics, you may wish to message me via email. You can still message me regarding sensitive information on Slack, but I will not initiate those conversations on Slack.\n**Please use this invitation link for our Slack workspace!**\n\nTips on asking questions\n\nIf you are unsure how to do a homework problem or have other questions, please ask myself or the TA’s either by email or posting your question(s) on Slack. \nWhen reaching out for help for a homework problem, please include some context on what you have already tried.\n\nFor example, including a photo of your work thus far with an explanation of where you think you might be wrong is a quick way for me to look it over your work and help you troubleshoot. This helps me see what parts you already understand and which you need help with.\nIf you are unsure how to start a problem, look through your notes and the book for examples that you think might be similar. When reaching out, mention these examples and why you think they might be helpful, but also why you are still unsure on how to proceed.\nIf you only write something similar to “I don’t know how to do problem xxx,” then my response will be to ask you what you tried so far. Thus, it will be quicker for you to let me know this information right away.\n\nIf asking for help about a specific example that you don’t understand, please also provide some detail beyond “I don’t understand example xxx.”\n\nWhich steps of the problem do you not understand? You can refer to a line number, for example.\nIf you don’t understand the first step, do you understand the ones following it?\n\nIn general, when asking a question, please provide the homework number it is from along with the chapter and problem number. If it’s an example from the notes or book, an example number or slide number will help finding it.\nWant more tips on asking questions? This list below is a good start. It’s from https://www.weareteachers.com/8-ways-to-pose-better-questions-in-math-class/.\nFinally, if I don’t respond within a day and you need a response soon, please remind me by emailing or messaging me again.\n\n\n\n\nSakai\nWhile most course materials will be delivered online through this website, assignments will be turned in through Sakai, OHSU’s course management system. I will include a link on this website to the Sakai assignment page. \n\n\nExplain Everything\nI plan to use Explain Everything on my iPad to deliver lectures. This application allows me to take real-time notes, access Poll Everywhere, and record the lecture. I hope to use these features to allow you to follow me during lecture and have access to a recording for asynchronous viewing. While I will try to always make a recorded lecture available to you after class, I want you to try to attend class in person. I understand that life events get in the way of in-person attendance, but your attendance in-person brings me joy while I teach, and then further motivates me to be a great teacher. \nNote: I am new to this application so I ask you for some grace as I learn to navigate it. \n\n\nWebex\nWebex software will be used for virtual office hours. To give everyone the best possible experience with Webex, we recommend the following best practices:\n\nPlease stay muted until you want to participate\nDuring office hours, please send a message in chat with your question or with a statement like “I have a question.” This makes sure I or the TA can address everyone’s questions in order. \nI encourage you to attend office hours with your video on. This helps me recognize you, and keep mental notes on what techniques/concepts I emphasize to facilitate your specific understanding. \n\n\n\nPoll Everywhere\nWe will use the Poll Everywhere tool as an interactive feature of the course. Poll Everywhere is a web-based application that allows students to participate by responding via text messages or by visiting a web page on an internet-enabled device (smartphone, tablet, laptop). Instructions will be displayed on-screen. The poll that is embedded within the presentation will update in real time. While there is no cost to use this software, standard text messaging rates will apply if you use your phone. Please make sure that you have a Poll Everywhere account before our first class. You are not required to use your OHSU/PSU email to make an account. \nDuring lectures I will pose questions to the class. These questions are designed to provide real-time feedback to both students and the instructor on how well students are grasping the material. This is meant to be an interactive, learning activity with NO contribution to your grade. Your identity will never be connected to your answers, so I encourage you to answer honestly.\n\n\nPennState STAT 414 Website\nPennState has a class offered to advanced undergraduates that has some overlap with our class. They have all their course notes posted on thispage. This is a great source if you would like to see class notes with different phrasing.\nNot all of our topics are covered in their notes, but the most important ones are. If you are having trouble finding our course’s concepts on their page, please make ask me at Office Hours, after class, or in a private meeting. I do not explicitly state corresponding sections under our schedule because I believe it is important for you to develop skills involving resources and learning key words that can help you find answers. \n\n\nR: Statistical Computing Software\nStudents will use statistical software to complete homework assignments. Students are required to use R/RStudio for this course. R can be freely downloaded. Helpful documentation on installing R is available. I encourage you to install R prior to attending our first lecture. Please email me if you need help installing R or RStudio.\nYou will need to download the following three things:\n\nR https://www.r-project.org/\nRstudio https://posit.co/download/rstudio-desktop/\nQuarto https://quarto.org/docs/get-started/\n\n\nAdditional R Resources\nYour learning and practicing of R will hopefully not be limited to this course. One of the best aspects of programming in R is that many resources are freely available online. Here are just a few additional resources you may explore beyond this class to continue your training in R.\n\n\nUseful online R resources\n\nR for the rest of us\nStatistical tools for high-throughput data analysis. ggplot2 essentials\nR-bloggers\nStack Overflow for troubleshooting\nR Graphical Manual\nQuick-R. Accessing the power of R\nR for SAS, STATA, and SPSS Users\nggplot2\nLearn R 4 free\nJoin a local R user groups\nLearning Machines\n\n\n\nOnline R courses to complement or refresh material from class\n\nR for the rest of us\nCoursera: R programming\nedX: R basics\nData Carpentry: For Biologists\nData Carpentry: For Ecologists\nPsychiatric R\nR coder"
  },
  {
    "objectID": "schedule/syllabus.html#types-of-assessments",
    "href": "schedule/syllabus.html#types-of-assessments",
    "title": "Syllabus",
    "section": "Types of assessments",
    "text": "Types of assessments\nThis class will use a combination of formative and summative assessments to build and test our knowledge. Below I define each of these types of assessments:\n\nFormative assessment: Activity or work meant to help students learn and practice. Feedback on these assessments are meant to help the instructor and student identify gaps in knowledge and highlight accomplishments.\nSummative assessment: Work meant to test how well students have achieved learning objectives. Grading of these assessments are meant to gauge how well a student grasps the learning objectives and will be able to use their knowledge outside of the classroom."
  },
  {
    "objectID": "schedule/syllabus.html#breakdown",
    "href": "schedule/syllabus.html#breakdown",
    "title": "Syllabus",
    "section": "Breakdown",
    "text": "Breakdown\n\nGrading & Requirements\nLetter grades will be assigned roughly according to the following scheme: A (&gt;=93%), A- (90-92%), B+ (88-89%), B(83-87%), B- (82-80%), C+(78-79%), C(73-77%), C- (70-72%), D (60 – 69%), F(&lt;60%).\nGrades will be based on homework assignments, midterm exam, class “attendance”, and final exam, as follows:\n\n\n\n\n\n\n\n\n\nCourse activity\nType of Assessment\nDue Date\nPercentage of final grade\n\n\nHomework\nFormative\nApprox. weekly\n55%\n\n\nPost-class survey\nN/A\nTwice Weekly\n5%\n\n\nMidterm Exam\nSummative\n\n20%\n\n\nFinal Exam\nSummative\n\n20%\n\n\n\n\n\nCriteria\n\nHomework grading\nNo student has the same amount of time available to dedicate to homework. This class may not be a priority to you, you may be taking several other courses, or you may need to dedicate time to other activities. Homeworks are formative assessments, meaning its purpose is to help you learn and practice. To reduce the pressure on you to have perfect or complete homework, I have a very simple grading policy: Your homework will be given a check mark if you turn something in (whether it is incomplete, complete, correct, or wrong). I highly encourage you to stay up-to-date with the homeworks and put in as much effort as you can. This will be the most helpful work in this class!\nAfter the due date, either the TA or myself will give you feedback (on one or more complete problems) and post the solutions.\n\n\nViewing Grades in Sakai\nPoints you receive for graded activities will be posted to the Sakai Gradebook. Click on the Gradebook link on the left navigation to view your points.\n\n\nLate Work Policy\nI encourage you to make your best effort to submit all assignments on time, but I understand circumstances arise that are beyond our control. Please see this Swansea University’s page on extenuating circumstances for some examples. Not all circumstances are covered here, so please reach out if you have questions. \n\nThe class will end on December 8, 2023. All coursework is expected to be completed by then. If you have extenuating circumstances, and need additional time to complete class assignments, please contact me. Together, we will come up with a plan for completion and to sort out registrar logistics.\nIf you have extenuating circumstances that may jeopardize your ability to do work for several weeks, please contact me. We will come up with a plan to keep you on track in the course and prevent any delay in your education.\nFor homework, there is a due date posted, but you may turn in the assignment any time before the class ends. I will give you the check regardless of when you submit the assignment. However, if you would like feedback on the homework, you must turn it in on time OR email me asking for feedback for your late homework.\nFor non-homework assignments, I ask you to email me directly. You can explain your circumstances and may ask me for an extension, but I won’t necessarily grant one.\nIf you have a emergency involving your self, family, pet, friend, classmate, or anything/one deemed important to you, please do not worry about immediately contacting me. We can work something out after your emergency. If I contact you during an emergency, it is only because I am worried, and you do NOT need to respond until you are able. \n\n\n\nRegrade Policy\nIf you think a question was incorrectly graded, first compare your answer to the answer key. If you believe a re-grade would be appropriate, write an email to me containing the question and a short explanation as to why the question(s) was/were incorrectly graded. Deadline: One week after assignments were returned to class (late requests will not be considered).\n\n\nAttendance Policy\nYou are expected to attend class and participate in-class polls and the exit ticket. For students who miss class or need a review, I will make video and audio recordings of lectures available. There are no guarantees against technical or other challenges for the recording availability or quality. For students who are unable to attend the class in-person and synchronously, viewing the recording within 7 days is acceptable. This is meant to keep you on track within the course and prevent a pile up of material. Make sure to complete the exit ticket to demonstrate attendance."
  },
  {
    "objectID": "schedule/syllabus.html#ongoing-course-feedback",
    "href": "schedule/syllabus.html#ongoing-course-feedback",
    "title": "Syllabus",
    "section": "Ongoing Course Feedback",
    "text": "Ongoing Course Feedback\nThroughout the duration of the course, you are also welcome to informally and anonymously submit your feedback through this Microsoft Form or Class Exit Tickets. This form will be available on Sakai. Students can submit feedback at any time and this form will be reviewed regularly by me. Your responses will be anonymous unless you elect to leave your email address. If I have done anything to make you feel uncomfortable, please give me feedback so I can change my behavior. Ultimately, this class is for you, and my individual social identity/behavior should not inhibit your learning. Thank you for your help making BSTA 513/613 a more successful class! Examples of ongoing feedback are:\n\nNicky talks a little fast during lecture time. May you speak slower?\nDuring Office Hours, Dr. Wakim made a face when I asked a question. This face made me feel self-conscious about my question.\nDr. W asked me a question about my experience that made me feel like a monolith for my race. Please do not assume I can speak on behalf of my social identity groups.\nThe in-class examples do not make me more interested in the material."
  },
  {
    "objectID": "schedule/syllabus.html#midterm-feedback",
    "href": "schedule/syllabus.html#midterm-feedback",
    "title": "Syllabus",
    "section": "Midterm Feedback",
    "text": "Midterm Feedback\nDuring the middle of the quarter, I will ask you to submit guided, anonymous feedback. Completion of feedback will be count towards your midterm exam grade. To insure anonymity, I will ask you to sign a separate, written statement that you completed the feedback."
  },
  {
    "objectID": "schedule/syllabus.html#final-course-feedback",
    "href": "schedule/syllabus.html#final-course-feedback",
    "title": "Syllabus",
    "section": "Final Course Feedback",
    "text": "Final Course Feedback\nAt the conclusion of the course, you will be asked to complete a formal online review of the course and the instructor. Your feedback on this University evaluation is critical to improving future student learning in this course as well as providing metrics relevant to the instructor’s career advancement."
  },
  {
    "objectID": "schedule/syllabus.html#instructor-expectations",
    "href": "schedule/syllabus.html#instructor-expectations",
    "title": "Syllabus",
    "section": "Instructor Expectations",
    "text": "Instructor Expectations\nCommitment to your learning and your success\nI believe that everyone has the ability to be successful in this course and I have put a lot of effort into designing the course in a way that maximizes your learning to ensure your success. Please talk to me before or after class or stop by my office if there is anything you want to discuss or about which you are unclear. I want to be supportive of your learning and growth.\nInclusive & supportive learning community\nI believe that learning happens best when we all learn together, as a community. This means creating a space characterized by generous listening, civility, humility, patience, and hospitality. I will attempt to promote a safe climate where we examine content from multiple cultural perspectives, and I will strive to create and maintain a classroom atmosphere in which you feel free to both listen to others and express your views and ask questions to increase your learning.\nOpenness to feedback\nI appreciate straightforward feedback from you regarding how well the class is meeting your needs. Let me know if material is not clear or when its relevance to the student learning outcomes for the course is not apparent. In particular, let me know if you identify bias or stereotyping in my teaching materials as I will seek to continuously improve. Please also let me know if there’s an aspect of the class you find particularly interesting, helpful, or enjoyable!\nResponsiveness\nI will monitor email as well as the discussion board daily and try respond to all messages within 24 hours Monday-Friday.\nClear guidelines and prompt feedback on assignments\nI will provide clear instructions for all assignments, and a grading rubric when applicable. I will provide detailed feedback on your submissions and will update grades promptly in Sakai."
  },
  {
    "objectID": "schedule/syllabus.html#student-expectations-and-resources",
    "href": "schedule/syllabus.html#student-expectations-and-resources",
    "title": "Syllabus",
    "section": "Student Expectations and Resources",
    "text": "Student Expectations and Resources\nAttend class\nYou are expected to attend all scheduled class meetings synchronously or watch the recording within 7 days. Attendance is taken through exit tickets. If you have issues accessing the poll on a specific day, please let me know. \nParticipate\nI encourage you to participate actively in class and online discussions. I will expect all students, and all instructors, to be respectful of each other’s contributions, whether I agree with them or not. Professional interactions are expected.\nBuild rapport\nIf you find that you have any trouble keeping up with assignments or other aspects of the course, make sure you let me know as early as possible. As you will find, building rapport and effective relationships are key to becoming an effective professional. Make sure that you are proactive in informing me when difficulties arise during the semester so that I can help you find a solution.\nComplete assignments\nAll assignments for this course will be submitted electronically through Sakai unless otherwise instructed.  I encourage you to make your best effort to submit all assignments on time, but I understand that sometimes circumstances arise that are beyond our control. If you need an extension, please contact me in congruence with the Late Policy.\nSeek help if you need it\nI believe it is important to support the physical and emotional well‐being of my students. If you are experiencing physical or mental health issues, I encourage you to use the resources on campus such as those listed below. If you have a health issue that is affecting your performance or participation in the course, and/or if you need help connecting with these resources, please contact the instructor or any of the TAs.\n\nStudent Health and Wellness Center (SHW), Website, 503-494-8665 (OHSU Students only)\nStudent Health and Counseling (SHAC), Website, 503-725-2800\n\nInform your instructor of any accommodations needed\nYou should speak with or email me before or during the first week of classes regarding any special needs. Students seeking academic accommodations should register with the appropriate service under the School policies below.\nSome religious holidays may occur on regularly scheduled class days. Because available class hours are so limited in number, we will have to hold class on all such days. Class video recordings will be available and you are encouraged to engage with the material outside of the regular class time. You are also encouraged to come to office hours with questions from the session.\nCommit to integrity\nAs a student in this course (and at PSU or OHSU) you are expected to maintain high degrees of professionalism, commitment to active learning and participation in this class and also integrity in your behavior in and out of the classroom.\nCheating and other forms of academic misconduct will not be tolerated in this course and will be dealt with firmly. Student academic misconduct refers to behavior that includes plagiarism, cheating on assignments, fabrication of data, falsification of records or official documents, intentional misuse of equipment or materials (including library materials), or aiding and abetting the perpetration of such acts. Preparation of papers or homework, assigned on an individual basis, must represent each student’s own individual effort. When used, resource materials should be cited in conventional reference format."
  },
  {
    "objectID": "schedule/syllabus.html#course-learning-objectives",
    "href": "schedule/syllabus.html#course-learning-objectives",
    "title": "Syllabus",
    "section": "Course Learning Objectives",
    "text": "Course Learning Objectives\nAt the end of this course, students should be able to…\n\nUnderstand basic concepts in probability\nCompute probabilities for random variables\nCompute probabilities using basic distributions\nPerform statistical computations and simulations using R"
  },
  {
    "objectID": "schedule/syllabus.html#description",
    "href": "schedule/syllabus.html#description",
    "title": "Syllabus",
    "section": "",
    "text": "This course is designed to introduce history, concepts and distributions in probability, Monte Carlo simulation techniques, and Markov chains. Students will also learn how to write R codes for various statistical computations and plots. Previous experience in R is not required. R is free software available from http://www.r-project.org.\n\n\nAt the end of this course, students should be able to…\n\nUnderstand basic concepts in probability\nCompute probabilities for random variables\nCompute probabilities using basic distributions\nPerform statistical computations and simulations using R"
  },
  {
    "objectID": "schedule/syllabus.html#instructors",
    "href": "schedule/syllabus.html#instructors",
    "title": "Syllabus",
    "section": "Instructors",
    "text": "Instructors\nHere is the instructor page."
  },
  {
    "objectID": "schedule/syllabus.html#meeting-times",
    "href": "schedule/syllabus.html#meeting-times",
    "title": "Syllabus",
    "section": "Meeting Times",
    "text": "Meeting Times\nMondays         10:30 AM – 12:00 PM PST in room RLSB 1S008\nWednesdays   10:30 AM – 12:00 PM PST in room RLSB 1S008\n\nKnown Exceptions\nWednesday, October 25       10:30 AM – 12:00 PM PST on Webex OR pre-recorded\nWednesday, November 22    No class"
  },
  {
    "objectID": "schedule/syllabus.html#materials",
    "href": "schedule/syllabus.html#materials",
    "title": "Syllabus",
    "section": "Materials",
    "text": "Materials\n\nTextbook\n\nIntroduction to Probability\n\nAuthors: Mark Daniel Ward and Ellen Gundlach\nPublisher: W. H. Freeman\nEdition: 1st\nISBN-13: 978-0716771098\nTextbook in Sakai\n\n\n\nSupplemental Readings (Optional)\n\nStatistical Inference, Casella and Berger, 2nd ed. (This will be the textbook for BSTA 551-552 Math Stat.)\nIntroduction to Probability, Charles M. Grinstead and J. Laurie Snell, http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/pdf.html\nProbability With Applications and R, Robert P. Dobrow, Wiley 2013 (eBook available from OHSU library)\nAn Introduction to R (free pdf available from http://cran.r-project.org/manuals.html)\n\n\n\n\nOnline Resources\n\nSlack\nWe will use Slack as our main form of communication for the class. If you are unsure how to do a homework problem or have other questions, please ask myself or the TAs either by email or posting your question(s) on Slack. Please know that Slack is not guarded by the OSHU firewall, so if you have a question about accommodations or any sensitive topics, you may wish to message me via email. You can still message me regarding sensitive information on Slack, but I will not initiate those conversations on Slack.\n**Please use this invitation link for our Slack workspace!**\n\nTips on asking questions\n\nIf you are unsure how to do a homework problem or have other questions, please ask myself or the TA’s either by email or posting your question(s) on Slack. \nWhen reaching out for help for a homework problem, please include some context on what you have already tried.\n\nFor example, including a photo of your work thus far with an explanation of where you think you might be wrong is a quick way for me to look it over your work and help you troubleshoot. This helps me see what parts you already understand and which you need help with.\nIf you are unsure how to start a problem, look through your notes and the book for examples that you think might be similar. When reaching out, mention these examples and why you think they might be helpful, but also why you are still unsure on how to proceed.\nIf you only write something similar to “I don’t know how to do problem xxx,” then my response will be to ask you what you tried so far. Thus, it will be quicker for you to let me know this information right away.\n\nIf asking for help about a specific example that you don’t understand, please also provide some detail beyond “I don’t understand example xxx.”\n\nWhich steps of the problem do you not understand? You can refer to a line number, for example.\nIf you don’t understand the first step, do you understand the ones following it?\n\nIn general, when asking a question, please provide the homework number it is from along with the chapter and problem number. If it’s an example from the notes or book, an example number or slide number will help finding it.\nWant more tips on asking questions? This list below is a good start. It’s from https://www.weareteachers.com/8-ways-to-pose-better-questions-in-math-class/.\nFinally, if I don’t respond within a day and you need a response soon, please remind me by emailing or messaging me again.\n\n\n\n\nSakai\nWhile most course materials will be delivered online through this website, assignments will be turned in through Sakai, OHSU’s course management system. I will include a link on this website to the Sakai assignment page. \n\n\nExplain Everything\nI plan to use Explain Everything on my iPad to deliver lectures. This application allows me to take real-time notes, access Poll Everywhere, and record the lecture. I hope to use these features to allow you to follow me during lecture and have access to a recording for asynchronous viewing. While I will try to always make a recorded lecture available to you after class, I want you to try to attend class in person. I understand that life events get in the way of in-person attendance, but your attendance in-person brings me joy while I teach, and then further motivates me to be a great teacher. \nNote: I am new to this application so I ask you for some grace as I learn to navigate it. \n\n\nWebex\nWebex software will be used for virtual office hours. To give everyone the best possible experience with Webex, we recommend the following best practices:\n\nPlease stay muted until you want to participate\nDuring office hours, please send a message in chat with your question or with a statement like “I have a question.” This makes sure I or the TA can address everyone’s questions in order. \nI encourage you to attend office hours with your video on. This helps me recognize you, and keep mental notes on what techniques/concepts I emphasize to facilitate your specific understanding. \n\n\n\nPoll Everywhere\nWe will use the Poll Everywhere tool as an interactive feature of the course. Poll Everywhere is a web-based application that allows students to participate by responding via text messages or by visiting a web page on an internet-enabled device (smartphone, tablet, laptop). Instructions will be displayed on-screen. The poll that is embedded within the presentation will update in real time. While there is no cost to use this software, standard text messaging rates will apply if you use your phone. Please make sure that you have a Poll Everywhere account before our first class. You are not required to use your OHSU/PSU email to make an account. \nDuring lectures I will pose questions to the class. These questions are designed to provide real-time feedback to both students and the instructor on how well students are grasping the material. This is meant to be an interactive, learning activity with NO contribution to your grade. Your identity will never be connected to your answers, so I encourage you to answer honestly.\n\n\nPennState STAT 414 Website\nPennState has a class offered to advanced undergraduates that has some overlap with our class. They have all their course notes posted on thispage. This is a great source if you would like to see class notes with different phrasing.\nNot all of our topics are covered in their notes, but the most important ones are. If you are having trouble finding our course’s concepts on their page, please make ask me at Office Hours, after class, or in a private meeting. I do not explicitly state corresponding sections under our schedule because I believe it is important for you to develop skills involving resources and learning key words that can help you find answers. \n\n\nR: Statistical Computing Software\nStudents will use statistical software to complete homework assignments. Students are required to use R/RStudio for this course. R can be freely downloaded. Helpful documentation on installing R is available. I encourage you to install R prior to attending our first lecture. Please email me if you need help installing R or RStudio.\nYou will need to download the following three things:\n\nR https://www.r-project.org/\nRstudio https://posit.co/download/rstudio-desktop/\nQuarto https://quarto.org/docs/get-started/\n\n\nAdditional R Resources\nYour learning and practicing of R will hopefully not be limited to this course. One of the best aspects of programming in R is that many resources are freely available online. Here are just a few additional resources you may explore beyond this class to continue your training in R.\n\n\nUseful online R resources\n\nR for the rest of us\nStatistical tools for high-throughput data analysis. ggplot2 essentials\nR-bloggers\nStack Overflow for troubleshooting\nR Graphical Manual\nQuick-R. Accessing the power of R\nR for SAS, STATA, and SPSS Users\nggplot2\nLearn R 4 free\nJoin a local R user groups\nLearning Machines\n\n\n\n\nOnline R courses to complement or refresh material from class\n\nR for the rest of us\nCoursera: R programming\nedX: R basics\nData Carpentry: For Biologists\nData Carpentry: For Ecologists\nPsychiatric R\nR coder"
  },
  {
    "objectID": "schedule/syllabus.html#assessment",
    "href": "schedule/syllabus.html#assessment",
    "title": "Syllabus",
    "section": "Assessment",
    "text": "Assessment\nThe course is structured around the following four components:\n\n\n\n\n\n\n\n\n\nComponent\nModality\nFrequency\nDescription\n\n\nLecture\nIn person\nTwice, Weekly\nCourse content is provided through in-person lectures. Lectures will consist of didactic lessons, interactive examples, and PollEverywhere questions. Sessions will be recorded through Explain Everything and posted to Sakai. Attending or viewing the lecture within 7 days of the original lecture date is mandatory. Class attendance will be taken through an Exit Ticket. If viewing the lecture asynchronously, you must take the Exit Ticket to verify your attendance.\n\n\nHomework\nOnline\nWeekly\nThe course includes 6 homework assignments. They are an opportunity for you to engage with important concepts, practice coding, and apply calculating skills. Homework assignments should be submitted online, and will be graded by TAs. Students are encouraged to work in groups for homework assignments, but each person should do their own summary and hand in their work. Homework assignments will be due on Thursday at 11 PM.\n\n\nMidterm Exam\nIn person\nOnce\nThe purpose of the midterm is to assess how well you have achieved the learning objectives through questions covering important concepts, conducting statistical processes, and interpreting output. We will have our midterm in-class, and it will be open book. Students must work on the exam independently.\n\n\nFinal Exam\nIn person\nOnce\nThe purpose of the final is to assess how well you have achieved the learning objectives through questions covering important concepts, conducting statistical processes, and interpreting output. We will have our final in-class, and it will be open book. Students must work on the exam independently. While the final exam is not explicitly cumulative, certain topics learned before the midterm will carry over to material in the later part of the course.\n\n\n\n\nTypes of assessments\nThis class will use a combination of formative and summative assessments to build and test our knowledge. Below I define each of these types of assessments:\n\nFormative assessment: Activity or work meant to help students learn and practice. Feedback on these assessments are meant to help the instructor and student identify gaps in knowledge and highlight accomplishments.\nSummative assessment: Work meant to test how well students have achieved learning objectives. Grading of these assessments are meant to gauge how well a student grasps the learning objectives and will be able to use their knowledge outside of the classroom.\n\n\n\nBreakdown\n\nGrading & Requirements\nLetter grades will be assigned roughly according to the following scheme: A (&gt;=93%), A- (90-92%), B+ (88-89%), B(83-87%), B- (82-80%), C+(78-79%), C(73-77%), C- (70-72%), D (60 – 69%), F(&lt;60%).\nGrades will be based on homework assignments, midterm exam, class “attendance”, and final exam, as follows:\n\n\n\n\n\n\n\n\n\nCourse activity\nType of Assessment\nDue Date\nPercentage of final grade\n\n\nHomework\nFormative\nApprox. weekly\n55%\n\n\nPost-class survey\nN/A\nTwice Weekly\n5%\n\n\nMidterm Exam\nSummative\n\n20%\n\n\nFinal Exam\nSummative\n\n20%\n\n\n\n\n\nCriteria\n\nHomework grading\nNo student has the same amount of time available to dedicate to homework. This class may not be a priority to you, you may be taking several other courses, or you may need to dedicate time to other activities. Homeworks are formative assessments, meaning its purpose is to help you learn and practice. To reduce the pressure on you to have perfect or complete homework, I have a very simple grading policy: Your homework will be given a check mark if you turn something in (whether it is incomplete, complete, correct, or wrong). I highly encourage you to stay up-to-date with the homeworks and put in as much effort as you can. This will be the most helpful work in this class!\nAfter the due date, either the TA or myself will give you feedback (on one or more complete problems) and post the solutions.\n\n\n\nViewing Grades in Sakai\nPoints you receive for graded activities will be posted to the Sakai Gradebook. Click on the Gradebook link on the left navigation to view your points."
  },
  {
    "objectID": "schedule/syllabus.html#course-instructor-evaluations",
    "href": "schedule/syllabus.html#course-instructor-evaluations",
    "title": "Syllabus",
    "section": "Course & Instructor Evaluations",
    "text": "Course & Instructor Evaluations\n\nOngoing Course Feedback\nThroughout the duration of the course, you are also welcome to informally and anonymously submit your feedback through this Microsoft Form or Class Exit Tickets. This form will be available on Sakai. Students can submit feedback at any time and this form will be reviewed regularly by me. Your responses will be anonymous unless you elect to leave your email address. If I have done anything to make you feel uncomfortable, please give me feedback so I can change my behavior. Ultimately, this class is for you, and my individual social identity/behavior should not inhibit your learning. Thank you for your help making BSTA 513/613 a more successful class! Examples of ongoing feedback are:\n\nNicky talks a little fast during lecture time. May you speak slower?\nDuring Office Hours, Dr. Wakim made a face when I asked a question. This face made me feel self-conscious about my question.\nDr. W asked me a question about my experience that made me feel like a monolith for my race. Please do not assume I can speak on behalf of my social identity groups.\nThe in-class examples do not make me more interested in the material.\n\n\n\nMidterm Feedback\nDuring the middle of the quarter, I will ask you to submit guided, anonymous feedback. Completion of feedback will be count towards your midterm exam grade. To insure anonymity, I will ask you to sign a separate, written statement that you completed the feedback.\n\n\nFinal Course Feedback\nAt the conclusion of the course, you will be asked to complete a formal online review of the course and the instructor. Your feedback on this University evaluation is critical to improving future student learning in this course as well as providing metrics relevant to the instructor’s career advancement."
  },
  {
    "objectID": "schedule/syllabus.html#schedule",
    "href": "schedule/syllabus.html#schedule",
    "title": "Syllabus",
    "section": "Schedule",
    "text": "Schedule\nPlease refer to the Schedule page. I will make changes to this schedule if we need more or less time on a concept. You do not need to read the corresponding chapters in the textbook for each class."
  },
  {
    "objectID": "schedule/syllabus.html#how-to-succeed-in-this-course",
    "href": "schedule/syllabus.html#how-to-succeed-in-this-course",
    "title": "Syllabus",
    "section": "How to succeed in this course",
    "text": "How to succeed in this course\nEvery professor has different expectations when assigning certain work or providing certain resources. I want to walk through each class resource and assignment so that you know what you can do to succeed in this class. For resources, I want you to optimize the opportunities to learn. For assignments, I want you to know the strategies that students can use to learn the most and prepare for future exams.\n\nResources\n\n\n\n\n\n\n\n\nResource\nWhat is it?\nHow do I use it?\n\n\nOffice Hours\nBlocks of time where a professor or TA dedicates for questions. The teaching staff will be located in a specific room. Several students may enter the space at a time and will ask specific or broad questions. If many students attend office hours, a queue will be created so that students can be served equally.\nThe main use of office hours is to ask questions about an assignment or lecture notes. You are welcome to sit and do homework in office hours. OH are also an informal way of meeting fellow students to collaborate with.\n\n\nLectures and lecture recordings\nTime shared between the professor and students where the professor conveys important class material. Material discussed in lectures include concepts, calculations, code, and examples. Lectures are a mix of presentation of information, working through examples together, interactive activities, and in-class polls.\nStudents should attend lectures in person if possible. You should attempt to understand new material presented by following the presentation slides, taking notes on additional details that may conveyed verbally, and working through examples with the professor. Students are encouraged to ask questions when you don’t understand the material at any point in the lecture.\n\n\nTextbooks\nWritten and published material that explains concepts, steps through calculations, provides examples, and provides practice problems. The listed textbooks is the basis for this course. While I am to cover all topics in class, the textbook provides alternative explanations and additional examples.\nWhile coming to class having read the accompanying textbook chapters helps understanding during class, I do not expect students to have read it. I see the textbook as a good resource if you are struggling with a specific topic after class, in need of an example while working on homework, or want additional practice when studying for the exam.\n\n\nWebsite\nThe course website is designed by me so that you have access to all the course materials in a more organized and flexible way. All resources delivered from me to you will be available on the website. Any assignments turned in will be through Sakai.\nYou can navigate through different course resources and information using the left-side tabs or top navigation bar. Course materials, like lecture notes, homework, data examples, and recordings, can be found under each week’s page under the schedule tab. You can also find the individual resources under the “Course Materials” tab on the left. Links to turn in assignments through Sakai will be given on the website. Please explore the tabs and get a sense of the organization.\n\n\nSakai\nSakai is a learning management system for higher ed. This is the university sanctioned LMS where we will submit assignments.\nYou will turn in assignments through Sakai under the “Submissions” tab. Generally, there will be a link to each assignment on the course website. You can also view your grades under “Gradebook” and links to Webex under “Webex.”\n\n\n\n\n\nAssignments\n\n\n\n\n\n\n\n\n\nAssignment\nType of assessment\nBefore you submit/take it\nAfter it is graded\n\n\nHomework\nFormative\n\nWork out each problem on your own as much as you can\nTalk through problems with a peer\nGo to Office Hours for help\nWrite down work that shows your thought process\nSearch your issue on Stack Exchange/Stack Overflow\n\n\nReview the solutions\nReview your mistakes\nFor solutions that involve writing sentences, check with me or a TA if your answer fits the solution\nGo to Office Hours to ask about your solutions\n\n\n\nMidterm / Final Exam\nSummative\n\nIdentify and achieve learning objectives in each lecture\nUnderstand why certain statistics tools are used for certain cases\nPractice problems that you struggled with\nCome to Office Hours for help with specific problems or concepts\n\n\nReview the solutions\nReview your mistakes\nFor solutions that involve writing sentences, check with me or a TA if your answer fits the solution\nGo to Office Hours to ask about your solutions\nDo not ask for a regrade unless you have viewed the solutions\n\n\n\nClass Surveys\nN/A\n\nBring appropriate electronic device to participate in polls\nComplete the survey during the last 5 minutes of class or after class within 7 days\n\n\nReview muddiest and clearest points from the week\n\n\n\n\nIf you would like any other course resources explained in this format, please request it through the Ongoing Course Feedback."
  },
  {
    "objectID": "schedule/syllabus.html#course-policies-and-resources",
    "href": "schedule/syllabus.html#course-policies-and-resources",
    "title": "Syllabus",
    "section": "Course Policies and Resources",
    "text": "Course Policies and Resources\n\nLate Work Policy\nI encourage you to make your best effort to submit all assignments on time, but I understand circumstances arise that are beyond our control. Please see this Swansea University’s page on extenuating circumstances for some examples. Not all circumstances are covered here, so please reach out if you have questions. \n\nThe class will end on December 8, 2023. All coursework is expected to be completed by then. If you have extenuating circumstances, and need additional time to complete class assignments, please contact me. Together, we will come up with a plan for completion and to sort out registrar logistics.\nIf you have extenuating circumstances that may jeopardize your ability to do work for several weeks, please contact me. We will come up with a plan to keep you on track in the course and prevent any delay in your education.\nFor homework, there is a due date posted, but you may turn in the assignment any time before the class ends. I will give you the check regardless of when you submit the assignment. However, if you would like feedback on the homework, you must turn it in on time OR email me asking for feedback for your late homework.\nFor non-homework assignments, I ask you to email me directly. You can explain your circumstances and may ask me for an extension, but I won’t necessarily grant one.\nIf you have a emergency involving your self, family, pet, friend, classmate, or anything/one deemed important to you, please do not worry about immediately contacting me. We can work something out after your emergency. If I contact you during an emergency, it is only because I am worried, and you do NOT need to respond until you are able. \n\n\n\nRegrade Policy\nIf you think a question was incorrectly graded, first compare your answer to the answer key. If you believe a re-grade would be appropriate, write an email to me containing the question and a short explanation as to why the question(s) was/were incorrectly graded. Deadline: One week after assignments were returned to class (late requests will not be considered).\n\n\nAttendance Policy\nYou are expected to attend class and participate in-class polls and the exit ticket. For students who miss class or need a review, I will make video and audio recordings of lectures available. There are no guarantees against technical or other challenges for the recording availability or quality. For students who are unable to attend the class in-person and synchronously, viewing the recording within 7 days is acceptable. This is meant to keep you on track within the course and prevent a pile up of material. Make sure to complete the exit ticket to demonstrate attendance.\n\n\nInstructor Expectations\nCommitment to your learning and your success\nI believe that everyone has the ability to be successful in this course and I have put a lot of effort into designing the course in a way that maximizes your learning to ensure your success. Please talk to me before or after class or stop by my office if there is anything you want to discuss or about which you are unclear. I want to be supportive of your learning and growth.\nInclusive & supportive learning community\nI believe that learning happens best when we all learn together, as a community. This means creating a space characterized by generous listening, civility, humility, patience, and hospitality. I will attempt to promote a safe climate where we examine content from multiple cultural perspectives, and I will strive to create and maintain a classroom atmosphere in which you feel free to both listen to others and express your views and ask questions to increase your learning.\nOpenness to feedback\nI appreciate straightforward feedback from you regarding how well the class is meeting your needs. Let me know if material is not clear or when its relevance to the student learning outcomes for the course is not apparent. In particular, let me know if you identify bias or stereotyping in my teaching materials as I will seek to continuously improve. Please also let me know if there’s an aspect of the class you find particularly interesting, helpful, or enjoyable!\nResponsiveness\nI will monitor email as well as the discussion board daily and try respond to all messages within 24 hours Monday-Friday.\nClear guidelines and prompt feedback on assignments\nI will provide clear instructions for all assignments, and a grading rubric when applicable. I will provide detailed feedback on your submissions and will update grades promptly in Sakai.\n\n\nStudent Expectations and Resources\nAttend class\nYou are expected to attend all scheduled class meetings synchronously or watch the recording within 7 days. Attendance is taken through exit tickets. If you have issues accessing the poll on a specific day, please let me know. \nParticipate\nI encourage you to participate actively in class and online discussions. I will expect all students, and all instructors, to be respectful of each other’s contributions, whether I agree with them or not. Professional interactions are expected.\nBuild rapport\nIf you find that you have any trouble keeping up with assignments or other aspects of the course, make sure you let me know as early as possible. As you will find, building rapport and effective relationships are key to becoming an effective professional. Make sure that you are proactive in informing me when difficulties arise during the semester so that I can help you find a solution.\nComplete assignments\nAll assignments for this course will be submitted electronically through Sakai unless otherwise instructed.  I encourage you to make your best effort to submit all assignments on time, but I understand that sometimes circumstances arise that are beyond our control. If you need an extension, please contact me in congruence with the Late Policy.\nSeek help if you need it\nI believe it is important to support the physical and emotional well‐being of my students. If you are experiencing physical or mental health issues, I encourage you to use the resources on campus such as those listed below. If you have a health issue that is affecting your performance or participation in the course, and/or if you need help connecting with these resources, please contact the instructor or any of the TAs.\n\nStudent Health and Wellness Center (SHW), Website, 503-494-8665 (OHSU Students only)\nStudent Health and Counseling (SHAC), Website, 503-725-2800\n\nInform your instructor of any accommodations needed\nYou should speak with or email me before or during the first week of classes regarding any special needs. Students seeking academic accommodations should register with the appropriate service under the School policies below.\nSome religious holidays may occur on regularly scheduled class days. Because available class hours are so limited in number, we will have to hold class on all such days. Class video recordings will be available and you are encouraged to engage with the material outside of the regular class time. You are also encouraged to come to office hours with questions from the session.\nCommit to integrity\nAs a student in this course (and at PSU or OHSU) you are expected to maintain high degrees of professionalism, commitment to active learning and participation in this class and also integrity in your behavior in and out of the classroom.\nCheating and other forms of academic misconduct will not be tolerated in this course and will be dealt with firmly. Student academic misconduct refers to behavior that includes plagiarism, cheating on assignments, fabrication of data, falsification of records or official documents, intentional misuse of equipment or materials (including library materials), or aiding and abetting the perpetration of such acts. Preparation of papers or homework, assigned on an individual basis, must represent each student’s own individual effort. When used, resource materials should be cited in conventional reference format."
  },
  {
    "objectID": "schedule/syllabus.html#course-communications",
    "href": "schedule/syllabus.html#course-communications",
    "title": "Syllabus",
    "section": "Course Communications",
    "text": "Course Communications\nSakai/Slack announcements\nFor important/urgent matters, I will communicate with you using announcements via Sakai that will be delivered to your OHSU Email account as well as displayed in the Sakai course site Announcements section. I will copy these announcements in Slack if they do not involve changes to the schedule. Unfortunately, there are certain announcements that OHSU requires I initiate behind the firewall.\nGeneral course questions\nIt is normal to have many questions about things that relate to the course, such as clarification about assignments, course materials, or assessments. Please post these on our Slack Workspace. Please use the channels that I created for questions. You are encouraged to give answers and help each other. The TAs and I will monitor these threads, so I will endorse or correct responses as needed. Please give us 24 hours to respond to questions within Monday-Friday. Work-life balance is important for us as well, so we will try to respond as quickly as we can within our healthy limits. \nE-mail\nE-mail should be used only for messages that are private in nature. Please send private messages to my OHSU email address (wakim@ohsu.edu). Messages sent through Sakai Inbox will not be answered. Do not send messages asking general information about the class; please post those on Slack instead."
  },
  {
    "objectID": "schedule/syllabus.html#further-student-resources",
    "href": "schedule/syllabus.html#further-student-resources",
    "title": "Syllabus",
    "section": "Further Student Resources",
    "text": "Further Student Resources\n\nSPH Writing Lab\nThe School of Public Health Writing Support serves graduate students (master’s and PhD) in SPH, offering help on all professional writing tasks, including class papers, dissertations, job application documents, personal statements, and grant applications, to name a few. Leslie Bienen, MFA, DVM offers one-on-one writing support and other workshops. Appointments are virtual for the time being. You can make an appointment by contacting writingsupportsph@pdx.edu or making an appointment through Calendly.\n\n\nGrammarly Subscription\nThe School of Public Health students have access to a subscription version of Grammarly. While Grammarly cannot improve the argument and flow of your work, it can help with spelling, grammar, and sentence structure. If you are interested in this tool, please add your name to this email form and we will get you added to the subscription.  Be sure to use your PSU login credentials to access the form.\n\n\nStudent Wellness\nI am committed to supporting the physical and emotional well-being of my students. Both PSU and OHSU have designated centers for student health. For OHSU, students can visit the Behavioral Health site, where you can find more information including the number to make an appointment. All student visits are free. OHSU students also have access to PSU’s Counseling Services through the school’s Student Health & Counseling. Information on additional student resources for OHSU students are available on the OHSU Health and Wellness Resource page. \n\n\nSupport for Food Insecurity\nStudents across the country experience food insecurity at alarming rates. OHSU and PSU both provide a list of resources to help combat food insecurity. Of note, the Committee to Improve Student Food Security (CISFS) at PSU provides a Free Food Market on the second Monday of each month. OHSU also provides SNAP Enrollment Assistance. The Supplemental Nutrition Assistance Program (SNAP) allocates money towards food for individuals below a certain income level. If you make less than $2,265 monthly, you may wish to enroll."
  },
  {
    "objectID": "schedule/syllabus.html#school-policies-and-resources",
    "href": "schedule/syllabus.html#school-policies-and-resources",
    "title": "Syllabus",
    "section": "School Policies and Resources",
    "text": "School Policies and Resources\n\nSchool of Public Health Handbook\nAll students are responsible for following the policies and expectations outlined in the student handbook for their program of study. Students are responsible for their own academic work and are expected to have read and practice principles of academic honesty, as presented in the handbook: https://ohsu-psu-sph.org/graduate/handbooks-policies-forms/.\n\n\nStudent Access & Accommodations\nThe School of Public Health values diversity and inclusion; we are committed to fostering mutual respect and full participation for all students. My goal is to create a learning environment that is equitable, usable, inclusive, and welcoming. If any aspects of instruction or course design result in barriers to your inclusion or learning, please notify me. \n\nIf you are already registered with disability services at either OHSU or PSU and you are taking a course at the opposite institution, you need to contact the office you’re registered with to transfer your accommodations.\nIf you are not already registered with a disability services office, and you have, or think you may have, a disability that may affect your work in this class, and feel you need accommodations, use the following table for guidance about which office to contact to initiate accommodations.\n\nResource Table\n\n\n\nEnrollment University and Standing\nWhere to Seek Accommodations\n\n\nUndergraduate School of Public Health major\nPSU’s Disability Resource Center\n\n503-725-4150\nSmith Memorial Student Union, Room 116\ndrc@pdx.edu\n\n\n\nAll PSU-registering Dual Degree (MSW/MPH and MURP/MPH) Graduate School of Public Health Majors and all PSU-registering PhD students admitted prior to fall 2016.\nPSU’s Disability Resource Center\n\n503-725-4150\nSmith Memorial Student Union, Room 116\ndrc@pdx.edu\nwww.pdx.edu/drc\n\n\n\nGraduate School of Public Health major (irrespective of institution at which you register)\nOHSU’s Office for Student Access\n(503) 494-0082\nStudentAccess@OHSU.edu\nOHSU Auditorium Building 330\n\n\nNon-SPH major, PSU-enrolled student\nPSU’s Disability Resource Center\n503-725-4150\nSmith Memorial Student Union, Room 116\ndrc@pdx.edu\nwww.pdx.edu/drc\n\n\nNon-SPH major, OHSU-enrolled student\nOHSU’s Office for Student Access\n(503) 494-0082\nStudentAccess@OHSU.edu\nOHSU Auditorium Building 330\n\n\n\n \nFor more information related accessibility and accommodations, please see the “Statement Regarding Students with Disabilities” within the Institutional Policies section of this syllabus.\n\n\nTitle IX\nThe School of Public Health is committed to providing an environment free of all forms of prohibited discrimination and discriminatory harassment. The School of Public Health students who have questions about an incident related to Title IX are welcome to contact either the OHSU or PSU’s Title IX Coordinator and they will direct you to the appropriate resource or office. Title IX pertains to any form of sex/gender discrimination, discriminatory harassment, sexual harassment or sexual violence.\n\nPSU’s Title IX Coordinator is Julie Caron, she may be reached at titleixccordinator@pdx.edu or 503-725-4410. Julie’s office is located at 1600 SW 4th Ave, In the Richard and Maureen Neuberger Center RMNC - Suite 830.\nThe OHSU Title IX Coordinator’s may be reachedat 503-494-0258 or titleix@ohsu.edu and is located at 2525 SW 3rd St.\n\nPlease note that faculty and the Title IX Coordinators will keep the information you disclose private but are not confidential. If you would like to speak with a confidential advocate, who will not disclose the information to a university official without your written consent, you may contact an advocate at PSU or OHSU.\n\nPSU’s confidential advocates are available in Women’s Resource Center (serving all genders) in Smith Student Memorial Union 479. You may schedule an appointment by (503-725-5672) or schedule on line at https://psuwrc.youcanbook.me. For more information about resources at PSU, please see PSU’sResponse to Sexual Misconduct website.\nOHSU’s advocates are available through the Confidential Advocacy Program (CAP) at 833-495-CAPS (2277) or by email CAPsupport@ohsu.edu, but please note, email is not a secure form of communication. Also visit www.ohsu.edu/CAP.\n\nAt OHSU, if you encounter any harassment, or discrimination based on race, color, religion, age, national origin or ancestry, veteran or military status, sex, marital status, pregnancy or parenting status, sexual orientation, gender identity or expression, disability or any other protected status, please contact the Affirmative Action and Equal Opportunity (AAEO) Department at 503-494-5148 or aaeo@ohsu.edu.\nAt PSU, you may contact the Office of Equity and Compliance if you experience any form of discrimination or discriminatory harassment as listed above at equityandcompliance@pdx.edu or by calling 503-725-5919.\n\n\nTechnical Support\nThe OHSU ITG Help Desk is available to assist students with email account or network account access issues between 6 a.m. and 6 p.m., Monday through Friday at 503-494-2222. For technical support in using the Sakai Course Management System, please contact the Sakai Help Desk at 877-972-5249 or email us at sakai@ohsu.edu"
  },
  {
    "objectID": "schedule/syllabus.html#ohsu-competencies",
    "href": "schedule/syllabus.html#ohsu-competencies",
    "title": "Syllabus",
    "section": "OHSU Competencies",
    "text": "OHSU Competencies\n\nList of OHSU Graduation Core Competencies\n\nProfessional Knowledge and Skills\nProfessionalism\nInformation Literacy\nCommunication\nTeamwork\nCommunity Engagement, Social Justice and Equity\nPatient Centered Care\n\nTo access a descriptive list of OHSU Graducation Core Competencies: OHSU Graduation Core Competencies"
  },
  {
    "objectID": "schedule/syllabus.html#institutional-policies-and-resources",
    "href": "schedule/syllabus.html#institutional-policies-and-resources",
    "title": "Syllabus",
    "section": "Institutional Policies and Resources",
    "text": "Institutional Policies and Resources\n\nStatement Regarding Students with Disabilities:\nOHSU is committed to inclusive and accessible learning environments in compliance with federal and state law. If you have a disability or think you may have a disability (mental health, attention-related, learning, vision, hearing, physical or health impacts) contact the Office for Student Access at (503) 494-0082 or OHSU Student Access to have a confidential conversation about academic accommodations. Information is also available at Student Access Website. Because accommodations may take time to implement and cannot be applied retroactively, it is important to have this discussion as soon as possible.\nPortland State students also have similar resources available via the PSU Disability Resource Center (website http://www.pdx.edu/drc ). Please contact the DRC at tel. (503) 725-4150 or email at drc@pdx.edu\n\n\nStudent Evaluation of Courses:\nCourse evaluation results are extremely important and used to help improve courses and the learning experience of future students. Responses will always remain anonymous and will only be available to instructors after grades have been posted. The results of scaled questions and comments go to both the instructor and their unit head/supervisor. Refer to Student Evaluation of Courses and Instructional Effectiveness, *Policy No. 02-50-035.\n*To access the OHSU Student Evaluation of Courses and Instructional Effectiveness Policy, you must log into the OHSU O2 website.\n\n\nCopyright Information:\nCopyright laws and fair use policies protect the rights of those who have produced the material. The copy in this course has been provided for private study, scholarship, or research. Other uses may require permission from the copyright holder. The user of this work is responsible for adhering to copyright law of the U.S. (Title 17, U.S. Code). To help you familiarize yourself with copyright and fair use policies, the University encourages you to visit its Copyright Web Page\nSakai course web sites contain material protected by copyrights held by the instructor, other individuals or institutions. Such material is used for educational purposes in accord with copyright law and/or with permission given by the owners of the original material. You may download one copy of the materials on any single computer for non-commercial, personal, or educational purposes only, provided that you (1) do not modify it, (2) use it only for the duration of this course, and (3) include both this notice and any copyright notice originally included with the material. Beyond this use, no material from the course web site may be copied, reproduced, re-published, uploaded, posted, transmitted, or distributed in any way without the permission of the original copyright holder. The instructor assumes no responsibility for individuals who improperly use copyrighted material placed on the web site.\n\n\nSyllabi Changes and Retention:\nSyllabi are considered to be a learning agreement between students and the faculty of record. Information contained in syllabi, other than the minimum requirements, may be subject to change as deemed appropriate by the faculty of record in concurrence with the academic program and the Office of the Provost. Refer to the *Course Syllabi Policy, 02-50-050.\n*To access the OHSU Course Syllabus Policy, you must log into the OHSU O2 website.\n\n\nCommitment to Diversity & Inclusion:\nOHSU is committed to creating and fostering a learning and working environment based on open communication and mutual respect. If you encounter sexual harassment, sexual misconduct, sexual assault, or discrimination based on race, color, religion, age, national origin, veteran’s status, ancestry, sex, marital status, pregnancy or parenting status, sexual orientation, gender identity, disability or any other protected status please contact the Affirmative Action and Equal Opportunity Department at 503-494-5148 or aaeo@ohsu.edu. Inquiries about Title IX compliance or sex/gender discrimination and harassment may be directed to the OHSU Title IX Coordinator at 503-494-0258 or titleix@ohsu.edu.\n\n\nModified Operations, Policy 01-40-010:\nPortland Campus:  Marquam Hill and South Waterfront\nStudents should review O2 or call OHSU’s weather alert line at 503-494-9021 for the most up-to-date information on OHSU-wide modified operations which include but are not limited to delays or closures for inclement weather.\nIf your home institution is not on the Portland campus (Marquam Hill or South Waterfront, contact your home institution for more information.\n\n\nOHSU Resources Available to Students*:\nRemote Learning Resources\nThe Remote Learning webpage on O2 contains concise, practical resources, and strategies for students that need to quickly transition to a fully remote instructional format.\nRegistrar’s Office\nMackenzie Hall, Rm. 1120\n503-494-7800; Email the Registrar\nStudent Registration Information: \nTo Register for Classes\nOHSU ITG Help Desk\nRegular staff hours are 6 a.m. to 6 p.m., Monday through Friday, but phones are answered seven days a week, 24 hours a day. Call 503 494-2222.\nTeaching and Learning Center\nAcademic Support Counseling and Sakai Course Management System, please contact the TLC Help Desk at 877-972-5249 or email TLC Help Desk\nStudent Academic Support Services\nFor resources on improving student’s study strategies, time management, motivation, test-taking skills and more, Please access the Student Academic Support Services Sakai page. For one-on-one appointments or to arrange a workshop for students, please contact Emily Hillhouse.\nConfidential Advocacy Program\nSupport for OHSU employees, students, and volunteers who have experienced any form of sexual misconduct, including sexual harassment, sexual assault, intimate-partner violence, stalking, relationship/dating violence, and other forms — regardless of when or where it took place. Contact Us.\nConcourse Syllabus Management\nFor help with accessing your Concourse Syllabus:  Please contact the Sakai help Desk for all other Concourse inquiries please visit the Concourse Support - Sakai or please contact the Mark Rivera at rivermar@ohsu.edu or call 503-494-0934\nPublic Safety\nOHSU Public Safety-Portland Campus (Marquam Hill and South Waterfront)\n\nEmergency on Campus: 503-494-4444 (Portland)\nNon-emergency: 503-494-7744; Contact Public Safety\n\nStudent Health & Wellness Center \nBaird Hall, Rm. 18 (Primary Care) and Rm. 6 (Behavioral Health)\n503-494-8665; For urgent care after hours, 503-494-8311 and ask for the Nurse on call.\nWellness Center Information  \nWellness Center Website\nIf your home institution is not on the Portland campus, contact your home institution student support services for more information.\nOmbudsman Office\nGaines Hall, Rm. 117\n707 SW Gaines Street, Portland, OR 97239\n503-494-5397; Contact Ombudsman; Ombudsman Website\nLibrary: Biomedical Information Communication Center\nBICC Library Hours of Operation\n\n\nPrivacy While Learning\nStudents may be asked to take classes remotely through videoconferencing software like WebEx. Some of these remote classes will be recorded. Any recording will capture the presenter’s audio, video, and computer screen. Student video and audio will be recorded if and when you unmute your audio and share your video during the recorded sessions. These recordings will not be shared with or accessible to the public without prior written consent. \n\n\nStudent Central\nKey information for students across OHSU’s Schools of Dentistry, Medicine, Nursing, the OHSU-PSU School of Public Health and the College of Pharmacy. Student Central helps you find out more about student services, resources, policies and technology."
  },
  {
    "objectID": "slides/9_joint_distributions.qqmd.html",
    "href": "slides/9_joint_distributions.qqmd.html",
    "title": "Chapter 9: Independence and Conditioning - or, Joint Distributions",
    "section": "",
    "text": "Chapter 9: Independence and Conditioning - or, Joint Distributions\n\nDefinition 1. The joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]\n\n\nExample 2. Let \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\n\n\nSolution:\nRemarks: Some properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)\n\n\n\nDefinition 3. The joint cdf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]\n\n\n\nExample 4. Find the joint cdf \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\) in Example 2.\n\nSolution:\n\nExample 5. Find the marginal cdfs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\) for Example 4.\n\nSolution:\n\nRemark: Some properties of joint cdf’s:\nIndependence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]\n\nDefinition 6. The conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\).\n\nRemark: The following properties follow from the conditional pmf definition:\n\nExample 7. Using \\(X\\) and \\(Y\\) from Example 2:\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\nSolution:\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counterexample.\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\).\n\n\nExample 8. Hypothetical 4-sided die\n\nSuppose you have a 4-sided die, and you roll the 4-sided die until the first 4 appears.\nLet \\(X\\) be the number of rolls required until (and including) the first 4.\nAfter the first 4, you keep rolling it again until you roll a 3.\nLet \\(Y\\) be the number of rolls, after the first 4, required until (and including) the 3.\n\n\nFind \\(p_{X,Y}(x,y)\\).\nUsing \\(p_{X,Y}(x,y)\\), find \\(p_{Y}(y)\\).\nFind \\(p_{X}(x)\\).\nAre \\(X\\) and \\(Y\\) are independent? Why or why not?\nFind \\(F_{X,Y}(x,y)\\).\n\n\nSolution:\nExample 8 cont’d."
  },
  {
    "objectID": "schedule/week_03_sched.html#homework",
    "href": "schedule/week_03_sched.html#homework",
    "title": "Week 3",
    "section": "Homework",
    "text": "Homework\nHomework 1 due 10/1"
  },
  {
    "objectID": "schedule/week_03_sched.html#post-class-surveys",
    "href": "schedule/week_03_sched.html#post-class-surveys",
    "title": "Week 3",
    "section": "Post-Class Surveys",
    "text": "Post-Class Surveys\nSurvey link!!"
  },
  {
    "objectID": "schedule/week_03_sched.html#statistician-of-the-week-regina-nuzzo",
    "href": "schedule/week_03_sched.html#statistician-of-the-week-regina-nuzzo",
    "title": "Week 3",
    "section": "Statistician of the Week: Regina Nuzzo",
    "text": "Statistician of the Week: Regina Nuzzo\n\n\n\n\n\n\n\nRegina Nuzzo\n\n\n\n\n\n\nDr. Nuzzo received her PhD in Statistics from Stanford University and is now Professor of Science, Technology, & Mathematics at Gallaudet University. Gallaudet University, federally funded and located in Washington, DC, is the only higher education institution where all programs are designed for the education of the deaf and hard of hearing. Dr. Nuzzo teaches statistics using American Sign Language.\nShe is the Senior Advisor for Statistics Communication and Media Innovation at the American Statistical Association and a freelance writer.\n\n\n\nTopics covered\nDr. Nuzzo is a statistician and a science journalist. Her work has appeared in Nature, Los Angeles Times, New York Times, Reader’s Digest, New Scientist, and Scientific American. Most of her work is in the “Health” or “Science” sections of the aforementioned outlets. Primarily, she works to help lay-audiences understand science and statistics in particular. She earned the American Statistical Association’s 2014 Excellence in Statistical Reporting Award for her article on p-values in Nature. Her work led to the ASA’s statement on p-values.\n\n\nRelevant work\n\nNuzzo, R. “Scientific method: Statistical errors.” Nature 506, 150–152 (2014).\nNuzzo, R. “Tips for Communicating Statistical Significance.” Science, Health, and Public Trust, National Institutes of Health, 2018.\nNuzzo, R. “Vying for a soul mate? Psych out the competition with science.” Health: Features. Los Angeles Times, 2008.\n\n\n\nOutside links\n\nWikipedia\nacademic\nLinkedin\npersonal\n\nPlease note the statisticians of the week are taken directly from the CURV project by Jo Hardin. I also invite you to check out this youtube video of her Women Rise Keynote address where she discusses her hearing impairment, career growth, and her work with p-values."
  },
  {
    "objectID": "syllabus.html#description",
    "href": "syllabus.html#description",
    "title": "BSTA 512/612 Syllabus",
    "section": "Description",
    "text": "Description\nWelcome to BSTA 512/612! In this course, we will focus on linear models, and build our understanding of regression analysis. We will build some theoretical understanding in order to interpret and apply regression models appropriately. We will learn how to build a regression model, interpret the model, and diagnose potential issues with our model.\n\nCourse Learning Objectives\nAt the end of this course, students should be able to…\n\nAnalyze real-world data to answer questions about multivariable relationships for a continuous outcome\nBuild, fit, and evaluate linear regression models\nAssess whether a proposed model is appropriate and describe its limitations\nUse R and Quarto to write reproducible reports\nCommunicate results from statistical analyses to a general audience\n\nThese learning objectives were adapted from Maria Tackett’s Regression Analysis course."
  },
  {
    "objectID": "syllabus.html#instructors",
    "href": "syllabus.html#instructors",
    "title": "BSTA 512/612 Syllabus",
    "section": "Instructors",
    "text": "Instructors\nHere is the instructor page. This also has office hours!"
  },
  {
    "objectID": "syllabus.html#meeting-times",
    "href": "syllabus.html#meeting-times",
    "title": "BSTA 512/612 Syllabus",
    "section": "Meeting Times",
    "text": "Meeting Times\nMondays          1:00 PM – 2:50 PM PST in Rood Family Pavilion Room 1217\nWednesdays    1:00 PM – 2:50 PM PST in Rood Family Pavilion Room 1217\n\nKnown Exceptions\nMonday, February 26              1:00 PM – 2:50 PM PST on Webex OR pre-recorded\nWednesday, February 28        1:00 PM – 2:50 PM PST on Webex OR pre-recorded"
  },
  {
    "objectID": "syllabus.html#materials",
    "href": "syllabus.html#materials",
    "title": "BSTA 512/612 Syllabus",
    "section": "Materials",
    "text": "Materials\n\nTextbooks\nIn lieu of a formally published textbook, we will be referencing the following two online textbooks. Similar to our class, the books integrate R into their lessons.\n\nA Progressive Introduction to Linear Models by Joshua French\nIntroduction to Regression Methods for Public Health Using R by Ramzi W. Nahhas\n\n\nSupplemental Readings (Optional)\n\nAn Introduction to R (free pdf available)\n\n\n\n\nOnline Resources\n\nSlack\nWe will use Slack as our main form of communication for the class. If you are unsure how to do a homework problem or have other questions, please ask me by posting your question(s) on Slack. Please know that Slack is not guarded by the OSHU firewall, so if you have a question about accommodations or any sensitive topics, you may wish to message me via email. You can still message me regarding sensitive information on Slack, but I will not initiate those conversations on Slack.\n**Please use this invitation link for our Slack workspace!**\nTips on asking questions:\n\nWhen reaching out for help for a homework problem, please include some context on what you have already tried.\n\nFor example, including a photo of your work thus far with an explanation of where you think you might be wrong is a quick way for me to look over your work and help you troubleshoot. This helps me see what parts you already understand and which you need help with. If your question involves code, please include the copied code (not a screenshot) and an attachment to your full file. This way I can see the exact line you need help with and the full code in case the problem starts earlier.\nIf you are unsure how to start a problem, look through your notes and the book for examples that you think might be similar. When reaching out, mention these examples and why you think they might be helpful, but also why you are still unsure on how to proceed.\nIf you only write something similar to “I don’t know how to do problem xxx,” then my response will be to ask you what you tried so far. Thus, it will be quicker for you to let me know this information right away.\n\nIf asking for help about a specific example that you don’t understand, please also provide some detail beyond “I don’t understand example xxx.”\n\nWhich steps of the problem do you not understand? You can refer to a line number, for example.\nIf you don’t understand the first step, do you understand the ones following it?\n\nIn general, when asking a question, please provide the homework number it is from along with the chapter and problem number. If it’s an example from the notes or book, an example number or slide number will help finding it.\nWant more tips on asking questions? This list on this site will help!\nFinally, if I don’t respond within a day and you need a response soon, please remind me by emailing or messaging me again.\n\n\n\nSakai\nWhile most course materials will be delivered online through this website, assignments will be turned in through Sakai, OHSU’s course management system. I will include a link on this website to the Sakai assignment page. \n\n\nExplain Everything\nI plan to use Explain Everything on my iPad to deliver lectures. This application allows me to take real-time notes, access Poll Everywhere, and record the lecture. I hope to use these features to allow you to follow me during lecture and have access to a recording for asynchronous viewing. While I will try to always make a recorded lecture available to you after class, I want you to try to attend class in person. I understand that life events get in the way of in-person attendance, but your attendance in-person brings me joy while I teach, and then further motivates me to be a great teacher. \n\n\nWebex\nWebex software will be used for virtual office hours. To give everyone the best possible experience with Webex, I recommend the following best practices:\n\nPlease stay muted until you want to participate\nDuring office hours, please send a message in chat with your question or with a statement like “I have a question.” This makes sure I or the TA can address everyone’s questions in order. \nI encourage you to attend office hours with your video on. This helps me recognize you, and keep mental notes on what techniques/concepts I emphasize to facilitate your specific understanding. \n\n\n\nPoll Everywhere\nWe will use the Poll Everywhere tool as an interactive feature of the course. Poll Everywhere is a web-based application that allows students to participate by responding via text messages or by visiting a web page on an internet-enabled device (smartphone, tablet, laptop). Instructions will be displayed on-screen. The poll that is embedded within the presentation will update in real time. While there is no cost to use this software, standard text messaging rates will apply if you use your phone. Please make sure that you have a Poll Everywhere account before our first class. You are not required to use your OHSU/PSU email to make an account. \nDuring lectures I will pose questions to the class. These questions are designed to provide real-time feedback to both students and the instructor on how well students are grasping the material. This is meant to be an interactive, learning activity with NO contribution to your grade. Your identity will never be connected to your answers, so I encourage you to answer honestly.\n\n\nPennState STAT 501 Website\nPennState has a class offered to online MS students that has some overlap with our class. They have all their course notes posted on this page. This is a great source if you would like to see class notes with different phrasing.\nNot all of our topics are covered in their notes, but the most important ones are. If you are having trouble finding our course’s concepts on their page, please make ask me at Office Hours, after class, or in a private meeting. I do not explicitly state corresponding sections under our schedule because I believe it is important for you to develop skills involving resources and learning key words that can help you find answers. \n\n\nR: Statistical Computing Software\nStudents will use statistical software to complete homework assignments. Students are required to use R/RStudio for this course. R can be freely downloaded. Helpful documentation on installing R is available. I encourage you to install R prior to attending our first lecture. Please email me if you need help installing R or RStudio.\nYou will need to download the following three things:\n\nR https://www.r-project.org/\nRstudio https://posit.co/download/rstudio-desktop/\nQuarto https://quarto.org/docs/get-started/\n\n\nAdditional R Resources\nYour learning and practicing of R will hopefully not be limited to this course. One of the best aspects of programming in R is that many resources are freely available online. Here are just a few additional resources you may explore beyond this class to continue your training in R.\n\n\nUseful online R resources\n\nR for the rest of us\nStatistical tools for high-throughput data analysis. ggplot2 essentials\nR-bloggers\nStack Overflow for troubleshooting\nR Graphical Manual\nQuick-R. Accessing the power of R\nR for SAS, STATA, and SPSS Users\nggplot2\nLearn R 4 free\nJoin a local R user groups\nLearning Machines\n\n\n\n\nOnline R courses to complement or refresh material from class\n\nR for the rest of us\nCoursera: R programming\nedX: R basics\nData Carpentry: For Biologists\nData Carpentry: For Ecologists\nPsychiatric R\nR coder"
  },
  {
    "objectID": "syllabus.html#assessment",
    "href": "syllabus.html#assessment",
    "title": "BSTA 512/612 Syllabus",
    "section": "Assessment",
    "text": "Assessment\nThe course is structured around the following four components:\n\n\n\n\n\n\n\n\n\nComponent\nModality\nFrequency\nDescription\n\n\nLecture\nIn person\nTwice, Weekly\nCourse content is provided through in-person lectures. Lectures will consist of didactic lessons, interactive examples, and PollEverywhere questions. Sessions will be recorded through Explain Everything and posted to Sakai. Attending or viewing the lecture within 7 days of the original lecture date is mandatory. Class attendance will be taken through an Exit Ticket. If viewing the lecture asynchronously, you must take the Exit Ticket to verify your attendance.\n\n\nHomework\nOnline\nWeekly\nThe course includes 7 homework assignments. They are an opportunity for you to engage with important concepts, practice coding, and apply calculating skills. Homework assignments should be submitted online, and will be graded by me. Students are encouraged to work in groups for homework assignments, but each person should do their own summary and hand in their work. Homework assignments will be due on Thursday at 11 PM.\n\n\nQuizzes\nIn person\nEvery 3 weeks\nThe purpose of the quizzes is to assess how well you have achieved the learning objectives through questions covering important concepts, conducting statistical processes, and interpreting output. We will have our quizzes in-class, and it will be open book. Students must work on the quizzes independently.\n\n\nProject (Labs and Report)\nOnline\n4 labs, 1 final report\nThe project will be a combination of submitted labs that will span the quarter and one final report submitted at the end of the quarter. This is meant to translate the tools learned in the course to the work one may do in the workforce. This will help instill the procedure for shaping research goals, model selection, analyzing data, and interpreting meaningful results. Labs will guide you through the needed analysis and background for the project. The final report will summarize your work over the labs and more closely align with a journal article. Students will work independently on each lab.\n\n\n\n\n\n\n\n\n\n\nTypes of assessments\nThis class will use a combination of formative and summative assessments to build and test our knowledge. Below I define each of these types of assessments:\n\nFormative assessment: Activity or work meant to help students learn and practice. Feedback on these assessments are meant to help the instructor and student identify gaps in knowledge and highlight accomplishments.\nSummative assessment: Work meant to test how well students have achieved learning objectives. Grading of these assessments are meant to gauge how well a student grasps the learning objectives and will be able to use their knowledge outside of the classroom."
  },
  {
    "objectID": "syllabus.html#course-instructor-evaluations",
    "href": "syllabus.html#course-instructor-evaluations",
    "title": "BSTA 512/612 Syllabus",
    "section": "Course & Instructor Evaluations",
    "text": "Course & Instructor Evaluations\n\nOngoing Course Feedback\nThroughout the duration of the course, you are also welcome to informally and anonymously submit your feedback through this Microsoft Form or Class Exit Tickets. This form will be available on Sakai. Students can submit feedback at any time and this form will be reviewed regularly by me. Your responses will be anonymous unless you elect to leave your email address. If I have done anything to make you feel uncomfortable, please give me feedback so I can change my behavior. Ultimately, this class is for you, and my individual social identity/behavior should not inhibit your learning. Thank you for your help making BSTA 512/612 a more successful class! Examples of ongoing feedback are:\n\nNicky talks a little fast during lecture time. May you speak slower?\nDuring Office Hours, Dr. Wakim made a face when I asked a question. This face made me feel self-conscious about my question.\nDr. W asked me a question about my experience that made me feel like a monolith. Please do not assume I can speak on behalf of my social identity groups.\nThe in-class examples do not make me more interested in the material.\n\n\n\nMid-quarter Feedback\nDuring the middle of the quarter, I will ask you to submit guided, anonymous feedback. Completion of feedback will be count towards your grade. To insure anonymity, I will ask you to sign a separate, written statement that you completed the feedback.\n\n\nFinal Course Feedback\nAt the conclusion of the course, you will be asked to complete a formal online review of the course and the instructor. Your feedback on this University evaluation is critical to improving future student learning in this course as well as providing metrics relevant to the instructor’s career advancement (or lack of). Since our class is on the smaller side, everyone’s participation is needed for feedback to be released."
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "BSTA 512/612 Syllabus",
    "section": "Schedule",
    "text": "Schedule\nPlease refer to the Schedule page. I will make changes to this schedule if we need more or less time on a concept. You do not need to read the corresponding chapters in the textbook for each class."
  },
  {
    "objectID": "syllabus.html#how-to-succeed-in-this-course",
    "href": "syllabus.html#how-to-succeed-in-this-course",
    "title": "BSTA 512/612 Syllabus",
    "section": "How to succeed in this course",
    "text": "How to succeed in this course\nEvery professor has different expectations when assigning certain work or providing certain resources. I want to walk through each class resource and assignment so that you know what you can do to succeed in this class. For resources, I want you to optimize the opportunities to learn. For assignments, I want you to know the strategies that students can use to learn the most and prepare for future exams.\n\nResources\n\n\n\n\n\n\n\n\nResource\nWhat is it?\nHow do I use it?\n\n\nOffice Hours\nBlocks of time a professor or TA dedicates for questions. The teaching staff will be located in a specific room. Several students may enter the space at a time and will ask specific or broad questions. If many students attend office hours, a queue will be created so that students can be served equally.\nThe main use of office hours is to ask questions about an assignment or lecture notes. You are welcome to sit and do homework in office hours. OH are also an informal way of meeting fellow students to collaborate with.\n\n\nLectures and lecture recordings\nTime shared between the professor and students where the professor conveys important class material. Material discussed in lectures include concepts, calculations, code, and examples. Lectures are a mix of presentation of information, working through examples together, interactive activities, and in-class polls.\nStudents should attend lectures in person if possible. You should attempt to understand new material presented by following the presentation slides, taking notes on additional details that may conveyed verbally, and working through examples with the professor. Students are encouraged to ask questions when you don’t understand the material at any point in the lecture.\n\n\nTextbooks\nWritten and published material that explains concepts, steps through calculations, provides examples, and provides practice problems. The listed textbooks is the basis for this course. While I am to cover all topics in class, the textbook provides alternative explanations and additional examples.\nWhile coming to class having read the accompanying textbook chapters helps understanding during class, I do not expect students to have read it. I see the textbook as a good resource if you are struggling with a specific topic after class, in need of an example while working on homework, or want additional practice when studying for the exam.\n\n\nWebsite\nThe course website is designed by me so that you have access to all the course materials in a more organized and flexible way. All resources delivered from me to you will be available on the website. Any assignments turned in will be through Sakai.\nYou can navigate through different course resources and information using the left-side tabs or top navigation bar. Course materials, like lecture notes, homework, data examples, and recordings, can be found under each week’s page under the schedule tab. You can also find the individual resources under the “Course Materials” tab on the left. Links to turn in assignments through Sakai will be given on the website. Please explore the tabs and get a sense of the organization.\n\n\nSakai\nSakai is a learning management system for higher ed. This is the university sanctioned LMS where we will submit assignments.\nYou will turn in assignments through Sakai under the “Submissions” tab. Generally, there will be a link to each assignment on the course website. You can also view your grades under “Gradebook” and links to Webex under “Webex.”\n\n\n\n\n\nAssignments\n\n\n\n\n\n\n\n\n\nAssignment\nType of assessment\nBefore you submit/take it\nAfter it is graded\n\n\nHomework\nFormative\n\nWork out each problem on your own as much as you can\nTalk through problems with a peer\nGo to Office Hours for help\nWrite down work that shows your thought process\nSearch your issue on Stack Exchange/Stack Overflow\n\n\nReview the solutions\nReview your mistakes\nFor solutions that involve writing sentences, check with me or a TA if your answer fits the solution\nGo to Office Hours to ask about your solutions\n\n\n\nQuizzes\nSummative\n\nIdentify and achieve learning objectives in each lecture\nUnderstand why certain statistics tools are used for certain cases\nPractice testing yourself and others on concepts\nCome to Office Hours for help with specific problems or concepts\n\n\nReview the solutions\nReview your mistakes\nFor solutions that involve writing sentences, check with me or a TA if your answer fits the solution\nGo to Office Hours to ask about your solutions\nDo not ask for a regrade unless you have viewed the solutions\n\n\n\nProject Labs and Report\nFormative and Summtive\n\nStart the lab as early as possible\nWork on R coding and check with classmates on work\nCome to Office Hours for help with specific R work\nFor the report, compile your work from the labs, and decide what is important in the analysis.\n\n\nThis will be graded at the end of the semester, so you will not have a chance to interact with my feedback as much\nIf you have questions about your grade, you may email me\nKeep the project paper for future reference\nYou can add this project to your resume!\n\n\n\nClass Exit Tickets\nN/A\n\nBring appropriate electronic device to participate in polls\nComplete the survey during the last 5 minutes of class or after class within 7 days\n\n\nReview muddiest and clearest points from the week\n\n\n\n\nIf you would like any other course resources explained in this format, please request it through the Ongoing Course Feedback."
  },
  {
    "objectID": "syllabus.html#course-policies-and-resources",
    "href": "syllabus.html#course-policies-and-resources",
    "title": "BSTA 512/612 Syllabus",
    "section": "Course Policies and Resources",
    "text": "Course Policies and Resources\n\nLate Work Policy\nI encourage you to make your best effort to submit all assignments on time, but I understand circumstances arise that are beyond our control. Please see this Swansea University’s page on extenuating circumstances for some examples. Not all circumstances are covered here, so please reach out if you have questions. \n\nThe class will end on March 22, 2024. All coursework is expected to be completed by then. If you have extenuating circumstances, and need additional time to complete class assignments, please contact me. Together, we will come up with a plan for completion and to sort out registrar logistics.\nIf you have extenuating circumstances that may jeopardize your ability to do work for several weeks, please contact me. We will come up with a plan to keep you on track in the course and prevent any delay in your education.\nFor homework, there is a due date posted, but you may turn in the assignment any time before the class ends. I will give you the check regardless of when you submit the assignment. However, if you would like feedback on the homework, you must turn it in on time OR email me asking for feedback for your late homework.\nFor non-homework assignments, including labs, I ask you to email me directly. You can explain your circumstances and may ask me for an extension, but I won’t necessarily grant one.\nFor labs, you will have ONE no-questions-asked, 3-day extension. Please use this wisely! You just need to send me a quick email saying “I am using my no-questions-asked extension for Lab __.”\nIf you have a emergency involving your self, family, pet, friend, classmate, or anything/one deemed important to you, please do not worry about immediately contacting me. We can work something out after your emergency. If I contact you during an emergency, it is only because I am worried, and you do NOT need to respond until you are able. \n\n\n\nRegrade Policy\nIf you think a question was incorrectly graded, first compare your answer to the answer key. If you believe a re-grade would be appropriate, write an email to me containing the question and a short explanation as to why the question(s) was/were incorrectly graded. Deadline: One week after assignments were returned to class (late requests will not be considered).\n\n\nAttendance Policy\nYou are expected to attend class, participate in-class polls, and complete the exit ticket. For students who miss class or need a review, I will make video and audio recordings of lectures available. There are no guarantees against technical or other challenges for the recording availability or quality. For students who are unable to attend the class in-person and synchronously, viewing the recording within 7 days is acceptable. This is meant to keep you on track within the course and prevent a pile up of material. Make sure to complete the exit ticket to demonstrate attendance.\n\n\nPlagiarism and Attribution\nPlease note that this section has been motivated by Dr. Steven Bedrick’s Course Policies and Grading site for BMI 525. (Note that this is a good example of informal attribution of someone else’s work.)\nIn this class, it is easy to use ChatGPT or other AI tools to solve your homework for you. Many problems follow a basic structure that is especially easy for ChatGPT to solve. In this class, you may use ChatGPT to help with your homework. You may even ask for direct answers. However, there are a few things I do not want you to do:\n\nDo not copy ChatGPT’s answer directly into your homework. Your homework is graded for full credit if you turn it in, in any state, so turning in ChatGPT’s answers is unacceptable. I rather see half-written answers that show what you’re thinking than see a correct answer from ChatGPT.\nDo not stop once ChatGPT answered a question. If it gives an explanation, interact with it! Make sure you understand the thought process of ChatGPT. Try writing out the process to help cement it in your head. Check the answer with what we learn in class.\nDo not use ChatGPT on our quizzes! Hence, you need to really understand how to solve these problems even if you use ChatGPT on the homework.\n\nAt the end of the day, ChatGPT is a resource that will be available to you in a job and outside of school. Thus, we should use it as a tool in school as well! Let me know if ChatGPT helped you understand something! I would love to incorporate it into future classes!\n\n\n\n\n\n\nImportant\n\n\n\nYou can think of this class as assembling a toolbox. When a handyperson starts working for the first time, they need to buy their tools. For their first few jobs, they might need help finding their tools, or remembering which tool is best used for what action. Eventually, they get to know their tools well, and using them appropriately becomes second nature.\nFor now, ChatGPT can help us find and use our tools, but we need to work towards using them as second nature!"
  },
  {
    "objectID": "syllabus.html#course-communications",
    "href": "syllabus.html#course-communications",
    "title": "BSTA 512/612 Syllabus",
    "section": "Course Communications",
    "text": "Course Communications\nSakai/Slack announcements\nFor important/urgent matters, I will communicate with you using announcements via Sakai that will be delivered to your OHSU Email account as well as displayed in the Sakai course site Announcements section. I will copy these announcements in Slack if they do not involve changes to the schedule. Unfortunately, there are certain announcements that OHSU requires I initiate behind the firewall.\nGeneral course questions\nIt is normal to have many questions about things that relate to the course, such as clarification about assignments, course materials, or assessments. Please post these on our Slack Workspace. Please use the channels that I created for questions. You are encouraged to give answers and help each other. I will monitor these threads, so I will endorse or correct responses as needed. Please give me 24 hours to respond to questions within Monday-Friday. Work-life balance is important for me as well, so I will try to respond as quickly as I can within my healthy limits. \nE-mail\nE-mail should be used only for messages that are private in nature. Please send private messages to my OHSU email address (wakim@ohsu.edu). Messages sent through Sakai Inbox will not be answered. Do not send messages asking general information about the class; please post those on Slack instead."
  },
  {
    "objectID": "syllabus.html#further-student-resources",
    "href": "syllabus.html#further-student-resources",
    "title": "BSTA 512/612 Syllabus",
    "section": "Further Student Resources",
    "text": "Further Student Resources\n\nSPH Writing Lab\nThe School of Public Health Writing Support serves graduate students (master’s and PhD) in SPH, offering help on all professional writing tasks, including class papers, dissertations, job application documents, personal statements, and grant applications, to name a few. Leslie Bienen, MFA, DVM offers one-on-one writing support and other workshops. Appointments are virtual for the time being. You can make an appointment by contacting writingsupportsph@pdx.edu or making an appointment through Calendly.\n\n\nGrammarly Subscription\nThe School of Public Health students have access to a subscription version of Grammarly. While Grammarly cannot improve the argument and flow of your work, it can help with spelling, grammar, and sentence structure. If you are interested in this tool, please add your name to this email form and they will get you added to the subscription. Be sure to use your PSU login credentials to access the form.\n\n\nStudent Wellness\nI am committed to supporting the physical and emotional well-being of my students. Both PSU and OHSU have designated centers for student health. For OHSU, students can visit the Behavioral Health site, where you can find more information including the number to make an appointment. All student visits are free. OHSU students also have access to PSU’s Counseling Services through the school’s Student Health & Counseling. Information on additional student resources for OHSU students are available on the OHSU Health and Wellness Resource page. \n\n\nSupport for Food Insecurity\nStudents across the country experience food insecurity at alarming rates. OHSU and PSU both provide a list of resources to help combat food insecurity. Of note, the Committee to Improve Student Food Security (CISFS) at PSU provides a Free Food Market on the second Monday of each month. OHSU also provides SNAP Enrollment Assistance. The Supplemental Nutrition Assistance Program (SNAP) allocates money towards food for individuals below a certain income level. If you make less than $2,430 monthly, you may wish to enroll.\n\n\nSupport for Students with Children\nStudents who have children can use the PSU resource: Resource Center for Students with Children. Resources are mostly focused on students with younger children. There are several great resources available, including: family-friendly study spaces, new baby starter packs, free kids clothing, and further information on financial resources for childcare."
  },
  {
    "objectID": "syllabus.html#school-policies-and-resources",
    "href": "syllabus.html#school-policies-and-resources",
    "title": "BSTA 512/612 Syllabus",
    "section": "School Policies and Resources",
    "text": "School Policies and Resources\n\nSchool of Public Health Handbook\nAll students are responsible for following the policies and expectations outlined in the student handbook for their program of study. Students are responsible for their own academic work and are expected to have read and practice principles of academic honesty, as presented in the handbook.\n\n\nStudent Access & Accommodations\nThe School of Public Health values diversity and inclusion; we are committed to fostering mutual respect and full participation for all students. My goal is to create a learning environment that is equitable, usable, inclusive, and welcoming. If any aspects of instruction or course design result in barriers to your inclusion or learning, please notify me. \n\nIf you are already registered with disability services at either OHSU or PSU and you are taking a course at the opposite institution, you need to contact the office you’re registered with to transfer your accommodations.\nIf you are not already registered with a disability services office, and you have, or think you may have, a disability that may affect your work in this class, and feel you need accommodations, use the following table for guidance about which office to contact to initiate accommodations.\n\nResource Table\n\n\n\nEnrollment University and Standing\nWhere to Seek Accommodations\n\n\nUndergraduate School of Public Health major\nPSU’s Disability Resource Center\n\n503-725-4150\nSmith Memorial Student Union, Room 116\ndrc@pdx.edu\n\n\n\nAll PSU-registering Dual Degree (MSW/MPH and MURP/MPH) Graduate School of Public Health Majors and all PSU-registering PhD students admitted prior to fall 2016.\nPSU’s Disability Resource Center\n\n503-725-4150\nSmith Memorial Student Union, Room 116\ndrc@pdx.edu\nwww.pdx.edu/drc\n\n\n\nGraduate School of Public Health major (irrespective of institution at which you register)\nOHSU’s Office for Student Access\n(503) 494-0082\nStudentAccess@OHSU.edu\nOHSU Auditorium Building 330\n\n\nNon-SPH major, PSU-enrolled student\nPSU’s Disability Resource Center\n503-725-4150\nSmith Memorial Student Union, Room 116\ndrc@pdx.edu\nwww.pdx.edu/drc\n\n\nNon-SPH major, OHSU-enrolled student\nOHSU’s Office for Student Access\n(503) 494-0082\nStudentAccess@OHSU.edu\nOHSU Auditorium Building 330\n\n\n\n \nFor more information related accessibility and accommodations, please see the “Statement Regarding Students with Disabilities” within the Institutional Policies section of this syllabus.\n\n\nTitle IX\nThe School of Public Health is committed to providing an environment free of all forms of prohibited discrimination and discriminatory harassment. The School of Public Health students who have questions about an incident related to Title IX are welcome to contact either the OHSU or PSU’s Title IX Coordinator and they will direct you to the appropriate resource or office. Title IX pertains to any form of sex/gender discrimination, discriminatory harassment, sexual harassment or sexual violence.\n\nPSU’s Title IX Coordinator is Julie Caron, she may be reached at titleixccordinator@pdx.edu or 503-725-4410. Julie’s office is located at 1600 SW 4th Ave, In the Richard and Maureen Neuberger Center RMNC - Suite 830.\nThe OHSU Title IX Coordinator’s may be reachedat 503-494-0258 or titleix@ohsu.edu and is located at 2525 SW 3rd St.\n\nPlease note that faculty and the Title IX Coordinators will keep the information you disclose private but are not confidential. If you would like to speak with a confidential advocate, who will not disclose the information to a university official without your written consent, you may contact an advocate at PSU or OHSU.\n\nPSU’s confidential advocates are available in Women’s Resource Center (serving all genders) in Smith Student Memorial Union 479. You may schedule an appointment by (503-725-5672) or schedule on line at https://psuwrc.youcanbook.me. For more information about resources at PSU, please see PSU’s Response to Sexual Misconduct website.\nOHSU’s advocates are available through the Confidential Advocacy Program (CAP) at 833-495-CAPS (2277) or by email CAPsupport@ohsu.edu, but please note, email is not a secure form of communication. Also visit www.ohsu.edu/CAP.\n\nAt OHSU, if you encounter any harassment, or discrimination based on race, color, religion, age, national origin or ancestry, veteran or military status, sex, marital status, pregnancy or parenting status, sexual orientation, gender identity or expression, disability or any other protected status, please contact the Affirmative Action and Equal Opportunity (AAEO) Department at 503-494-5148 or aaeo@ohsu.edu.\nAt PSU, you may contact the Office of Equity and Compliance if you experience any form of discrimination or discriminatory harassment as listed above at equityandcompliance@pdx.edu or by calling 503-725-5919.\n\n\nTechnical Support\nThe OHSU ITG Help Desk is available to assist students with email account or network account access issues between 6 a.m. and 6 p.m., Monday through Friday at 503-494-2222. For technical support in using the Sakai Course Management System, please contact the Sakai Help Desk at 877-972-5249 or email us at sakai@ohsu.edu"
  },
  {
    "objectID": "syllabus.html#ohsu-competencies",
    "href": "syllabus.html#ohsu-competencies",
    "title": "BSTA 512/612 Syllabus",
    "section": "OHSU Competencies",
    "text": "OHSU Competencies\n\nList of OHSU Graduation Core Competencies\n\nProfessional Knowledge and Skills\nProfessionalism\nInformation Literacy\nCommunication\nTeamwork\nCommunity Engagement, Social Justice and Equity\nPatient Centered Care\n\nTo access a descriptive list of OHSU Graducation Core Competencies: OHSU Graduation Core Competencies"
  },
  {
    "objectID": "syllabus.html#institutional-policies-and-resources",
    "href": "syllabus.html#institutional-policies-and-resources",
    "title": "BSTA 512/612 Syllabus",
    "section": "Institutional Policies and Resources",
    "text": "Institutional Policies and Resources\n\nStatement Regarding Students with Disabilities\nOHSU is committed to inclusive and accessible learning environments in compliance with federal and state law. If you have a disability or think you may have a disability (mental health, attention-related, learning, vision, hearing, physical or health impacts) contact the Office for Student Access at (503) 494-0082 or OHSU Student Access to have a confidential conversation about academic accommodations. Information is also available at Student Access Website. Because accommodations may take time to implement and cannot be applied retroactively, it is important to have this discussion as soon as possible.\nPortland State students also have similar resources available via the PSU Disability Resource Center (website http://www.pdx.edu/drc ). Please contact the DRC at tel. (503) 725-4150 or email at drc@pdx.edu\n\n\nStudent Evaluation of Courses\nCourse evaluation results are extremely important and used to help improve courses and the learning experience of future students. Responses will always remain anonymous and will only be available to instructors after grades have been posted. The results of scaled questions and comments go to both the instructor and their unit head/supervisor. Refer to Student Evaluation of Courses and Instructional Effectiveness, *Policy No. 02-50-035.\n*To access the OHSU Student Evaluation of Courses and Instructional Effectiveness Policy, you must log into the OHSU O2 website.\n\n\nCopyright Information\nCopyright laws and fair use policies protect the rights of those who have produced the material. The copy in this course has been provided for private study, scholarship, or research. Other uses may require permission from the copyright holder. The user of this work is responsible for adhering to copyright law of the U.S. (Title 17, U.S. Code). To help you familiarize yourself with copyright and fair use policies, the University encourages you to visit its Copyright Web Page\nSakai course web sites contain material protected by copyrights held by the instructor, other individuals or institutions. Such material is used for educational purposes in accord with copyright law and/or with permission given by the owners of the original material. You may download one copy of the materials on any single computer for non-commercial, personal, or educational purposes only, provided that you (1) do not modify it, (2) use it only for the duration of this course, and (3) include both this notice and any copyright notice originally included with the material. Beyond this use, no material from the course web site may be copied, reproduced, re-published, uploaded, posted, transmitted, or distributed in any way without the permission of the original copyright holder. The instructor assumes no responsibility for individuals who improperly use copyrighted material placed on the web site.\n\n\nSyllabi Changes and Retention\nSyllabi are considered to be a learning agreement between students and the faculty of record. Information contained in syllabi, other than the minimum requirements, may be subject to change as deemed appropriate by the faculty of record in concurrence with the academic program and the Office of the Provost. Refer to the *Course Syllabi Policy, 02-50-050.\n*To access the OHSU Course Syllabus Policy, you must log into the OHSU O2 website.\n\n\nCommitment to Diversity & Inclusion\nOHSU is committed to creating and fostering a learning and working environment based on open communication and mutual respect. If you encounter sexual harassment, sexual misconduct, sexual assault, or discrimination based on race, color, religion, age, national origin, veteran’s status, ancestry, sex, marital status, pregnancy or parenting status, sexual orientation, gender identity, disability or any other protected status please contact the Affirmative Action and Equal Opportunity Department at 503-494-5148 or aaeo@ohsu.edu. Inquiries about Title IX compliance or sex/gender discrimination and harassment may be directed to the OHSU Title IX Coordinator at 503-494-0258 or titleix@ohsu.edu.\n\n\nModified Operations, Policy 01-40-010\nPortland Campus:  Marquam Hill and South Waterfront\nStudents should review O2 or call OHSU’s weather alert line at 503-494-9021 for the most up-to-date information on OHSU-wide modified operations which include but are not limited to delays or closures for inclement weather.\nIf your home institution is not on the Portland campus (Marquam Hill or South Waterfront, contact your home institution for more information.\n\n\nOHSU Resources Available to Students*:\nRemote Learning Resources\nThe Remote Learning webpage on O2 contains concise, practical resources, and strategies for students that need to quickly transition to a fully remote instructional format.\nRegistrar’s Office\nMackenzie Hall, Rm. 1120\n503-494-7800; Email the Registrar\nStudent Registration Information: \nTo Register for Classes\nOHSU ITG Help Desk\nRegular staff hours are 6 a.m. to 6 p.m., Monday through Friday, but phones are answered seven days a week, 24 hours a day. Call 503 494-2222.\nTeaching and Learning Center\nAcademic Support Counseling and Sakai Course Management System, please contact the TLC Help Desk at 877-972-5249 or email TLC Help Desk\nStudent Academic Support Services\nFor resources on improving student’s study strategies, time management, motivation, test-taking skills and more, Please access the Student Academic Support Services Sakai page. For one-on-one appointments or to arrange a workshop for students, please contact Emily Hillhouse.\nConfidential Advocacy Program\nSupport for OHSU employees, students, and volunteers who have experienced any form of sexual misconduct, including sexual harassment, sexual assault, intimate-partner violence, stalking, relationship/dating violence, and other forms — regardless of when or where it took place. Contact Us.\nConcourse Syllabus Management\nFor help with accessing your Concourse Syllabus:  Please contact the Sakai help Desk for all other Concourse inquiries please visit the Concourse Support - Sakai or please contact the Mark Rivera at rivermar@ohsu.edu or call 503-494-0934\nPublic Safety\nOHSU Public Safety-Portland Campus (Marquam Hill and South Waterfront)\n\nEmergency on Campus: 503-494-4444 (Portland)\nNon-emergency: 503-494-7744; Contact Public Safety\n\nStudent Health & Wellness Center \nBaird Hall, Rm. 18 (Primary Care) and Rm. 6 (Behavioral Health)\n503-494-8665; For urgent care after hours, 503-494-8311 and ask for the Nurse on call.\nWellness Center Information  \nWellness Center Website\nIf your home institution is not on the Portland campus, contact your home institution student support services for more information.\nOmbudsman Office\nGaines Hall, Rm. 117\n707 SW Gaines Street, Portland, OR 97239\n503-494-5397; Contact Ombudsman; Ombudsman Website\nLibrary: Biomedical Information Communication Center\nBICC Library Hours of Operation\n\n\nPrivacy While Learning\nStudents may be asked to take classes remotely through videoconferencing software like WebEx. Some of these remote classes will be recorded. Any recording will capture the presenter’s audio, video, and computer screen. Student video and audio will be recorded if and when you unmute your audio and share your video during the recorded sessions. These recordings will not be shared with or accessible to the public without prior written consent. \n\n\nStudent Central\nKey information for students across OHSU’s Schools of Dentistry, Medicine, Nursing, the OHSU-PSU School of Public Health and the College of Pharmacy. Student Central helps you find out more about student services, resources, policies and technology."
  },
  {
    "objectID": "slides/2_Probability-solutions.html#learning-objectives",
    "href": "slides/2_Probability-solutions.html#learning-objectives",
    "title": "Chapter 2: Probability",
    "section": "Learning Objectives",
    "text": "Learning Objectives"
  },
  {
    "objectID": "slides/2_Probability-solutions.html",
    "href": "slides/2_Probability-solutions.html",
    "title": "Chapter 2: Probability",
    "section": "",
    "text": "Example 1\n\n\nSuppose you have a regular well-shuffled deck of cards. What’s the probability of drawing:\n\nany heart\nthe queen of hearts\nany queen\n\nSolution:\n\nany heart = 13/52 = 1/4\nthe queen of hearts = 1/52\nany queen = 4/52 = 1/13\n\n\n\n\n\n\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}.\\]\n\n\n\n\\(\\mathbb{P}(A)\\) is a function with\n\ninput: event \\(A\\) from the sample space \\(S\\), (\\(A \\subseteq S\\))\noutput: a number between 0 and 1 (inclusive)\n\n\\[\\mathbb{P}(A): S \\rightarrow [0,1]\\]\nA function that follows some specific rules though!\nSee Probability Axioms on next slide."
  },
  {
    "objectID": "slides/2_Probability.html#probabilities-of-equally-likely-events-12",
    "href": "slides/2_Probability.html#probabilities-of-equally-likely-events-12",
    "title": "Chapter 2: Probability",
    "section": "Probabilities of equally likely events (1/2)",
    "text": "Probabilities of equally likely events (1/2)\n\n\nExample 1\n\n\nSuppose you have a regular well-shuffled deck of cards. What’s the probability of drawing:\n\nany heart\nthe queen of hearts\nany queen"
  },
  {
    "objectID": "slides/2_Probability.html#probabilities-of-equally-likely-events-22",
    "href": "slides/2_Probability.html#probabilities-of-equally-likely-events-22",
    "title": "Chapter 2: Probability",
    "section": "Probabilities of equally likely events (2/2)",
    "text": "Probabilities of equally likely events (2/2)\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}.\\]"
  },
  {
    "objectID": "slides/2_Probability.html#a-probability-is-a-function",
    "href": "slides/2_Probability.html#a-probability-is-a-function",
    "title": "Chapter 2: Probability",
    "section": "A probability is a function…",
    "text": "A probability is a function…\n\\(\\mathbb{P}(A)\\) is a function with\n\nInput: event \\(A\\) from the sample space \\(S\\), (\\(A \\subseteq S\\))\nOutput: a number between 0 and 1 (inclusive)\n\n\\[\\mathbb{P}(A): S \\rightarrow [0,1]\\]\nA function that follows some specific rules though!\n \nSee Probability Axioms on next slide."
  },
  {
    "objectID": "slides/2_Probability.html#probability-axioms-1",
    "href": "slides/2_Probability.html#probability-axioms-1",
    "title": "Chapter 2: Probability",
    "section": "Probability Axioms",
    "text": "Probability Axioms\n\n\nAxiom 1\n\n\nFor every event \\(A\\), \\(0\\leq\\mathbb{P}(A)\\leq 1\\).\n\n\n\n\nAxiom 2\n\n\nFor the sample space \\(S\\), \\(\\mathbb{P}(S)=1\\).\n\n\n\n\nAxiom 3\n\n\nIf \\(A_1, A_2, A_3, \\ldots\\), is a collection of disjoint events, then \\[\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i).\\]"
  },
  {
    "objectID": "slides/2_Probability.html#some-probability-properties-1",
    "href": "slides/2_Probability.html#some-probability-properties-1",
    "title": "Chapter 2: Probability",
    "section": "Some probability properties",
    "text": "Some probability properties\nUsing the Axioms, we can prove all other probability properties!\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nProposition 4\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\n\n\nProposition 5\n\n\n\\(\\mathbb{P}(A \\cup B \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\\\ \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\\\ \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C)\\)"
  },
  {
    "objectID": "slides/2_Probability.html#proposition-1-proof",
    "href": "slides/2_Probability.html#proposition-1-proof",
    "title": "Chapter 2: Probability",
    "section": "Proposition 1 Proof",
    "text": "Proposition 1 Proof\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)"
  },
  {
    "objectID": "slides/2_Probability.html#proposition-2-proof",
    "href": "slides/2_Probability.html#proposition-2-proof",
    "title": "Chapter 2: Probability",
    "section": "Proposition 2 Proof",
    "text": "Proposition 2 Proof\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)"
  },
  {
    "objectID": "slides/2_Probability.html#proposition-3-proof",
    "href": "slides/2_Probability.html#proposition-3-proof",
    "title": "Chapter 2: Probability",
    "section": "Proposition 3 Proof",
    "text": "Proposition 3 Proof\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)"
  },
  {
    "objectID": "slides/2_Probability.html#partitions-1",
    "href": "slides/2_Probability.html#partitions-1",
    "title": "Chapter 2: Probability",
    "section": "Partitions",
    "text": "Partitions\n\n\n\n\nDefinition: Partition\n\n\nA set of events \\(\\{A_i\\}_{i=1}^{n}\\) create a partition of \\(A\\), if\n\nthe \\(A_i\\)’s are disjoint (mutually exclusive) and\n\\(\\bigcup \\limits_{i=1}^n A_i = A\\)\n\n\n\n\n\nExample 2\n\n\n\nIf \\(A \\subset B\\), then \\(\\{A, B \\cap A^C\\}\\) is a partition of \\(B\\).\nIf \\(S = \\bigcup \\limits_{i=1}^n A_i\\), and the \\(A_i\\)’s are disjoint, then the \\(A_i\\)’s are a partition of the sample space.\n\n\n\n\n\n\n\nCreating partitions is sometimes used to help calculate probabilities, since by Axiom 3 we can add the probabilities of disjoint events."
  },
  {
    "objectID": "slides/2_Probability.html#venn-diagram-probabilities-1",
    "href": "slides/2_Probability.html#venn-diagram-probabilities-1",
    "title": "Chapter 2: Probability",
    "section": "Venn Diagram Probabilities",
    "text": "Venn Diagram Probabilities\n\n\n\n\nExample 3\n\n\nIf a subject has an\n\n80% chance of taking their medication this week,\n70% chance of taking their medication next week, and\n10% chance of not taking their medication either week,\n\nthen find the probability of them taking their medication exactly one of the two weeks.\n\n\n\nHint: Draw a Venn diagram labelling each of the parts to find the probability.\n\n\n\n\nChapter 2 Slides"
  },
  {
    "objectID": "slides/2_Probability.html#pick-an-equally-likely-card-any-equally-likely-card",
    "href": "slides/2_Probability.html#pick-an-equally-likely-card-any-equally-likely-card",
    "title": "Chapter 2: Probability",
    "section": "Pick an equally likely card, any equally likely card",
    "text": "Pick an equally likely card, any equally likely card\n\n\nExample 1\n\n\nSuppose you have a regular well-shuffled deck of cards. What’s the probability of drawing:\n\nany heart\nthe queen of hearts\nany queen"
  },
  {
    "objectID": "slides/2_Probability.html#lets-break-down-this-probability",
    "href": "slides/2_Probability.html#lets-break-down-this-probability",
    "title": "Chapter 2: Probability",
    "section": "Let’s break down this probability",
    "text": "Let’s break down this probability\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}.\\]"
  },
  {
    "objectID": "slides/2_Probability.html#proposition-4-visual-proof",
    "href": "slides/2_Probability.html#proposition-4-visual-proof",
    "title": "Chapter 2: Probability",
    "section": "Proposition 4 Visual Proof",
    "text": "Proposition 4 Visual Proof\n\n\nProposition 4\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)"
  },
  {
    "objectID": "slides/2_Probability.html#proposition-5-visual-proof",
    "href": "slides/2_Probability.html#proposition-5-visual-proof",
    "title": "Chapter 2: Probability",
    "section": "Proposition 5 Visual Proof",
    "text": "Proposition 5 Visual Proof\n\n\nProposition 5\n\n\n\\(\\mathbb{P}(A \\cup B \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C)\\)"
  },
  {
    "objectID": "slides/2_Probability.html#weekly-medications",
    "href": "slides/2_Probability.html#weekly-medications",
    "title": "Chapter 2: Probability",
    "section": "Weekly medications",
    "text": "Weekly medications\n\n\n\n\nExample 3\n\n\nIf a subject has an\n\n80% chance of taking their medication this week,\n70% chance of taking their medication next week, and\n10% chance of not taking their medication either week,\n\nthen find the probability of them taking their medication exactly one of the two weeks.\n\n\n\nHint: Draw a Venn diagram labelling each of the parts to find the probability.\n\n\n\n\nChapter 2 Slides"
  },
  {
    "objectID": "schedule/week_01_sched.html#class-exit-tickets",
    "href": "schedule/week_01_sched.html#class-exit-tickets",
    "title": "Week 1",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (9/25)\n Wednesday (9/27)"
  },
  {
    "objectID": "schedule/week_02_sched.html#class-exit-tickets",
    "href": "schedule/week_02_sched.html#class-exit-tickets",
    "title": "Week 2",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (10/2)\n Wednesday (10/4)"
  },
  {
    "objectID": "schedule/week_02_sched.html#statistician-of-the-week",
    "href": "schedule/week_02_sched.html#statistician-of-the-week",
    "title": "Week 2",
    "section": "Statistician of the Week:",
    "text": "Statistician of the Week:"
  },
  {
    "objectID": "schedule/week_01_sched.html#on-the-horizon",
    "href": "schedule/week_01_sched.html#on-the-horizon",
    "title": "Week 1",
    "section": "On the Horizon",
    "text": "On the Horizon\n\nHomework 0 due 9/28\nHomework 1 due 10/5"
  },
  {
    "objectID": "schedule/week_02_sched.html#on-the-horizon",
    "href": "schedule/week_02_sched.html#on-the-horizon",
    "title": "Week 2",
    "section": "On the Horizon",
    "text": "On the Horizon\nHomework 1 due 10/5"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#coin-toss-example-1-coin-13",
    "href": "slides/1_Outcomes_Events_Sample.html#coin-toss-example-1-coin-13",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Coin Toss Example: 1 coin (1/3)",
    "text": "Coin Toss Example: 1 coin (1/3)\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n \nWhat is the sample space?\n \nWhat are the possible events?"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#coin-toss-example-1-coin-23",
    "href": "slides/1_Outcomes_Events_Sample.html#coin-toss-example-1-coin-23",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Coin Toss Example: 1 coin (2/3)",
    "text": "Coin Toss Example: 1 coin (2/3)\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n\nHeads (\\(H\\))\nTails (\\(T\\))\n\n\n \n\n\nNote\n\n\nWhen something happens at random, such as a coin toss, there are several possible outcomes, and exactly one of the outcomes will occur."
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#coin-toss-example-1-coin-33",
    "href": "slides/1_Outcomes_Events_Sample.html#coin-toss-example-1-coin-33",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Coin Toss Example: 1 coin (3/3)",
    "text": "Coin Toss Example: 1 coin (3/3)\n\n\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all outcomes\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some outcomes. An event can include multiple outcomes or no outcomes.\n\n\n\n\nWhat is the sample space?\n\n\\(S =\\)\n\n\n \n\nWhat are the possible events?\n\n\n\n\n\n\n \nWhen thinking about events, think about outcomes that you might be asking the probability of."
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#coin-toss-example-2-coins",
    "href": "slides/1_Outcomes_Events_Sample.html#coin-toss-example-2-coins",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Coin Toss Example: 2 coins",
    "text": "Coin Toss Example: 2 coins\nSuppose you toss two coins.\n\nWhat is the sample space? Assume the coins are distinguishable\n\n\\(S =\\)\n\n\n \n\nWhat are some possible events?\n\n\\(A =\\) exactly one \\(H =\\)\n\\(B =\\) at least one \\(H =\\)"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#more-info-on-events-and-sample-spaces",
    "href": "slides/1_Outcomes_Events_Sample.html#more-info-on-events-and-sample-spaces",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "More info on events and sample spaces",
    "text": "More info on events and sample spaces\n\nWe usually use capital letters from the beginning of the alphabet to denote events. However, other letters might be chosen to be more descriptive.\n\n \n\nWe use the notation \\(|S|\\) to denote the size of the sample space.\n\n \n\nThe total number of possible events is \\(2^{|S|}\\), which is the total number of possible subsets of \\(S\\). We will prove this later in the course.\n\n \n\nThe empty set, denoted by \\(\\emptyset\\), is the set containing no outcomes."
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#example-keep-sampling-until",
    "href": "slides/1_Outcomes_Events_Sample.html#example-keep-sampling-until",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Example: Keep sampling until…",
    "text": "Example: Keep sampling until…\nSuppose you keep sampling people until you have someone with high blood pressure (BP)\n \nWhat is the sample space?\n\nLet \\(H =\\) denote someone with high BP.\nLet \\(H^C =\\) denote someone with not high blood pressure, such as low or regular BP.\n\n \n\nThen, \\(S =\\)"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#set-theory-12",
    "href": "slides/1_Outcomes_Events_Sample.html#set-theory-12",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Set Theory (1/2)",
    "text": "Set Theory (1/2)\n\n\n \n\n\nDefinition: Union\n\n\nThe union of events \\(A\\) and \\(B\\), denoted by \\(A \\cup B\\), contains all outcomes that are in \\(A\\) or \\(B\\) or both\n\n\n\n\nDefinition: Intersection\n\n\nThe intersection of events \\(A\\) and \\(B\\), denoted by \\(A \\cap B\\), contains all outcomes that are both in \\(A\\) and \\(B\\).\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#set-theory-22",
    "href": "slides/1_Outcomes_Events_Sample.html#set-theory-22",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Set Theory (2/2)",
    "text": "Set Theory (2/2)\n\n\n \n\n\nDefinition: Complement\n\n\nThe complement of event \\(A\\), denoted by \\(A^C\\) or \\(A'\\), contains all outcomes in the sample space \\(S\\) that are not in \\(A\\) .\n\n\n\n\nDefinition: Mutually Exclusive\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive, or disjoint, if they have no outcomes in common. In this case \\(A \\cap B = \\emptyset\\), where \\(\\emptyset\\) is the empty set.\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#bp-example-variation-13",
    "href": "slides/1_Outcomes_Events_Sample.html#bp-example-variation-13",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "BP example variation (1/3)",
    "text": "BP example variation (1/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\n \nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\nEvent all \\(n\\) subjects have high BP\nEvent at least one subject has high BP\nEvent all of them do not have high BP\nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#bp-example-variation-23",
    "href": "slides/1_Outcomes_Events_Sample.html#bp-example-variation-23",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "BP example variation (2/3)",
    "text": "BP example variation (2/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\n \nEvent all \\(n\\) subjects have high BP\n \n \nEvent at least one subject has high BP"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#bp-example-variation-33",
    "href": "slides/1_Outcomes_Events_Sample.html#bp-example-variation-33",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "BP example variation (3/3)",
    "text": "BP example variation (3/3)\n\nEvent all of them do not have high BP\n \n \n \nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#de-morgans-laws",
    "href": "slides/1_Outcomes_Events_Sample.html#de-morgans-laws",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "De Morgan’s Laws",
    "text": "De Morgan’s Laws\n\n\nTheorem: De Morgan’s 1st Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcap\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcup\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“all not A = \\((\\)at least one event A\\()^C\\)”\n\n\nTheorem: De Morgan’s 2nd Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcup\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“at least one event not A = \\((\\)all A\\()^C\\)”"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#remarks-on-de-morgans-laws",
    "href": "slides/1_Outcomes_Events_Sample.html#remarks-on-de-morgans-laws",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Remarks on De Morgan’s Laws",
    "text": "Remarks on De Morgan’s Laws\n\nThese laws also hold for infinite collections of events.\n \nDraw Venn diagrams to convince yourself that these are true!\n \nThese laws are very useful when calculating probabilities.\n\nThis is because calculating the probability of the intersection of events is often much easier than the union of events.\nThis is not obvious right now, but we will see in the coming chapters why.\n\n\n\n\nChapter 1 Slides"
  },
  {
    "objectID": "slides/0_Intro.html#nicky-wakim-sheher",
    "href": "slides/0_Intro.html#nicky-wakim-sheher",
    "title": "Welcome to BSTA 550!",
    "section": "Nicky Wakim (she/her)",
    "text": "Nicky Wakim (she/her)\n\n\n\nCall me “Nicky,” “Dr. W,” “Professor Wakim,” or any combo!\nAssistant Professor of Biostatistics\n \nOriginally from DC area (Virginia side!)\nTwo kitties\nVolleyball, biking, spikeball, pickleball\nBut also sleeping, TV, and reading\nJust started taking a couple classes at PCC (French, ceramics, yoga)\nSlowly regrowing my plant collection after moving from Michigan\n\n\n\n\n Video"
  },
  {
    "objectID": "slides/0_Intro.html#lets-go-through-the-syllabus",
    "href": "slides/0_Intro.html#lets-go-through-the-syllabus",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s go through the syllabus!",
    "text": "Let’s go through the syllabus!\nSyllabus page\n\n\nIntro"
  },
  {
    "objectID": "homework/HW0.html",
    "href": "homework/HW0.html",
    "title": "Homework 0",
    "section": "",
    "text": "This homework must be turned into Sakai. I want to make sure we are all familiar with the process of downloading a .qmd file, editing it, and resubmitting an .html and .qmd file.\nHere are the instructions for downloading and submitting your homework:\n\nGo to this github site to download the homework’s .qmd file.\nWhen you reach the site, it should look like this:\nClick the “Download raw file” icon () to download the .qmd file. This will likely download the file into your “Downloads” folder. It is up to you to move the file into the appropriate folder.\nPlease rename you homework as Lastname_Firstinitial_HW0.qmd . This will help organize the homeworks when the TAs grade them.\nPlease also add the following line under subtitle: \"BSTA 512/612\": author: First-name Last-name with your first and last name so it is attached to the viewable document.\nEdit the document with your explanations and code. If you are writing out an answer or calculating by hand, you can take a picture of your work and embed it within the .qmd file. The pictures will be viewable on the .html file.\nPlease upload your homework to this Sakai assignment. Upload both your .qmd code file and the rendered .html file.\n\nThese instructions will not appear on every homework. You may come back to this page for reference.\n\n\nThis homework is meant to introduce yourself to me and your peers. In the first class, we will all briefly introduce ourselves, but we don’t have enough time in-depth introductions. Thus, I’d like you to share some information with the class over Slack.\n\n\n\nGrading will be done as a check/no check for turning in your work. If you are stressed about time, please turn in whatever you have completed."
  },
  {
    "objectID": "homework/HW0.html#purpose",
    "href": "homework/HW0.html#purpose",
    "title": "Homework 0",
    "section": "",
    "text": "This homework is meant to introduce yourself to me. Most of you have probably been in several classes together, but I’m a brand new face! In the first class, I will briefly introduce myself, but we don’t have enough time for in-class introductions for everyone. Thus, I’d like you to share some information with me."
  },
  {
    "objectID": "homework/HW0.html#gradingrubric",
    "href": "homework/HW0.html#gradingrubric",
    "title": "Homework 0",
    "section": "",
    "text": "Grading will be done using a scale from 0-5. We will use the following scale on only this homework assignment: If you are stressed about time, please give yourself an extension."
  },
  {
    "objectID": "homework/HW0.html#question-1",
    "href": "homework/HW0.html#question-1",
    "title": "Homework 0",
    "section": "Question 1",
    "text": "Question 1\nPlease upload a picture of yourself to Slack. Please follow the below steps to add a picture of yourself in Slack:\n\nGo to the top right corner in Slack and click your profile picture.\nClick \"Profile.\"\nIn the picture of the clip art person, click \"Upload Photo\" in top right corner.\nUpload a picture file of yourself."
  },
  {
    "objectID": "homework/HW0.html#question-2",
    "href": "homework/HW0.html#question-2",
    "title": "Homework 0",
    "section": "Question 2",
    "text": "Question 2\nProvide a pronunciation of your name: Please follow the below steps to add an audio and written pronunciation of your name in Slack:\n\nGo to the top right corner in Slack and click your profile picture.\nClick \"Profile.\"\nTo the right of your name, click \"Edit.\"\nUnder \"Name Recording,\" click \"Record Audio Clip.\"\nPlease say your name once at a normal pace then once slowly. Please listen to my audio for an example.\nYou may also edit the written pronunciation of your name. This is optional. I realize that doing this is may require a lot of time researching phonetics."
  },
  {
    "objectID": "homework/HW0.html#question-3",
    "href": "homework/HW0.html#question-3",
    "title": "Homework 0",
    "section": "Question 3",
    "text": "Question 3\nPlease complete the following whenisgood poll so that we can schedule office hours. Please use a unique identifier (does not have to be your name), so that I can make sure each student can attend at least one office hour."
  },
  {
    "objectID": "homework/HW0.html#question-4",
    "href": "homework/HW0.html#question-4",
    "title": "Homework 0",
    "section": "Question 4",
    "text": "Question 4\nCompletion of this question is optional. If you are comfortable sharing your pronouns, please edit your name in Slack to include them. For example, I have changed my name to be \"Nicky Wakim (she/her)\". If you prefer to not share your pronouns, then I will refer to you using they/them pronouns."
  },
  {
    "objectID": "homework/HW0.html#question-5",
    "href": "homework/HW0.html#question-5",
    "title": "Homework 0",
    "section": "Question 5",
    "text": "Question 5\nPlease post an introduction in the #random channel. Your introduction may include information like:\n\nPreferred name\nPronouns\nCareer interests\nHobbies\nFamily, children, and/or fur babies\nAdventures\nWillingness to join a study group\nBig three astrology signs\nMotivation for taking the course\nAnticipated Spring trip/activity\n\nPlease feel free to get creative with what you share! You don’t need to adhere to this list."
  },
  {
    "objectID": "homework/HW0.html#question-6",
    "href": "homework/HW0.html#question-6",
    "title": "Homework 0",
    "section": "Question 6",
    "text": "Question 6\nCompletion of this question is only necessary if you have accommodations. If you have any learning accommodations, please email me about your needs. I should receive a direct email from the Office of Student Access, but it is important that we discuss how accommodations will translate to our class."
  },
  {
    "objectID": "slides/0_Intro.html",
    "href": "slides/0_Intro.html",
    "title": "Welcome to BSTA 550!",
    "section": "",
    "text": "Call me “Nicky,” “Dr. W,” “Professor Wakim,” or any combo!\nAssistant Professor of Biostatistics\n \nOriginally from DC area (Virginia side!)\nTwo kitties\nVolleyball, biking, spikeball, pickleball\nBut also sleeping, TV, and reading\nJust started taking a couple classes at PCC (French, ceramics, yoga)\nSlowly regrowing my plant collection after moving from Michigan\n\n\n\n\n Video"
  },
  {
    "objectID": "slides/0_Intro.html#some-important-tasks",
    "href": "slides/0_Intro.html#some-important-tasks",
    "title": "Welcome to BSTA 550!",
    "section": "Some important tasks",
    "text": "Some important tasks\n\nJoin the Slack page!\nStar the class website: https://nwakim.github.io/F2023_BSTA_550/\nComplete the WhenIsGood for office hours\nComplete Homework 0 by this Thursday at 11pm!\nHighly suggest that you make an appointment with a learning specialist through Student Academic Support Services!"
  },
  {
    "objectID": "homework/HW0.html#directions",
    "href": "homework/HW0.html#directions",
    "title": "Homework 0",
    "section": "",
    "text": "This homework must be turned into Sakai. I want to make sure we are all familiar with the process of downloading a .qmd file, editing it, and resubmitting an .html and .qmd file.\nHere are the instructions for downloading and submitting your homework:\n\nGo to this github site to download the homework’s .qmd file.\nWhen you reach the site, it should look like this:\nClick the “Download raw file” icon () to download the .qmd file. This will likely download the file into your “Downloads” folder. It is up to you to move the file into the appropriate folder.\nPlease rename you homework as Lastname_Firstinitial_HW0.qmd . This will help organize the homeworks when the TAs grade them.\nPlease also add the following line under subtitle: \"BSTA 512/612\": author: First-name Last-name with your first and last name so it is attached to the viewable document.\nEdit the document with your explanations and code. If you are writing out an answer or calculating by hand, you can take a picture of your work and embed it within the .qmd file. The pictures will be viewable on the .html file.\nPlease upload your homework to this Sakai assignment. Upload both your .qmd code file and the rendered .html file.\n\nThese instructions will not appear on every homework. You may come back to this page for reference.\n\n\nThis homework is meant to introduce yourself to me and your peers. In the first class, we will all briefly introduce ourselves, but we don’t have enough time in-depth introductions. Thus, I’d like you to share some information with the class over Slack.\n\n\n\nGrading will be done as a check/no check for turning in your work. If you are stressed about time, please turn in whatever you have completed."
  },
  {
    "objectID": "homework/HW0.html#questions",
    "href": "homework/HW0.html#questions",
    "title": "Homework 0",
    "section": "Questions",
    "text": "Questions\n\nQuestion 1\nPlease upload a picture of yourself to Slack. Please follow the below steps to add a picture of yourself in Slack:\n\nGo to the top right corner in Slack and click your profile picture.\nClick “Profile.”\nIn the picture of the clip art person, click “Upload Photo” in top right corner.\nUpload a picture file of yourself.\n\nPlease include the picture you used below. This will make sure we are all able to insert a picture within Quarto. It will also make sure I can see the photo within the .html file.\n\n\nQuestion 2\nProvide a pronunciation of your name: Please follow the below steps to add an audio and written pronunciation of your name in Slack:\n\nGo to the top right corner in Slack and click your profile picture.\nClick “Profile.”\nTo the right of your name, click “Edit.”\nUnder “Name Recording,” click “Record Audio Clip.”\nPlease say your name once at a normal pace then once slowly. Please listen to my audio for an example.\nYou may also edit the written pronunciation of your name. This is optional. I realize that doing this is may require a lot of time researching phonetics.\n\n\n\nQuestion 3\nPlease complete the following whenisgood poll so that we can schedule office hours. Please use a unique identifier (does not have to be your name), so that I can make sure each student can attend at least one office hour.\n\n\nQuestion 4\nCompletion of this question is optional. If you are comfortable sharing your pronouns, please edit your name in Slack to include them. For example, I have changed my name to be “Nicky Wakim (she/her)”. If you prefer to not share your pronouns, then I will refer to you using they/them pronouns.\n\n\nQuestion 5\nPlease post an introduction in the #random channel on Slack. You do not need to include all of the below items, but your introduction may include information like:\n\nPreferred name\nPronouns\nAre you new to Portland?\nCareer interests\nHobbies\nFamily, children, and/or fur babies\nFavorite/recent adventures, restaurants, TV shows, books, podcasts, games, etc.\nWillingness to join a study group\nMotivation for taking the course\nAnticipated Winter trip/activity\nAny resolutions/vibes/outlooks that you are thinking about as we start the new calendar year/quarter\n\nPlease feel free to get creative with what you share! You don’t need to adhere to this list.\n\n\nQuestion 6\nCompletion of this question is only necessary if you have accommodations. If you have any learning accommodations, please email me about your needs. I should receive a direct email from the Office of Student Access, but it is important that we discuss how accommodations will translate to our class."
  },
  {
    "objectID": "syllabus.html#course-expectations",
    "href": "syllabus.html#course-expectations",
    "title": "BSTA 512/612 Syllabus",
    "section": "Course Expectations",
    "text": "Course Expectations\n\nInstructor Expectations\nCommitment to your learning and your success\nI believe that everyone has the ability to be successful in this course and I have put a lot of effort into designing the course in a way that maximizes your learning to ensure your success. Please talk to me before or after class or stop by my office if there is anything you want to discuss or about which you are unclear. I want to be supportive of your learning and growth.\nInclusive & supportive learning community\nI believe that learning happens best when we all learn together, as a community. This means creating a space characterized by generous listening, civility, humility, patience, and hospitality. I will attempt to promote a safe climate where we examine content from multiple cultural perspectives, and I will strive to create and maintain a classroom atmosphere in which you feel free to both listen to others and express your views and ask questions to increase your learning.\nOpenness to feedback\nI appreciate straightforward feedback from you regarding how well the class is meeting your needs. Let me know if material is not clear or when its relevance to the student learning outcomes for the course is not apparent. In particular, let me know if you identify bias or stereotyping in my teaching materials as I will seek to continuously improve. Please also let me know if there’s an aspect of the class you find particularly interesting, helpful, or enjoyable!\nResponsiveness\nI will monitor email as well as the discussion board daily and try respond to all messages within 24 hours Monday-Friday.\nClear guidelines and prompt feedback on assignments\nI will provide clear instructions for all assignments, and a grading rubric when applicable. I will provide detailed feedback on your submissions and will update grades promptly in Sakai.\n\n\nStudent Expectations and Resources\nAttend class\nYou are expected to attend all scheduled class meetings synchronously or watch the recording within 7 days. Attendance is taken through exit tickets. If you have issues accessing the poll on a specific day, please let me know. \nParticipate\nI encourage you to participate actively in class and online discussions. I will expect all students, and all instructors, to be respectful of each other’s contributions, whether I agree with them or not. Professional interactions are expected.\nBuild rapport\nIf you find that you have any trouble keeping up with assignments or other aspects of the course, make sure you let me know as early as possible. As you will find, building rapport and effective relationships are key to becoming an effective professional. Make sure that you are proactive in informing me when difficulties arise during the quarter so that I can help you find a solution.\nComplete assignments\nAll assignments for this course will be submitted electronically through Sakai unless otherwise instructed.  I encourage you to make your best effort to submit all assignments on time, but I understand that sometimes circumstances arise that are beyond our control. If you need an extension, please contact me in congruence with the Late Policy.\nSeek help if you need it\nI believe it is important to support the physical and emotional well‐being of my students. If you are experiencing physical or mental health issues, I encourage you to use the resources on campus such as those listed below. If you have a health issue that is affecting your performance or participation in the course, and/or if you need help connecting with these resources, please contact me.\n\nStudent Health and Wellness Center (SHW), Website, 503-494-8665 (OHSU Students only)\nStudent Health and Counseling (SHAC), Website, 503-725-2800\n\nInform your instructor of any accommodations needed\nYou should speak with or email me before or during the first week of classes regarding any special needs. Students seeking academic accommodations should register with the appropriate service under the School policies below.\nSome religious holidays may occur on regularly scheduled class days. Because available class hours are so limited in number, we will have to hold class on all such days. Class video recordings will be available and you are encouraged to engage with the material outside of the regular class time. You are also encouraged to come to office hours with questions from the session.\nCommit to integrity\nAs a student in this course (and at PSU or OHSU) you are expected to maintain high degrees of professionalism, commitment to active learning and participation in this class and also integrity in your behavior in and out of the classroom.\nCheating and other forms of academic misconduct will not be tolerated in this course and will be dealt with firmly. Student academic misconduct refers to behavior that includes plagiarism, cheating on assignments, fabrication of data, falsification of records or official documents, intentional misuse of equipment or materials (including library materials), or aiding and abetting the perpetration of such acts. Preparation of exams, assigned on an individual basis, must represent each student’s own individual effort. When used, resource materials should be cited in conventional reference format."
  },
  {
    "objectID": "schedule/week_08_sched.html#on-the-horizon",
    "href": "schedule/week_08_sched.html#on-the-horizon",
    "title": "Week 8",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "schedule/week_08_sched.html#class-exit-tickets",
    "href": "schedule/week_08_sched.html#class-exit-tickets",
    "title": "Week 8",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (11/13)\n Wednesday (11/15)"
  },
  {
    "objectID": "schedule/week_08_sched.html#statistician-of-the-week-name",
    "href": "schedule/week_08_sched.html#statistician-of-the-week-name",
    "title": "Week 8",
    "section": "Statistician of the Week: Name",
    "text": "Statistician of the Week: Name"
  },
  {
    "objectID": "schedule/week_03_sched.html#on-the-horizon",
    "href": "schedule/week_03_sched.html#on-the-horizon",
    "title": "Week 3",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "schedule/week_03_sched.html#class-exit-tickets",
    "href": "schedule/week_03_sched.html#class-exit-tickets",
    "title": "Week 3",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (9/25)\n Wednesday (9/27)"
  },
  {
    "objectID": "schedule/week_03_sched.html#statistician-of-the-week",
    "href": "schedule/week_03_sched.html#statistician-of-the-week",
    "title": "Week 3",
    "section": "Statistician of the Week:",
    "text": "Statistician of the Week:\n\n\n\n\n\n\n\nDavid Blackwell\n\n\n\n\n\n\nBlackwell was the first black person to receive a PhD in statistics (from University of Illinois at Urbana-Champaign, in 1941 at the age of 22) in the US and the first black scholar to be admitted to the National Academy of Sciences. He was a statistician at UC Berkeley for more than 50 years. He was hired in 1954 after the department almost made him an offer in 1942 (but declined to do so when one faculty member’s wife said she didn’t want Blackwell hired because she wouldn’t feel comfortable having faculty events in her home with a black man). Hear Blackwell tell the story in his own words.\n\n\n\nTopics covered\nBlackwell contributed to game theory, probability theory, information science, and Bayesian statistics. The Rao-Blackwell theorem (often seen in a senior level undergraduate class on statistical theory) is named after him.\n\n\nRelevant work\n\nBlackwell, D. (1947). “Conditional expectation and unbiased sequential estimation”. Annals of Mathematical Statistics. 18 (1): 105–110. doi:10.1214/aoms/1177730497.\n\n\n\nOutside links\n\nWikipedia\nMAD\n\nPlease note the statisticians of the week are taken directly from the CURV project by Jo Hardin."
  },
  {
    "objectID": "schedule/week_09_sched.html#on-the-horizon",
    "href": "schedule/week_09_sched.html#on-the-horizon",
    "title": "Week 9",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "schedule/week_09_sched.html#class-exit-tickets",
    "href": "schedule/week_09_sched.html#class-exit-tickets",
    "title": "Week 9",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (11/20)"
  },
  {
    "objectID": "schedule/week_09_sched.html#statistician-of-the-week",
    "href": "schedule/week_09_sched.html#statistician-of-the-week",
    "title": "Week 9",
    "section": "Statistician of the Week:",
    "text": "Statistician of the Week:"
  },
  {
    "objectID": "schedule/week_10_sched.html#on-the-horizon",
    "href": "schedule/week_10_sched.html#on-the-horizon",
    "title": "Week 10",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "schedule/week_10_sched.html#class-exit-tickets",
    "href": "schedule/week_10_sched.html#class-exit-tickets",
    "title": "Week 10",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (11/27)\n Wednesday (11/29)"
  },
  {
    "objectID": "schedule/week_10_sched.html#statistician-of-the-week",
    "href": "schedule/week_10_sched.html#statistician-of-the-week",
    "title": "Week 10",
    "section": "Statistician of the Week:",
    "text": "Statistician of the Week:"
  },
  {
    "objectID": "schedule/week_11_sched.html#on-the-horizon",
    "href": "schedule/week_11_sched.html#on-the-horizon",
    "title": "Week 11",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "schedule/week_11_sched.html#end-of-quarter-feedback",
    "href": "schedule/week_11_sched.html#end-of-quarter-feedback",
    "title": "Week 11",
    "section": "End of quarter feedback!",
    "text": "End of quarter feedback!"
  },
  {
    "objectID": "schedule/week_11_sched.html#statistician-of-the-week",
    "href": "schedule/week_11_sched.html#statistician-of-the-week",
    "title": "Week 11",
    "section": "Statistician of the Week:",
    "text": "Statistician of the Week:"
  },
  {
    "objectID": "schedule/week_07_sched.html#on-the-horizon",
    "href": "schedule/week_07_sched.html#on-the-horizon",
    "title": "Week 7",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "schedule/week_07_sched.html#class-exit-tickets",
    "href": "schedule/week_07_sched.html#class-exit-tickets",
    "title": "Week 7",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (11/6)\n Wednesday (11/8)"
  },
  {
    "objectID": "schedule/week_07_sched.html#statistician-of-the-week",
    "href": "schedule/week_07_sched.html#statistician-of-the-week",
    "title": "Week 7",
    "section": "Statistician of the Week:",
    "text": "Statistician of the Week:"
  },
  {
    "objectID": "schedule/week_06_sched.html#on-the-horizon",
    "href": "schedule/week_06_sched.html#on-the-horizon",
    "title": "Week 6",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "schedule/week_06_sched.html#class-exit-tickets",
    "href": "schedule/week_06_sched.html#class-exit-tickets",
    "title": "Week 6",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (10/30)"
  },
  {
    "objectID": "schedule/week_06_sched.html#statistician-of-the-week",
    "href": "schedule/week_06_sched.html#statistician-of-the-week",
    "title": "Week 6",
    "section": "Statistician of the Week:",
    "text": "Statistician of the Week:"
  },
  {
    "objectID": "schedule/week_05_sched.html#on-the-horizon",
    "href": "schedule/week_05_sched.html#on-the-horizon",
    "title": "Week 5",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "schedule/week_05_sched.html#class-exit-tickets",
    "href": "schedule/week_05_sched.html#class-exit-tickets",
    "title": "Week 5",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (10/23)\n Wednesday (10/25)"
  },
  {
    "objectID": "schedule/week_05_sched.html#statistician-of-the-week",
    "href": "schedule/week_05_sched.html#statistician-of-the-week",
    "title": "Week 5",
    "section": "Statistician of the Week:",
    "text": "Statistician of the Week:"
  },
  {
    "objectID": "schedule/week_04_sched.html#on-the-horizon",
    "href": "schedule/week_04_sched.html#on-the-horizon",
    "title": "Week 4",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "schedule/week_04_sched.html#class-exit-tickets",
    "href": "schedule/week_04_sched.html#class-exit-tickets",
    "title": "Week 4",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (10/16)\n Wednesday (10/18)"
  },
  {
    "objectID": "schedule/week_04_sched.html#statistician-of-the-week",
    "href": "schedule/week_04_sched.html#statistician-of-the-week",
    "title": "Week 4",
    "section": "Statistician of the Week:",
    "text": "Statistician of the Week:"
  },
  {
    "objectID": "schedule/week_02_sched.html#statistician-of-the-week-talithia-williams",
    "href": "schedule/week_02_sched.html#statistician-of-the-week-talithia-williams",
    "title": "Week 2",
    "section": "Statistician of the Week: Talithia Williams",
    "text": "Statistician of the Week: Talithia Williams\n\n\n\n\n\n\n\nTalithia Williams\n\n\n\n\n\n\nDr. Williams earned a BS in Mathematics from Spelman College, an MS in Mathematics from Howard University, and a PhD (2008) in Statistics from Rice University. Dr. Williams is Associate Professor and Director of the Clinic Program at Harvey Mudd College. She has also served as Associate Dean for Faculty Development and Diversity at Harvey Mudd.\n\n\n\nTopics covered\nDr. Williams works on statistical models which describe spatial and temporal aspects of data. Some of her most important work has focused on developing models to predict cataract surgical rates for countries in Africa.\n\n\nRelevant work\n\nDray, A. and Williams, T. An incidence estimation model for multi-stage diseases with differential mortality. Statistics in Medicine, 2012.\nLewallen, S., Courtright, P., Etya’ale, D., Mathenge, W., Schmidt, E., Oye, J., Clark, A., Williams, T. Cataract Incidence in Sub-Saharan Africa: What does Mathematical Modeling tell us about Geographic Variations and Surgical Needs?. Ophthalmic epidemiology, 2013.\n\n\n\nOutside links\n\nWikipedia\nMAD\nLinkedin\npersonal\n\n\n\nOther\nDr. Williams was the co-host of the 2018 PBS Nova Wonders series.\nPlease note the statisticians of the week are taken directly from the CURV project by Jo Hardin."
  },
  {
    "objectID": "schedule/week_04_sched.html#statistician-of-the-week-joy-buolamwini",
    "href": "schedule/week_04_sched.html#statistician-of-the-week-joy-buolamwini",
    "title": "Week 4",
    "section": "Statistician of the Week: Joy Buolamwini",
    "text": "Statistician of the Week: Joy Buolamwini\n\n\n\n\n\n\n\nJoy Buolamwini\n\n\n\n\n\n\nDr. Buolamwini earned a BS in Computer Science from Georgia Institute of Technology, an Master’s from University of Oxford, and MS and PhD (2022) degrees in Media Arts & Sciences from Massachusetts Institute of Technology. While a graduate student, Dr. Buolamwini was part of the MIT Media Lab. Additionally, she is the founder of the Algorithmic Justice League.\n\n\n\nTopics covered\nDr. Buolamwini has done substantial work demonstrating how algorithms can encode bias. Her undergraduate senior project was to create a inspired “mask” mirror as a way to raise spirits for the person who looked into the mirror. The project relied on off the shelf facial recognition software that could not recognize Dr. Buolamwini’s face.\nSince then, she has focused her work on demonstrating bias across racial and gender spectra in off the shelf software. Her work has been cited as directly influencing Microsoft and Google’s changes to their algorithms.\nAmong many other aspects, a big focus of Dr. Buolamwini’s work is pointing out the biased data which directly impacts how algorithms learn how to do tasks.\n\n\nRelevant work\n\nBuolamwini, J., Gebru, T. Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. Proceedings of Machine Learning Research 81:1–15, 2018 Conference on Fairness, Accountability, and Transparency.\nRaji, I & Buolamwini, J. Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products. Conference on Artificial Intelligence, Ethics, and Society, 2019\n\n\n\nOutside links\n\nWikipedia\nLinkedin\npersonal\n\n\n\nOther\nDr. Buolamwini has done a lot of work on how data propagates through systems to encode the same types of bias into different algorithms. In her video AI, Ain’t I a Woman? she demonstrates how systems designed to determine gender are particularly poor when using dark skinned faces.\nHer work was featured in a recent documentary Coded Bias.\nPlease note the statisticians of the week are taken directly from the CURV project by Jo Hardin."
  },
  {
    "objectID": "schedule/week_05_sched.html#statistician-of-the-week-liz-hare",
    "href": "schedule/week_05_sched.html#statistician-of-the-week-liz-hare",
    "title": "Week 5",
    "section": "Statistician of the Week: Liz Hare",
    "text": "Statistician of the Week: Liz Hare\n\n\n\n\n\n\n\nLiz Hare\n\n\n\n\n\n\nDr. Hare got her BA from Bryn Mawr College and her PhD in Genetics (1998) from The George Washington University. She works primarily in dog / animal genetics; although, as a quantitative geneticist her statistical and computational methodology is quite sophisticated.\nDr. Hare is active in the MiR (Minorities in R) Community which aims to support historically underrepresented R users around the world.\n\n\n\nTopics covered\nHer computational language of choice is R, and much of her work has focused on open science with an eye toward inclusion and equity. In many software programs, the user has the ability to include alt text: text descriptions that convey the content and meaning to blind and low-vision readers.\n\nyou really need to tell us what the data is saying and why you included it.\n\n\nWhat kind of graph or chart is it?\nWhat variables are on the axes?\nWhat are the ranges of the variables?\nWhat does the appearance tell you about the relationships between the variables?\n\n\n\nRelevant work\n\nL. Hare, Writing Alt Text to Communicate the Meaning in Data Visualizations, Do No Harm Guide: centering accessibility in data visualization, eds Schwabish, Popkin, Feng, Chapter 4, 2022.\n\n\n\nOutside links\n\nGoogle Scholar\nLinkedin\nprofessional\nfosstodon"
  },
  {
    "objectID": "schedule/week_03_sched.html#statistician-of-the-week-david-blackwell",
    "href": "schedule/week_03_sched.html#statistician-of-the-week-david-blackwell",
    "title": "Week 3",
    "section": "Statistician of the Week: David Blackwell",
    "text": "Statistician of the Week: David Blackwell\n\n\n\n\n\n\n\nDavid Blackwell\n\n\n\n\n\n\nBlackwell was the first black person to receive a PhD in statistics (from University of Illinois at Urbana-Champaign, in 1941 at the age of 22) in the US and the first black scholar to be admitted to the National Academy of Sciences. He was a statistician at UC Berkeley for more than 50 years. He was hired in 1954 after the department almost made him an offer in 1942 (but declined to do so when one faculty member’s wife said she didn’t want Blackwell hired because she wouldn’t feel comfortable having faculty events in her home with a black man). Hear Blackwell tell the story in his own words.\n\n\n\nTopics covered\nBlackwell contributed to game theory, probability theory, information science, and Bayesian statistics. The Rao-Blackwell theorem (often seen in a senior level undergraduate class on statistical theory) is named after him.\n\n\nRelevant work\n\nBlackwell, D. (1947). “Conditional expectation and unbiased sequential estimation”. Annals of Mathematical Statistics. 18 (1): 105–110. doi:10.1214/aoms/1177730497.\n\n\n\nOutside links\n\nWikipedia\nMAD\n\nPlease note the statisticians of the week are taken directly from the CURV project by Jo Hardin."
  },
  {
    "objectID": "schedule/week_06_sched.html#statistician-of-the-week-lester-mackey",
    "href": "schedule/week_06_sched.html#statistician-of-the-week-lester-mackey",
    "title": "Week 6",
    "section": "Statistician of the Week: Lester Mackey",
    "text": "Statistician of the Week: Lester Mackey\n\n\n\n\n\n\n\nLester Mackey\n\n\n\n\n\n\nDr. Mackey is a machine learning researcher at Microsoft Research New England and an adjunct professor at Stanford University. His PhD (Computer Science 2012) and MA (Statistics 2011) are both from University of California, Berkeley, while his undergraduate degree (Computer Science 2007) is from Princeton University.\nHe is involved in Stanford’s initiative of Statistics for Social Good and has the following quote on his website:\n\nQuixotic though it may sound, I hope to use computer science and statistics to change the world for the better.\n\n\n\n\nTopics covered\nFrom Dr. Mackey’s personal website his areas of research are:\n\nstatistical machine learning\nscalable algorithms\nhigh-dimensional statistics\napproximate inference\nprobability\n\n\n\nRelevant work\n\nKoulik Khamaru, Yash Deshpande, Lester Mackey, and Martin J. Wainwright, Near-optimal inference in adaptive linear regression\n\n\nWhen data is collected in an adaptive manner, even simple methods like ordinary least squares can exhibit non-normal asymptotic behavior. As an undesirable consequence, hypothesis tests and confidence intervals based on asymptotic normality can lead to erroneous results. We propose a family of online debiasing estimators to correct these distributional anomalies in least squares estimation. Our proposed methods take advantage of the covariance structure present in the dataset and provide sharper estimates in directions for which more information has accrued. We establish an asymptotic normality property for our proposed online debiasing estimators under mild conditions on the data collection process and provide asymptotically exact confidence intervals…\n\n\nPierre Bayle, Alexandre Bayle, Lucas Janson, and Lester Mackey, Cross-validation Confidence Intervals for Test Error Advances in Neural Information Processing Systems (NeurIPS), December 2020.\n\n\nThis work develops central limit theorems for cross-validation and consistent estimators of its asymptotic variance under weak stability conditions on the learning algorithm. Together, these results provide practical, asymptotically-exact confidence intervals for k-fold test error and valid, powerful hypothesis tests of whether one learning algorithm has smaller k-fold test error than another. These results are also the first of their kind for the popular choice of leave-one-out cross-validation. In our real-data experiments with diverse learning algorithms, the resulting intervals and tests outperform the most popular alternative methods from the literature…\n\n\n\nOutside links\n\nMathematically Gifted & Black\nLinkedin\npersonal\n\n\n\nOther\nThe precursor to kaggle was a $1 million prize given by Netflix to the most accurate prediction of ratings that people give to the movies they watch. As undergraduates, Dr. Mackey and two friends led the competition for a few hours in its first year. Later, groups merged and Dr. Mackey’s group merged with a few others, forming The Ensemble. Their final analysis came in second with the exact same error rates as the winning entry. The winning entry, however, had been submitted 20 minutes prior. Sigh."
  },
  {
    "objectID": "schedule/week_07_sched.html#statistician-of-the-week-w.e.b.-du-bois",
    "href": "schedule/week_07_sched.html#statistician-of-the-week-w.e.b.-du-bois",
    "title": "Week 7",
    "section": "Statistician of the Week: W.E.B. Du Bois",
    "text": "Statistician of the Week: W.E.B. Du Bois\n\n\n\n\n\n\n\nW.E.B. Du Bois\n\n\n\n\n\n\nDu Bois was a sociologist and among the earliest data scientists. As Battle-Baptiste and Rusert say, his work can be thought of as\n\nthe rendering of information in a visual format to help communicate data while also generating new patterns and knoweldge throughout the act of visualization itselt.1\n\n\n\n\nTopics covered\nDu Bois was a sociologist who contributed to the field of data visualization through infographics related to the African American in the early twentieth century.\n\n\nRelevant work\n\nRusert, B., and Battle-Baptiste, W. “W. E. B. Du Bois’s Data Portraits: Visualizing Black America”, Princeton Architectural Press, 2018. https://papress.com/products/w-e-b-du-boiss-data-portraits-visualizing-black-america\n\n\n\nOutside links\n\nWikipedia\nTidyTuesday data viz and TidyTuesday challenge provided the data needed to re-create most of Du Bois’s original graphs (his originals were drawn by hand).\nData Journalism in the study of W.E.B. Du Bois\nW.E.B. Du Bois: retracing his attempt to challenge racism with data\nW.E.B. Du Bois’ Visionary Infographics Come Together for the First Time in Full Color\n\n\n\nOther\nIn 1900 Du Bois contributed approximately 60 data visualizations to an exhibit at the Exposition Universelle in Paris, an exhibit designed to illustrate the progress made by African Americans since the end of slavery (only 37 years prior, in 1863).\nAt their core, the data visualizations advocate for African American progress. They not only speak to the progress that had been made, but they centered many of the challenges that continued to exist at the time. The set of visualizations demonstrate how powerfully a picture can tell 1000 words, as the information Du Bois used was primarily available from public records (e.g., census and other government reports).\nWhitney Battle-Baptiste and Britt Rusert have reproduced and narrated the images from the exhibit in W.E.B. Du Bois’s Data Portraits: Visualizing Black America, the color line at the turn of the twentieth century."
  },
  {
    "objectID": "schedule/week_07_sched.html#footnotes",
    "href": "schedule/week_07_sched.html#footnotes",
    "title": "Week 7",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBattle-Baptiste and Rusert, W.E.B. Du Bois’s Data Portraits: Visualizing Black America, the color line at the turn of the twentieth century, 2018, page 8.↩︎"
  },
  {
    "objectID": "schedule/week_08_sched.html#statistician-of-the-week-desi-small-rodriguez",
    "href": "schedule/week_08_sched.html#statistician-of-the-week-desi-small-rodriguez",
    "title": "Week 8",
    "section": "Statistician of the Week: Desi Small-Rodriguez",
    "text": "Statistician of the Week: Desi Small-Rodriguez\n\n\n\n\n\n\n\nDesi Small-Rodriguez\n\n\n\n\n\n\nDr. Small-Rodriguez is a social demographer and an Assistant Professor of Sociology and American Indian Studies at UCLA. She received a PhD in Sociology from the University of Arizona and a PhD in Demography from the University of Waikato. Dr. Small-Rodriguez is Northern Cheyenne and Chicana and grounds her work in Indigenous studies, sociology of race and ethnicity, critical demography, and health policy research. She directs the Data Warriors Lab (a mobile data sovereignty lab serving Indigenous communities) and was previously a member of the Collaboratory for Indigenous Data Governance. She is a founding member of the Global Indigenous Data Alliance.\n\n\n\nTopics covered\nDr. Small-Rodriguez is passionate about Indigenous data sovereignty and Indigenous data governance. Using networks of Indigenous scholars and survey methods, she works toward the following two goals: (1) better collection and use of data on Indigenous people that has been gathered by external sources such as the census and other federal entities; (2) development of data methods and practitioners within the Indigenous community. Dr. Small-Rodriguez also works for health and economic justice on Indian Reservations.\n\n\nRelevant work\n\nS.R. Carroll, D. Rodriguez-Lonebear, A. Martinez, “Indigenous Data Governance: Strategies from United States Native Nations.” Data Science Journal, 2019. https://datascience.codata.org/article/10.5334/dsj-2019-031/\n\n\n“Indigenous data sovereignty is the right of each Native nation to govern the collection, ownership, and application of the tribe’s data.”\n\n\nRodriguez-Lonebear D, Barceló NE, Akee R, Carroll SR. “American Indian Reservations and COVID-19: Correlates of Early Infection Rates in the Pandemic.” J Public Health Manag Pract. 2020. doi: 10.1097/PHH.0000000000001206.\n\n\n\nOutside links\n\nacademic\nLinkedin\npersonal"
  },
  {
    "objectID": "schedule/week_09_sched.html#statistician-of-the-week-mike-dairyko",
    "href": "schedule/week_09_sched.html#statistician-of-the-week-mike-dairyko",
    "title": "Week 9",
    "section": "Statistician of the Week: Mike Dairyko",
    "text": "Statistician of the Week: Mike Dairyko\n\n\n\n\n\n\n\nMike Dairyko\n\n\n\n\n\n\nDr. Dairyko was a Posse Scholar at Pomona College where a linear algebra class set him on a career path centered around mathematics. Through that class he found his way to two different summer REU programs and eventually to a PhD in Applied Mathematics from Iowa State University (2018). While initially believing that he would stay in academia after his graduate work, being introduced to machine learning methods caused him to pursue data science jobs after graduation.\nDr. Dairyko served as a Senior Manager of Data Science at the Milwaukee Brewers and is now the Director of Ticketing Analytics at the Milwaukee Bucks. Helping the organization get the most out of budgeting, revenue, and ticket sales allows him to fully use his training in mathematics and data science.\n\n\n\nTopics covered\nDr. Dairyko’s graduate work is in graph theory, in particular, exponential domination. In a graph, exponential domination is the extent to which a particular vertex influences the remaining vertices in a graph. His published work falls very much within the realm of mathematics, proving that particular properties of graphs exist. However, graph theory is intimately related to machine learning; for example, it is the foundational structure of a neural network. Understanding properties of graphs help data scientists develop even more powerful models to harness information from data.\n\n\nRelevant work\n\nM. Dairyko, A linear programming method for exponential domination. The Golden Anniversary Celebration of the National Association of Mathematicians, Volume 759 of Contemporary mathematics. Eds O. Ortega, E. Lawrence, E. Goins (2020).\nM. Dairyko, L.Hogben, J. Lin, J. Lockhart, D. Roberson, S. Severini, M. Young, Note on von Neumann and Rényi entropies of a graph. Linear Algebra and its Applications, 2017.\n\n\n\nOutside links\n\nMAD\nLinkedin\nGoogle Scholar\n\n\n\nOther\nDr. Dairyko’s path from mathematics to data science has been written about in SIAM and in the Iowa State University newsletter Math Matters."
  },
  {
    "objectID": "schedule/week_10_sched.html#statistician-of-the-week-florence-nightingale",
    "href": "schedule/week_10_sched.html#statistician-of-the-week-florence-nightingale",
    "title": "Week 10",
    "section": "Statistician of the Week: Florence Nightingale",
    "text": "Statistician of the Week: Florence Nightingale\n\n\n\n\n\n\n\nFlorence Nightingale\n\n\n\n\n\n\nNightingale was a nurse who is considered to be the founder of modern nursing. In particular, she was admant about the importance of hygiene and sanitary conditions. She was born into a wealthy and well-connected family and had a large amount of privilege. Educated by her father, she showed an ability toward making analytic arguments at an early age. For her work, she was awarded the Royal Red Cross, the Lady of Grace of the Order of St John, and the Order of Merit.\n\n\n\nTopics covered\nNightingale was a nurse and statistician who used her analytic abilities to better understand and improve public health. She served in the Crimean War where Britain and France fought against the Russian invasion of the Ottoman Empire. Nightingale worked to convince Queen Victoria that poor sanitation and overcrowding were causing unnecessary death. She was able to show, for example, that peacetime soldiers (who lived in poorly kept barracks) were dying in much higher number than comparable civilian men. Her genius was to collect data meticulously and to display it in ways that were accessible to the general public. Her visualizations are lauded as pioneering and the first of their kind to tell effective stories of important issues.\n\n\nRelevant work\n\nRJ Andrews, “Florence Nightingale’s Data Revolution” in Scientific American 327, 2, 78-85, 2022. doi:10.1038/scientificamerican0822-78,\n\n\n\n\n\n\n“Diagram of the causes of mortality in the army in the East” was published in Notes on Matters Affecting the Health, Efficiency, and Hospital Administration of the British Army and sent to Queen Victoria in 1858.\n\n\n\n\n\nS Julious, “On the battlefields of the Crimean War and in the hills of Sheffield, Florence Nightingale’s legacy lives on”, The Tribune, Feb 17, 2023.\n\n\n\nOutside links\n\nWikipedia"
  },
  {
    "objectID": "schedule/week_11_sched.html#statistician-of-the-week-maricela-cruz",
    "href": "schedule/week_11_sched.html#statistician-of-the-week-maricela-cruz",
    "title": "Week 11",
    "section": "Statistician of the Week: Maricela Cruz",
    "text": "Statistician of the Week: Maricela Cruz\n\n\n\n\n\n\n\nMaricela Cruz\n\n\n\n\n\n\nDr. Cruz did her undergraduate work at Pomona College, majoring in mathematics. Her PhD in Statistics is from University of California, Irvine. She is now Assistant Biostatistics Investigator, Kaiser Permanente Washington Health Research Institute (KPWHRI) and Affiliate Assistant Investigator, Department of Biostatistics, University of Washington.\nIn an interview done by Lathisms, Dr. Cruz reminds us:\n\nNavigating institutions that have systematically excluded groups of people can be taxing, especially for people from one or more of these groups. Surround yourself with those who believe in you, give you the space to ask ‘silly’ questions, value your input, and/or understand your struggles. Do activities that will help you blow off steam. No one person or activity will meet all your support needs, so find the right group and balance for you.\n\n\n\n\nTopics covered\nDr. Cruz’s dissertation work was on interrupted time series models used to determine intervention timing. Indeed, her primary research questions are to understand complex health interventions. At KPWHRI she has continued to work on epidemiological methods, particularly those appropriate for longitudinal and multilevel data.\n\n\nRelevant work\n\nCruz M, Ombao H, Gillen DL, A Generalized Interrupted Time Series Model for Assessing Complex Health Care Interventions. Statistics in Biosciences, 2022.\nCruz M, Gillen DL, Bender M, & Ombao H, Assessing health care interventions via an interrupted time series model: study power and design considerations. Statistics in Medicine, 2019.\n\n\n\nOutside links\n\nLathisms\nLinkedin\nKaiser Permanente"
  },
  {
    "objectID": "slides/22_Counting_Intro.html#basic-counting-examples-13",
    "href": "slides/22_Counting_Intro.html#basic-counting-examples-13",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (1/3)",
    "text": "Basic Counting Examples (1/3)\n\n\nExample 1\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\nHow many possible ways are there to order them?\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\nHow many ways to order them without replacement and only need 6?\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "slides/22_Counting_Intro.html#basic-counting-examples-23",
    "href": "slides/22_Counting_Intro.html#basic-counting-examples-23",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (2/3)",
    "text": "Basic Counting Examples (2/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.1\n\n\nHow many possible ways are there to order them?\n\n\n \n\n\nExample 1.2\n\n\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?"
  },
  {
    "objectID": "slides/22_Counting_Intro.html#basic-counting-examples-33",
    "href": "slides/22_Counting_Intro.html#basic-counting-examples-33",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (3/3)",
    "text": "Basic Counting Examples (3/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.3\n\n\nHow many ways to order them without replacement and only need 6?\n\n\n \n\n\nExample 1.4\n\n\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "slides/22_Counting_Intro.html#permutations-and-combinations-1",
    "href": "slides/22_Counting_Intro.html#permutations-and-combinations-1",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Permutations and Combinations",
    "text": "Permutations and Combinations\n\n\nDefinition: Permutations\n\n\nPermutations are the number of ways to arrange in order \\(r\\) distinct objects when there are \\(n\\) total.\n\\[nPr = \\frac{n!}{(n-r)!}\\]\n\n\n\n\nDefinition: Combinations\n\n\nCombinations are the number of ways to choose (order doesn’t matter) \\(r\\) objects from \\(n\\) without replacement.\n\\[nCr = \\textrm{\"n choose r\"} = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "slides/22_Counting_Intro.html#some-combinations-properties",
    "href": "slides/22_Counting_Intro.html#some-combinations-properties",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Some combinations properties",
    "text": "Some combinations properties\n\n\\[\\binom{n}{r} = \\binom{n}{n-r}\\]\n \n \n\\[\\binom{n}{1} = n\\]\n \n \n\\[\\binom{n}{0} = 1\\]"
  },
  {
    "objectID": "slides/22_Counting_Intro.html#more-examples-order-matters-vs.-not-12",
    "href": "slides/22_Counting_Intro.html#more-examples-order-matters-vs.-not-12",
    "title": "Chapter 22: Introduction to Counting",
    "section": "More examples: order matters vs. not (1/2)",
    "text": "More examples: order matters vs. not (1/2)\n\n\n\n\nExample 2\n\n\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\norder doesn’t matter?"
  },
  {
    "objectID": "slides/22_Counting_Intro.html#more-examples-order-matters-vs.-not-22",
    "href": "slides/22_Counting_Intro.html#more-examples-order-matters-vs.-not-22",
    "title": "Chapter 22: Counting",
    "section": "More examples: order matters vs. not (2/2)",
    "text": "More examples: order matters vs. not (2/2)\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\n\n\\[\\frac{13P2}{52P2} = \\frac{\\frac{13!}{11!}}{\\frac{52!}{50!}} = \\frac{13\\cdot12}{52\\cdot51}\\]\n\norder doesn’t matter?\n\n\\[\\frac{\\binom{13}{2}}{\\binom{52}{2}} = \\frac{\\frac{13!}{2!11!}}{\\frac{52!}{2!50!}} = \\frac{13\\cdot12}{52\\cdot51}\\]"
  },
  {
    "objectID": "slides/22_Counting_Intro.html#table-of-different-cases",
    "href": "slides/22_Counting_Intro.html#table-of-different-cases",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Table of different cases",
    "text": "Table of different cases\nSee table on pg. 277 of textbook\n\n\\(n\\) = total number of objects\n\\(r\\) = number objects needed\n\n\n\n\n\n\n\n\n\nwith replacement\nwithout replacement\n\n\n\n\norder matters\n\\[n^r\\]\n\\[nPr = \\frac{n!}{(n-r)!}\\]\n\n\norder doesn’t matter\n\\[ \\binom{n+r-1}{r}\\]\n\\[nCr = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "slides_solns/2_Probability-solutions.html",
    "href": "slides_solns/2_Probability-solutions.html",
    "title": "Chapter 2: Probability",
    "section": "",
    "text": "Example 1\n\n\nSuppose you have a regular well-shuffled deck of cards. What’s the probability of drawing:\n\nany heart\nthe queen of hearts\nany queen\n\nSolution:\n\nany heart = 13/52 = 1/4\nthe queen of hearts = 1/52\nany queen = 4/52 = 1/13\n\n\n\n\n\n\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}.\\]\n\n\n\n\\(\\mathbb{P}(A)\\) is a function with\n\ninput: event \\(A\\) from the sample space \\(S\\), (\\(A \\subseteq S\\))\noutput: a number between 0 and 1 (inclusive)\n\n\\[\\mathbb{P}(A): S \\rightarrow [0,1]\\]\nA function that follows some specific rules though!\nSee Probability Axioms on next slide."
  },
  {
    "objectID": "slides_solns/2_Probability-solutions.html#probabilities-of-equally-likely-events-12",
    "href": "slides_solns/2_Probability-solutions.html#probabilities-of-equally-likely-events-12",
    "title": "Chapter 2: Probability",
    "section": "",
    "text": "Example 1\n\n\nSuppose you have a regular well-shuffled deck of cards. What’s the probability of drawing:\n\nany heart\nthe queen of hearts\nany queen\n\nSolution:\n\nany heart = 13/52 = 1/4\nthe queen of hearts = 1/52\nany queen = 4/52 = 1/13"
  },
  {
    "objectID": "slides_solns/2_Probability-solutions.html#probabilities-of-equally-likely-events-22",
    "href": "slides_solns/2_Probability-solutions.html#probabilities-of-equally-likely-events-22",
    "title": "Chapter 2: Probability",
    "section": "",
    "text": "If \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}.\\]"
  },
  {
    "objectID": "slides_solns/2_Probability-solutions.html#a-probability-is-a-function",
    "href": "slides_solns/2_Probability-solutions.html#a-probability-is-a-function",
    "title": "Chapter 2: Probability",
    "section": "",
    "text": "\\(\\mathbb{P}(A)\\) is a function with\n\ninput: event \\(A\\) from the sample space \\(S\\), (\\(A \\subseteq S\\))\noutput: a number between 0 and 1 (inclusive)\n\n\\[\\mathbb{P}(A): S \\rightarrow [0,1]\\]\nA function that follows some specific rules though!\nSee Probability Axioms on next slide."
  },
  {
    "objectID": "slides_solns/2_Probability-solutions.html#probability-axioms-1",
    "href": "slides_solns/2_Probability-solutions.html#probability-axioms-1",
    "title": "Chapter 2: Probability",
    "section": "Probability Axioms",
    "text": "Probability Axioms\n\n\nAxiom 1\n\n\nFor every event \\(A\\), \\(0\\leq\\mathbb{P}(A)\\leq 1\\).\n\n\n\n\nAxiom 2\n\n\nFor the sample space \\(S\\), \\(\\mathbb{P}(S)=1\\).\n\n\n\n\nAxiom 3\n\n\nIf \\(A_1, A_2, A_3, \\ldots\\), is a collection of disjoint events, then \\[\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i).\\]"
  },
  {
    "objectID": "slides_solns/2_Probability-solutions.html#some-probability-properties-1",
    "href": "slides_solns/2_Probability-solutions.html#some-probability-properties-1",
    "title": "Chapter 2: Probability",
    "section": "Some probability properties",
    "text": "Some probability properties\nUsing the Axioms, we can prove all other probability properties!\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nProposition 4\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\n\n\nProposition 5\n\n\n\\(\\mathbb{P}(A \\cup B \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\\\ \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\\\ \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C)\\)"
  },
  {
    "objectID": "slides_solns/2_Probability-solutions.html#proposition-1-proof",
    "href": "slides_solns/2_Probability-solutions.html#proposition-1-proof",
    "title": "Chapter 2: Probability",
    "section": "Proposition 1 Proof",
    "text": "Proposition 1 Proof\n\ncountdown::countdown(1, top = 0)\n\n\n−+\n01:00\n\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\nProposition 1 Proof\n\n\nSince \\(A\\) and \\(A^C\\) are disjoint, we know from Axiom 3 that \\(\\mathbb{P}(A \\cup A^C) = \\mathbb{P}(A) + \\mathbb{P}(A^C)\\).\nHowever, \\(S = A \\cup A^C\\), and by Axiom 2, \\(\\mathbb{P}(S) = 1\\), implying \\(\\mathbb{P}(A \\cup A^C) = \\mathbb{P}(S) = 1\\).\nThus, \\(\\mathbb{P}(A) + \\mathbb{P}(A^C) = 1\\), or \\(\\mathbb{P}(A) = 1 - \\mathbb{P}(A^C)\\)"
  },
  {
    "objectID": "slides_solns/2_Probability-solutions.html#proposition-2-proof",
    "href": "slides_solns/2_Probability-solutions.html#proposition-2-proof",
    "title": "Chapter 2: Probability",
    "section": "Proposition 2 Proof",
    "text": "Proposition 2 Proof\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\nProposition 2 Proof (different from book)\n\n\nWe know \\(\\emptyset = S^C\\).\nThus by Prop 1,\n\\[\\mathbb{P}(\\emptyset) = \\mathbb{P}(S^C) = 1- \\mathbb{P}(S) = 1-1 =0\n.\\]"
  },
  {
    "objectID": "slides_solns/2_Probability-solutions.html#proposition-3-proof",
    "href": "slides_solns/2_Probability-solutions.html#proposition-3-proof",
    "title": "Chapter 2: Probability",
    "section": "Proposition 3 Proof",
    "text": "Proposition 3 Proof\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\nProposition 3 Proof\n\n\nCreate a partition! Make a Venn diagram.\n\\[%\\left(\n\\begin{array}{ccl}\nB &=& A \\cup (B \\cap A^C) \\\\\n\\mathbb{P}(B) &=& \\mathbb{P}(A) + \\mathbb{P}(B \\cap A^C) \\\\\n\\mathbb{P}(B)  & \\geq &   \\mathbb{P}(A),\n\\end{array}\n%\\right)\\] since \\(\\mathbb{P}(B \\cap A^C) \\geq 0\\)."
  },
  {
    "objectID": "slides_solns/2_Probability-solutions.html#partitions-1",
    "href": "slides_solns/2_Probability-solutions.html#partitions-1",
    "title": "Chapter 2: Probability",
    "section": "Partitions",
    "text": "Partitions\n\n\nDefinition: Partition\n\n\nA set of events \\(\\{A_i\\}_{i=1}^{n}\\) create a partition of \\(A\\), if\n\nthe \\(A_i\\)’s are disjoint (mutually exclusive) and\n\\(\\bigcup \\limits_{i=1}^n A_i = A\\)\n\n\n\n\n\nExample 2\n\n\n\nIf \\(A \\subset B\\), then \\(\\{A, B \\cap A^C\\}\\) is a partition of \\(B\\).\nIf \\(S = \\bigcup \\limits_{i=1}^n A_i\\), then the \\(A_i\\)’s are a partition of the sample space.\n\n\n\nCreating partitions is sometimes used to help calculate probabilities, since by Axiom 3 we can add the probabilities of disjoint events."
  },
  {
    "objectID": "slides_solns/2_Probability-solutions.html#venn-diagram-probabilities-1",
    "href": "slides_solns/2_Probability-solutions.html#venn-diagram-probabilities-1",
    "title": "Chapter 2: Probability",
    "section": "Venn Diagram Probabilities",
    "text": "Venn Diagram Probabilities\n\n\n\nExample 3\n\n\nIf a subject has an\n\n80% chance of taking their medication this week,\n70% chance of taking their medication next week, and\n10% chance of not taking their medication either week,\n\nthen find the probability of them taking their medication exactly one of the two weeks.\n\nHint: Draw a Venn diagram labelling each of the parts to find the probability.Answer: \\(\\mathbb{P}(A \\cap B) = 0.6\\)."
  },
  {
    "objectID": "slides_solns/22_Counting_Intro-solutions.html",
    "href": "slides_solns/22_Counting_Intro-solutions.html",
    "title": "Chapter 22: Counting",
    "section": "",
    "text": "Example 1\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\nHow many possible ways are there to order them?\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\nHow many ways to order them if without replacements and only need 6?\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?\n\n\n\n\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\n\nExample 1.1\n\n\nHow many possible ways are there to order them?\n\n\n\\(10!\\)\n\n\nExample 1.2\n\n\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\n\n\n\nneed 10 total?\n\n\\(10^{10}\\)\n\nneed 6 total?\n\n\\(10^6\\)\n\n\n\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\n\nExample 1.3\n\n\nHow many ways to order them if without replacements and only need 6?\n\n\n\\[\\frac{10!}{4!}=151,200\\]\n\n\nExample 1.4\n\n\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?\n\n\n\\[\\frac{\\frac{10!}{4!}}{6!} = \\frac{10!}{4!6!}=210\\]\nThere are \\(6!\\) ways to order the 6 subjects."
  },
  {
    "objectID": "slides_solns/22_Counting_Intro-solutions.html#basic-counting-examples-13",
    "href": "slides_solns/22_Counting_Intro-solutions.html#basic-counting-examples-13",
    "title": "Chapter 22: Counting",
    "section": "",
    "text": "Example 1\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\nHow many possible ways are there to order them?\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\nHow many ways to order them if without replacements and only need 6?\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "slides_solns/22_Counting_Intro-solutions.html#basic-counting-examples-23",
    "href": "slides_solns/22_Counting_Intro-solutions.html#basic-counting-examples-23",
    "title": "Chapter 22: Counting",
    "section": "",
    "text": "Suppose we have 10 (distinguishable) subjects for study.\n\n\nExample 1.1\n\n\nHow many possible ways are there to order them?\n\n\n\\(10!\\)\n\n\nExample 1.2\n\n\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\n\n\n\nneed 10 total?\n\n\\(10^{10}\\)\n\nneed 6 total?\n\n\\(10^6\\)"
  },
  {
    "objectID": "slides_solns/22_Counting_Intro-solutions.html#basic-counting-examples-33",
    "href": "slides_solns/22_Counting_Intro-solutions.html#basic-counting-examples-33",
    "title": "Chapter 22: Counting",
    "section": "",
    "text": "Suppose we have 10 (distinguishable) subjects for study.\n\n\nExample 1.3\n\n\nHow many ways to order them if without replacements and only need 6?\n\n\n\\[\\frac{10!}{4!}=151,200\\]\n\n\nExample 1.4\n\n\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?\n\n\n\\[\\frac{\\frac{10!}{4!}}{6!} = \\frac{10!}{4!6!}=210\\]\nThere are \\(6!\\) ways to order the 6 subjects."
  },
  {
    "objectID": "slides_solns/22_Counting_Intro-solutions.html#permutations-and-combinations-1",
    "href": "slides_solns/22_Counting_Intro-solutions.html#permutations-and-combinations-1",
    "title": "Chapter 22: Counting",
    "section": "Permutations and Combinations",
    "text": "Permutations and Combinations\n\n\nDefinition: Permutations\n\n\nPermutations are the number of ways to arrange in order \\(r\\) distinct objects when there are \\(n\\) total.\n\\[nPr = \\frac{n!}{(n-r)!}\\]\n\n\n\n\nDefinition: Combinations\n\n\nCombinations are the number of ways to choose (order doesn’t matter) \\(r\\) objects from \\(n\\) without replacement.\n\\[nCr = \\textrm{\"n choose r\"} = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "slides_solns/22_Counting_Intro-solutions.html#some-combinations-properties",
    "href": "slides_solns/22_Counting_Intro-solutions.html#some-combinations-properties",
    "title": "Chapter 22: Counting",
    "section": "Some combinations properties",
    "text": "Some combinations properties\n\n\\[\\binom{n}{r} = \\binom{n}{n-r}\\]\n\\[\\binom{n}{1} = n\\]\n\\[\\binom{n}{0} = 1\\]"
  },
  {
    "objectID": "slides_solns/22_Counting_Intro-solutions.html#more-examples-order-matters-vs.-not-12",
    "href": "slides_solns/22_Counting_Intro-solutions.html#more-examples-order-matters-vs.-not-12",
    "title": "Chapter 22: Counting",
    "section": "More examples: order matters vs. not (1/2)",
    "text": "More examples: order matters vs. not (1/2)\n\n\nExample 2\n\n\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\norder doesn’t matter?"
  },
  {
    "objectID": "slides_solns/22_Counting_Intro-solutions.html#more-examples-order-matters-vs.-not-22",
    "href": "slides_solns/22_Counting_Intro-solutions.html#more-examples-order-matters-vs.-not-22",
    "title": "Chapter 22: Counting",
    "section": "More examples: order matters vs. not (2/2)",
    "text": "More examples: order matters vs. not (2/2)\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\n\n\\[\\frac{13P2}{52P2} = \\frac{\\frac{13!}{11!}}{\\frac{52!}{50!}} = \\frac{13\\cdot12}{52\\cdot51}\\]\n\norder doesn’t matter?\n\n\\[\\frac{\\binom{13}{2}}{\\binom{52}{2}} = \\frac{\\frac{13!}{2!11!}}{\\frac{52!}{2!50!}} = \\frac{13\\cdot12}{52\\cdot51}\\]"
  },
  {
    "objectID": "slides_solns/22_Counting_Intro-solutions.html#table-of-different-cases",
    "href": "slides_solns/22_Counting_Intro-solutions.html#table-of-different-cases",
    "title": "Chapter 22: Counting",
    "section": "Table of different cases",
    "text": "Table of different cases\nSee table on pg. 277 of textbook\n\n\\(n\\) = total number of objects\n\\(r\\) = number objects needed\n\n\n\n\n\n\n\n\n\nwith replacement\nwithout replacement\n\n\n\n\norder matters\n\\(n^r\\)\n\\(nPr = \\frac{n!}{(n-r)!}\\)\n\n\norder doesn’t matter\n\\(\\binom{n+r-1}{r}\\)\n\\(nCr = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\)"
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "",
    "text": "Suppose you toss one coin.\n\nWhat are the possible outcomes?\n \nWhat is the sample space?\n \nWhat are the possible events?\n\n\n\n\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n\nHeads (\\(H\\))\nTails (\\(T\\))\n\nNote: When something happens at random, such as a coin toss, there are several possible outcomes, and exactly one of the outcomes will occur.\n\n\n\n\n\n\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all possible outcomes.\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some possible outcomes.\n\n\n\n\nWhat is the sample space?\n\n\\(S = \\{H, T\\}\\)\n\nWhat are the possible events?\n\n\\(\\{H\\}\\)\n\\(\\{T\\}\\)\n\\(\\{H, T\\}\\)\n\\(\\emptyset\\)\n\n \nWhen thinking about events, think about outcomes that you might be asking the probability of."
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-1-coin-13",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-1-coin-13",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "",
    "text": "Suppose you toss one coin.\n\nWhat are the possible outcomes?\n \nWhat is the sample space?\n \nWhat are the possible events?"
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-1-coin-23",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-1-coin-23",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "",
    "text": "Suppose you toss one coin.\n\nWhat are the possible outcomes?\n\nHeads (\\(H\\))\nTails (\\(T\\))\n\nNote: When something happens at random, such as a coin toss, there are several possible outcomes, and exactly one of the outcomes will occur."
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-1-coin-33",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-1-coin-33",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "",
    "text": "Definition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all possible outcomes.\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some possible outcomes.\n\n\n\n\nWhat is the sample space?\n\n\\(S = \\{H, T\\}\\)\n\nWhat are the possible events?\n\n\\(\\{H\\}\\)\n\\(\\{T\\}\\)\n\\(\\{H, T\\}\\)\n\\(\\emptyset\\)\n\n \nWhen thinking about events, think about outcomes that you might be asking the probability of."
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-2-coins",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#coin-toss-example-2-coins",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Coin Toss Example: 2 coins",
    "text": "Coin Toss Example: 2 coins\nSuppose you toss two coins.\n\nWhat is the sample space? Assume the coins are distinguishable\n\n\\(S =\\) \\[S = \\{HH, TT, HT, TH\\}\\]\n\nWhat are some possible events?\n\n\\(A\\) = exactly one \\(H\\) = \\(\\{HT, TH\\}\\)\n\\(B\\) = at least one \\(H\\) = \\(\\{HH, HT, TH\\}\\)"
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#more-info-on-events-and-sample-spaces",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#more-info-on-events-and-sample-spaces",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "More info on events and sample spaces",
    "text": "More info on events and sample spaces\n\nWe usually use capital letters from the beginning of the alphabet to denote events. However, other letters might be chosen to be more descriptive.\nWe use the notation \\(|S|\\) to denote the size of the sample space.\nThe total number of possible events is \\(2^{|S|}\\), which is the total number of possible subsets of \\(S\\). We will prove this later in the course.\nThe empty set, denoted by \\(\\emptyset\\), is the set containing no outcomes."
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#example-keep-sampling-until",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#example-keep-sampling-until",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Example: Keep sampling until…",
    "text": "Example: Keep sampling until…\nSuppose you keep sampling people until you have someone with high blood pressure (BP). What is the sample space?\n\nLet \\(H =\\) denote someone with high BP.\nLet \\(H^C =\\) denote someone with not high blood pressure, such as low or regular BP.\nThen, \\(S =\\)\n\n\\[S = \\{H, (H, H^C), (H, H, H^C), (H, H, H, H^C), \\ldots\\]"
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#set-theory-12",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#set-theory-12",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Set Theory (1/2)",
    "text": "Set Theory (1/2)\n\n\n\n\nDefinition: Union\n\n\nThe union of events \\(A\\) and \\(B\\), denoted by \\(A \\cup B\\), contains all outcomes that are in \\(A\\) or \\(B\\).\n\n\n\n\nDefinition: Intersection\n\n\nThe intersection of events \\(A\\) and \\(B\\), denoted by \\(A \\cap B\\), contains all outcomes that are both in \\(A\\) and \\(B\\).\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#set-theory-22",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#set-theory-22",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Set Theory (2/2)",
    "text": "Set Theory (2/2)\n\n\n\n\nDefinition: Complement\n\n\nThe complement of event \\(A\\), denoted by \\(A^C\\) or \\(A'\\), contains all outcomes in the sample space \\(S\\) that are not in \\(A\\) .\n\n\n\n\nDefinition: Mutually Exclusive\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive, or disjoint, if they have no outcomes in common. In this case \\(A \\cap B = \\emptyset\\), where \\(\\emptyset\\) is the empty set.\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#bp-example-variation-13",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#bp-example-variation-13",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "BP example variation (1/3)",
    "text": "BP example variation (1/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\nEvent all \\(n\\) subjects have high BP\nEvent at least one subject has high BP\nEvent all of them do not have high BP\nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#bp-example-variation-23",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#bp-example-variation-23",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "BP example variation (2/3)",
    "text": "BP example variation (2/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\n\\[H_i^C\\]\nEvent all \\(n\\) subjects have high BP\n\\[H_1 \\textrm{ and } H_2 \\textrm{ and } \\ldots = \\bigcap\\limits_{i=1}^{n}H_i\\]\nEvent at least one subject has high BP\n\\[H_1 \\textrm{ or } H_2 \\textrm{ or } \\ldots = \\bigcup\\limits_{i=1}^{n}H_i\\]"
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#bp-example-variation-33",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#bp-example-variation-33",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "BP example variation (3/3)",
    "text": "BP example variation (3/3)\n\nEvent all of them do not have high BP\n\\(H_1^C\\) and \\(H_2^C\\) and... \\[\\bigcap\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcup\\limits_{i=1}^{n}H_i\\Big)^C\\] = complement of at least one person having high BP\nEvent at least one subject does not have high BP\n\\(H_1^C\\) or \\(H_2^C\\) or... \\[\\bigcup\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}H_i\\Big)^C\\] = complement of all having high BP"
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#de-morgans-laws",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#de-morgans-laws",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "De Morgan’s Laws",
    "text": "De Morgan’s Laws\n\n\nTheorem: De Morgan’s 1st Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcap\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcup\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“all not A = \\((\\)at least one event A\\()^C\\)”\n\n\nTheorem: De Morgan’s 2nd Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcup\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“at least one event not A = \\((\\)all A\\()^C\\)”"
  },
  {
    "objectID": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#remarks-on-de-morgans-laws",
    "href": "slides_solns/1_Outcomes_Events_Sample_space-solutions.html#remarks-on-de-morgans-laws",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Remarks on De Morgan’s Laws",
    "text": "Remarks on De Morgan’s Laws\n\nThese laws also hold for infinite collections of events.\nDraw Venn diagrams to convince yourself that these are true!\nThese laws are very useful when calculating probabilities.\n\nThis is because calculating the probability of the intersection of events is often much easier than the union of events.\nThis is not obvious right now, but we will see in the coming chapters why."
  },
  {
    "objectID": "slides/2_Probability.html",
    "href": "slides/2_Probability.html",
    "title": "Chapter 2: Probability",
    "section": "",
    "text": "Example 1\n\n\nSuppose you have a regular well-shuffled deck of cards. What’s the probability of drawing:\n\nany heart\nthe queen of hearts\nany queen\n\n\n\n\n\n\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}.\\]\n\n\n\n\\(\\mathbb{P}(A)\\) is a function with\n\nInput: event \\(A\\) from the sample space \\(S\\), (\\(A \\subseteq S\\))\nOutput: a number between 0 and 1 (inclusive)\n\n\\[\\mathbb{P}(A): S \\rightarrow [0,1]\\]\nA function that follows some specific rules though!\n \nSee Probability Axioms on next slide."
  },
  {
    "objectID": "slides/0_Intro.html#lets-visit-the-website",
    "href": "slides/0_Intro.html#lets-visit-the-website",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website",
    "text": "Let’s visit the website\n\nHomepage\n\nGitHub\n\nSyllabus\nSchedule\n\nWeeks, class info, exams, homeworks\n\nSearch\n\n\n\nImportant Note\n\n\nThis is my first time teaching the course. I will work hard to answer your questions in class, but I will often need some time outside of class to make sure I give you the best answer possible! Also, many of the examples are not my own. I will work to improve examples, but if you have feedback or suggestions, I am happy to hear them!"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html",
    "href": "slides/1_Outcomes_Events_Sample.html",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "",
    "text": "Suppose you toss one coin.\n\nWhat are the possible outcomes?\n \nWhat is the sample space?\n \nWhat are the possible events?\n\n\n\n\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n\nHeads (\\(H\\))\nTails (\\(T\\))\n\n\n \n\n\nNote\n\n\nWhen something happens at random, such as a coin toss, there are several possible outcomes, and exactly one of the outcomes will occur.\n\n\n\n\n\n\n\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all outcomes\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some outcomes. An event can include multiple outcomes or no outcomes.\n\n\n\n\nWhat is the sample space?\n\n\\(S =\\)\n\n\n \n\nWhat are the possible events?\n\n\n\n\n\n\n \nWhen thinking about events, think about outcomes that you might be asking the probability of."
  },
  {
    "objectID": "homework/HW1.html#directions",
    "href": "homework/HW1.html#directions",
    "title": "Homework 1",
    "section": "Directions",
    "text": "Directions\n\nPlease upload your homework to Sakai. Upload both your .Rmd code file and the knitted .html file.\nFor each question, make sure to include all code and resulting output in the html file to support your answers.\nShow the work of your calculations using R code within a code chunk. Make sure that both your code and output are visible in the knitted html file.\nWrite all answers in complete sentences as if communicating the results to a collaborator.\n\n\n\n\n\n\n\nTip\n\n\n\nIt is a good idea to try rendering your document from time to time as you go along! Note that rendering automatically saves your qmd file and rendering frequently helps you catch your errors more quickly."
  },
  {
    "objectID": "schedule/week_01_sched.html#why-is-the-number-of-possible-events-2s",
    "href": "schedule/week_01_sched.html#why-is-the-number-of-possible-events-2s",
    "title": "Week 1",
    "section": "Why is the number of possible events \\(2^{|S|}\\)?",
    "text": "Why is the number of possible events \\(2^{|S|}\\)?"
  },
  {
    "objectID": "weekly_pages/week_01_sched.html#resources",
    "href": "weekly_pages/week_01_sched.html#resources",
    "title": "Week 1",
    "section": "Resources",
    "text": "Resources\nBelow is a table with links to resources. Icons in orange mean there is an available file link.\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording(s)\n\n\n\n\n\nIntro\n\n\n\n\n\n1\nOutcomes, Events, and Sample Space\n\n\n\n\n\n2\nProbability\n\n\n\n\n\n22\nIntroduction to Counting\n\n\n\n\n\n23\nCase Study on Counting\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "weekly_pages/week_01_sched.html#on-the-horizon",
    "href": "weekly_pages/week_01_sched.html#on-the-horizon",
    "title": "Week 1",
    "section": "On the Horizon",
    "text": "On the Horizon\n\nHomework 0 due 9/28\nHomework 1 due 10/5"
  },
  {
    "objectID": "weekly_pages/week_01_sched.html#class-exit-tickets",
    "href": "weekly_pages/week_01_sched.html#class-exit-tickets",
    "title": "Week 1",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (9/25)\n Wednesday (9/27)"
  },
  {
    "objectID": "weekly_pages/week_01_sched.html#additional-information",
    "href": "weekly_pages/week_01_sched.html#additional-information",
    "title": "Week 1",
    "section": "Additional Information",
    "text": "Additional Information\nAs we start the course, here are some administrative items that we need to do:\n\nPlease join the Slack page\nPlease read the syllabus on your own time\n\n\nExtra Practice/Learning\n\nIf you would like a Calculus review, please see this page!\nCombinatorics practice problems\n\nhandout (& answers)\nTry to complete as many of these as you can before class on Wednesday.\nWe will discuss some of them Wednesday in class.\n\nPixar has a series of videos explaining how they use combinatorics in making animations\n\nThis is a great & fun introduction to the basic principles of counting\nI highly recommend looking at them, especially if you have not studied permutations and combinations before.\n\nThere is a table on p. 277 of the book with formulas for 4 different common counting cases (does order matter (y/n) vs. sampling with replacement (y/n).\n\nIn class we covered all cases except “order does not matter and sampling with replacement.”\n\nThis case is often referred to as the “stars and bars” problem.\nSee this page for a proof to the Stars and Bars Theorem.\n\nNote: Their notation is opposite of what our textbook uses. The website uses k instead of n and n instead of r."
  },
  {
    "objectID": "weekly_pages/week_01_sched.html#statistician-of-the-week-regina-nuzzo",
    "href": "weekly_pages/week_01_sched.html#statistician-of-the-week-regina-nuzzo",
    "title": "Week 1",
    "section": "Statistician of the Week: Regina Nuzzo",
    "text": "Statistician of the Week: Regina Nuzzo\n\n\n\n\n\n\n\nRegina Nuzzo\n\n\n\n\n\n\nDr. Nuzzo received her PhD in Statistics from Stanford University and is now Professor of Science, Technology, & Mathematics at Gallaudet University. Gallaudet University, federally funded and located in Washington, DC, is the only higher education institution where all programs are designed for the education of the deaf and hard of hearing. Dr. Nuzzo teaches statistics using American Sign Language.\nShe is the Senior Advisor for Statistics Communication and Media Innovation at the American Statistical Association and a freelance writer.\n\n\n\nTopics covered\nDr. Nuzzo is a statistician and a science journalist. Her work has appeared in Nature, Los Angeles Times, New York Times, Reader’s Digest, New Scientist, and Scientific American. Most of her work is in the “Health” or “Science” sections of the aforementioned outlets. Primarily, she works to help lay-audiences understand science and statistics in particular. She earned the American Statistical Association’s 2014 Excellence in Statistical Reporting Award for her article on p-values in Nature. Her work led to the ASA’s statement on p-values.\n\n\nRelevant work\n\nNuzzo, R. “Scientific method: Statistical errors.” Nature 506, 150–152 (2014).\nNuzzo, R. “Tips for Communicating Statistical Significance.” Science, Health, and Public Trust, National Institutes of Health, 2018.\nNuzzo, R. “Vying for a soul mate? Psych out the competition with science.” Health: Features. Los Angeles Times, 2008.\n\n\n\nOutside links\n\nWikipedia\nacademic\nLinkedin\npersonal\n\nPlease note the statisticians of the week are taken directly from the CURV project by Jo Hardin. I also invite you to check out this youtube video of her Women Rise Keynote address where she discusses her hearing impairment, career growth, and her work with p-values."
  },
  {
    "objectID": "weekly_pages/week_01_sched.html#muddiest-points",
    "href": "weekly_pages/week_01_sched.html#muddiest-points",
    "title": "Week 1",
    "section": "Muddiest Points",
    "text": "Muddiest Points\n\n1. Why is the number of possible events \\(2^{|S|}\\)?\nIn class, we were wondering why/if \\(2^{|S|}\\) is the general formula for calculating the total number of possible events. We were specifically wondering if the \\(2\\) came from the fact that we had two options (heads and tails) for our outcome. Let’s work through the example of a 6-sided die to explain this further. The sample space is \\(S=\\{1, 2, 3, 4, 5, 6\\}\\). So is the total number of possible events \\(2^6\\) or \\(6^6\\) or something else? We can actually think about an event by using an indicator variable for each outcome of the sample space. An indicator variable is just a way to give us a yes/no answer to a question. So in this case, we are wondering: is this outcome a part of our event? If our event is \\(\\{1\\}\\) then for the outcome \\(1\\), the answer is “yes, the outcome is part of the event. For outcomes \\(2-6\\), the answer is”no, the outcome is not apart of the event.”\n\nFor each outcome, we have a “yes” or “no” answer. We can look at another example of an event. Let’s say our event is rolling an even number:\n\nFor \\(2\\), \\(4\\), and \\(6\\), the answer is “yes.” We can define the indicator variable for whether an outcome is in an event or not. The indicator gives a 1 or 0 for yes and no respectively.\n\nAs stated above, the \\(2\\) in \\(2^6\\) comes from the \\(2\\) options from our indicator. Each side has two options, and there are \\(6\\) sides. Thus, \\(2^6\\) possible events.\n\n\n2. What is an event??\nI think this will become clearer when we start thinking about events in the context of probability. When we think of events outside of probability, we may think of something we actually do or something that happens, like going to a concert or coming to class or missing the streetcar. In this case, we think of the event as the single thing (out of all the options) that actually occured. For example, if I’m taking the streetcar to class, I can think of two definitive options of what might occur: I miss the streetcar or I get on the streetcar. Only one of these things can occur, which I may call an event colloquially.\nIt is important to make the distinction with events defined within probability. Events are not necessarily a single thing that occurred. Instead it can be a collection of things that may occur. In the example of the streetcar, I can define my event to include both options. Thus, my event is that I make the streetcar or I miss it. Both of these things cannot happen simultaneously, but if I want to calculate the probability that I miss or make the streetcar, then it is helpful to have the event defined."
  },
  {
    "objectID": "weekly_pages/week_01_sched.html#clearest-points",
    "href": "weekly_pages/week_01_sched.html#clearest-points",
    "title": "Week 1",
    "section": "Clearest Points",
    "text": "Clearest Points\nMostly: heads/tails example, sample space, how to draw a quarter, possible events for two coins."
  },
  {
    "objectID": "weeks/week_01_sched.html#resources",
    "href": "weeks/week_01_sched.html#resources",
    "title": "Week 1",
    "section": "Resources",
    "text": "Resources\nBelow is a table with links to resources. Icons in orange mean there is an available file link.\n\n\n\nLesson\nTopic\nSlides\nAnnotated Slides\nRecording(s)\n\n\n\n\n\nIntro\n\n\n\n\n\n1\nReview\n\n\n\n\n\n\n2\nData Management\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser.\n\nFor example, in Chrome: I would click on the 3 vertical dots in the top right corner, then click Print, then change the Destination to “Save as PDF.”\nIt doesn’t seem to work well in Safari… Let me know if you’re having trouble.\n\n\nHere is the link to my Poll Everywhere!!"
  },
  {
    "objectID": "weeks/week_01_sched.html#on-the-horizon",
    "href": "weeks/week_01_sched.html#on-the-horizon",
    "title": "Week 1",
    "section": "On the Horizon",
    "text": "On the Horizon\n\nHomework 0 due 1/11"
  },
  {
    "objectID": "weeks/week_01_sched.html#class-exit-tickets",
    "href": "weeks/week_01_sched.html#class-exit-tickets",
    "title": "Week 1",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (1/8)\n Wednesday (1/10)"
  },
  {
    "objectID": "weeks/week_01_sched.html#additional-information",
    "href": "weeks/week_01_sched.html#additional-information",
    "title": "Week 1",
    "section": "Additional Information",
    "text": "Additional Information\nAs we start the course, here are some administrative items that we need to do:\n\nPlease join the Slack page\nPlease read the syllabus on your own time"
  },
  {
    "objectID": "weeks/week_01_sched.html#statistician-of-the-week-regina-nuzzo",
    "href": "weeks/week_01_sched.html#statistician-of-the-week-regina-nuzzo",
    "title": "Week 1",
    "section": "Statistician of the Week: Regina Nuzzo",
    "text": "Statistician of the Week: Regina Nuzzo\n\n\n\n\n\n\n\nRegina Nuzzo\n\n\n\n\n\n\nDr. Nuzzo received her PhD in Statistics from Stanford University and is now Professor of Science, Technology, & Mathematics at Gallaudet University. Gallaudet University, federally funded and located in Washington, DC, is the only higher education institution where all programs are designed for the education of the deaf and hard of hearing. Dr. Nuzzo teaches statistics using American Sign Language.\nShe is the Senior Advisor for Statistics Communication and Media Innovation at the American Statistical Association and a freelance writer.\n\n\n\nTopics covered\nDr. Nuzzo is a statistician and a science journalist. Her work has appeared in Nature, Los Angeles Times, New York Times, Reader’s Digest, New Scientist, and Scientific American. Most of her work is in the “Health” or “Science” sections of the aforementioned outlets. Primarily, she works to help lay-audiences understand science and statistics in particular. She earned the American Statistical Association’s 2014 Excellence in Statistical Reporting Award for her article on p-values in Nature. Her work led to the ASA’s statement on p-values.\n\n\nRelevant work\n\nNuzzo, R. “Scientific method: Statistical errors.” Nature 506, 150–152 (2014).\nNuzzo, R. “Tips for Communicating Statistical Significance.” Science, Health, and Public Trust, National Institutes of Health, 2018.\nNuzzo, R. “Vying for a soul mate? Psych out the competition with science.” Health: Features. Los Angeles Times, 2008.\n\n\n\nOutside links\n\nWikipedia\nacademic\nLinkedin\npersonal\n\nPlease note the statisticians of the week are taken directly from the CURV project by Jo Hardin. I also invite you to check out this youtube video of her Women Rise Keynote address where she discusses her hearing impairment, career growth, and her work with p-values."
  },
  {
    "objectID": "weeks/week_01_sched.html#muddiest-points",
    "href": "weeks/week_01_sched.html#muddiest-points",
    "title": "Week 1",
    "section": "Muddiest Points",
    "text": "Muddiest Points\n\n1. Relationship between distributions\nJust to clarify! We will be using the distributions in the context of hypothesis testing. I just wanted you to see some of the cool connections between the distributions. (We don’t need to know the connections for a lot of what we do in this class.)\nAlso, I will discuss each distribution again as we hit the hypothesis tests that use them!\nThere is a big, scary (but fun!) infographic at the end of a famous stat textbook (Casella and Berger) that shows all the connections between distributions:\n\nWe mostly talk about the red, circled area. Each line with the directional arrow represents a specific transformation that is needed to go from the starting distribution to the distribution at the end of the arrow.\nAgain, this is NOT information we need to perform regression, but it is really interesting to see the connections between these distributions.\n\n\n2. A word about the distributions\nI feel like I might’ve scared us with all the distribution talk.\nI want to be clear: We will further discuss and explore the distributions as we use them within the course. It will be more important to understand their use within regression then knowing the distribution in depth. Basically, when we implement specific hypothesis tests, we just need to know which distribution is most appropriate for the test.\n\n\n3. Is the F distribution used for things outside of ANOVA?\nYes! In regression, we often use the F-distribution through the F-test (same as ANOVA) However, in regression, we are comparing the variance of two models, that may differ by a coefficient. See the STAT 501 page for more info if interested. In ANOVA, we are comparing variance between and within groups. Both use the same test, but with different goals!\n\n\n4. Multivariable vs multivariate?\nSome people misuse “multivariate” instead of “multivariable” modeling. In this class, we will only look at multivariable regression. Here’s the big difference:\n\nMultivariable: model with multiple independent variables (covariates, predictors)\n\nIf we want to see how our outcome (height) is related to parent height, birth country, sex assigned at birth, etc.\n\nMultivariate: model with multiple dependent variables (outcome)\n\nIf we want to extend the outcome from height to height and head circumference. Multivariate modeling would try to model both outcomes together and see how they are related to other variables.\n\n\n\n\n5. More on the functions and problems we had in class!\n\nmutate()\ncoming soon\n\n\npipe %&gt;%\ncoming soon\n\n\nselect() everything but a certain variable\ncoming soon\n\n\npivot_longer() the negative sign that appears before variables that you’re managing in pivot_longer and one other time\ncoming soon\n\n\nacross()\ncoming soon\n\n\ntbl_summary(): Trying to figure out how to change the median values to mean\nOh, wow! Turns out we solved it in class, but I made big mistake with my slides. The code for the table was in two places, but we fixed the one that was NOT running and showing on the slide!\nSo turns out, it worked!!\nHere’s the code:\n\nlibrary(tidyverse)  ## Need to load to use selec() and %&gt;%\nlibrary(gtsummary)  ## Needed package for tbl_summary()\n\ndata(\"dds.discr\")\n\ndds.discr1 = dds.discr %&gt;% \n  rename(SAB = gender, \n         R_E = ethnicity)\n\ndds.discr1 %&gt;%\n  select(-id, -age.cohort) %&gt;%\n  tbl_summary(label = c(age ~ \"Age\", \n                        R_E ~ \"Race/Ethnicity\", \n                        SAB ~ \"Sex Assigned at Birth\", \n                        expenditures ~ \"Expenditures\") ,\n              statistic = list(all_continuous() ~ \"{mean} ({sd})\"))\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 1,0001\n    \n  \n  \n    Age\n23 (18)\n    Sex Assigned at Birth\n\n        Female\n503 (50%)\n        Male\n497 (50%)\n    Expenditures\n18,066 (19,543)\n    Race/Ethnicity\n\n        American Indian\n4 (0.4%)\n        Asian\n129 (13%)\n        Black\n59 (5.9%)\n        Hispanic\n376 (38%)\n        Multi Race\n26 (2.6%)\n        Native Hawaiian\n3 (0.3%)\n        Other\n2 (0.2%)\n        White not Hispanic\n401 (40%)\n  \n  \n  \n    \n      1 Mean (SD); n (%)\n    \n  \n\n\n\n\n\n\n\n6. Are there benefits to ggplot compared to the base R graphing functions?\nThe main benefit I see for ggplot is that the syntax and grammar of our coding in tidyr and dplyr is very similar to ggplot. Your effort in strengthening one will help with the others.\nI am certainly not going to force you to use ggplot over base R. At the end of the day, it is really whatever makes the most sense to you. I will say: ggplot2 seems to be where most statisticians and epidemiologists are headed. And I really believe that ggplot is more efficient with coding."
  },
  {
    "objectID": "weeks/week_01_sched.html#clearest-points",
    "href": "weeks/week_01_sched.html#clearest-points",
    "title": "Week 1",
    "section": "Clearest Points",
    "text": "Clearest Points\nMostly: heads/tails example, sample space, how to draw a quarter, possible events for two coins."
  },
  {
    "objectID": "weeks/week_02_sched.html#resources",
    "href": "weeks/week_02_sched.html#resources",
    "title": "Week 2",
    "section": "Resources",
    "text": "Resources\nTopics for SLR:\n\nassumptions\n\n\n\nparameter estimation and interpretation\nproperties of LSE\nestimation of variance?\n\n\n\n\n\n\n\n\n\n\n\n\nLesson\nTopic\nReadings\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n3\nSimple Linear Regression\n\n\n\n\n\n\n4\n\n\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "weeks/week_02_sched.html#on-the-horizon",
    "href": "weeks/week_02_sched.html#on-the-horizon",
    "title": "Week 2",
    "section": "On the Horizon",
    "text": "On the Horizon\n\nHomework 1 due 10/5"
  },
  {
    "objectID": "weeks/week_02_sched.html#class-exit-tickets",
    "href": "weeks/week_02_sched.html#class-exit-tickets",
    "title": "Week 2",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (10/2)\n Wednesday (10/4)"
  },
  {
    "objectID": "weeks/week_02_sched.html#additional-information",
    "href": "weeks/week_02_sched.html#additional-information",
    "title": "Week 2",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "weeks/week_02_sched.html#statistician-of-the-week-talithia-williams",
    "href": "weeks/week_02_sched.html#statistician-of-the-week-talithia-williams",
    "title": "Week 2",
    "section": "Statistician of the Week: Talithia Williams",
    "text": "Statistician of the Week: Talithia Williams\n\n\n\n\n\n\n\nTalithia Williams\n\n\n\n\n\n\nDr. Williams earned a BS in Mathematics from Spelman College, an MS in Mathematics from Howard University, and a PhD (2008) in Statistics from Rice University. Dr. Williams is Associate Professor and Director of the Clinic Program at Harvey Mudd College. She has also served as Associate Dean for Faculty Development and Diversity at Harvey Mudd.\n\n\n\nTopics covered\nDr. Williams works on statistical models which describe spatial and temporal aspects of data. Some of her most important work has focused on developing models to predict cataract surgical rates for countries in Africa.\n\n\nRelevant work\n\nDray, A. and Williams, T. An incidence estimation model for multi-stage diseases with differential mortality. Statistics in Medicine, 2012.\nLewallen, S., Courtright, P., Etya’ale, D., Mathenge, W., Schmidt, E., Oye, J., Clark, A., Williams, T. Cataract Incidence in Sub-Saharan Africa: What does Mathematical Modeling tell us about Geographic Variations and Surgical Needs?. Ophthalmic epidemiology, 2013.\n\n\n\nOutside links\n\nWikipedia\nMAD\nLinkedin\npersonal\n\n\n\nOther\nDr. Williams was the co-host of the 2018 PBS Nova Wonders series.\nPlease note the statisticians of the week are taken directly from the CURV project by Jo Hardin."
  },
  {
    "objectID": "weeks/week_02_sched.html#muddiest-points",
    "href": "weeks/week_02_sched.html#muddiest-points",
    "title": "Week 2",
    "section": "Muddiest Points",
    "text": "Muddiest Points\n\ng=3"
  },
  {
    "objectID": "weeks/week_02_sched.html#clearest-points",
    "href": "weeks/week_02_sched.html#clearest-points",
    "title": "Week 2",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_04_sched.html#resources",
    "href": "weeks/week_04_sched.html#resources",
    "title": "Week 4",
    "section": "Resources",
    "text": "Resources\nTopics:\n\nSLR vs MLR\ninterpreting model parameters\nmatrix representation\nparameter estimation (OLS)\nproperties of estimators\nsums of squares\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n9\nIndependence and Conditioning (Joint Distributions)\n\n\n\n\n\n10\nExpected Values of discrete RVs\n\n\n\n\n\n11\nExpected Values of sums of discrete RVs\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "weeks/week_04_sched.html#on-the-horizon",
    "href": "weeks/week_04_sched.html#on-the-horizon",
    "title": "Week 4",
    "section": "On the Horizon",
    "text": "On the Horizon\n\nHomework 3 due 10/19 at 11pm\nVirtual Class 10/25\nMidterm 11/1 (in class)"
  },
  {
    "objectID": "weeks/week_04_sched.html#class-exit-tickets",
    "href": "weeks/week_04_sched.html#class-exit-tickets",
    "title": "Week 4",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (10/16) Question about course set up\n Wednesday (10/18)"
  },
  {
    "objectID": "weeks/week_04_sched.html#additional-information",
    "href": "weeks/week_04_sched.html#additional-information",
    "title": "Week 4",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "weeks/week_04_sched.html#statistician-of-the-week-joy-buolamwini",
    "href": "weeks/week_04_sched.html#statistician-of-the-week-joy-buolamwini",
    "title": "Week 4",
    "section": "Statistician of the Week: Joy Buolamwini",
    "text": "Statistician of the Week: Joy Buolamwini\n\n\n\n\n\n\n\nJoy Buolamwini\n\n\n\n\n\n\nDr. Buolamwini earned a BS in Computer Science from Georgia Institute of Technology, an Master’s from University of Oxford, and MS and PhD (2022) degrees in Media Arts & Sciences from Massachusetts Institute of Technology. While a graduate student, Dr. Buolamwini was part of the MIT Media Lab. Additionally, she is the founder of the Algorithmic Justice League.\n\n\n\nTopics covered\nDr. Buolamwini has done substantial work demonstrating how algorithms can encode bias. Her undergraduate senior project was to create a inspired “mask” mirror as a way to raise spirits for the person who looked into the mirror. The project relied on off the shelf facial recognition software that could not recognize Dr. Buolamwini’s face.\nSince then, she has focused her work on demonstrating bias across racial and gender spectra in off the shelf software. Her work has been cited as directly influencing Microsoft and Google’s changes to their algorithms.\nAmong many other aspects, a big focus of Dr. Buolamwini’s work is pointing out the biased data which directly impacts how algorithms learn how to do tasks.\n\n\nRelevant work\n\nBuolamwini, J., Gebru, T. Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. Proceedings of Machine Learning Research 81:1–15, 2018 Conference on Fairness, Accountability, and Transparency.\nRaji, I & Buolamwini, J. Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products. Conference on Artificial Intelligence, Ethics, and Society, 2019\n\n\n\nOutside links\n\nWikipedia\nLinkedin\npersonal\n\n\n\nOther\nDr. Buolamwini has done a lot of work on how data propagates through systems to encode the same types of bias into different algorithms. In her video AI, Ain’t I a Woman? she demonstrates how systems designed to determine gender are particularly poor when using dark skinned faces.\nHer work was featured in a recent documentary Coded Bias.\nPlease note the statisticians of the week are taken directly from the CURV project by Jo Hardin."
  },
  {
    "objectID": "weeks/week_04_sched.html#muddiest-points",
    "href": "weeks/week_04_sched.html#muddiest-points",
    "title": "Week 4",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_04_sched.html#clearest-points",
    "href": "weeks/week_04_sched.html#clearest-points",
    "title": "Week 4",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_03_sched.html#resources",
    "href": "weeks/week_03_sched.html#resources",
    "title": "Week 3",
    "section": "Resources",
    "text": "Resources\nTopics:\n\nhypothesis testing\n\nslope\nintercept\n\nsums of squares (ANOVA table?)\ncoefficient of determination\nF test: overall fit\n\nBelow is a table with links to resources. Icons in orange mean there is an available file link.\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n5\nBayes’ Theorem\n\n\n \n\n\n7\nRandom Variables\n\n\n\n\n\n8\npmf’s and CDFs\n\n\n\n\n\n9\nIndependence and Conditioning (Joint Distributions)\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "weeks/week_03_sched.html#on-the-horizon",
    "href": "weeks/week_03_sched.html#on-the-horizon",
    "title": "Week 3",
    "section": "On the Horizon",
    "text": "On the Horizon\n\nHomework 2 due 10/12\nBiostatistics Group Mentoring Session: 10/12\n\nLet me know if you need an extension of HW 2 because of this"
  },
  {
    "objectID": "weeks/week_03_sched.html#class-exit-tickets",
    "href": "weeks/week_03_sched.html#class-exit-tickets",
    "title": "Week 3",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (10/9)\n Wednesday (10/11)"
  },
  {
    "objectID": "weeks/week_03_sched.html#additional-information",
    "href": "weeks/week_03_sched.html#additional-information",
    "title": "Week 3",
    "section": "Additional Information",
    "text": "Additional Information\n\nAnnouncements for 10/9\n\nHomework 1 solutions are posted!\n\n\n\nAnnouncements for 10/11\n\nHomework 1 released! Here are some overarching notes:\n\nIf you start with “the probability that …” you must end with a value between 0 and 1.\n\nIf you start with “the percent chance…” then you can have a value between 0% and 100%\n\n\\(P(A)\\) is not the same as probability of A only. Event A can overlap with B and C, so we need to find the part of A that does not overlap with B and C\n\nHence we get \\(P(A \\cap B^c \\cap C^c)\\)\n\n\nGroup advising tomorrow at 5pm in Vanport 515!\n\nIf you can’t get in, you can also Slack me\n\nRising Voices Retreat"
  },
  {
    "objectID": "weeks/week_03_sched.html#statistician-of-the-week-david-blackwell",
    "href": "weeks/week_03_sched.html#statistician-of-the-week-david-blackwell",
    "title": "Week 3",
    "section": "Statistician of the Week: David Blackwell",
    "text": "Statistician of the Week: David Blackwell\n\n\n\n\n\n\n\nDavid Blackwell\n\n\n\n\n\n\nBlackwell was the first black person to receive a PhD in statistics (from University of Illinois at Urbana-Champaign, in 1941 at the age of 22) in the US and the first black scholar to be admitted to the National Academy of Sciences. He was a statistician at UC Berkeley for more than 50 years. He was hired in 1954 after the department almost made him an offer in 1942 (but declined to do so when one faculty member’s wife said she didn’t want Blackwell hired because she wouldn’t feel comfortable having faculty events in her home with a black man). Hear Blackwell tell the story in his own words.\n\n\n\nTopics covered\nBlackwell contributed to game theory, probability theory, information science, and Bayesian statistics. The Rao-Blackwell theorem (you’ll likely see it in BSTA 551) is named after him.\n\n\nRelevant work\n\nBlackwell, D. (1947). “Conditional expectation and unbiased sequential estimation”. Annals of Mathematical Statistics. 18 (1): 105–110. doi:10.1214/aoms/1177730497.\n\n\n\nOutside links\n\nWikipedia\nMAD\n\nPlease note the statisticians of the week are taken directly from the CURV project by Jo Hardin."
  },
  {
    "objectID": "weeks/week_03_sched.html#muddiest-points",
    "href": "weeks/week_03_sched.html#muddiest-points",
    "title": "Week 3",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nI am still working on these! Trying to go through them by end of day 10/11\n\n1. Breast Cancer Example with Bayes Theorem\n\n\n2. Random Variables??\nHow are they functions? Why are they random? Why do we need them?\n\nBasically quantifying the random outcome\n\nWe can calculate probabilities more easily with RVs and we can use easier math notation\n\nStill random because each value that the random variable takes is with a specific probability (not a certainty)\n\nSo the “random” part of random variable comes from the outcome in a random process and that randomness carries through to the RV\n\nSince the RV is a function of a random process: it is dependent on the probability space\n\nSo the function itself is deterministic, BUT each outcome of the function still holds a specific probability\n\nThe function part is essential for later manipulations of the RV\n\nWe will start taking derivatives and integrals of the RVs (especially important for continuous RVs)\nWithout a way to represent the probability as a overarching function, it is much harder to calculate derivatives and integrals\n\n\n\n\n3. Why is is incorrect to say \\(\\omega \\geq 5\\) in our defined household random variable? And incorrect to say \\(x \\geq 5\\) in the pmf? And why can we use inequalities, like \\(3 \\leq x &lt; 4\\), in our CDF?\nRandom variable part: \\[X(\\omega)= \\left\\{\n        \\begin{array}{ll}\n            \\omega & \\quad \\omega=1, 2, 3, 4\\\\\n            5+ & \\quad \\omega = 5, 6, 7, ...\n        \\end{array}\n    \\right.\\]\n\nWhy can’t we say \\(\\omega \\geq 5\\)? If values \\(5, 6, 7, …\\) are the only values greater than \\(5\\) that are defined in the sample space, doesn’t \\(\\omega \\geq 5\\) mean the same thing as \\(\\omega = 5, 6, 7, ...\\)?\n\nSince a number like 5.5 is not possible within our sample space,\n\n\nHere is the pmf for our household example: \\[p_X(x)= \\left\\{\n        \\begin{array}{ll}\n            0.28 & \\quad x = 1\\\\\n            0.35 & \\quad x = 2\\\\\n            0.15 & \\quad x = 3\\\\\n            0.13 & \\quad x = 4\\\\\n            0.09 & \\quad x = 5+ \\\\\n            0    & \\quad \\text{otherwise}\n        \\end{array}\n    \\right.\\]\n\nWhen it comes to the pmf, we cannot use \\(x \\geq 5\\) or \\(1 \\leq x &lt; 2\\) instead of \\(x=5+\\) or \\(x=1\\) because \\(x \\geq 5\\) and \\(1 \\leq x &lt; 2\\) implies values like \\(x=1.3\\) and \\(x=200.01\\) will have a non-zero probability. Both of those values are included in the “otherwise” portion of the pmf, and have a probability of \\(0\\).\n\nHere is the CDF for our household example: \\[F_X(x)= \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt; 1\\\\\n            0.28 & \\quad 1 \\leq x &lt; 2\\\\\n            0.63 & \\quad 2 \\leq x &lt; 3\\\\\n            0.78 & \\quad 3 \\leq x &lt; 4\\\\\n            0.91 & \\quad 4 \\leq x &lt; 5 \\\\\n            1   & \\quad x \\geq 5\n        \\end{array}\n    \\right.\\]\n\nFor the CDF, when we calculate \\(F_X(x=1.3)\\), for a discrete RV, there is no difference between \\(F_X(x=1.3)\\) and \\(F_X(x=1)\\). \\(F_X(x=1)\\) certainly feels more appropriate because \\(x=1\\) and \\(p_X(1)\\) is explicitly defined in our pmf. However, \\(p_X(1.3)\\) is also defined in our pmf. It falls under the “otherwise” category. Thus, \\(p_X(1.3) = 0\\) and for every value \\(1 &lt; x &lt; 2\\) the probability is \\(0\\). So for \\(1 &lt; x &lt; 2\\), there is no additional probability added into the CDF. Thus, \\(F_X(x)\\) for \\(1 &lt; x &lt; 2\\) is the same as \\(F_X(1) = 0.28\\).\n\n\n\n4. What is CDF? And what is it good for?\n\nWhat is the purpose of the CDF?\n\nOne purpose of the CDF is to calculate the probability of intervals of \\(x\\). For example, if we want to calculate the probability that some random variable \\(x\\) is between 30 and 35, we can say the probability is \\(P(30 \\leq x \\leq 35)\\). An easy way to calculate this is to find the difference between the two CDFs (\\(F_X(35) - F_X(30)\\)). We’ll see more about it in later chapters. It’s particularly helpful for continuous random variables.\nThe CDF starts to become very useful when we start discussing how certain we are of an observation (aka how much do we trust that an observation is coming from our prescribed distribution). Let’s say we tossed 50 fair coins. While the observation of 49 heads is possible, the probability is very small. And the probability that we get 49 or more heads is 0.000000000000045.\n\n\n\n# Here I am using pbinom() to calculate the cumulative probability that I toss 49 \n#   or more heads (q = 48) out of the 50 coins I tossed (size = 50) when the \n#   probability of heads is 0.5 (prob = 0.5). pbinom() automatically calculates \n#   the probability that we have 49 or less heads, so the \"lower.tail = F\" gives \n#   us the probability that we get 49 or more heads.\npbinom(q = 48, size = 50, prob = 0.5, lower.tail = F)\n\n[1] 4.52971e-14\n\n\n\n\nWhy did I use q=48 instead of q=49 for \\(49\\) or more heads. If you type ?dbinom in your console in R, a Help tab will open. It will tell you that when lower.tail=F we are calculating \\(P(X&gt;x)\\), but we want the probability to include \\(49\\), so we put \\(48\\). Note, this will be different when we get to continuous functions.\n\nThis probability may lead us to question whether the observed 49 heads really came from a fair coin. Maybe the probability that any given toss lands on heads is 0.99. What would the probability of 49 or more heads be then?\n\n\n# Here I am using pbinom() to calculate the cumulative probability that I toss 49 \n#   or more heads (q = 48) out of the 50 coins I tossed (size = 50) when the \n#   probability of heads is 0.99 (prob = 0.99).\npbinom(q = 48, size = 50, prob = 0.99, lower.tail = F)\n\n[1] 0.9105647\n\n\n\nNow the probability of getting 49 or more heads is 0.91. Pretty high! And I might be more inclined to believe my observation was from this unfair coin.\nThe cumulative probability gives us a sense of where in the distribution does an observation (like 49 heads) fall. Is it on the fringe? Or more centered within the probability density? This will definitely be clearer when we discuss continuous RVs.\n\n\n\n\nWhat does it mean if the CDF is 1?\nFor example, in the household problem the CDF for 5 or more individuals is 1 (\\(F_x(5+)=1\\)). This means the probability that households have \\(5+\\) individuals or less (so the probability that a household has 1, 2, 3, 4, or 5+ individuals) is 1.\n\n\n\n5. What’s up with the subtle changes in notation?\n\nWhat’s the difference between \\(X(\\omega)\\) and \\(x\\)?\n\nIn class we defined \\(X(\\omega) = x\\). We call \\(X(\\omega)\\) or \\(X\\) the random variable and \\(x\\) the realized value of that random variable.\nFor example: If I roll 20 dice, what is the number of dice that come up with 6?\n\n\\(X\\) (or \\(X(\\omega)\\)) is the number of 6’s that come up\n\\(x\\) is the realized value (like 4 dice have 6’s) that can be observed\nThe number of 6’s (\\(X\\) or \\(X(\\omega)\\)) is not yet a realized value, but it can be any of the realized values, \\(x\\)!\n\nI thought this Reddit thread is pretty helpful!"
  },
  {
    "objectID": "weeks/week_03_sched.html#clearest-points",
    "href": "weeks/week_03_sched.html#clearest-points",
    "title": "Week 3",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_11_sched.html#resources",
    "href": "weeks/week_11_sched.html#resources",
    "title": "Week 11",
    "section": "Resources",
    "text": "Resources\nFinal exam week!"
  },
  {
    "objectID": "weeks/week_11_sched.html#on-the-horizon",
    "href": "weeks/week_11_sched.html#on-the-horizon",
    "title": "Week 11",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_11_sched.html#end-of-quarter-feedback",
    "href": "weeks/week_11_sched.html#end-of-quarter-feedback",
    "title": "Week 11",
    "section": "End of quarter feedback!",
    "text": "End of quarter feedback!"
  },
  {
    "objectID": "weeks/week_11_sched.html#additional-information",
    "href": "weeks/week_11_sched.html#additional-information",
    "title": "Week 11",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "weeks/week_11_sched.html#statistician-of-the-week-maricela-cruz",
    "href": "weeks/week_11_sched.html#statistician-of-the-week-maricela-cruz",
    "title": "Week 11",
    "section": "Statistician of the Week: Maricela Cruz",
    "text": "Statistician of the Week: Maricela Cruz\n\n\n\n\n\n\n\nMaricela Cruz\n\n\n\n\n\n\nDr. Cruz did her undergraduate work at Pomona College, majoring in mathematics. Her PhD in Statistics is from University of California, Irvine. She is now Assistant Biostatistics Investigator, Kaiser Permanente Washington Health Research Institute (KPWHRI) and Affiliate Assistant Investigator, Department of Biostatistics, University of Washington.\nIn an interview done by Lathisms, Dr. Cruz reminds us:\n\nNavigating institutions that have systematically excluded groups of people can be taxing, especially for people from one or more of these groups. Surround yourself with those who believe in you, give you the space to ask ‘silly’ questions, value your input, and/or understand your struggles. Do activities that will help you blow off steam. No one person or activity will meet all your support needs, so find the right group and balance for you.\n\n\n\n\nTopics covered\nDr. Cruz’s dissertation work was on interrupted time series models used to determine intervention timing. Indeed, her primary research questions are to understand complex health interventions. At KPWHRI she has continued to work on epidemiological methods, particularly those appropriate for longitudinal and multilevel data.\n\n\nRelevant work\n\nCruz M, Ombao H, Gillen DL, A Generalized Interrupted Time Series Model for Assessing Complex Health Care Interventions. Statistics in Biosciences, 2022.\nCruz M, Gillen DL, Bender M, & Ombao H, Assessing health care interventions via an interrupted time series model: study power and design considerations. Statistics in Medicine, 2019.\n\n\n\nOutside links\n\nLathisms\nLinkedin\nKaiser Permanente"
  },
  {
    "objectID": "weeks/week_11_sched.html#muddiest-points",
    "href": "weeks/week_11_sched.html#muddiest-points",
    "title": "Week 11",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_11_sched.html#clearest-points",
    "href": "weeks/week_11_sched.html#clearest-points",
    "title": "Week 11",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_06_sched.html#resources",
    "href": "weeks/week_06_sched.html#resources",
    "title": "Week 6",
    "section": "Resources",
    "text": "Resources\nTopics:\n\nqualitative covariates\ncoding schemes\ninterpretation of parameters\nscoring cateogrical covariates\nreplacing continuous with categorical covariates\n\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n17\nNegative Binomial RV\n\n\n\n\n\n18\nPoisson RV\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "weeks/week_06_sched.html#on-the-horizon",
    "href": "weeks/week_06_sched.html#on-the-horizon",
    "title": "Week 6",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_06_sched.html#class-exit-tickets",
    "href": "weeks/week_06_sched.html#class-exit-tickets",
    "title": "Week 6",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (10/30)"
  },
  {
    "objectID": "weeks/week_06_sched.html#additional-information",
    "href": "weeks/week_06_sched.html#additional-information",
    "title": "Week 6",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "weeks/week_06_sched.html#statistician-of-the-week-lester-mackey",
    "href": "weeks/week_06_sched.html#statistician-of-the-week-lester-mackey",
    "title": "Week 6",
    "section": "Statistician of the Week: Lester Mackey",
    "text": "Statistician of the Week: Lester Mackey\n\n\n\n\n\n\n\nLester Mackey\n\n\n\n\n\n\nDr. Mackey is a machine learning researcher at Microsoft Research New England and an adjunct professor at Stanford University. His PhD (Computer Science 2012) and MA (Statistics 2011) are both from University of California, Berkeley, while his undergraduate degree (Computer Science 2007) is from Princeton University.\nHe is involved in Stanford’s initiative of Statistics for Social Good and has the following quote on his website:\n\nQuixotic though it may sound, I hope to use computer science and statistics to change the world for the better.\n\n\n\n\nTopics covered\nFrom Dr. Mackey’s personal website his areas of research are:\n\nstatistical machine learning\nscalable algorithms\nhigh-dimensional statistics\napproximate inference\nprobability\n\n\n\nRelevant work\n\nKoulik Khamaru, Yash Deshpande, Lester Mackey, and Martin J. Wainwright, Near-optimal inference in adaptive linear regression\n\n\nWhen data is collected in an adaptive manner, even simple methods like ordinary least squares can exhibit non-normal asymptotic behavior. As an undesirable consequence, hypothesis tests and confidence intervals based on asymptotic normality can lead to erroneous results. We propose a family of online debiasing estimators to correct these distributional anomalies in least squares estimation. Our proposed methods take advantage of the covariance structure present in the dataset and provide sharper estimates in directions for which more information has accrued. We establish an asymptotic normality property for our proposed online debiasing estimators under mild conditions on the data collection process and provide asymptotically exact confidence intervals…\n\n\nPierre Bayle, Alexandre Bayle, Lucas Janson, and Lester Mackey, Cross-validation Confidence Intervals for Test Error Advances in Neural Information Processing Systems (NeurIPS), December 2020.\n\n\nThis work develops central limit theorems for cross-validation and consistent estimators of its asymptotic variance under weak stability conditions on the learning algorithm. Together, these results provide practical, asymptotically-exact confidence intervals for k-fold test error and valid, powerful hypothesis tests of whether one learning algorithm has smaller k-fold test error than another. These results are also the first of their kind for the popular choice of leave-one-out cross-validation. In our real-data experiments with diverse learning algorithms, the resulting intervals and tests outperform the most popular alternative methods from the literature…\n\n\n\nOutside links\n\nMathematically Gifted & Black\nLinkedin\npersonal\n\n\n\nOther\nThe precursor to kaggle was a $1 million prize given by Netflix to the most accurate prediction of ratings that people give to the movies they watch. As undergraduates, Dr. Mackey and two friends led the competition for a few hours in its first year. Later, groups merged and Dr. Mackey’s group merged with a few others, forming The Ensemble. Their final analysis came in second with the exact same error rates as the winning entry. The winning entry, however, had been submitted 20 minutes prior. Sigh."
  },
  {
    "objectID": "weeks/week_06_sched.html#muddiest-points",
    "href": "weeks/week_06_sched.html#muddiest-points",
    "title": "Week 6",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_06_sched.html#clearest-points",
    "href": "weeks/week_06_sched.html#clearest-points",
    "title": "Week 6",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_07_sched.html#resources",
    "href": "weeks/week_07_sched.html#resources",
    "title": "Week 7",
    "section": "Resources",
    "text": "Resources\nTopics:\n\nmodeling using interactions\ninterpreting parameters of interacition models\ninteractions involning\n\ncat by cat\ncat by cont\ncont by cont\n\n\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n24\nContinuous RVs and PDFs\n\n\n\n\n\n25\nJoint Densities\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "weeks/week_07_sched.html#on-the-horizon",
    "href": "weeks/week_07_sched.html#on-the-horizon",
    "title": "Week 7",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_07_sched.html#class-exit-tickets",
    "href": "weeks/week_07_sched.html#class-exit-tickets",
    "title": "Week 7",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (11/6)\n Wednesday (11/8)"
  },
  {
    "objectID": "weeks/week_07_sched.html#additional-information",
    "href": "weeks/week_07_sched.html#additional-information",
    "title": "Week 7",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "weeks/week_07_sched.html#statistician-of-the-week-w.e.b.-du-bois",
    "href": "weeks/week_07_sched.html#statistician-of-the-week-w.e.b.-du-bois",
    "title": "Week 7",
    "section": "Statistician of the Week: W.E.B. Du Bois",
    "text": "Statistician of the Week: W.E.B. Du Bois\n\n\n\n\n\n\n\nW.E.B. Du Bois\n\n\n\n\n\n\nDu Bois was a sociologist and among the earliest data scientists. As Battle-Baptiste and Rusert say, his work can be thought of as\n\nthe rendering of information in a visual format to help communicate data while also generating new patterns and knoweldge throughout the act of visualization itselt.1\n\n\n\n\nTopics covered\nDu Bois was a sociologist who contributed to the field of data visualization through infographics related to the African American in the early twentieth century.\n\n\nRelevant work\n\nRusert, B., and Battle-Baptiste, W. “W. E. B. Du Bois’s Data Portraits: Visualizing Black America”, Princeton Architectural Press, 2018. https://papress.com/products/w-e-b-du-boiss-data-portraits-visualizing-black-america\n\n\n\nOutside links\n\nWikipedia\nTidyTuesday data viz and TidyTuesday challenge provided the data needed to re-create most of Du Bois’s original graphs (his originals were drawn by hand).\nData Journalism in the study of W.E.B. Du Bois\nW.E.B. Du Bois: retracing his attempt to challenge racism with data\nW.E.B. Du Bois’ Visionary Infographics Come Together for the First Time in Full Color\n\n\n\nOther\nIn 1900 Du Bois contributed approximately 60 data visualizations to an exhibit at the Exposition Universelle in Paris, an exhibit designed to illustrate the progress made by African Americans since the end of slavery (only 37 years prior, in 1863).\nAt their core, the data visualizations advocate for African American progress. They not only speak to the progress that had been made, but they centered many of the challenges that continued to exist at the time. The set of visualizations demonstrate how powerfully a picture can tell 1000 words, as the information Du Bois used was primarily available from public records (e.g., census and other government reports).\nWhitney Battle-Baptiste and Britt Rusert have reproduced and narrated the images from the exhibit in W.E.B. Du Bois’s Data Portraits: Visualizing Black America, the color line at the turn of the twentieth century."
  },
  {
    "objectID": "weeks/week_07_sched.html#muddiest-points",
    "href": "weeks/week_07_sched.html#muddiest-points",
    "title": "Week 7",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_07_sched.html#clearest-points",
    "href": "weeks/week_07_sched.html#clearest-points",
    "title": "Week 7",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_07_sched.html#footnotes",
    "href": "weeks/week_07_sched.html#footnotes",
    "title": "Week 7",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBattle-Baptiste and Rusert, W.E.B. Du Bois’s Data Portraits: Visualizing Black America, the color line at the turn of the twentieth century, 2018, page 8.↩︎"
  },
  {
    "objectID": "weeks/week_08_sched.html#resources",
    "href": "weeks/week_08_sched.html#resources",
    "title": "Week 8",
    "section": "Resources",
    "text": "Resources\nTOpics:\n\nevaluation\n\nTesting full vs reduced model\ntesting if two covariate groups are the same\n\ndiagnostics\n\npurpose\nmodel assumptions\n\nimpact of violating assumptions\n\n\n\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n25\nJoint PDFs\n\n\n\n\n\n26\nIndependent continuous random variables\n\n\n\n\n\n27\nConditional distributions\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "weeks/week_08_sched.html#on-the-horizon",
    "href": "weeks/week_08_sched.html#on-the-horizon",
    "title": "Week 8",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_08_sched.html#class-exit-tickets",
    "href": "weeks/week_08_sched.html#class-exit-tickets",
    "title": "Week 8",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (11/13)\n Wednesday (11/15)"
  },
  {
    "objectID": "weeks/week_08_sched.html#additional-information",
    "href": "weeks/week_08_sched.html#additional-information",
    "title": "Week 8",
    "section": "Additional Information",
    "text": "Additional Information\n\nExtra Practice/Learning"
  },
  {
    "objectID": "weeks/week_08_sched.html#statistician-of-the-week-desi-small-rodriguez",
    "href": "weeks/week_08_sched.html#statistician-of-the-week-desi-small-rodriguez",
    "title": "Week 8",
    "section": "Statistician of the Week: Desi Small-Rodriguez",
    "text": "Statistician of the Week: Desi Small-Rodriguez\n\n\n\n\n\n\n\nDesi Small-Rodriguez\n\n\n\n\n\n\nDr. Small-Rodriguez is a social demographer and an Assistant Professor of Sociology and American Indian Studies at UCLA. She received a PhD in Sociology from the University of Arizona and a PhD in Demography from the University of Waikato. Dr. Small-Rodriguez is Northern Cheyenne and Chicana and grounds her work in Indigenous studies, sociology of race and ethnicity, critical demography, and health policy research. She directs the Data Warriors Lab (a mobile data sovereignty lab serving Indigenous communities) and was previously a member of the Collaboratory for Indigenous Data Governance. She is a founding member of the Global Indigenous Data Alliance.\n\n\n\nTopics covered\nDr. Small-Rodriguez is passionate about Indigenous data sovereignty and Indigenous data governance. Using networks of Indigenous scholars and survey methods, she works toward the following two goals: (1) better collection and use of data on Indigenous people that has been gathered by external sources such as the census and other federal entities; (2) development of data methods and practitioners within the Indigenous community. Dr. Small-Rodriguez also works for health and economic justice on Indian Reservations.\n\n\nRelevant work\n\nS.R. Carroll, D. Rodriguez-Lonebear, A. Martinez, “Indigenous Data Governance: Strategies from United States Native Nations.” Data Science Journal, 2019. https://datascience.codata.org/article/10.5334/dsj-2019-031/\n\n\n“Indigenous data sovereignty is the right of each Native nation to govern the collection, ownership, and application of the tribe’s data.”\n\n\nRodriguez-Lonebear D, Barceló NE, Akee R, Carroll SR. “American Indian Reservations and COVID-19: Correlates of Early Infection Rates in the Pandemic.” J Public Health Manag Pract. 2020. doi: 10.1097/PHH.0000000000001206.\n\n\n\nOutside links\n\nacademic\nLinkedin\npersonal"
  },
  {
    "objectID": "weeks/week_08_sched.html#muddiest-points",
    "href": "weeks/week_08_sched.html#muddiest-points",
    "title": "Week 8",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_08_sched.html#clearest-points",
    "href": "weeks/week_08_sched.html#clearest-points",
    "title": "Week 8",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_05_sched.html#resources",
    "href": "weeks/week_05_sched.html#resources",
    "title": "Week 5",
    "section": "Resources",
    "text": "Resources\n\ntopics\n\nhypothesis testing is overall topic\nsums of squares\nF test\nnested models?\ncovariate subset test\nsingle covariate test\n\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n12\nVariance of discrete RVs\n\n\n\n\n\n13\n\n\n\n\n\n\n14\nBernoulli RV\n\n\n\n\n\n15\nBinomial RV\n\n\n\n\n\n16\nGeometric RV\n\n\n\n\n\n19\nHypergeometric RV\n\n\n\n\n\n20\nDiscrete Uniform RV\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "weeks/week_05_sched.html#on-the-horizon",
    "href": "weeks/week_05_sched.html#on-the-horizon",
    "title": "Week 5",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_05_sched.html#class-exit-tickets",
    "href": "weeks/week_05_sched.html#class-exit-tickets",
    "title": "Week 5",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (10/23)\n Wednesday (10/25)"
  },
  {
    "objectID": "weeks/week_05_sched.html#additional-information",
    "href": "weeks/week_05_sched.html#additional-information",
    "title": "Week 5",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "weeks/week_05_sched.html#statistician-of-the-week-liz-hare",
    "href": "weeks/week_05_sched.html#statistician-of-the-week-liz-hare",
    "title": "Week 5",
    "section": "Statistician of the Week: Liz Hare",
    "text": "Statistician of the Week: Liz Hare\n\n\n\n\n\n\n\nLiz Hare\n\n\n\n\n\n\nDr. Hare got her BA from Bryn Mawr College and her PhD in Genetics (1998) from The George Washington University. She works primarily in dog / animal genetics; although, as a quantitative geneticist her statistical and computational methodology is quite sophisticated.\nDr. Hare is active in the MiR (Minorities in R) Community which aims to support historically underrepresented R users around the world.\n\n\n\nTopics covered\nHer computational language of choice is R, and much of her work has focused on open science with an eye toward inclusion and equity. In many software programs, the user has the ability to include alt text: text descriptions that convey the content and meaning to blind and low-vision readers.\n\nyou really need to tell us what the data is saying and why you included it.\n\n\nWhat kind of graph or chart is it?\nWhat variables are on the axes?\nWhat are the ranges of the variables?\nWhat does the appearance tell you about the relationships between the variables?\n\n\n\nRelevant work\n\nL. Hare, Writing Alt Text to Communicate the Meaning in Data Visualizations, Do No Harm Guide: centering accessibility in data visualization, eds Schwabish, Popkin, Feng, Chapter 4, 2022.\n\n\n\nOutside links\n\nGoogle Scholar\nLinkedin\nprofessional\nfosstodon"
  },
  {
    "objectID": "weeks/week_05_sched.html#muddiest-points",
    "href": "weeks/week_05_sched.html#muddiest-points",
    "title": "Week 5",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_05_sched.html#clearest-points",
    "href": "weeks/week_05_sched.html#clearest-points",
    "title": "Week 5",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_09_sched.html#resources",
    "href": "weeks/week_09_sched.html#resources",
    "title": "Week 9",
    "section": "Resources",
    "text": "Resources\nTopics:\n\npurpose\nmodel assumptions\n\nimpact of violating assumptions\n\nusing residuals to help with diagnosis\ntransforming data\n\nprtedictors\noutcome\npredictors +outcome\n\ninfluential obs/outliers\nmulticollinearity\n\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n28\nExpected value of continuous RVs\n\n\n\n\n\n29\nVariance of continuous RVs\n\n\n\n\n\n31\nUniform RV\n\n\n\n\n\n32\nExponential RV\n\n\n\n\n\n33\nGamma RV\n\n\n\n\n\n35\nNormal RV\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "weeks/week_09_sched.html#on-the-horizon",
    "href": "weeks/week_09_sched.html#on-the-horizon",
    "title": "Week 9",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_09_sched.html#class-exit-tickets",
    "href": "weeks/week_09_sched.html#class-exit-tickets",
    "title": "Week 9",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (11/20)"
  },
  {
    "objectID": "weeks/week_09_sched.html#additional-information",
    "href": "weeks/week_09_sched.html#additional-information",
    "title": "Week 9",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "weeks/week_09_sched.html#statistician-of-the-week-mike-dairyko",
    "href": "weeks/week_09_sched.html#statistician-of-the-week-mike-dairyko",
    "title": "Week 9",
    "section": "Statistician of the Week: Mike Dairyko",
    "text": "Statistician of the Week: Mike Dairyko\n\n\n\n\n\n\n\nMike Dairyko\n\n\n\n\n\n\nDr. Dairyko was a Posse Scholar at Pomona College where a linear algebra class set him on a career path centered around mathematics. Through that class he found his way to two different summer REU programs and eventually to a PhD in Applied Mathematics from Iowa State University (2018). While initially believing that he would stay in academia after his graduate work, being introduced to machine learning methods caused him to pursue data science jobs after graduation.\nDr. Dairyko served as a Senior Manager of Data Science at the Milwaukee Brewers and is now the Director of Ticketing Analytics at the Milwaukee Bucks. Helping the organization get the most out of budgeting, revenue, and ticket sales allows him to fully use his training in mathematics and data science.\n\n\n\nTopics covered\nDr. Dairyko’s graduate work is in graph theory, in particular, exponential domination. In a graph, exponential domination is the extent to which a particular vertex influences the remaining vertices in a graph. His published work falls very much within the realm of mathematics, proving that particular properties of graphs exist. However, graph theory is intimately related to machine learning; for example, it is the foundational structure of a neural network. Understanding properties of graphs help data scientists develop even more powerful models to harness information from data.\n\n\nRelevant work\n\nM. Dairyko, A linear programming method for exponential domination. The Golden Anniversary Celebration of the National Association of Mathematicians, Volume 759 of Contemporary mathematics. Eds O. Ortega, E. Lawrence, E. Goins (2020).\nM. Dairyko, L.Hogben, J. Lin, J. Lockhart, D. Roberson, S. Severini, M. Young, Note on von Neumann and Rényi entropies of a graph. Linear Algebra and its Applications, 2017.\n\n\n\nOutside links\n\nMAD\nLinkedin\nGoogle Scholar\n\n\n\nOther\nDr. Dairyko’s path from mathematics to data science has been written about in SIAM and in the Iowa State University newsletter Math Matters."
  },
  {
    "objectID": "weeks/week_09_sched.html#muddiest-points",
    "href": "weeks/week_09_sched.html#muddiest-points",
    "title": "Week 9",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_09_sched.html#clearest-points",
    "href": "weeks/week_09_sched.html#clearest-points",
    "title": "Week 9",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_10_sched.html#resources",
    "href": "weeks/week_10_sched.html#resources",
    "title": "Week 10",
    "section": "Resources",
    "text": "Resources\ntopics:\n\nstepwise/other automated selections in traditional stat books = NO\nother options!!\n\nprioritiing predicton or interpretability\n\ncomparing potential models\n\nr-squared, PRESS, Mallow’s Cp\nAIC, BIC\n\n\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n43\nMoment generating functions\n\n\n\n\n\n36\nSums of independent normal random variables\n\n\n\n\n\n37\nCentral limit theorem\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser."
  },
  {
    "objectID": "weeks/week_10_sched.html#on-the-horizon",
    "href": "weeks/week_10_sched.html#on-the-horizon",
    "title": "Week 10",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_10_sched.html#class-exit-tickets",
    "href": "weeks/week_10_sched.html#class-exit-tickets",
    "title": "Week 10",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (11/27)\n Wednesday (11/29)"
  },
  {
    "objectID": "weeks/week_10_sched.html#additional-information",
    "href": "weeks/week_10_sched.html#additional-information",
    "title": "Week 10",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "weeks/week_10_sched.html#statistician-of-the-week-florence-nightingale",
    "href": "weeks/week_10_sched.html#statistician-of-the-week-florence-nightingale",
    "title": "Week 10",
    "section": "Statistician of the Week: Florence Nightingale",
    "text": "Statistician of the Week: Florence Nightingale\n\n\n\n\n\n\n\nFlorence Nightingale\n\n\n\n\n\n\nNightingale was a nurse who is considered to be the founder of modern nursing. In particular, she was admant about the importance of hygiene and sanitary conditions. She was born into a wealthy and well-connected family and had a large amount of privilege. Educated by her father, she showed an ability toward making analytic arguments at an early age. For her work, she was awarded the Royal Red Cross, the Lady of Grace of the Order of St John, and the Order of Merit.\n\n\n\nTopics covered\nNightingale was a nurse and statistician who used her analytic abilities to better understand and improve public health. She served in the Crimean War where Britain and France fought against the Russian invasion of the Ottoman Empire. Nightingale worked to convince Queen Victoria that poor sanitation and overcrowding were causing unnecessary death. She was able to show, for example, that peacetime soldiers (who lived in poorly kept barracks) were dying in much higher number than comparable civilian men. Her genius was to collect data meticulously and to display it in ways that were accessible to the general public. Her visualizations are lauded as pioneering and the first of their kind to tell effective stories of important issues.\n\n\nRelevant work\n\nRJ Andrews, “Florence Nightingale’s Data Revolution” in Scientific American 327, 2, 78-85, 2022. doi:10.1038/scientificamerican0822-78,\n\n\n\n\n\n\n“Diagram of the causes of mortality in the army in the East” was published in Notes on Matters Affecting the Health, Efficiency, and Hospital Administration of the British Army and sent to Queen Victoria in 1858.\n\n\n\n\n\nS Julious, “On the battlefields of the Crimean War and in the hills of Sheffield, Florence Nightingale’s legacy lives on”, The Tribune, Feb 17, 2023.\n\n\n\nOutside links\n\nWikipedia"
  },
  {
    "objectID": "weeks/week_10_sched.html#muddiest-points",
    "href": "weeks/week_10_sched.html#muddiest-points",
    "title": "Week 10",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_10_sched.html#clearest-points",
    "href": "weeks/week_10_sched.html#clearest-points",
    "title": "Week 10",
    "section": "Clearest Points",
    "text": "Clearest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "slides/22_Counting_Intro.html",
    "href": "slides/22_Counting_Intro.html",
    "title": "Chapter 22: Introduction to Counting",
    "section": "",
    "text": "Example 1\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\nHow many possible ways are there to order them?\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\nHow many ways to order them without replacement and only need 6?\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?\n\n\n\n\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.1\n\n\nHow many possible ways are there to order them?\n\n\n \n\n\nExample 1.2\n\n\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\n\n\n\n\n\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.3\n\n\nHow many ways to order them without replacement and only need 6?\n\n\n \n\n\nExample 1.4\n\n\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "homework/HW2.html#directions",
    "href": "homework/HW2.html#directions",
    "title": "Homework 2",
    "section": "Directions",
    "text": "Directions\n\nPlease upload your homework to Sakai. Upload both your .Rmd code file and the knitted .html file.\nFor each question, make sure to include all code and resulting output in the html file to support your answers.\nShow the work of your calculations using R code within a code chunk. Make sure that both your code and output are visible in the knitted html file.\nWrite all answers in complete sentences as if communicating the results to a collaborator.\n\nPoints (usually 0.5-1) will be deducted for not including a sentence summarizing results in the context of the research study.\nQuestions not requiring a sentence are\n\nCh 7 # 1, 2, 5\nCh 6 # 5, 6\nCh 14 # 2, 12, 14\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIt is a good idea to try rendering your document from time to time as you go along! Note that rendering automatically saves your qmd file and rendering frequently helps you catch your errors more quickly."
  },
  {
    "objectID": "slides/3_IndependentEvents.html#revisiting-our-coin-toss",
    "href": "slides/3_IndependentEvents.html#revisiting-our-coin-toss",
    "title": "Chapter 3: Independent Events",
    "section": "Revisiting our coin toss",
    "text": "Revisiting our coin toss\nQuestion: Which of the following sequences of coin tosses of heads (\\(H\\)) and tails (\\(T\\)) is more likely to happen, assuming the coin is fair?\n\\[HTTHHHTHTHHTTTH\\] or \\[HTTTTTTTTHTTTTT\\]"
  },
  {
    "objectID": "slides/3_IndependentEvents.html#independent-events",
    "href": "slides/3_IndependentEvents.html#independent-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independent Events",
    "text": "Independent Events\n\n\nDefinition: Independence\n\n\nEvents \\(A\\) and \\(B\\) are independent if \\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B).\\]\n\n\nNotation: For shorthand, we sometimes write \\[A \\mathrel{\\unicode{x2AEB}} B,\\] to denote that \\(A\\) and \\(B\\) are independent events."
  },
  {
    "objectID": "slides/3_IndependentEvents.html#example-of-two-dice",
    "href": "slides/3_IndependentEvents.html#example-of-two-dice",
    "title": "Chapter 3: Independent Events",
    "section": "Example of two dice",
    "text": "Example of two dice\n\n\nExample 1\n\n\nTwo dice (red and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event red die is a six. Are events \\(A\\) and \\(B\\) independent?"
  },
  {
    "objectID": "slides/3_IndependentEvents.html#independence-of-3-events",
    "href": "slides/3_IndependentEvents.html#independence-of-3-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independence of 3 Events",
    "text": "Independence of 3 Events\n\n\nDefinition: Independence of 3 Events\n\n\nEvents \\(A\\), \\(B\\), and \\(C\\) are mutually independent if\n\n\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B)\\)\n\\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(C)\\)\n\\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\\(\\mathbb{P}(A \\cap B \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\n\nRemark:\nOn your homework you will show that \\((1) \\not \\Rightarrow (2)\\) and \\((2) \\not \\Rightarrow (1)\\)."
  },
  {
    "objectID": "slides/3_IndependentEvents.html#probability-at-least-one-smoker",
    "href": "slides/3_IndependentEvents.html#probability-at-least-one-smoker",
    "title": "Chapter 3: Independent Events",
    "section": "Probability at least one smoker",
    "text": "Probability at least one smoker\n\n\n\n\nExample 2\n\n\nSuppose you take a random sample of \\(n\\) people, of which people are smokers and non-smokers independently of each other. Let\n\n\\(A_i =\\) event person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\), and\n\\(p_i =\\) probability person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\).\n\nFind the probability that at least one person in the random sample is a smoker."
  },
  {
    "objectID": "slides/3_IndependentEvents.html#three-people-toss-a-coin",
    "href": "slides/3_IndependentEvents.html#three-people-toss-a-coin",
    "title": "Chapter 3: Independent Events",
    "section": "Three people toss a coin",
    "text": "Three people toss a coin\n\n\nExample 3\n\n\n\\(A, B,\\) and \\(C\\) toss a fair coin in order. The first to throw heads wins. What are their respective chances of winning?\n\n\nLet\n\n\\(A_H\\) and \\(A_T\\) be the events player A tosses heads and tails, respectively.\nSimilarly define \\(B_H\\), \\(B_T\\), \\(C_H\\), and \\(C_T\\).\n\n\n\nChapter 3 Slides"
  },
  {
    "objectID": "slides/1_Outcomes_Events_Sample.html#learning-objectives",
    "href": "slides/1_Outcomes_Events_Sample.html#learning-objectives",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDefine basic terms related to events such as events, outcomes, and sample space.\nUse proper set notation for events\nCharacterize possible outcomes, when something random occurs\nDescribe events into which outcomes can be grouped\nDefine important terms and rules within set theory such as unions, intersections, complements, mutually exclusive, and De Morgan’s Laws"
  },
  {
    "objectID": "slides/2_Probability.html#learning-objectives",
    "href": "slides/2_Probability.html#learning-objectives",
    "title": "Chapter 2: Probability",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDefine basic axioms and propositions in probability\nAssign probabilities to events, and perform manipulations on probabilities to make calculations easier"
  },
  {
    "objectID": "slides/22_Counting_Intro.html#learning-objectives",
    "href": "slides/22_Counting_Intro.html#learning-objectives",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDefine permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "slides/3_IndependentEvents.html#learning-objectives",
    "href": "slides/3_IndependentEvents.html#learning-objectives",
    "title": "Chapter 3: Independent Events",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nDefine independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "slides/3_IndependentEvents.html#building-geometric-series",
    "href": "slides/3_IndependentEvents.html#building-geometric-series",
    "title": "Chapter 3: Independent Events",
    "section": "Building geometric series",
    "text": "Building geometric series\n\n\nExample 3\n\n\n\\(A, B,\\) and \\(C\\) toss a fair coin in order. The first to throw heads wins. What are their respective chances of winning?\n\n\nLet\n\n\\(A_H\\) and \\(A_T\\) be the events player A tosses heads and tails, respectively.\nSimilarly define \\(B_H\\), \\(B_T\\), \\(C_H\\), and \\(C_T\\)."
  },
  {
    "objectID": "slides/4_Conditional_Probability.html#learning-objectives",
    "href": "slides/4_Conditional_Probability.html#learning-objectives",
    "title": "Chapter 4: Conditional Probability",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUse set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "slides/4_Conditional_Probability.html#lets-revisit-our-deck-of-cards",
    "href": "slides/4_Conditional_Probability.html#lets-revisit-our-deck-of-cards",
    "title": "Chapter 4: Conditional Probability",
    "section": "Let’s revisit our deck of cards",
    "text": "Let’s revisit our deck of cards\n\n\n\n\nExample 1\n\n\nSuppose we randomly draw 2 cards from a standard deck of cards. What is the probability that we draw a spade then a heart?\n\n\nLet\n\nLet \\(A =\\) event \\(1^{st}\\) card is spades\nLet \\(B =\\) event \\(2^{nd}\\) card is heart"
  },
  {
    "objectID": "slides/4_Conditional_Probability.html#conditional-probability-with-two-dice",
    "href": "slides/4_Conditional_Probability.html#conditional-probability-with-two-dice",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional probability with two dice",
    "text": "Conditional probability with two dice\n\n\n\n\nExample 2\n\n\nTwo dice (red and blue) are rolled. If the dice do not show the same face, what is the probability that one of the dice is a 1?\n\n\n\n\n\n\nChapter 4 Slides"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#learning-objectives",
    "href": "slides/5_Bayes_Theorem.html#learning-objectives",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#calculating-probability-with-higher-order-multiplication-rule",
    "href": "slides/5_Bayes_Theorem.html#calculating-probability-with-higher-order-multiplication-rule",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with Higher Order Multiplication Rule",
    "text": "Calculating probability with Higher Order Multiplication Rule\n\n\n\n\nExample 1\n\n\nSuppose we draw 5 cards from a standard shuffled deck of 52 cards. What is the probability of a flush, that is all the cards are of the same suit (including straight flushes)?\n\n\n\n\n\nHigher Order Multiplication Rule\n\n\n\\[\\mathbb{P}(A_1\\cap A_2 \\cap  \\ldots \\cap A_n)=\\mathbb{P}(A_1)\\cdot\\mathbb{P}(A_2|A_1) \\cdot \\\\\n\\mathbb{P}(A_3|A_1A_2)\\ldots \\cdot\\mathbb{P}(A_n|A_1A_2\\ldots A_{n-1})\\]"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#calculating-probability-with-law-of-total-probability",
    "href": "slides/5_Bayes_Theorem.html#calculating-probability-with-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with Law of Total Probability",
    "text": "Calculating probability with Law of Total Probability\n\n\n\n\nExample 2\n\n\nSuppose 1% of people assigned female at birth (AFAB) and 5% of people assigned male at birth (AMAB) are color-blind. Assume person born is equally likely AFAB or AMAB (not including intersex). What is the probability that a person chosen at random is color-blind?\n\n\n\n\n\nLaw of Total Probability for 2 Events\n\n\nFor events \\(A\\) and \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=&\\mathbb{P}(B \\cap A) + \\mathbb{P}(B \\cap A^C)\\\\\n           &=& \\mathbb{P}(B|A) \\cdot \\mathbb{P}(A)+ \\mathbb{P}(B | A^C)\\cdot \\mathbb{P}(A^C)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#calculating-probability-with-generalized-version-of-law-of-total-probability",
    "href": "slides/5_Bayes_Theorem.html#calculating-probability-with-generalized-version-of-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized version of Law of Total Probability",
    "text": "Calculating probability with generalized version of Law of Total Probability\n\n\nExample 3\n\n\nIndividuals are diagnosed with a particular type of cancer that can take on three different disease forms,* \\(D_1\\), \\(D_2\\), and \\(D_3\\). It is known that amongst people diagnosed with this particular type of cancer,\n\n20% of people will eventually be diagnosed with form \\(D_1\\),\n30% with form \\(D_2\\), and\n50% with form \\(D_3\\).\n\nThe probability of requiring chemotherapy (\\(C\\)) differs among the three forms of disease:\n\n80% with \\(D_1\\),\n30% with \\(D_2\\), and\n10% with \\(D_3\\).\n\nBased solely on the preliminary test of being diagnosed with the cancer, what is the probability of requiring chemotherapy (the event C)?\n\n\n\n\nLaw of Total Probability (general)\n\n\nIf \\(\\{A_i\\}_{i=1}^{n} = \\{A_1, A_2, \\ldots, A_n\\}\\) form a partition of the sample space, then for event \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=& \\sum_{i=1}^{n} \\mathbb{P}(B \\cap A_i)\\\\\n           &=& \\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability",
    "href": "slides/5_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#lets-revisit-the-color-blind-example",
    "href": "slides/5_Bayes_Theorem.html#lets-revisit-the-color-blind-example",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Let’s revisit the color-blind example",
    "text": "Let’s revisit the color-blind example\n\n\n\n\nExample 4\n\n\nRecall the color-blind example (Example 2), where\n\na person is AMAB with probability 0.5,\nAMAB people are color-blind with probability 0.05, and\nall people are color-blind with probability 0.03.\n\nAssuming people are AMAB or AFAB, find the probability that a color-blind person is AMAB."
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#calculate-probability-with-both-rules",
    "href": "slides/5_Bayes_Theorem.html#calculate-probability-with-both-rules",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculate probability with both rules",
    "text": "Calculate probability with both rules\n\n\n\n\nExample 5\n\n\nSuppose\n\n1% of women aged 40-50 years have breast cancer,\na woman with breast cancer has a 90% chance of a positive test from a mammogram, and\na woman has a 10% chance of a false-positive result from a mammogram.\n\nWhat is the probability that a woman has breast cancer given that she just had a positive test?"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#general-law-of-total-proability",
    "href": "slides/5_Bayes_Theorem.html#general-law-of-total-proability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "General Law of Total Proability",
    "text": "General Law of Total Proability\n\n\nLaw of Total Probability (general)\n\n\nIf \\(\\{A_i\\}_{i=1}^{n} = \\{A_1, A_2, \\ldots, A_n\\}\\) form a partition of the sample space, then for event \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=& \\sum_{i=1}^{n} \\mathbb{P}(B \\cap A_i)\\\\\n           &=& \\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "slides/4_Conditional_Probability.html#general-process-for-probability-word-problems",
    "href": "slides/4_Conditional_Probability.html#general-process-for-probability-word-problems",
    "title": "Chapter 4: Conditional Probability",
    "section": "General Process for Probability Word Problems",
    "text": "General Process for Probability Word Problems\n\nClearly define your events of interest\nTranslate question to probability using defined events OR Venn Diagram\nAsk yourself:\n\nAre we sampling with or without replacement?\nDoes order matter?\n\nUse axioms, properties, partitions, facts, etc. to define the end probability calculation into smaller parts\n\nIf probabilities are given to you, Venn Diagrams may help you parse out the events and probability calculations\nIf you need to find probabilities with counting, pictures or diagrams might help here\n\nWrite out a concluding statement that gives the probability context\n(For own check) Make sure the calculated probability follows the axioms. Is is between 0 and 1?"
  },
  {
    "objectID": "slides/22_Counting_Intro.html#enumerating-events-and-sample-space",
    "href": "slides/22_Counting_Intro.html#enumerating-events-and-sample-space",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Enumerating Events and Sample Space",
    "text": "Enumerating Events and Sample Space\n\nRecall, \\(P(A) = \\dfrac{|A|}{|S|}\\). And within combinatorics, we can use the previous equations to help enumerate the event and sample space.\nI left something out though… the enumeration of the event is not just one of the above formulas.\nFor example in the example of the spades when order does not matter, we actually need to enumerate the other cards that were NOT spades. So the event is choosing 2 spades out of 13 AND choosing 0 other cards of 39 cards (13 hearts + 13 clubs + 13 diamonds).\nThus the probability is actually:\n\n\\[ P(\\text{two spades}) = \\dfrac{{13 \\choose 2}{39 \\choose 0}}{{52 \\choose 2}} \\]\n\nNote that \\(13 + 39 = 52\\) and \\(2+ 0 = 2\\). So the numerator’s \\(n\\)’s add up to the denominator’s \\(n\\) and the numerator’s \\(r\\)’s add up to the denominator’s \\(r\\)’s\n\n\n\nChapter 22 Slides"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-.smaller-.hidden",
    "href": "slides/5_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-.smaller-.hidden",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability {.smaller, .hidden}",
    "text": "Calculating probability with generalized Law of Total Probability {.smaller, .hidden}\n\n\n\n\nExample 3\n\n\nIndividuals are diagnosed with a particular type of cancer that can take on three different disease forms,* \\(D_1\\), \\(D_2\\), and \\(D_3\\). It is known that amongst people diagnosed with this particular type of cancer,\n\n20% of people will eventually be diagnosed with form \\(D_1\\),\n30% with form \\(D_2\\), and\n50% with form \\(D_3\\).\n\nThe probability of requiring chemotherapy (\\(C\\)) differs among the three forms of disease:\n\n80% with \\(D_1\\),\n30% with \\(D_2\\), and\n10% with \\(D_3\\).\n\nBased solely on the preliminary test of being diagnosed with the cancer, what is the probability of requiring chemotherapy (the event C)?"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-.smaller",
    "href": "slides/5_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-.smaller",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability {.smaller}",
    "text": "Calculating probability with generalized Law of Total Probability {.smaller}\n\n\n\n\nExample 3\n\n\nIndividuals are diagnosed with a particular type of cancer that can take on three different disease forms,* \\(D_1\\), \\(D_2\\), and \\(D_3\\). It is known that amongst people diagnosed with this particular type of cancer,\n\n20% of people will eventually be diagnosed with form \\(D_1\\),\n30% with form \\(D_2\\), and\n50% with form \\(D_3\\).\n\nThe probability of requiring chemotherapy (\\(C\\)) differs among the three forms of disease:\n\n80% with \\(D_1\\),\n30% with \\(D_2\\), and\n10% with \\(D_3\\).\n\nBased solely on the preliminary test of being diagnosed with the cancer, what is the probability of requiring chemotherapy (the event C)?"
  },
  {
    "objectID": "slides/7_Random_Variables.html#what-is-a-random-variable",
    "href": "slides/7_Random_Variables.html#what-is-a-random-variable",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "What is a random variable?",
    "text": "What is a random variable?\n\n\nDefinition: Random Variable\n\n\nFor a given sample space \\(S\\), a random variable (r.v.) is a function whose domain is \\(S\\) and whose range is the set of real numbers \\(\\mathbb{R}\\). A random variable assigns a real number to each outcome in the sample space."
  },
  {
    "objectID": "slides/7_Random_Variables.html#learning-objectives",
    "href": "slides/7_Random_Variables.html#learning-objectives",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nMap the sample space to the set of real numbers using a discrete and continuous random variable\nDistinguish between discrete and continuous random variables from a written description"
  },
  {
    "objectID": "slides/7_Random_Variables.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "href": "slides/7_Random_Variables.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s demonstrate this definition with our coin toss",
    "text": "Let’s demonstrate this definition with our coin toss\n\n\n\n\nExample 1\n\n\nSuppose we toss 3 fair coins.\n\nWhat is the sample space?\nWhat are the probabilities for each of the elements in the sample space?\nWhat are the probabilities that you get 0, 1, 2, or 3 tails?"
  },
  {
    "objectID": "slides/7_Random_Variables.html#lets-stretch-our-definition-of-random-variables",
    "href": "slides/7_Random_Variables.html#lets-stretch-our-definition-of-random-variables",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s stretch our definition of random variables",
    "text": "Let’s stretch our definition of random variables\n\n\n\n\nExample 2\n\n\nWhat are some other random variables we could consider in Example 1?"
  },
  {
    "objectID": "slides/7_Random_Variables.html#some-remarks-on-random-variables",
    "href": "slides/7_Random_Variables.html#some-remarks-on-random-variables",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Some remarks on random variables",
    "text": "Some remarks on random variables\n\nA random variable’s value is completely determined by the outcome \\(\\omega\\), where \\(\\omega \\in S\\)\n\nWhat is random is the outcome \\(\\omega\\)\n\nA random variable is a function from the sample space (with outcomes \\(\\omega\\)) to the set of real numbers\n\nWe typically write \\(X\\) instead of \\(X(\\omega)\\), where \\(X\\) is our random variable\n\nFor example, if we roll three dice, there are \\(6^3 = 216\\) possible outcomes (which is \\(\\omega\\))\n\nWe can define a random variable as the sum of the of the three dice\nIf our outcome is the set of numbers the dice landed on ( \\(\\omega=(a,b,c)\\) ), then \\[ X(\\omega) = X = a + b + c \\]"
  },
  {
    "objectID": "slides/7_Random_Variables.html#lets-look-at-sample-space",
    "href": "slides/7_Random_Variables.html#lets-look-at-sample-space",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s look at sample space,",
    "text": "Let’s look at sample space,\n\n\n\n\nExample 4\n\n\nLet \\(X =\\) how many hours you slept last night.\n\nWhat is the sample space \\(S\\)?\nWhat is the range of possible values for \\(X\\)?\nWhat is \\(X(\\omega)\\)?"
  },
  {
    "objectID": "slides/7_Random_Variables.html#lets-look-at-a-continuous-r.v.",
    "href": "slides/7_Random_Variables.html#lets-look-at-a-continuous-r.v.",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s look at a continuous R.V.",
    "text": "Let’s look at a continuous R.V.\n\n\n\n\nExample 3\n\n\nLet \\(X =\\) how many hours you slept last night.\n\nWhat is the sample space \\(S\\)?\nWhat is the range of possible values for \\(X\\)?\nWhat is \\(X(\\omega)\\)?"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#learning-objectives",
    "href": "slides/8_pmfs_and_cdfs.html#learning-objectives",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate probabilities for discrete random variables\nCalculate and graph a probability mass function (pmf)\nCalculate and graph a cumulative distribution function (CDF)"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#what-is-a-random-variable",
    "href": "slides/8_pmfs_and_cdfs.html#what-is-a-random-variable",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "What is a random variable?",
    "text": "What is a random variable?\n\n\nDefinition: probability distribution or probability mass function (pmf)\n\n\nThe probability distribution or probability mass function (pmf) of a discrete r.v.* \\(X\\) is defined for every number \\(x\\) by \\[p_X(x) = \\mathbb{P}(X=x) = \\mathbb{P}(\\mathrm{all }\\ \\omega\\in S:X(\\omega) = x)\\]"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "href": "slides/8_pmfs_and_cdfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Let’s demonstrate this definition with our coin toss",
    "text": "Let’s demonstrate this definition with our coin toss\n\n\n\n\nExample 1\n\n\nSuppose we toss 3 coins with probability of tails \\(p\\). If \\(X\\) is the random variable counting the number of tails, what are the probabilities of each value of \\(X\\)?"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#what-is-a-probability-mass-function",
    "href": "slides/8_pmfs_and_cdfs.html#what-is-a-probability-mass-function",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "What is a probability mass function?",
    "text": "What is a probability mass function?\n\n\nDefinition: probability distribution or probability mass function (pmf)\n\n\nThe probability distribution or probability mass function (pmf) of a discrete r.v. \\(X\\) is defined for every number \\(x\\) by \\[p_X(x) = \\mathbb{P}(X=x) = \\mathbb{P}(\\mathrm{all }\\ \\omega\\in S:X(\\omega) = x)\\]"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#remarks-on-the-pmf",
    "href": "slides/8_pmfs_and_cdfs.html#remarks-on-the-pmf",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Remarks on the pmf",
    "text": "Remarks on the pmf\n\n\nProperties of pmf\n\n\nA pmf \\(p_X(x)\\) must satisfy the following properties:\n\n\\(0 \\leq p_X(x) \\leq 1\\) for all \\(x\\).\n\\(\\sum \\limits_{\\{all\\ x\\}}p_X(x)=1\\).\n\n\n\n\nSome distributions depend on parameters\n\nEach value of a parameter gives a different pmf\nIn previous example, the number of coins tossed was a parameter\n\nWe tossed 3 coins\nIf we tossed 4 coins, we’d get a different pmf!\n\nThe collection of all pmf’s for different values of the parameters is called a family of pmf’s"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#binomial-family-of-rvs",
    "href": "slides/8_pmfs_and_cdfs.html#binomial-family-of-rvs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Binomial family of RVs",
    "text": "Binomial family of RVs\n\n\n\n\nExample 2\n\n\nSuppose you toss \\(n\\) coins, each with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#bernoulli-family-of-rvs",
    "href": "slides/8_pmfs_and_cdfs.html#bernoulli-family-of-rvs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Bernoulli family of RVs",
    "text": "Bernoulli family of RVs\n\n\n\n\nExample 3\n\n\nSuppose you toss 1 coin, with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#household-size",
    "href": "slides/8_pmfs_and_cdfs.html#household-size",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size",
    "text": "Household size\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes.\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#what-is-a-cumulative-distribution-function",
    "href": "slides/8_pmfs_and_cdfs.html#what-is-a-cumulative-distribution-function",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "What is a cumulative distribution function?",
    "text": "What is a cumulative distribution function?\n\n\nDefinition: cumulative distribution function (CDF)\n\n\nThe cumulative distribution function (cdf) of a discrete r.v. \\(X\\) with pmf \\(p_X(x)\\), is defined for every value \\(x\\) by \\[F_X(x) = \\mathbb{P}(X \\leq x) = \\sum \\limits_{\\{all\\ y:\\ y\\leq x\\}}p_X(y)\\]"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#household-size-continued",
    "href": "slides/8_pmfs_and_cdfs.html#household-size-continued",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size continued",
    "text": "Household size continued\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nGraph the cdf of household sizes in 2019.\nWrite the cdf as a function."
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#properties-of-discrete-cdfs",
    "href": "slides/8_pmfs_and_cdfs.html#properties-of-discrete-cdfs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Properties of discrete CDFs",
    "text": "Properties of discrete CDFs\n\n\\(F(x)\\) is increasing or flat (never decreasing)\n\\(\\min\\limits_x F(x) = 0\\)\n\\(\\max\\limits_xF(x)=1\\)\nCDF is a step function\n\n\n\nChapter 8 Slides"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#household-size-14",
    "href": "slides/8_pmfs_and_cdfs.html#household-size-14",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (1/4)",
    "text": "Household size (1/4)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes.\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf.\nGraph the cdf of household sizes in 2019.\nWrite the cdf as a function."
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#household-size-24",
    "href": "slides/8_pmfs_and_cdfs.html#household-size-24",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (2/4)",
    "text": "Household size (2/4)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes."
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#household-size-34",
    "href": "slides/8_pmfs_and_cdfs.html#household-size-34",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (3/4)",
    "text": "Household size (3/4)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#household-size-44",
    "href": "slides/8_pmfs_and_cdfs.html#household-size-44",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (4/4)",
    "text": "Household size (4/4)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nGraph the cdf of household sizes in 2019.\nWrite the cdf as a function."
  },
  {
    "objectID": "slides/9_joint_distributions.html#learning-objectives",
    "href": "slides/9_joint_distributions.html#learning-objectives",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate probabilities for a pair of discrete random variables\nCalculate and graph a joint, marginal, and conditional probability mass function (pmf)\nCalculate and graph a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "slides/9_joint_distributions.html#what-is-a-joint-pmf",
    "href": "slides/9_joint_distributions.html#what-is-a-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint pmf?",
    "text": "What is a joint pmf?\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]"
  },
  {
    "objectID": "slides/9_joint_distributions.html#example",
    "href": "slides/9_joint_distributions.html#example",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nHints:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counterexample\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "slides/9_joint_distributions.html#remarks-on-the-join-pmf",
    "href": "slides/9_joint_distributions.html#remarks-on-the-join-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the join pmf",
    "text": "Remarks on the join pmf\nSome properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "slides/9_joint_distributions.html#what-is-a-join-cdf",
    "href": "slides/9_joint_distributions.html#what-is-a-join-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a join CDF?",
    "text": "What is a join CDF?\n\n\nDefinition: joint CDF\n\n\nThe joint CDF of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]"
  },
  {
    "objectID": "slides/9_joint_distributions.html#example-1",
    "href": "slides/9_joint_distributions.html#example-1",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "slides/9_joint_distributions.html#example-2",
    "href": "slides/9_joint_distributions.html#example-2",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nHints:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counterexample\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "slides/9_joint_distributions.html#remarks-on-the-joint-cdf",
    "href": "slides/9_joint_distributions.html#remarks-on-the-joint-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint CDF",
    "text": "Remarks on the joint CDF\n\n\\(F_X(x)\\): right most columns of the CDf table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "slides/9_joint_distributions.html#independence-and-conditioning",
    "href": "slides/9_joint_distributions.html#independence-and-conditioning",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Independence and Conditioning",
    "text": "Independence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]"
  },
  {
    "objectID": "slides/9_joint_distributions.html#what-is-the-conditional-pmf",
    "href": "slides/9_joint_distributions.html#what-is-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is the conditional pmf?",
    "text": "What is the conditional pmf?\n\n\nDefinition: conditional pmf\n\n\nThe conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\)."
  },
  {
    "objectID": "slides/9_joint_distributions.html#remarks-on-teh-conditional-pmf",
    "href": "slides/9_joint_distributions.html#remarks-on-teh-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on teh conditional pmf",
    "text": "Remarks on teh conditional pmf\nRemark: The following properties follow from the conditional pmf definition:"
  },
  {
    "objectID": "slides/9_joint_distributions.html#example-3",
    "href": "slides/9_joint_distributions.html#example-3",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Example",
    "text": "Example\n\nExample 7. Using \\(X\\) and \\(Y\\) from Example 2:\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\nHints:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counterexample.\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)."
  },
  {
    "objectID": "slides/9_joint_distributions.html#hypothetical-4-sided-die",
    "href": "slides/9_joint_distributions.html#hypothetical-4-sided-die",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Hypothetical 4-sided die",
    "text": "Hypothetical 4-sided die\n\n\nExample 3\n\n\n\nSuppose you have a 4-sided die, and you roll the 4-sided die until the first 4 appears.\nLet \\(X\\) be the number of rolls required until (and including) the first 4.\nAfter the first 4, you keep rolling it again until you roll a 3.\nLet \\(Y\\) be the number of rolls, after the first 4, required until (and including) the 3.\n\n\nFind \\(p_{X,Y}(x,y)\\).\nUsing \\(p_{X,Y}(x,y)\\), find \\(p_{Y}(y)\\).\nFind \\(p_{X}(x)\\).\nAre \\(X\\) and \\(Y\\) are independent? Why or why not?\nFind \\(F_{X,Y}(x,y)\\).\n\n\n\n\n\nChapter 9 Slides"
  },
  {
    "objectID": "slides/9_joint_distributions.html#remarks-on-the-joint-and-marginal-cdf",
    "href": "slides/9_joint_distributions.html#remarks-on-the-joint-and-marginal-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint and marginal CDF",
    "text": "Remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDf table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "slides/9_joint_distributions.html#remarks-on-the-conditional-pmf",
    "href": "slides/9_joint_distributions.html#remarks-on-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the conditional pmf",
    "text": "Remarks on the conditional pmf\nThe following properties follow from the conditional pmf definition:\n\nIf \\(X \\perp Y\\) (independent)\n\n\\(p_{X|Y}(x|y) = p_X(x)\\) for all \\(x\\) and \\(y\\)\n\\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\\) for all \\(x\\) and \\(y\\)\nWhich also implies (\\(\\Rightarrow\\)): \\(F_{X,Y}(x,y) = F_X(x)F_Y(y)\\) for all \\(x\\) and \\(y\\)\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\]\n\\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]"
  },
  {
    "objectID": "slides/9_joint_distributions.html#remarks-on-the-joint-pmf",
    "href": "slides/9_joint_distributions.html#remarks-on-the-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint pmf",
    "text": "Remarks on the joint pmf\nSome properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "slides/9_joint_distributions.html#what-is-a-joint-cdf",
    "href": "slides/9_joint_distributions.html#what-is-a-joint-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint CDF?",
    "text": "What is a joint CDF?\n\n\nDefinition: joint CDF\n\n\nThe joint CDF of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]"
  },
  {
    "objectID": "slides/9_joint_distributions.html#this-chapters-main-example",
    "href": "slides/9_joint_distributions.html#this-chapters-main-example",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "This chapter’s main example",
    "text": "This chapter’s main example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?"
  },
  {
    "objectID": "slides/9_joint_distributions.html#joint-pmf",
    "href": "slides/9_joint_distributions.html#joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint pmf",
    "text": "Joint pmf\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)"
  },
  {
    "objectID": "slides/9_joint_distributions.html#marginal-pmfs",
    "href": "slides/9_joint_distributions.html#marginal-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal pmf’s",
    "text": "Marginal pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)"
  },
  {
    "objectID": "slides/9_joint_distributions.html#joint-and-marginal-cdfs",
    "href": "slides/9_joint_distributions.html#joint-and-marginal-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint and marginal CDFs",
    "text": "Joint and marginal CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "slides/9_joint_distributions.html#hypothetical-4-sided-die-.visabilityhidden",
    "href": "slides/9_joint_distributions.html#hypothetical-4-sided-die-.visabilityhidden",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Hypothetical 4-sided die {.visability=“hidden”}",
    "text": "Hypothetical 4-sided die {.visability=“hidden”}\n\n\nExample 3\n\n\n\nSuppose you have a 4-sided die, and you roll the 4-sided die until the first 4 appears.\nLet \\(X\\) be the number of rolls required until (and including) the first 4.\nAfter the first 4, you keep rolling it again until you roll a 3.\nLet \\(Y\\) be the number of rolls, after the first 4, required until (and including) the 3.\n\n\nFind \\(p_{X,Y}(x,y)\\).\nUsing \\(p_{X,Y}(x,y)\\), find \\(p_{Y}(y)\\).\nFind \\(p_{X}(x)\\).\nAre \\(X\\) and \\(Y\\) are independent? Why or why not?\nFind \\(F_{X,Y}(x,y)\\).\n\n\n\n\n\nChapter 9 Slides"
  },
  {
    "objectID": "slides/9_joint_distributions.html#conditional-pmfs",
    "href": "slides/9_joint_distributions.html#conditional-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Conditional pmf’s",
    "text": "Conditional pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "slides/5_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-.smaller-visibilityhidden",
    "href": "slides/5_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-.smaller-visibilityhidden",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability {.smaller, visibility=“hidden”}",
    "text": "Calculating probability with generalized Law of Total Probability {.smaller, visibility=“hidden”}\n\n\n\n\nExample 3\n\n\nIndividuals are diagnosed with a particular type of cancer that can take on three different disease forms,* \\(D_1\\), \\(D_2\\), and \\(D_3\\). It is known that amongst people diagnosed with this particular type of cancer,\n\n20% of people will eventually be diagnosed with form \\(D_1\\),\n30% with form \\(D_2\\), and\n50% with form \\(D_3\\).\n\nThe probability of requiring chemotherapy (\\(C\\)) differs among the three forms of disease:\n\n80% with \\(D_1\\),\n30% with \\(D_2\\), and\n10% with \\(D_3\\).\n\nBased solely on the preliminary test of being diagnosed with the cancer, what is the probability of requiring chemotherapy (the event C)?\n\n\n\nSkipping in class! Let me know if you would like me to post solutions to this if you work through it!"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#household-size-34-1",
    "href": "slides/8_pmfs_and_cdfs.html#household-size-34-1",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (3/4)",
    "text": "Household size (3/4)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nMake a plot of the pmf"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#household-size-15",
    "href": "slides/8_pmfs_and_cdfs.html#household-size-15",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (1/5)",
    "text": "Household size (1/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes.\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf.\nWrite the cdf as a function.\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#household-size-25",
    "href": "slides/8_pmfs_and_cdfs.html#household-size-25",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (2/5)",
    "text": "Household size (2/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes."
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#household-size-35",
    "href": "slides/8_pmfs_and_cdfs.html#household-size-35",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (3/5)",
    "text": "Household size (3/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf"
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#household-size-45",
    "href": "slides/8_pmfs_and_cdfs.html#household-size-45",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (4/5)",
    "text": "Household size (4/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWrite the cdf as a function."
  },
  {
    "objectID": "slides/8_pmfs_and_cdfs.html#household-size-55",
    "href": "slides/8_pmfs_and_cdfs.html#household-size-55",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (5/5)",
    "text": "Household size (5/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "slides/9_joint_distributions.html#joint-cdfs",
    "href": "slides/9_joint_distributions.html#joint-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint CDFs",
    "text": "Joint CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "slides/9_joint_distributions.html#marginal-cdfs",
    "href": "slides/9_joint_distributions.html#marginal-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal CDFs",
    "text": "Marginal CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "slides/10_Expected_Values.html#our-good-friend-the-6-sided-die",
    "href": "slides/10_Expected_Values.html#our-good-friend-the-6-sided-die",
    "title": "Chapter 10: Expected Values of Discrete r.v.’s",
    "section": "Our good friend, the 6-sided die",
    "text": "Our good friend, the 6-sided die\n\n\nExample 1.\n\n\nSuppose you roll a fair 6-sided die. What value do you expect to get?"
  },
  {
    "objectID": "slides/10_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "href": "slides/10_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Our good and fair friend, the 6-sided die",
    "text": "Our good and fair friend, the 6-sided die\n\n\n\n\nExample 1\n\n\nSuppose you roll a fair 6-sided die. What value do you expect to get?"
  },
  {
    "objectID": "slides/10_Expected_Values.html#learning-objectives",
    "href": "slides/10_Expected_Values.html#learning-objectives",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate the mean (expected value) of discrete random variables"
  },
  {
    "objectID": "slides/10_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "href": "slides/10_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Our good and not-so-fair friend, the 6-sided die",
    "text": "Our good and not-so-fair friend, the 6-sided die\n\n\n\n\nExample 2\n\n\nSuppose the die is 6-sided, but not fair. And the probabilities of each side is distributed as:\n\n\n\n\\(x\\)\n\\(p_X(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.05\n\n\n3\n0.02\n\n\n4\n0.30\n\n\n5\n0.50\n\n\n6\n0.03\n\n\n\nWhat value do you expect to get on a roll?"
  },
  {
    "objectID": "slides/10_Expected_Values.html#quick-remark-on-expected-values",
    "href": "slides/10_Expected_Values.html#quick-remark-on-expected-values",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Quick remark on expected values",
    "text": "Quick remark on expected values\n\nLet’s think about expected values vs. actual outcomes\nExpected values are not necessarily an actual outcome\n\nIt could be that our expected value is not in the sample space (\\(E(X) \\notin S\\))"
  },
  {
    "objectID": "slides/10_Expected_Values.html#what-is-an-expected-value",
    "href": "slides/10_Expected_Values.html#what-is-an-expected-value",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "What is an expected value?",
    "text": "What is an expected value?\n\n\nDefinition: Expected value\n\n\nThe expected value of a discrete r.v. \\(X\\) that takes on values \\(x_1, x_2, \\ldots, x_n\\) is \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\n\n\nExpected values are not necessarily an actual outcome\n\nIn previous example, we cannot roll a 3.5\nIt could be that our expected value is not in the sample space (\\(E(X) \\notin S\\))\n\nDefinition holds when \\(X\\) takes on countably infinitely many values (think \\(n=\\infty\\))"
  },
  {
    "objectID": "slides/10_Expected_Values.html#remarks-on-the-expected-value",
    "href": "slides/10_Expected_Values.html#remarks-on-the-expected-value",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Remarks on the expected value",
    "text": "Remarks on the expected value\n\nThe definition holds if the r.v. \\(X\\) takes on countably infinitely many values \\(x_1, x_2, \\ldots\\), as well: \\[\\mathbb{E}[X] = \\sum_{i=1}^{\\infty} x_ip_X(x_i).\\]\nAnother way to define the expected value of a discrete r.v. is to do so at the \\(\\omega\\) level, where the \\(\\omega\\)’s are outcomes in the sample space:\n\nSuppose \\(\\omega_1, \\omega_2, \\ldots, \\omega_n\\) are the possible outcomes of a random phenomenon. If outcome \\(\\omega_i\\) causes the r.v. X to take on value \\(x_i\\) (meaning \\(X(\\omega_i)=x_i\\)), then \\[\\mathbb{E}[X] = \\sum_{i=1}^{\\infty} x_i\\mathbb{P}(\\{\\omega_i\\}).\\]"
  },
  {
    "objectID": "slides/10_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "href": "slides/10_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Expected value of a Bernoulli distribution",
    "text": "Expected value of a Bernoulli distribution\n\n\n\n\nExample 3\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad\\mathrm{(success)}\\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\\mathrm{(failure)}\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "slides/10_Expected_Values.html#lets-slightly-change-our-random-variable",
    "href": "slides/10_Expected_Values.html#lets-slightly-change-our-random-variable",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Let’s slightly change our random variable",
    "text": "Let’s slightly change our random variable\n\n\n\n\nExample 5\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\\\\n            -1 & \\quad \\mathrm{with\\ probability}\\ 1-p\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "slides/10_Expected_Values.html#dartboard",
    "href": "slides/10_Expected_Values.html#dartboard",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Dartboard",
    "text": "Dartboard\n\nExample 6. Suppose I throw darts at a dartboard until I hit the bullseye, and that my probability of hitting the bullseye is \\(p\\). Suppose further that all of my throws are independent, and that the probability of a bullseye never changes, no matter how many times I throw a dart. How many times should I expect to have to throw the dart until I hit the bullseye?"
  },
  {
    "objectID": "slides/10_Expected_Values.html#ghost",
    "href": "slides/10_Expected_Values.html#ghost",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Ghost! 👻",
    "text": "Ghost! 👻\n\n\n\n\nExample 6\n\n\nA ghost is trick-or-treating. It comes to a house where it is known that there are 30 candies in the bag and only one is a watermelon Jolly Rancher, which is the ghost’s favorite. The ghost takes pieces of candy without replacement until it gets the watermelon Jolly Rancher. How many pieces of candy do we expect the ghost to take?"
  },
  {
    "objectID": "slides/10_Expected_Values.html#some-more-remarks",
    "href": "slides/10_Expected_Values.html#some-more-remarks",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Some more remarks",
    "text": "Some more remarks\nRemark: Both examples are repeated random processes. They are fundamentally different though:\n\nThe bullseye example (6) is “with replacement” since the probability of success remains constant.\nThe ghost trick-or-treating example (7) is without replacement, and thus the probability of success changes with each trial.\n\n\n\nChapter 10 Slides"
  },
  {
    "objectID": "slides/10_Expected_Values.html#bullseye",
    "href": "slides/10_Expected_Values.html#bullseye",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Bullseye! 🎯",
    "text": "Bullseye! 🎯\n\n\n\n\nExample 5\n\n\nSuppose I throw darts at a dartboard until I hit the bullseye, and that my probability of hitting the bullseye is \\(p\\). Suppose further that all of my throws are independent, and that the probability of a bullseye never changes, no matter how many times I throw a dart. How many times should I expect to have to throw the dart until I hit the bullseye?"
  },
  {
    "objectID": "slides/10_Expected_Values.html#some-remarks-on-last-two-examples",
    "href": "slides/10_Expected_Values.html#some-remarks-on-last-two-examples",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Some remarks on last two examples",
    "text": "Some remarks on last two examples\nBoth examples are repeated random processes. They are fundamentally different though:\n\nThe bullseye example is “with replacement” since the probability of success remains constant.\nThe ghost trick-or-treating example is without replacement, and thus the probability of success changes with each trial.\n\n\n\nChapter 10 Slides"
  },
  {
    "objectID": "homework/HW4.html#directions",
    "href": "homework/HW4.html#directions",
    "title": "Homework 4",
    "section": "Directions",
    "text": "Directions\n\nPlease upload your homework to Sakai. Upload both your .Rmd code file and the knitted .html file.\nFor each question, make sure to include all code and resulting output in the html file to support your answers.\nShow the work of your calculations using R code within a code chunk. Make sure that both your code and output are visible in the knitted html file.\nWrite all answers in complete sentences as if communicating the results to a collaborator.\n\nPoints (usually 0.5-1) will be deducted for not including a sentence summarizing results in the context of the research study.\nQuestions not requiring a sentence are: none - include a summary for all questions\n\n\n\nTip: It is a good idea to try kitting your document from time to time as you go along! Note that knitting automatically saves your Rmd file and knitting frequently helps you catch your errors more quickly."
  },
  {
    "objectID": "homework/HW3.html#directions",
    "href": "homework/HW3.html#directions",
    "title": "Homework 3",
    "section": "Directions",
    "text": "Directions\n\nPlease upload your homework to Sakai. Upload both your .Rmd code file and the knitted .html file.\nFor each question, make sure to include all code and resulting output in the html file to support your answers.\nShow the work of your calculations using R code within a code chunk. Make sure that both your code and output are visible in the knitted html file.\nWrite all answers in complete sentences as if communicating the results to a collaborator.\n\nPoints (usually 0.5-1) will be deducted for not including a sentence summarizing results in the context of the research study.\nQuestions not requiring a sentence are from the last section “Regression with one categorical predictor” #2, 3, 5, 7.\n\n\n\nTip: It is a good idea to try kitting your document from time to time as you go along! Note that knitting automatically saves your Rmd file and knitting frequently helps you catch your errors more quickly."
  },
  {
    "objectID": "homework/HW7.html#directions",
    "href": "homework/HW7.html#directions",
    "title": "Homework 7",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n28\nTB # 18\nTB # 1, 10\n\n\n291\nTB # 26, NTB # 1, 3\nTB # 10, 14, 23, 11, 13, 32\n\n\n30\n\nTB # 4, 7-12\n\n\n31\nTB # 18\nTB # 13, 14, 17\n\n\n32\nTB # 8\nTB # 3, 5, 102, 15\n\n\n33\nNTB # 4\nTB # 3, 9, 10\n\n\n35\nTB # 10, NTB # 5\nTB # 6, 9, 24\n\n\n43\nTB # 93, 104, 11, 125, NTB # 6, 7, 8\nTB # 1-4, NTB # 9\n\n\n36\nTB # 126, 14\nTB # 4, 11, 13, 15, 16\n\n\n37\nTB # 24, 30\nTB # 2, 4, 13, 20, 29"
  },
  {
    "objectID": "homework/HW6.html#directions",
    "href": "homework/HW6.html#directions",
    "title": "Homework 6",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n19\nTB # 6\n# 1, 18, 19\n\n\n18\nTB # 24\n# 1, 26, 27\n\n\nCalculus Review\n\nNTB # 1\n\n\n24\nTB # 19, 20*\n# 2, 3, 7, 17, 18, 22, 23\n\n\n25\nTB # 18, NTB # 2\n# 1, 4, 8, 17, 23, 24\n\n\n26**\nTB # 12, NTB # 3, 4\n# 7, 9, 19, 20\n\n\n27\nTB # 12***\n# 6, 8, 13, 17\n\n\n\n\n* (Ch 24) Also find the cdf \\(F_X(x)\\)\n** Although within Chapter 26, these exercises are primarily practicing the material from Chapter 25.\n** For Ch 27 # 12, in order to find the conditional densities in parts (a) and (b), you will need to calculate \\(f_Y(y)\\) for the specific regions of \\(y\\) specified. After finding the conditional densities in parts (a) and (b), also calculate the conditional probabilities below. Please submit these together with your other work in parts (a) and (b):\n\nFind \\(\\mathbb{P}[0.5 &lt; X &lt; 3 | Y = 4]\\).\nFind \\(\\mathbb{P}[0.5 &lt; X &lt; 3 | Y = 7]\\).\n\n\nNon-textbook problems (NTB):\n\nCalculus Review\n\n\\[\\int_0^yc(x+y)dx\\]\n\\[\\frac{d}{dx}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\frac{d}{dy}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\int_0^y2e^{-x}e^{-y}dx\\]\n\\[\\int_0^\\infty xye^{-(x+y)}dy\\]\n\\[\\int_x^{2x} 2e^{-(x+3y)}dy\\]\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(y\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(y\\).\n\nLet \\(X_1, X_2, \\ldots, X_n\\) be i.i.d. random variables with common pdf \\(f_X(x)\\) and cdf \\(F_X(x)\\). Find the pdf for the random variable \\(Z\\), where \\(Z = max(X_1, X_2, \\ldots, X_n)\\).\nLet \\(X\\) and \\(Y\\) be independent random variables with respective pdf’s \\(f_X(x)=\\frac{1}{5}\\), for \\(0\\leq x\\leq 5\\), and \\(f_Y(y)=2e^{-2y}\\), for \\(y&gt;0\\).\n\nFind the joint distribution \\(f_{X,Y}(x,y)\\).\nFind the probability that \\(X\\) is less than \\(Y\\).\nLet \\(Z\\) be the random variable that is the smaller of \\(X\\) and \\(Y\\). Find the cumulative distribution function for \\(Z\\).\nFind the pdf for Z.\n\nSuppose that the random variables \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)\\), for \\(0&lt;x&lt;1\\), and \\(\\frac{1}{2}&lt;y&lt;1\\). Set up the equation for the cdf of \\(Z\\), where \\(Z=X/Y\\).\nHint: First determine what the possible values for \\(Z\\) are. Then make a sketch of the domain of the joint pdf and shade in the region representing the cdf of Z for different values of \\(z\\). Make sure to pay close attention to how the region we need to integrate over changes as \\(z\\) changes. The cdf has two different cases depending on the value of \\(z\\). Plug in specific values of \\(z\\) and shade in the region representing the cdf to see why two different cases are needed."
  },
  {
    "objectID": "homework/HW5.html#directions",
    "href": "homework/HW5.html#directions",
    "title": "Homework 5",
    "section": "Directions",
    "text": "Directions\n\nPlease upload your homework to Sakai. Upload both your .Rmd code file and the knitted .html file.\nFor each question, make sure to include all code and resulting output in the html file to support your answers.\nShow the work of your calculations using R code within a code chunk. Make sure that both your code and output are visible in the knitted html file.\nWrite all answers in complete sentences as if communicating the results to a collaborator.\n\nPoints (usually 0.5-1) will be deducted for not including a sentence summarizing results in the context of the research study.\nQuestions not requiring a sentence are: none - include a summary for all questions\n\n\n\nTip: It is a good idea to try kitting your document from time to time as you go along! Note that knitting automatically saves your Rmd file and knitting frequently helps you catch your errors more quickly.\n\n\nHW 5 specific directions\n\nFor all hypothesis tests, include\n\nthe null and alternative hypotheses (and if applicable the regression model(s) being tested),\nR code to run the test, and\na conclusion in the context of the problem.\n\nYou do not need to run the hypothesis tests using the formula unless directed otherwise."
  },
  {
    "objectID": "slides/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "href": "slides/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Revisiting our two card draw",
    "text": "Revisiting our two card draw\n\n\n\n\nExample 1\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw. Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "slides/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw-1",
    "href": "slides/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw-1",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Revisiting our two card draw",
    "text": "Revisiting our two card draw\n\n\n\n\nExample 2\n\n\nWhat is the expected number of hearts in Example 1 if you draw 200 cards?"
  },
  {
    "objectID": "slides/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "href": "slides/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Sum of discrete RVs",
    "text": "Sum of discrete RVs\n\n\nTheorem 11.1: Sum of discrete RVs\n\n\nFor discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^n a_iX_i\\Bigg] = \\sum_{i=1}^n a_i\\mathbb{E}[X_i] .\\] Remark: The theorem holds for infinitely r.v.’s \\(X_i\\) as well.\n\n\n\nFor two RVs, \\(X\\) and \\(Y\\):\n\nWe can say \\(E[X+Y] = E[X] + E[Y]\\)\n… and constant numbers \\(a\\) and \\(b\\), we can also say \\(E[aX+bY] = aE[X] + bE[Y]\\)\nWe can also also say \\(E[X-Y] = E[X] - E[Y]\\), since \\(b=-1\\)"
  },
  {
    "objectID": "slides/11_Expected_Values_of_Sums_of_rvs.html#corollaries",
    "href": "slides/11_Expected_Values_of_Sums_of_rvs.html#corollaries",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Corollaries",
    "text": "Corollaries\n\n\n\n\nCorollary 11.1.1\n\n\nFor a discrete r.v. \\(X\\), and constants \\(a\\) and \\(b\\), \\[\\mathbb{E}[aX+b] = a\\mathbb{E}[X] + b.\\]\n\n\n\n\n\nCorollary 11.1.2\n\n\nIf \\(X_i\\), \\(i=1,2,\\dots, n\\), are i.i.d. r.v.’s, then \\[\\mathbb{E}[\\sum_{i=1}^n X_i] = n\\mathbb{E}[X_1] .\\]"
  },
  {
    "objectID": "slides/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-ghost",
    "href": "slides/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-ghost",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Revisiting our ghost! 👻",
    "text": "Revisiting our ghost! 👻\n\n\n\n\nExample 3\n\n\nThe ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost takes five pieces of candy without replacement. How many pieces of chocolate do we expect the ghost to take?"
  },
  {
    "objectID": "slides/11_Expected_Values_of_Sums_of_rvs.html#hotels",
    "href": "slides/11_Expected_Values_of_Sums_of_rvs.html#hotels",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Hotels",
    "text": "Hotels\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Landport and needs to book 30 hotel rooms. The average price of a room is $200. In addition, there is a 10% tourism tax for each room. What is the expected cost for the 30 hotel rooms?\n\n\n\n\n\n\nChapter 11 Slides"
  },
  {
    "objectID": "slides/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "href": "slides/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Cost of hotel rooms",
    "text": "Cost of hotel rooms\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200. In addition, there is a 10% tourism tax for each room. What is the expected cost for the 30 hotel rooms?\n\n\n\n\n\n\nChapter 11 Slides"
  },
  {
    "objectID": "slides/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "href": "slides/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Corollaries from Thm 11.1",
    "text": "Corollaries from Thm 11.1\n\n\n\n\nCorollary 11.1.1\n\n\nFor a discrete r.v. \\(X\\), and constants \\(a\\) and \\(b\\), \\[\\mathbb{E}[aX+b] = a\\mathbb{E}[X] + b.\\]\n\n\n\n\n\nCorollary 11.1.2\n\n\nIf \\(X_i\\), \\(i=1,2,\\dots, n\\), are i.i.d. r.v.’s, then \\[\\mathbb{E}\\bigg[\\sum_{i=1}^n X_i\\bigg] = n\\mathbb{E}[X_1] .\\]"
  },
  {
    "objectID": "slides/10_Expected_Values.html#bullseye-.visibilityhidden",
    "href": "slides/10_Expected_Values.html#bullseye-.visibilityhidden",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Bullseye! 🎯 {.visibility=“hidden”}",
    "text": "Bullseye! 🎯 {.visibility=“hidden”}\n\n\n\n\nExample 5\n\n\nSuppose I throw darts at a dartboard until I hit the bullseye, and that my probability of hitting the bullseye is \\(p\\). Suppose further that all of my throws are independent, and that the probability of a bullseye never changes, no matter how many times I throw a dart. How many times should I expect to have to throw the dart until I hit the bullseye?"
  },
  {
    "objectID": "slides/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "href": "slides/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "What if we draw A LOT of cards?",
    "text": "What if we draw A LOT of cards?\n\n\n\n\nExample 2\n\n\nWhat is the expected number of hearts in Example 1 if you draw 200 cards?\n\n\n\n\nRecall Binomial RV with \\(n=200\\):\n\\[p_X(x) = {200 \\choose x}p^x(1-p)^{200-x}\\] \\[\\text{  for } x = 0, 1, 2, ..., 200\\]"
  },
  {
    "objectID": "slides/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "href": "slides/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "slides/01_SLR.html#nicky-wakim-sheher",
    "href": "slides/01_SLR.html#nicky-wakim-sheher",
    "title": "Simple Linear Regression (SLR)",
    "section": "Nicky Wakim (she/her)",
    "text": "Nicky Wakim (she/her)\n\n\n\nCall me “Nicky,” “Dr. W,” “Professor Wakim,” or any combo!\nAssistant Professor of Biostatistics\n \nOriginally from DC area (Virginia side!)\nTwo kitties\nVolleyball, biking, spikeball, pickleball\nBut also sleeping, TV, and reading\nJust started taking a couple classes at PCC (French, ceramics, yoga)\nSlowly regrowing my plant collection after moving from Michigan\n\n\n\n\n Video"
  },
  {
    "objectID": "slides/01_SLR.html#some-important-tasks",
    "href": "slides/01_SLR.html#some-important-tasks",
    "title": "Simple Linear Regression (SLR)",
    "section": "Some important tasks",
    "text": "Some important tasks\n\nJoin the Slack page!\nStar the class website: https://nwakim.github.io/F2023_BSTA_550/\nComplete the WhenIsGood for office hours\nComplete Homework 0 by this Thursday at 11pm!\nHighly suggest that you make an appointment with a learning specialist through Student Academic Support Services!"
  },
  {
    "objectID": "slides/01_SLR.html#lets-visit-the-website",
    "href": "slides/01_SLR.html#lets-visit-the-website",
    "title": "Simple Linear Regression (SLR)",
    "section": "Let’s visit the website",
    "text": "Let’s visit the website\n\nHomepage\n\nGitHub\n\nSyllabus\nSchedule\n\nWeeks, class info, exams, homeworks\n\nSearch\n\n\n\nImportant Note\n\n\nThis is my first time teaching the course. I will work hard to answer your questions in class, but I will often need some time outside of class to make sure I give you the best answer possible! Also, many of the examples are not my own. I will work to improve examples, but if you have feedback or suggestions, I am happy to hear them!"
  },
  {
    "objectID": "slides/01_SLR.html#lets-go-through-the-syllabus",
    "href": "slides/01_SLR.html#lets-go-through-the-syllabus",
    "title": "Simple Linear Regression (SLR)",
    "section": "Let’s go through the syllabus!",
    "text": "Let’s go through the syllabus!\nSyllabus page\n\n\nIntro"
  },
  {
    "objectID": "slides/01_SLR.html#simple-linear-regression-model",
    "href": "slides/01_SLR.html#simple-linear-regression-model",
    "title": "Simple Linear Regression (SLR)",
    "section": "Simple Linear Regression Model",
    "text": "Simple Linear Regression Model\nThe (population) regression line is denoted by:\n\n\\[\\begin{aligned}\nY & =  \\beta_0 + \\beta_1X + \\epsilon \\nonumber\n\\end{aligned}\\]\n\n\n\\(\\beta_0\\) and \\(\\beta_1\\) are unknown population parameters\n\\(\\epsilon\\) (epsilon) is the error about the line\n\nIt is assumed to be a random variable with a…\nNormal distribution with mean 0 and constant variance \\(\\sigma^2\\)\n\nOur goal is to estimate \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma^2\\)\n\nThe point estimates based on a sample are denoted by \\(\\hat{\\beta_0}\\), \\(\\hat{\\beta_1}\\), and \\(\\hat{\\sigma^2}\\)"
  },
  {
    "objectID": "slides/01_SLR.html#linear-models",
    "href": "slides/01_SLR.html#linear-models",
    "title": "Simple Linear Regression (SLR)",
    "section": "“Linear” Models",
    "text": "“Linear” Models"
  },
  {
    "objectID": "slides/01_SLR.html#model-components",
    "href": "slides/01_SLR.html#model-components",
    "title": "Simple Linear Regression (SLR)",
    "section": "Model Components",
    "text": "Model Components"
  },
  {
    "objectID": "slides/01_SLR.html#interpretations",
    "href": "slides/01_SLR.html#interpretations",
    "title": "Simple Linear Regression (SLR)",
    "section": "Interpretations",
    "text": "Interpretations"
  },
  {
    "objectID": "slides/01_SLR.html#parameter-estimation-best-fit-line",
    "href": "slides/01_SLR.html#parameter-estimation-best-fit-line",
    "title": "Simple Linear Regression (SLR)",
    "section": "Parameter estimation: best fit line",
    "text": "Parameter estimation: best fit line"
  },
  {
    "objectID": "slides/01_SLR.html#least-squares-model-assumptions",
    "href": "slides/01_SLR.html#least-squares-model-assumptions",
    "title": "Simple Linear Regression (SLR)",
    "section": "Least squares model assumptions",
    "text": "Least squares model assumptions"
  },
  {
    "objectID": "slides/01_SLR.html#estimate-of-variance",
    "href": "slides/01_SLR.html#estimate-of-variance",
    "title": "Simple Linear Regression (SLR)",
    "section": "Estimate of variance??",
    "text": "Estimate of variance??\n\n\nIntro"
  },
  {
    "objectID": "slides/00_Intro.html",
    "href": "slides/00_Intro.html",
    "title": "Welcome to BSTA 512/612!",
    "section": "",
    "text": "Call me “Nicky,” “Dr. W,” “Professor Wakim,” or any combo!\nAssistant Professor of Biostatistics\n \nOriginally from DC area (Virginia side!)\nTwo kitties\nVolleyball, biking, pickleball\nBut also sleeping, TV, and reading\nJust started taking a couple classes at PCC (French, ceramics, yoga)\nSlowly regrowing my plant collection after moving from Michigan\n\n\n\n\n Video"
  },
  {
    "objectID": "slides/00_Intro.html#nicky-wakim-sheher",
    "href": "slides/00_Intro.html#nicky-wakim-sheher",
    "title": "Welcome to BSTA 512/612!",
    "section": "Nicky Wakim (she/her)",
    "text": "Nicky Wakim (she/her)\n\n\n\nCall me “Nicky,” “Dr. W,” “Professor Wakim,” or any combo!\nAssistant Professor of Biostatistics\n \nOriginally from DC area (Virginia side!)\nTwo kitties\nVolleyball, biking, pickleball\nBut also sleeping, TV, and reading\nJust started taking a couple classes at PCC (French, ceramics, yoga)\nSlowly regrowing my plant collection after moving from Michigan\n\n\n\n\n Video"
  },
  {
    "objectID": "slides/00_Intro.html#some-important-tasks",
    "href": "slides/00_Intro.html#some-important-tasks",
    "title": "Welcome to BSTA 512/612!",
    "section": "Some important tasks",
    "text": "Some important tasks\n\nJoin the Slack page!\nStar the class website: https://nwakim.github.io/W2024_BSTA_512/\nComplete the WhenIsGood for office hours\nComplete Homework 0 by this Thursday at 11pm!\nHighly suggest that you make an appointment with a learning specialist through Student Academic Support Services!"
  },
  {
    "objectID": "slides/00_Intro.html#lets-visit-the-website",
    "href": "slides/00_Intro.html#lets-visit-the-website",
    "title": "Welcome to BSTA 512/612!",
    "section": "Let’s visit the website",
    "text": "Let’s visit the website\n\nHomepage\n\nGitHub\n\nSyllabus\nSchedule\n\nWeeks, class info, quizzes, homeworks, projects\n\nSearch\n\n\n\nImportant Note\n\n\nThis is my first time teaching the course. I will work hard to answer your questions in class, but I will often need some time outside of class to make sure I give you the best answer possible! Also, many of the examples are not my own. I will work to improve examples, but if you have feedback or suggestions, I am happy to hear them!"
  },
  {
    "objectID": "slides/00_Intro.html#lets-go-through-the-syllabus",
    "href": "slides/00_Intro.html#lets-go-through-the-syllabus",
    "title": "Welcome to BSTA 512/612!",
    "section": "Let’s go through the syllabus!",
    "text": "Let’s go through the syllabus!\nSyllabus page\n\n\nIntro"
  },
  {
    "objectID": "weeks/week_02_sched.html",
    "href": "weeks/week_02_sched.html",
    "title": "Week 2",
    "section": "",
    "text": "```{css, echo=FALSE} .title{ font-size: 40px; color: #006a4e; background-color: #fff; padding: 10px; }\n.description{ font-size: 20px; color: #fff; background-color: #006a4e; padding: 10px; } ```"
  },
  {
    "objectID": "weeks/week_02_sched.html#statistician-of-the-week",
    "href": "weeks/week_02_sched.html#statistician-of-the-week",
    "title": "Week 2",
    "section": "Statistician of the Week",
    "text": "Statistician of the Week"
  },
  {
    "objectID": "slides/Module_A.html",
    "href": "slides/Module_A.html",
    "title": "Linear Regression",
    "section": "",
    "text": "&lt;!DOCTYPE html&gt;\n\n\n\n\n\n\nModule A\n\n\n\n\n\n\n\n\nBIOSTAT 650 Theory and Application of Linear Regression Module A: Introduction\n\n\n\n\nOutline Syllabus Module A Topics: Introduction to linear regression Overview of specific topics in BIOSTAT 650 Review of basic material\n\n\n\n\nCourse Description:  This is the first course in applied statistics for both incoming MS, MPH and PhD students. It is taught at the MS level.\n\n\nBoth theoretical and applied aspects of linear regression modeling will be covered in this course, including model building, model refinement, model diagnostics, hypothesis testing, parameter interpretation and scientific interpretation of results.\n\n\nStudents are expected to use R or SAS, when necessary, for homework assignments.\n\n\nTopics to be covered include simple linear regression, multiple regression, analysis of variance, residual and influence diagnostics, variable transformations, multicollinearity, model selection and validation.\n\n\n\n\nCourse Objectives:  The overall objective of this course is to help the student integrate and apply linear regression methods to scientific studies.\n\n\nThe student will learn to identify the scientific goals of a study\n\n\ndevelop a statistical strategy appropriate for those goals\n\n\nplan strategies for linear regression analysis and to implement these strategies\n\n\nbe aware of problems that arise in study design, power and data collection\n\n\ninterpret the results of linear regression analysis and convert them into a language understandable to the broad scientific community\n\n\n\n\nSchedule\n\n\nOnline class: M/W 1:00pm - 3:00pm Online lectures will be recorded No class on Sep 6 (Labor Day), Oct 18 (Fall Study Break)\n\n\nOffice hours (OH): Office hours will NOT be recorded Monday TBD (GSI) Wednesday 3:00pm - 5:00pm (instructor) Mousumi: please change to yours Note: if you are in a very different time zone, please email the instructor to schdule a separate OH when needed Exams and project Midterm I    (20%): Oct 6 (in class) Midterm II   (20%): Nov 22 (in class) Final project (30%): Group presentation on Dec 6 and 8 Final project (30%): Final report due on Dec 10\n\n\n\n\n Homework 30% Approximately weekly homework due on Mondays Suggestions: Begin working on homework questions shortly after they are assigned Attempt all homework questions alone (thoughtfully), before consulting others\n\n\nEthics: Collaborating on homework is OK, but homework turned in should reflect each student’s understanding Regrade policy: Please carefully review the homework/exam solution. To request a revised grade, please see the instructor or GSI during office hours. If no misgrading is found after examination of your case, your grade will be further lowered by the same amount (X points). A grade is considered “final” two weeks after it has been posted\n\n\n\n\nEmailing\n\n\nWe strongly encourage you to come to the office hour if you have technical questions such as how to approach a particular homework problem. Discussion on technical issues over email is inefficient.\n\n\nWhen emailing about this course, please put “BIOSTAT650” (no space) into the subject line\n\n\n\n\nOther suggestions Always try to think about “Why is this material important?” (if unclear, then ask) explain concepts/methods/results in layman language and/or in a graph\n\n\nHelp me, your classmates, and yourself learn better by Asking questions in class (raise your hand or type in the chat box) Turning your video on (not required but recommended)\n\n\nSpend time: 4 credit hour class means In class: 4 hours per week Outside of class: 8 to 12 hours per week (=2 to 3 hours for each credit)\n\n\n\n\nIntroduction to Linear Regression\n\n\n\n\nWhat is Linear Regression? Regression: a technique to study the association between two variables Response variable (outcome, dependent variable) Blood pressure Grouping variable (predictor, independent variable, explanatory variable) Male vs female – within each group, the value of the grouping variable is constant Drug dosage – continuous predictor of interest, infinitely many groups Adjustment for other variables\n\n\nLinear model: for our purposes, refers to linearity w.r.t. the parameters\n\n\nResponse variable is a linear function of parameters\n\n\nRegression models describe association, not causality\n\n\n\n\nWhy should I care? Most widely used and most developed method in statistics Appropriate in many practical settings Important to understand limitations Easy to interpret\n\n\nFun fact: one of the most frequently asked data scientist interview question What are the assumptions underlying linear regression?\n\n\n\n\nWhy should I care?\n\n\nMost importantly, it serves as a building block Essential concepts and ideas extend well to other regression methods and other areas e.g. you will see the following generic equation frequently: \\(\\sum_{i=1}^nX_i\\trans(Y_i-\\mu_i)=0\\) where \\(\\mu_i=X_i\\trans\\beta\\) in linear regression It says “the residuals are orthogonal to the covariates”\n\n\nTechniques used in linear regression apply to other regression methods e.g. estimation, hypothesis testing, model diagnosis\n\n\n\n\nLinear Regression: Objectives\n\n\nObjectives of any data analysis can generally be categorized as either inference or prediction\n\n\nrare that only one objective of interest in practice, both are usually of various degrees of importance\n\n\nInference:\n\n\nEstimation Hypothesis testing\n\n\n\n\nInference: Estimation \n\n\nIncludes both point and interval estimation\n\n\nSign of regression coefficient may be of interest; or, both sign and magnitude e.g., estimate mean change in serum cholesterol per unit increase in BMI model parameters must have clear interpretation (limits complexity of model)\n\n\n\n\nInference: Hypothesis Testing\n\n\nWe observe the data in the study sample; what can we infer about the underlying population of interest?\n\n\nHypothesis testing reduces results of study down to a sequence of yes/no answers\n\n\nModel parameters must be interpretable for inference to be meaningful\n\n\ne.g., on average, does serum cholesterol change as BMI (body mass index) increases? what about each of the following: age, gender, race, SBP (systolic blood pressure)?\n\n\n\n\nPrediction\n\n\nUsing regression model to predict response for yet unobserved subjects Accuracy and precision of predictions take precedence over interpretability of regression parameters\n\n\ne.g., develop a linear regression model to predict serum cholesterol given a set of patient characteristics (age, gender, race, BMI, SBP, etc)\n\n\n\n\n Data Analysis Process: Overview\n\n\nDescriptive analysis often skipped or done carelessly\n\n\nVERY important first step\n\n\nPropose model often done in close consultation with investigators\n\n\nEstimate model parameters\n\n\nAssess underlying assumptions of model → return to (1)?\n\n\nHypothesis testing and/or prediction\n\n\nInterpretation, conclusions\n\n\n\n\nWhat will be covered in BIOSTAT 650?\n\n\n\n\nSimple Linear Regression: one predictor SLR features one response variable and a single covariate\n\n\nModel: Yi = β0 + β1Xi + ϵi\n\n\nYi: response β0, β1: parameters Xi: covariate ϵi: error\n\n\n“Simple”: one covariate only\n\n\nRather restrictive since only one covariate is involved\n\n\noften, interest lies in several covariates if only interested in one certain covariate, may need to adjust for other covariates\n\n\n\n\nMultiple Linear Regression: multiple predictors\n\n\nMultiple Regression: q(&gt;1) covariates Model Yi = β0 + β1Xi1 + β2Xi2 + … + βqXiq + ϵi\n\n\n\n\n0.01\n\n\n\n0.75\n\n\nFor compactness, often use matrix notation Compared to simple linear regression βj’s have much different interpretation\n\n\nMuch more complicated than SLR; Much greater chance to mis-model the data set\n\n\n\n0.25 \n\n\n\n\n\n\nResidual Diagnostics  Most of the assumptions underlying linear regression model are about the error term: \\[\\begin{split}\n            \\epsilon_i &amp; \\sim  N(0,\\sigma^2)  \\\\\n            \\epsilon_i &amp; \\ind \\epsilon_j,\\; \\forall i, \\;j,\\; i\\neq\nj\n        \\end{split}\\] Failure of any of these assumptions to hold could invalidate various aspects of the analysis\n\n\nResiduals = estimated errors: ϵ̂i\n\n\nResidual diagnostics aims to check validity of error assumptions after model fitting\n\n\nresults of residual diagnostics could imply that modifications to model are required\n\n\n\n\nTransformations of the outcome Consider the following SLR model: Yi = β0 + β1Xi + ϵi It is possible that, instead, some function of Yi, say h(Yi), should be modeled: h(Yi) = β0 + β1Xi + ϵi Possible choices for h(⋅): $$\n\\[\\begin{aligned}\n            h(Y_i) &amp; = &amp; \\log(Y_i) \\nonumber \\\\\n            h(Y_i) &amp; = &amp; \\log_{10}(Y_i) \\nonumber \\\\\n            h(Y_i) &amp; = &amp; \\sqrt{Y_i} \\nonumber \\\\\n            h(Y_i) &amp; = &amp; 1/Y_i \\nonumber\n            \n\\end{aligned}\\]\n\\[&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt; Transformations of the covariate(s)&lt;/span&gt; Consider the\nfollowing SLR model: &lt;span class=\"math display\"&gt;\\]\n\\[\\begin{aligned}\n        Y_i &amp; = &amp; \\beta_0 + \\beta_1X_{i} +  \\beta_2 X^2_{i} +\n\\epsilon_i \\nonumber\n        \n\\end{aligned}\\]\n\\[&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;This is still a linear model! “Linear\" refers to being linear in the\ncoefficients Transformation of the covariate can include &lt;span\nclass=\"math display\"&gt;\\]\n\\[\\begin{aligned}\n            &amp;   &amp;  \\log(X_i) \\nonumber \\\\\n            &amp;   &amp;X^2_{i}, \\cdots, X^q_{i}   \\nonumber \\\\\n            &amp;   &amp;\\sqrt{X_i} \\nonumber \\\\\n            &amp;   &amp; \\mbox{splines:} ~~~ (X_i-a)_+\\nonumber\n            \n\\end{aligned}\\]\n\\[&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Transformations&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Need to be very careful when using transformations&lt;/p&gt;\n&lt;p&gt;interpretation of parameters changes completely transforming the\noutcome alters assumptions regarding error structure&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Outliers/Influence Diagnostics&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Consider the fitted model: &lt;span\nclass=\"math display\"&gt;&lt;em&gt;Ŷ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;β̂&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; + &lt;em&gt;β̂&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;em&gt;X&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;What impact does &lt;span\nclass=\"math inline\"&gt;(&lt;em&gt;X&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;,&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;)&lt;/span&gt;\nhave on &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Ŷ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;? How much\ndoes the &lt;span class=\"math inline\"&gt;&lt;em&gt;i&lt;/em&gt;&lt;/span&gt;’th subject\ninfluence &lt;span class=\"math inline\"&gt;&lt;em&gt;β̂&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;/span&gt;? By\nwhat amount would &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;β̂&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/span&gt; change if the &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;i&lt;/em&gt;&lt;/span&gt;’th subject were deleted? If the\n&lt;span class=\"math inline\"&gt;&lt;em&gt;i&lt;/em&gt;&lt;/span&gt;’th observation heavily\ninfluences &lt;span class=\"math inline\"&gt;&lt;em&gt;β̂&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/span&gt;,\nshould it be removed?&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Multicollinearity&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Consider: linear regression model with covariates &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;, …, &lt;em&gt;X&lt;/em&gt;&lt;sub&gt;&lt;em&gt;q&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;\nCovariates are not assumed to be independent (e.g., age, height, weight,\netc) However, extreme correlations among the covariates interferes with\nthe model fitting:&lt;/p&gt;\n&lt;p&gt;may be impossible to compute &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;β̂&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;’s computed\n&lt;span class=\"math inline\"&gt;&lt;em&gt;β̂&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;’s may\nhave extremely large standard errors fitted model may be quite\nunreliable&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Model Selection&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Consider: state-wide survey, wherein information on 30 covariates\ncollected&lt;/p&gt;\n&lt;p&gt;When objective is to find the ‘best’ model, several algorithms may\nsimplify the process&lt;/p&gt;\n&lt;p&gt;Forward Selection: start with 0 covariates add (most significant)\ncovariates one at a time until further addition does not improve the\nmodel’s fit&lt;/p&gt;\n&lt;p&gt;Backward Elimination: start with full model successively delete\n(least significant) covariates, until such deletions results in marked\ndecrease in model’s adequacy&lt;/p&gt;\n&lt;p&gt;Stepwise Selection: combination of forward selection and backward\nelimination&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Model Validation &lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Concept: how accurate is the fitted model on new data (not used to\ncompute the parameter estimates)&lt;/p&gt;\n&lt;p&gt;e.g., data splitting:&lt;/p&gt;\n&lt;p&gt;split data set in two fit model to first half of data set, &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;β̂&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;, …, &lt;em&gt;β̂&lt;/em&gt;&lt;sub&gt;&lt;em&gt;p&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;&lt;/span&gt;\ncompare &lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;\nand &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Ŷ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;&lt;/span&gt;,\nin second half of data set&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Weighted Regression&lt;/span&gt; Units &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;i&lt;/em&gt;&lt;/span&gt; are not always sampled completely\nat random Surveys may oversample certain subpopulations&lt;/p&gt;\n&lt;p&gt;Some units are given more weight during the estimation process&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Linear vs. &lt;span&gt;&lt;em&gt;Generalized&lt;/em&gt;&lt;/span&gt; Linear\nModels&lt;/span&gt; Linear regression: &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt; assumed to be\ncontinuous&lt;br /&gt;\n(and &lt;span class=\"math inline\"&gt;&lt;em&gt;ϵ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt; is\nnormally distributed)&lt;/p&gt;\n&lt;p&gt;Suppose &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt; is an\nindicator variable (e.g., 1=cancer; 0=cancer-free)&lt;/p&gt;\n&lt;p&gt;&lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;\nfollows a Bernoulli distribution assumptions of linear regression\nblatantly violated&lt;/p&gt;\n&lt;p&gt;Generalized Linear Model (GLM): used to model non-Normal responses;\ne.g.,&lt;/p&gt;\n&lt;p&gt;&lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;∼&lt;/span&gt;\nBernoulli/Binomial: logistic regression &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt; is a count:\nPoisson regression&lt;/p&gt;\n&lt;p&gt;Will study GLM extensively in BIOSTAT 651&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Multiple vs.\n&lt;span&gt;&lt;em&gt;Multivari&lt;span&gt;&lt;u&gt;ate&lt;/u&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;\nregression&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Simple linear regression (this course): one outcome &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;, one predictor variable &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Multiple linear regression (this course): one outcome &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;, multiple predictor variables\n&lt;span class=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Multivari&lt;span&gt;&lt;u&gt;ate&lt;/u&gt;&lt;/span&gt;&lt;/em&gt; regression: multiple\noutcome variables &lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;, e.g. same\noutcome measured repeatedly over time multiple related outcomes (e.g.,\nheight and weight) considered simultaneously as outcome can be of any\ndistribution, i.e., multivariate GLM&lt;/p&gt;\n&lt;p&gt;Will study multivariate regression extensively in BIOSTAT 653&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;&lt;span style=\"color: royalblue\"&gt;&lt;strong&gt;In class\nexercise&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;\n&lt;span&gt;&lt;span style=\"color: royalblue\"&gt;&lt;strong&gt;Maternal Bone Lead as an\nIndependent Risk Factor for Fetal Neurotoxicity: A Prospective\nStudy&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Background&lt;/span&gt; Lead (Pb) is a neurotoxicant It is associated\nwith decreased mental development (in children), and accelerated mental\ndecline in the elderly.&lt;/p&gt;\n&lt;p&gt;Studies typically measure lead concentrations in blood, and correlate\nthem (e.g., linear regression) with measurements of intelligence (e.g.,\nBAYLEY mental development index, IQ tests)&lt;/p&gt;\n&lt;p&gt;Prenatal exposure measurements typically assessed by amount of lead\nin umbilical cord&lt;/p&gt;\n&lt;p&gt;Novel biomarker is bone lead concentration—premise is that lead\nleaches out of the mother’s bones throughout pregnancy&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Gomaa et al. Study Objective and Design&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Prospective Study: Children-mothers recruited at birth, followed\nuntil children are 24 months old&lt;/p&gt;\n&lt;p&gt;Research question: is lead exposure associated with mental\ndevelopment?&lt;/p&gt;\n&lt;p&gt;Lead exposure is measured by: Lead concentration in umbilical blood\nLead concentration in maternal bones&lt;/p&gt;\n&lt;p&gt;Mental development Is measured by: BAYLEY’s index of mental\ndevelopment (MDI)&lt;/p&gt;\n&lt;p&gt;Statistical question: Test if umbilical cord blood lead and bone lead\nconcentration are predictors of BAYLEY’s MDI&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Confounding Variables &lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;What are confounders? A confounder can make the observed association\nappear stronger than the true association, weaker than the true\nassociation, or even the reverse of the true association&lt;/p&gt;\n&lt;p&gt;Confounders in this case:&lt;/p&gt;\n&lt;p&gt;demographics (age, gender, education, marital status) Breastfeeding\nduration Maternal IQ&lt;/p&gt;\n&lt;p&gt;Sometimes confounders and predictor variables are called\n“covariates”&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Acknowledgement&lt;/span&gt;&lt;/p&gt;\n&lt;table&gt;\n&lt;tbody&gt;\n&lt;tr class=\"odd\"&gt;\n&lt;td style=\"text-align: center;\"&gt;&lt;img src=\"pic/mousumibanerjee\"\nstyle=\"height:30mm\" alt=\"image\" /&gt;&lt;/td&gt;\n&lt;td style=\"text-align: center;\"&gt;&lt;img src=\"pic/brisa\" style=\"height:30mm\"\nalt=\"image\" /&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"even\"&gt;\n&lt;td style=\"text-align: center;\"&gt;Mousumi Banerjee&lt;/td&gt;\n&lt;td style=\"text-align: center;\"&gt;Brisa N. Sánchez&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"odd\"&gt;\n&lt;td style=\"text-align: center;\"&gt;University of Michigan&lt;/td&gt;\n&lt;td style=\"text-align: center;\"&gt;Drexel University&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;Thank you for your slides!&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span style=\"color: royalblue\"&gt;&lt;strong&gt;Brief Review of Basic\nStatistics&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Basic Statistics&lt;/span&gt;&lt;/p&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.5&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Random variable &lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt; Sample\n&lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;, &lt;em&gt;i&lt;/em&gt; = 1, …, &lt;em&gt;n&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Summation: &lt;span class=\"math inline\"&gt;$\\sum_{i=1}^n Y_i =Y_1 + Y_2 +\n\\ldots + Y_n$&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Product: &lt;span class=\"math inline\"&gt;$\\prod_{i=1}^n Y_i = Y_1 \\times\nY_2 \\times \\ldots \\times Y_n$&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Expected Value (or mean): &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;μ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;E&lt;/em&gt;[&lt;em&gt;Y&lt;/em&gt;] = ∫&lt;sub&gt;−∞&lt;/sub&gt;&lt;sup&gt;∞&lt;/sup&gt;&lt;em&gt;y&lt;/em&gt;&lt;em&gt;f&lt;/em&gt;(&lt;em&gt;y&lt;/em&gt;)&lt;em&gt;d&lt;/em&gt;&lt;em&gt;y&lt;/em&gt;&lt;/span&gt;\nreflects ‘center’ of &lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;’s\ndistribution&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.5&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Rules of Expected Values &lt;/span&gt;&lt;/p&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.5&lt;/span&gt; Expectation of sum: &lt;span\nclass=\"math inline\"&gt;$E\\left[\\sum_{i=1}^n Y_i \\right] = \\sum_{i=1}^n\nE[Y_i]\n        \\nonumber$&lt;/span&gt; No assumption of independence required&lt;/p&gt;\n&lt;p&gt;Let &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;a&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;, …, &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;\nbe constants &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;E&lt;/em&gt;[&lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;] = &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;em&gt;E&lt;/em&gt;[&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;]&lt;/span&gt;&lt;br /&gt;\n&lt;span class=\"math inline\"&gt;$E\\left[\\sum_{i=1}^n a_iY_i\n        \\right] = \\sum_{i=1}^n a_iE[Y_i]$&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Expectation of product: &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;E&lt;/em&gt;[&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;] = &lt;em&gt;E&lt;/em&gt;[&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;]&lt;em&gt;E&lt;/em&gt;[&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;]&lt;/span&gt;&lt;br /&gt;\nif &lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt; and\n&lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt; are\nindependent&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.5&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Variance and standard deviation&lt;/span&gt;&lt;/p&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.5&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Variance: &lt;span class=\"math display\"&gt;\\]\n\\[\\begin{split}\n        &amp;Var(Y) =  E[(Y-\\mu_Y)^2]\\\\\n        = &amp;\\int_{-\\infty}^\\infty (y-\\mu_Y)^2 f(y) dy\n        %=  E[Y^2] - \\mu_Y^2\n        \\end{split}\\]\n\\[&lt;/span&gt; reflects spread of &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;’s distribution units: (units of\n&lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;)&lt;span\nclass=\"math inline\"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Standard deviation: &lt;span class=\"math display\"&gt;\\]\n\\[\\begin{split}\n        SD(Y)  = &amp;\\; \\sqrt{Var(Y)}  \\\\\n        SD(aY)  = &amp;\\; aSD(Y)\n        \\end{split}\\]\n\\[&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;reflects dispersion in &lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;’s\ndistribution measured in same unit as &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.5&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Rules of Variances&lt;/span&gt;&lt;/p&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.5&lt;/span&gt; Variance&lt;br /&gt;\n&lt;span\nclass=\"math inline\"&gt;&lt;em&gt;V&lt;/em&gt;&lt;em&gt;a&lt;/em&gt;&lt;em&gt;r&lt;/em&gt;(&lt;em&gt;Y&lt;/em&gt;) = &lt;em&gt;E&lt;/em&gt;[(&lt;em&gt;Y&lt;/em&gt;−&lt;em&gt;μ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;]&lt;/span&gt;&lt;br /&gt;\n&lt;span class=\"math inline\"&gt;${\\color{white}{Var(Y)}} =E[Y^2] -\n\\mu_Y^2$&lt;/span&gt; Variance of linear combination: &lt;span\nclass=\"math display\"&gt;\\]\n\\[\\begin{split}\n        &amp;~Var(aY+b)\\\\\n         = &amp;~ Var(aY) \\\\\n         = &amp;~ E[(aY-E[aY])^2]\\\\\n         = &amp;~ a^2 E[(Y-E[Y])^2]\\\\\n         = &amp;~ a^2 Var(Y)\n        \\end{split}\\]\n\\[&lt;/span&gt; &lt;img src=\"pic/shift\" style=\"height:0.7in\"\nalt=\"image\" /&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.5&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Covariance&lt;/span&gt;&lt;/p&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.6&lt;/span&gt; &lt;span class=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt;, &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;: random variables Covariance:\n&lt;span\nclass=\"math inline\"&gt;cov(&lt;em&gt;Y&lt;/em&gt;,&lt;em&gt;X&lt;/em&gt;) = &lt;em&gt;E&lt;/em&gt;[(&lt;em&gt;Y&lt;/em&gt;−&lt;em&gt;μ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/sub&gt;)(&lt;em&gt;X&lt;/em&gt;−&lt;em&gt;μ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;X&lt;/em&gt;&lt;/sub&gt;)]&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Measures (linear) association between &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt;, &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;&lt;br /&gt;\n&lt;span&gt;&lt;span class=\"math inline\"&gt; &gt; 0&lt;/span&gt;, large values of &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt; tend to occur with large values of\n&lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;&lt;br /&gt;\n&lt;span class=\"math inline\"&gt; &lt; 0&lt;/span&gt;, large values of &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt; tend to coincide with small values\nof &lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;&lt;br /&gt;\n&lt;span class=\"math inline\"&gt; = 0&lt;/span&gt;, size of &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt; provides no information on size of\n&lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;&lt;/span&gt; When the covariance\nis calculated, the data are not standardized Not scale-invariant: can\ninterpret direction but not magnitude&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.4&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Correlation&lt;/span&gt;&lt;/p&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.5&lt;/span&gt; &lt;span class=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt;, &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;: random variables Correlation:\n&lt;span class=\"math inline\"&gt;$\\mbox{corr}(X,Y) =\n\\frac{\\mbox{cov}(X,Y)}{SD(X)SD(Y)}$&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Scaled measure of linear association,&lt;/p&gt;\n&lt;p&gt;&lt;span\nclass=\"math inline\"&gt; − 1 ≤ corr(&lt;em&gt;X&lt;/em&gt;,&lt;em&gt;Y&lt;/em&gt;) ≤ 1&lt;/span&gt; easier\nto interpret than covariance&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.5&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Rules of covariance &lt;/span&gt; &lt;span\nclass=\"math inline\"&gt;cov(&lt;em&gt;Y&lt;/em&gt;,&lt;em&gt;X&lt;/em&gt;) = &lt;em&gt;E&lt;/em&gt;[(&lt;em&gt;Y&lt;/em&gt;−&lt;em&gt;μ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/sub&gt;)(&lt;em&gt;X&lt;/em&gt;−&lt;em&gt;μ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;X&lt;/em&gt;&lt;/sub&gt;)] = &lt;em&gt;E&lt;/em&gt;[&lt;em&gt;X&lt;/em&gt;&lt;em&gt;Y&lt;/em&gt;] − &lt;em&gt;E&lt;/em&gt;[&lt;em&gt;X&lt;/em&gt;]&lt;em&gt;E&lt;/em&gt;[&lt;em&gt;Y&lt;/em&gt;]&lt;/span&gt;\n&lt;span\nclass=\"math inline\"&gt;cov(&lt;em&gt;Y&lt;/em&gt;,&lt;em&gt;Y&lt;/em&gt;) = var(&lt;em&gt;Y&lt;/em&gt;)&lt;/span&gt;\nIndependent &lt;span\nclass=\"math inline\"&gt;$\\stackrel{\\Rightarrow}{\\not\\Leftarrow}$&lt;/span&gt;\nuncorrelated If &lt;span class=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt; and &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt; are independent, &lt;span\nclass=\"math inline\"&gt;cov(&lt;em&gt;X&lt;/em&gt;,&lt;em&gt;Y&lt;/em&gt;) = 0&lt;/span&gt; If &lt;span\nclass=\"math inline\"&gt;cov(&lt;em&gt;X&lt;/em&gt;,&lt;em&gt;Y&lt;/em&gt;) = 0&lt;/span&gt; and &lt;span\nclass=\"math inline\"&gt;(&lt;em&gt;X&lt;/em&gt;,&lt;em&gt;Y&lt;/em&gt;) ∼ Bivariate Normal&lt;/span&gt;,\nthen &lt;span class=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt; and &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt; are independent Covariance is\nsymmetric, additive, and scale preserving &lt;span\nclass=\"math display\"&gt;\\]\n\\[\\begin{aligned}\n\\mbox{cov} (X,Y) &amp; = &amp; \\mbox{cov} (Y,X) \\nonumber \\\\\n\\mbox{cov} (X,Y_1+Y_2) &amp; = &amp; \\mbox{cov} (X,Y_1)+\\mbox{cov}\n(X,Y_2) \\nonumber \\\\\n\\mbox{cov} (X,aY) &amp; = &amp; a\\;\\mbox{cov} (X,Y) \\nonumber\n%\\mbox{cov} (Y,Y) &amp; = &amp; \\mbox{var} (Y) \\nonumber\n\\end{aligned}\\]\n\\[&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Rules of variance&lt;/span&gt;&lt;/p&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.6&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Variance of sum: &lt;span&gt;&lt;span\nclass=\"math display\"&gt;\\]\n\\[\\begin{split}\n        &amp;Var\\left(\\sum_{i=1}^n Y_i\\right)\n        =  \\sum_{i=1}^n\\sum_{j=1}^n\n        \\mbox{cov}(Y_i,Y_j )  \\\\\n        = &amp; \\sum_{i=1}^n Var(Y_i)   + \\sum_{i=1}^n\\sum_{j=1}^n\nI(j\\neq i) \\mbox{cov}(Y_i, Y_j )  \\\\\n        = &amp; \\sum_{i=1}^n Var(Y_i) + 2\\sum_{i=1}^n \\sum_{j=i+1}^n\n        \\mbox{cov}(Y_i, Y_j )\n        \\end{split}\\]\n\\[&lt;/span&gt;&lt;/span&gt; if &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;, …, &lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;\nare mutually independent, then &lt;span\nclass=\"math inline\"&gt;$Var\\left(\\sum_{i=1}^n Y_i\\right) = \\sum_{i=1}^n\nVar(Y_i)$&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.4&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Estimator of Mean&lt;/span&gt; Suppose we obtained a simple random\nsample from some underlying population, then we can derive sample\nestimates of each of the population quantities defined previously\nSuppose &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;, …, &lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;\nare &lt;span&gt;&lt;em&gt;iid&lt;/em&gt;&lt;/span&gt; with mean &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;μ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt; and variance\n&lt;span\nclass=\"math inline\"&gt;&lt;em&gt;σ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.6&lt;/span&gt; Estimator of mean: &lt;span\nclass=\"math display\"&gt;\\]Y = {i=1}^n Y_i = \\[&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;&lt;span class=\"math inline\"&gt;$E[\\overline{Y}]= \\frac{1}{n} \\sum_{i=1}^n\nE[Y_i] = \\mu_Y$&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;&lt;span class=\"math inline\"&gt;$Var(\\overline{Y})= n^{-2} \\sum_{i=1}^n\nVar(Y_i) = \\sigma_Y^2/n$&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.37&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Variance and Covariance Estimator&lt;/span&gt;&lt;/p&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.6&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Estimators of variance:&lt;/p&gt;\n&lt;p&gt;&lt;span class=\"math inline\"&gt;$\\widehat{\\sigma}^2_Y =  \\frac{1}{n}\n\\sum_{i=1}^n (Y_i-E[Y_i])^2$&lt;/span&gt;&lt;br /&gt;\nif population mean is known &lt;span\nclass=\"math inline\"&gt;$\\widehat{\\sigma}^2_Y = \\frac{1}{n-1} \\sum_{i=1}^n\n                (Y_i-\\overline{Y})^2$&lt;/span&gt;&lt;br /&gt;\nif population mean is unknown&lt;/p&gt;\n&lt;p&gt;Estimator of covariance:&lt;br /&gt;\nSuppose pairs &lt;span\nclass=\"math inline\"&gt;(&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;,&lt;em&gt;X&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;), …, (&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;,&lt;em&gt;X&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;)&lt;/span&gt;\nare &lt;span&gt;&lt;em&gt;iid&lt;/em&gt;&lt;/span&gt;. &lt;span\nclass=\"math inline\"&gt;$\\widehat{\\mbox{cov}} (X,Y) = \\frac{1}{n-1}\n\\sum_{i=1}^n\n                (Y_i-\\overline{Y})(X_i-\\overline{X})$&lt;/span&gt; &lt;span\nclass=\"math inline\"&gt;$\\widehat{\\mbox{corr}} (X,Y) =$&lt;/span&gt; ?&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\"&gt;\n&lt;p&gt;&lt;span&gt;0.4&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Distributions that will be used in this class&lt;/span&gt; Normal\ndistribution Chi-square distribution t distribution F distribution&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Normal Distribution&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Density: &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt; ∼ &lt;em&gt;N&lt;/em&gt;(&lt;em&gt;μ&lt;/em&gt;,&lt;em&gt;σ&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;)&lt;/span&gt;,\n&lt;span class=\"math display\"&gt;\\]\n\\[\\begin{aligned}\n        f_Y(y) &amp; = &amp;\n        \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left\\{\\frac{-1}{2}\\left(\\frac{y-\\mu}{\\sigma}\n        \\right)^2\\right\\} \\nonumber\n        \n\\end{aligned}\\]\n\\[&lt;/span&gt; If we know &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;E&lt;/em&gt;(&lt;em&gt;Y&lt;/em&gt;) = &lt;em&gt;μ&lt;/em&gt;&lt;/span&gt;, &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;V&lt;/em&gt;&lt;em&gt;a&lt;/em&gt;&lt;em&gt;r&lt;/em&gt;(&lt;em&gt;Y&lt;/em&gt;) = &lt;em&gt;σ&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;\nthen&lt;/p&gt;\n&lt;p&gt;/3 of &lt;span class=\"math inline\"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;’s distribution lies\nwithin 1 &lt;span class=\"math inline\"&gt;&lt;em&gt;σ&lt;/em&gt;&lt;/span&gt; of &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;μ&lt;/em&gt;&lt;/span&gt; % &lt;span\nclass=\"math inline\"&gt;…&lt;/span&gt; &lt;span class=\"math inline\"&gt;…&lt;/span&gt; is\nwithin &lt;span class=\"math inline\"&gt;&lt;em&gt;μ&lt;/em&gt; ± 2&lt;em&gt;σ&lt;/em&gt;&lt;/span&gt; &lt;span\nclass=\"math inline\"&gt; &gt; 99&lt;/span&gt;% &lt;span class=\"math inline\"&gt;…&lt;/span&gt;\n&lt;span class=\"math inline\"&gt;…&lt;/span&gt; lies within &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;μ&lt;/em&gt; ± 3&lt;em&gt;σ&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Arguably, the most important distribution in statistics&lt;/p&gt;\n&lt;p&gt;Linear combinations of Normals are Normal&lt;br /&gt;\ne.g., &lt;span\nclass=\"math inline\"&gt;(&lt;em&gt;a&lt;/em&gt;&lt;em&gt;Y&lt;/em&gt;+&lt;em&gt;b&lt;/em&gt;) ∼ N(&lt;em&gt;a&lt;/em&gt;&lt;em&gt;μ&lt;/em&gt;+&lt;em&gt;b&lt;/em&gt;, &lt;em&gt;a&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;em&gt;σ&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;)&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Standard normal: &lt;span class=\"math display\"&gt;\\]\n\\[\\begin{aligned}\n        Z=\\frac{Y-\\mu}{\\sigma} \\sim \\mbox{N}(0,1) \\nonumber\n        \n\\end{aligned}\\]\n\\[&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;Chi-square Distribution&lt;/span&gt; Notation: &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt; ∼ &lt;em&gt;χ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;d&lt;/em&gt;&lt;em&gt;f&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;\n&lt;span class=\"math inline\"&gt;&lt;em&gt;d&lt;/em&gt;&lt;em&gt;f&lt;/em&gt;=&lt;/span&gt; degrees of\nfreedom &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;E&lt;/em&gt;[&lt;em&gt;X&lt;/em&gt;] = &lt;em&gt;d&lt;/em&gt;&lt;em&gt;f&lt;/em&gt;&lt;/span&gt;\n&lt;span class=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt; takes on only positive\nvalues If &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Z&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt; ∼ N(0,1)&lt;/span&gt;,\nthen &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Z&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; ∼ &lt;em&gt;χ&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;If &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Z&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;, …, &lt;em&gt;Z&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;\nare independent, with &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;Z&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt; ∼ N(0,1)&lt;/span&gt;,\nthen &lt;span class=\"math display\"&gt;\\]\n\\[\\begin{aligned}\n        \\sum_{i=1}^n Z_i^2 &amp; \\sim &amp; \\chi^2_n \\nonumber\n        \n\\end{aligned}\\]\n\\[&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Used in hypothesis testing and CI’s involving variance&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;t Distribution&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;If &lt;span class=\"math inline\"&gt;&lt;em&gt;Z&lt;/em&gt; ∼ N(0,1)&lt;/span&gt; and &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;S&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt; ∼ &lt;em&gt;χ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;d&lt;/em&gt;&lt;em&gt;f&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;\nand &lt;span class=\"math inline\"&gt;&lt;em&gt;Z&lt;/em&gt;&lt;/span&gt; and &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;S&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt; are independent,&lt;/p&gt;\n&lt;p&gt;&lt;span class=\"math display\"&gt;\\]\n\\[\\begin{aligned}\n        \\frac{Z}{S/\\sqrt{df}} &amp; \\sim &amp; t_{df} \\nonumber\n        \n\\end{aligned}\\]\n\\[&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Symmetric, bell-shaped; tails heavier than Normal &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;E&lt;/em&gt;[&lt;em&gt;t&lt;/em&gt;&lt;sub&gt;&lt;em&gt;d&lt;/em&gt;&lt;em&gt;f&lt;/em&gt;&lt;/sub&gt;] = 0&lt;/span&gt;;\n&lt;span\nclass=\"math inline\"&gt;&lt;em&gt;V&lt;/em&gt;&lt;em&gt;a&lt;/em&gt;&lt;em&gt;r&lt;/em&gt;(&lt;em&gt;t&lt;/em&gt;&lt;sub&gt;&lt;em&gt;d&lt;/em&gt;&lt;em&gt;f&lt;/em&gt;&lt;/sub&gt;)&lt;/span&gt;\ngreater than 1 &lt;span\nclass=\"math inline\"&gt;lim&lt;sub&gt;&lt;em&gt;d&lt;/em&gt;&lt;em&gt;f&lt;/em&gt; → ∞&lt;/sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;sub&gt;&lt;em&gt;d&lt;/em&gt;&lt;em&gt;f&lt;/em&gt;&lt;/sub&gt; → N(0,1)&lt;/span&gt;\nfor &lt;span class=\"math inline\"&gt;&lt;em&gt;d&lt;/em&gt;&lt;em&gt;f&lt;/em&gt; &gt; 30&lt;/span&gt;, the\n&lt;span\nclass=\"math inline\"&gt;&lt;em&gt;t&lt;/em&gt;&lt;sub&gt;&lt;em&gt;d&lt;/em&gt;&lt;em&gt;f&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;\nclosely resembles the &lt;span class=\"math inline\"&gt;N(0,1)&lt;/span&gt;\ndistribution&lt;/p&gt;\n&lt;p&gt;In linear modeling, used for inference on individual regression\nparameters&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"frame\"&gt;\n&lt;p&gt;&lt;span&gt;F Distribution&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;If &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; ∼ &lt;em&gt;χ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;d&lt;/em&gt;&lt;em&gt;f&lt;/em&gt;1&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;\nand &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; ∼ &lt;em&gt;χ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;d&lt;/em&gt;&lt;em&gt;f&lt;/em&gt;2&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;,\nwhere &lt;span\nclass=\"math inline\"&gt;&lt;em&gt;X&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; ⊥ &lt;em&gt;X&lt;/em&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;,\nthen: &lt;span class=\"math display\"&gt;\\]\n\\[\\begin{aligned}\n        \\frac{X_1^2/df1}{X_2^2/df2} &amp; \\sim &amp; F_{df1,df2}\n\\nonumber\n        \n\\end{aligned}\\]\n\\[&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;only takes on positive values&lt;/p&gt;\n&lt;p&gt;connection to &lt;span class=\"math inline\"&gt;&lt;em&gt;t&lt;/em&gt;&lt;/span&gt;\ndistribution:&lt;/p&gt;\n&lt;p&gt;&lt;span class=\"math display\"&gt;\\]\n\\[\\begin{aligned}\n            \\{ t_{df} \\}^2 &amp; \\stackrel{{\\cal D}}{=} &amp; F_{1,df}\n\\nonumber\n            \n\\end{aligned}\\]\n$$\n\n\nUsed extensively in linear regression (hypothesis testing)\n\n\n\n\nQuestions?"
  },
  {
    "objectID": "slides/Module_A.html#outline",
    "href": "slides/Module_A.html#outline",
    "title": "Module A",
    "section": "Outline",
    "text": "Outline\nSyllabus Module A Topics: Introduction to linear regression Overview of specific topics in BIOSTAT 650 Review of basic material\n\nCourse Description: This is the first course in applied statistics for both incoming MS, MPH and PhD students. It is taught at the MS level.\nBoth theoretical and applied aspects of linear regression modeling will be covered in this course, including model building, model refinement, model diagnostics, hypothesis testing, parameter interpretation and scientific interpretation of results.\nStudents are expected to use R or SAS, when necessary, for homework assignments.\nTopics to be covered include simple linear regression, multiple regression, analysis of variance, residual and influence diagnostics, variable transformations, multicollinearity, model selection and validation.\n\n\nCourse Objectives: The overall objective of this course is to help the student integrate and apply linear regression methods to scientific studies.\nThe student will learn to identify the scientific goals of a study\ndevelop a statistical strategy appropriate for those goals\nplan strategies for linear regression analysis and to implement these strategies\nbe aware of problems that arise in study design, power and data collection\ninterpret the results of linear regression analysis and convert them into a language understandable to the broad scientific community"
  },
  {
    "objectID": "slides/Module_A.html#schedule",
    "href": "slides/Module_A.html#schedule",
    "title": "Module A",
    "section": "Schedule",
    "text": "Schedule\nOnline class: M/W 1:00pm - 3:00pm Online lectures will be recorded No class on Sep 6 (Labor Day), Oct 18 (Fall Study Break)\nOffice hours (OH): Office hours will NOT be recorded Monday TBD (GSI) Wednesday 3:00pm - 5:00pm (instructor) Mousumi: please change to yours Note: if you are in a very different time zone, please email the instructor to schdule a separate OH when needed Exams and project Midterm I    (20%): Oct 6 (in class) Midterm II   (20%): Nov 22 (in class) Final project (30%): Group presentation on Dec 6 and 8\nFinal project (30%):Final report due on Dec 10 :::\n\nHomework 30% Approximately weekly homework due on Mondays Suggestions: Begin working on homework questions shortly after they are assigned Attempt all homework questions alone (thoughtfully), before consulting others\nEthics: Collaborating on homework is OK, but homework turned in should reflect each student’s understanding Regrade policy: Please carefully review the homework/exam solution. To request a revised grade, please see the instructor or GSI during office hours. If no misgrading is found after examination of your case, your grade will be further lowered by the same amount (X points). A grade is considered “final” two weeks after it has been posted\n\n\nEmailing\nWe strongly encourage you to come to the office hour if you have technical questions such as how to approach a particular homework problem. Discussion on technical issues over email is inefficient.\nWhen emailing about this course, please put “BIOSTAT650” (no space) into the subject line\n\n\nOther suggestions Always try to think about “Why is this material important?” (if unclear, then ask) explain concepts/methods/results in layman language and/or in a graph\nHelp me, your classmates, and yourself learn better by Asking questions in class (raise your hand or type in the chat box) Turning your video on (not required but recommended)\nSpend time: 4 credit hour class means In class: 4 hours per week Outside of class: 8 to 12 hours per week (=2 to 3 hours for each credit)\n\n\nIntroduction to Linear Regression\n\n\nWhat is Linear Regression? Regression: a technique to study the association between two variables Response variable (outcome, dependent variable) Blood pressure Grouping variable (predictor, independent variable, explanatory variable) Male vs female – within each group, the value of the grouping variable is constant Drug dosage – continuous predictor of interest, infinitely many groups Adjustment for other variables\nLinear model: for our purposes, refers to linearity w.r.t. the parameters\nResponse variable is a linear function of parameters\nRegression models describe association, not causality\n\n\nWhy should I care? Most widely used and most developed method in statistics Appropriate in many practical settings Important to understand limitations Easy to interpret\nFun fact: one of the most frequently asked data scientist interview question What are the assumptions underlying linear regression?\n\n\nWhy should I care?\nMost importantly, it serves as a building block Essential concepts and ideas extend well to other regression methods and other areas e.g. you will see the following generic equation frequently:\n\\(\\sum_{i=1}^nX_i\\trans(Y_i-\\mu_i)=0\\) where \\(\\mu_i=X_i\\trans\\beta\\) in linear regression\nIt says “the residuals are orthogonal to the covariates\"\nTechniques used in linear regression apply to other regression methods e.g. estimation, hypothesis testing, model diagnosis\n\n\nLinear Regression: Objectives\nObjectives of any data analysis can generally be categorized as either inference or prediction\nrare that only one objective of interest in practice, both are usually of various degrees of importance\nInference:\nEstimation Hypothesis testing\n\n\nInference: Estimation\nIncludes both point and interval estimation\nSign of regression coefficient may be of interest; or, both sign and magnitude e.g., estimate mean change in serum cholesterol per unit increase in BMI model parameters must have clear interpretation (limits complexity of model)\n\n\nInference: Hypothesis Testing\nWe observe the data in the study sample; what can we infer about the underlying population of interest?\nHypothesis testing reduces results of study down to a sequence of yes/no answers\nModel parameters must be interpretable for inference to be meaningful\ne.g., on average, does serum cholesterol change as BMI (body mass index) increases? what about each of the following: age, gender, race, SBP (systolic blood pressure)?\n\n\nPrediction\nUsing regression model to predict response for yet unobserved subjects Accuracy and precision of predictions take precedence over interpretability of regression parameters\ne.g., develop a linear regression model to predict serum cholesterol given a set of patient characteristics (age, gender, race, BMI, SBP, etc)\n\n\nData Analysis Process: Overview\nDescriptive analysis often skipped or done carelessly\nVERY important first step\nPropose model often done in close consultation with investigators\nEstimate model parameters\nAssess underlying assumptions of model \\(\\longrightarrow\\) return to (1)?\nHypothesis testing and/or prediction\nInterpretation, conclusions\n\n\nWhat will be covered in BIOSTAT 650?\n\n\nSimple Linear Regression: one predictor SLR features one response variable and a single covariate\nModel: \\[Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i \\nonumber\\]\n\\(Y_i\\): response \\(\\beta_0\\), \\(\\beta_1\\): parameters \\(X_i\\): covariate \\(\\epsilon_i\\): error\n“Simple”: one covariate only\nRather restrictive since only one covariate is involved\noften, interest lies in several covariates if only interested in one certain covariate, may need to adjust for other covariates\n\n\nMultiple Linear Regression: multiple predictors\nMultiple Regression: \\(q(&gt;1)\\) covariates Model \\[Y_i  =  \\beta_0 + \\beta_1X_{i1} + \\beta_2X_{i2} +\\ldots +\n        \\beta_qX_{iq} +  \\epsilon_i\\]\n\n\n0.01\n\n0.75\nFor compactness, often use matrix notation Compared to simple linear regression \\(\\beta_j\\)’s have much different interpretation\nMuch more complicated than SLR;\nMuch greater chance to mis-model the data set\n\n0.25 \n\n\n\n\nResidual Diagnostics Most of the assumptions underlying linear regression model are about the error term: \\[\\begin{split}\n            \\epsilon_i & \\sim  N(0,\\sigma^2)  \\\\\n            \\epsilon_i & \\ind \\epsilon_j,\\; \\forall i, \\;j,\\; i\\neq j\n        \\end{split}\\] Failure of any of these assumptions to hold could invalidate various aspects of the analysis\nResiduals = estimated errors: \\(\\widehat{\\epsilon}_i\\)\nResidual diagnostics aims to check validity of error assumptions after model fitting\nresults of residual diagnostics could imply that modifications to model are required\n\n\nTransformations of the outcome Consider the following SLR model: \\[Y_i = \\beta_0 + \\beta_1X_{i} +  \\epsilon_i\\] It is possible that, instead, some function of \\(Y_i\\), say \\(h(Y_i)\\), should be modeled: \\[h(Y_i) =\\beta_0 + \\beta_1X_{i} +  \\epsilon_i\\] Possible choices for \\(h(\\cdot)\\): $$\n\\[\\begin{aligned}\n            h(Y_i) & = & \\log(Y_i) \\nonumber \\\\\n            h(Y_i) & = & \\log_{10}(Y_i) \\nonumber \\\\\n            h(Y_i) & = & \\sqrt{Y_i} \\nonumber \\\\\n            h(Y_i) & = & 1/Y_i \\nonumber\n            \n\\end{aligned}\\]\n$$\n\n\nTransformations of the covariate(s) Consider the following SLR model: $$\n\\[\\begin{aligned}\n        Y_i & = & \\beta_0 + \\beta_1X_{i} +  \\beta_2 X^2_{i} + \\epsilon_i \\nonumber\n        \n\\end{aligned}\\]\n$$\nThis is still a linear model! “Linear\" refers to being linear in the coefficients Transformation of the covariate can include $$\n\\[\\begin{aligned}\n            &   &  \\log(X_i) \\nonumber \\\\\n            &   &X^2_{i}, \\cdots, X^q_{i}   \\nonumber \\\\\n            &   &\\sqrt{X_i} \\nonumber \\\\\n            &   & \\mbox{splines:} ~~~ (X_i-a)_+\\nonumber\n            \n\\end{aligned}\\]\n$$\n\n\nTransformations\nNeed to be very careful when using transformations\ninterpretation of parameters changes completely transforming the outcome alters assumptions regarding error structure\n\n\nOutliers/Influence Diagnostics\nConsider the fitted model: \\[\\widehat{Y}_i = \\widehat{\\beta}_0 + \\widehat{\\beta}_1X_{i}\\]\nWhat impact does \\((X_i,Y_i)\\) have on \\(\\widehat{Y}_i\\)? How much does the \\(i\\)’th subject influence \\(\\widehat{\\beta}_0\\)? By what amount would \\(\\widehat{\\beta}_1\\) change if the \\(i\\)’th subject were deleted? If the \\(i\\)’th observation heavily influences \\(\\widehat{\\beta}_1\\), should it be removed?\n\n\nMulticollinearity\nConsider: linear regression model with covariates \\(X_1,\\ldots,X_q\\) Covariates are not assumed to be independent (e.g., age, height, weight, etc) However, extreme correlations among the covariates interferes with the model fitting:\nmay be impossible to compute \\(\\widehat{\\beta}_j\\)’s computed \\(\\widehat{\\beta}_j\\)’s may have extremely large standard errors fitted model may be quite unreliable\n\n\nModel Selection\nConsider: state-wide survey, wherein information on 30 covariates collected\nWhen objective is to find the ‘best’ model, several algorithms may simplify the process\nForward Selection: start with 0 covariates add (most significant) covariates one at a time until further addition does not improve the model’s fit\nBackward Elimination: start with full model successively delete (least significant) covariates, until such deletions results in marked decrease in model’s adequacy\nStepwise Selection: combination of forward selection and backward elimination\n\n\nModel Validation\nConcept: how accurate is the fitted model on new data (not used to compute the parameter estimates)\ne.g., data splitting:\nsplit data set in two fit model to first half of data set, \\(\\widehat{\\beta}_1^*,\\dots,\\widehat{\\beta}_p^*\\) compare \\(Y_i\\) and \\(\\widehat{Y}_i^*\\), in second half of data set\n\n\nWeighted Regression Units \\(i\\) are not always sampled completely at random Surveys may oversample certain subpopulations\nSome units are given more weight during the estimation process\n\n\nLinear vs. Generalized Linear Models Linear regression: \\(Y_i\\) assumed to be continuous\n(and \\(\\epsilon_i\\) is normally distributed)\nSuppose \\(Y_i\\) is an indicator variable (e.g., 1=cancer; 0=cancer-free)\n\\(Y_i\\) follows a Bernoulli distribution assumptions of linear regression blatantly violated\nGeneralized Linear Model (GLM): used to model non-Normal responses; e.g.,\n\\(Y_i\\sim\\) Bernoulli/Binomial: logistic regression \\(Y_i\\) is a count: Poisson regression\nWill study GLM extensively in BIOSTAT 651\n\n\nMultiple vs. Multivariate regression\nSimple linear regression (this course): one outcome \\(Y\\), one predictor variable \\(X\\)\nMultiple linear regression (this course): one outcome \\(Y\\), multiple predictor variables \\(X\\)\nMultivariate regression: multiple outcome variables \\(Y\\), e.g. same outcome measured repeatedly over time multiple related outcomes (e.g., height and weight) considered simultaneously as outcome can be of any distribution, i.e., multivariate GLM\nWill study multivariate regression extensively in BIOSTAT 653\n\n\nIn class exercise\nMaternal Bone Lead as an Independent Risk Factor for Fetal Neurotoxicity: A Prospective Study\n\n\nBackground Lead (Pb) is a neurotoxicant It is associated with decreased mental development (in children), and accelerated mental decline in the elderly.\nStudies typically measure lead concentrations in blood, and correlate them (e.g., linear regression) with measurements of intelligence (e.g., BAYLEY mental development index, IQ tests)\nPrenatal exposure measurements typically assessed by amount of lead in umbilical cord\nNovel biomarker is bone lead concentration—premise is that lead leaches out of the mother’s bones throughout pregnancy\n\n\nGomaa et al. Study Objective and Design\nProspective Study: Children-mothers recruited at birth, followed until children are 24 months old\nResearch question: is lead exposure associated with mental development?\nLead exposure is measured by: Lead concentration in umbilical blood Lead concentration in maternal bones\nMental development Is measured by: BAYLEY’s index of mental development (MDI)\nStatistical question: Test if umbilical cord blood lead and bone lead concentration are predictors of BAYLEY’s MDI\n\n\nConfounding Variables\nWhat are confounders? A confounder can make the observed association appear stronger than the true association, weaker than the true association, or even the reverse of the true association\nConfounders in this case:\ndemographics (age, gender, education, marital status) Breastfeeding duration Maternal IQ\nSometimes confounders and predictor variables are called “covariates”\n\n\nAcknowledgement\n\n\n\n\n\n\n\nMousumi Banerjee\nBrisa N. Sánchez\n\n\nUniversity of Michigan\nDrexel University\n\n\n\nThank you for your slides!\n\n\nBrief Review of Basic Statistics\n\n\nBasic Statistics\n\n\n0.5\nRandom variable \\(Y\\) Sample \\(Y_i, i=1,\\dots, n\\)\nSummation: \\(\\sum_{i=1}^n Y_i =Y_1 + Y_2 + \\ldots + Y_n\\)\nProduct: \\(\\prod_{i=1}^n Y_i = Y_1 \\times Y_2 \\times \\ldots \\times Y_n\\)\nExpected Value (or mean): \\(\\mu_Y= E[Y] = \\int_{-\\infty}^\\infty y f(y) dy\\) reflects ‘center’ of \\(Y\\)’s distribution\n\n0.5\n\n\n\n\nRules of Expected Values\n\n\n0.5 Expectation of sum: \\(E\\left[\\sum_{i=1}^n Y_i \\right] = \\sum_{i=1}^n E[Y_i]  \\nonumber\\) No assumption of independence required\nLet \\(a_1,\\ldots,a_n\\) be constants \\(E[a_iY_i] = a_iE[Y_i]\\)\n\\(E\\left[\\sum_{i=1}^n a_iY_i  \\right] = \\sum_{i=1}^n a_iE[Y_i]\\)\nExpectation of product: \\(E[Y_iY_j] = E[Y_i]E[Y_j]\\)\nif \\(Y_i\\) and \\(Y_j\\) are independent\n\n0.5\n\n\n\n\nVariance and standard deviation\n\n\n0.5\nVariance: \\[\\begin{split}\n        &Var(Y) =  E[(Y-\\mu_Y)^2]\\\\\n        = &\\int_{-\\infty}^\\infty (y-\\mu_Y)^2 f(y) dy\n        %=  E[Y^2] - \\mu_Y^2\n        \\end{split}\\] reflects spread of \\(Y\\)’s distribution units: (units of \\(Y\\))\\(^2\\)\nStandard deviation: \\[\\begin{split}\n        SD(Y)  = &\\; \\sqrt{Var(Y)}  \\\\\n        SD(aY)  = &\\; aSD(Y)\n        \\end{split}\\]\nreflects dispersion in \\(Y\\)’s distribution measured in same unit as \\(Y\\)\n\n0.5\n\n\n\n\nRules of Variances\n\n\n0.5 Variance\n\\(Var(Y)=E[(Y-\\mu_Y)^2]\\)\n\\({\\color{white}{Var(Y)}} =E[Y^2] - \\mu_Y^2\\) Variance of linear combination: \\[\\begin{split}\n        &~Var(aY+b)\\\\\n         = &~ Var(aY) \\\\\n         = &~ E[(aY-E[aY])^2]\\\\\n         = &~ a^2 E[(Y-E[Y])^2]\\\\\n         = &~ a^2 Var(Y)\n        \\end{split}\\] \n\n0.5\n\n\n\n\nCovariance\n\n\n0.6 \\(X\\), \\(Y\\): random variables Covariance: \\(\\mbox{cov}(Y,X)= E[(Y-\\mu_Y)(X-\\mu_X)]\\)\nMeasures (linear) association between \\(X\\), \\(Y\\)\n\\(&gt;0\\), large values of \\(X\\) tend to occur with large values of \\(Y\\)\n\\(&lt;0\\), large values of \\(X\\) tend to coincide with small values of \\(Y\\)\n\\(=0\\), size of \\(X\\) provides no information on size of \\(Y\\) When the covariance is calculated, the data are not standardized Not scale-invariant: can interpret direction but not magnitude\n\n0.4\n\n\n\n\nCorrelation\n\n\n0.5 \\(X\\), \\(Y\\): random variables Correlation: \\(\\mbox{corr}(X,Y) = \\frac{\\mbox{cov}(X,Y)}{SD(X)SD(Y)}\\)\nScaled measure of linear association,\n\\(-1 \\leq \\mbox{corr}(X,Y) \\leq 1\\) easier to interpret than covariance\n\n0.5\n\n\n\n\nRules of covariance \\(\\mbox{cov}(Y,X)= E[(Y-\\mu_Y)(X-\\mu_X)]= E[XY]-E[X]E[Y]\\) \\(\\mbox{cov} (Y,Y) = \\mbox{var} (Y)\\) Independent \\(\\stackrel{\\Rightarrow}{\\not\\Leftarrow}\\) uncorrelated If \\(X\\) and \\(Y\\) are independent, \\(\\mbox{cov}(X,Y)=0\\) If \\(\\mbox{cov}(X,Y)=0\\) and \\((X,Y)\\sim \\text{Bivariate Normal}\\), then \\(X\\) and \\(Y\\) are independent Covariance is symmetric, additive, and scale preserving \\[\\begin{aligned}\n\\mbox{cov} (X,Y) & = & \\mbox{cov} (Y,X) \\nonumber \\\\\n\\mbox{cov} (X,Y_1+Y_2) & = & \\mbox{cov} (X,Y_1)+\\mbox{cov} (X,Y_2) \\nonumber \\\\\n\\mbox{cov} (X,aY) & = & a\\;\\mbox{cov} (X,Y) \\nonumber\n%\\mbox{cov} (Y,Y) & = & \\mbox{var} (Y) \\nonumber\n\\end{aligned}\\]\n\n\nRules of variance\n\n\n0.6\nVariance of sum: \\[\\setlength{\\jot}{1pt}\n        \\begin{split}\n        &Var\\left(\\sum_{i=1}^n Y_i\\right)\n        =  \\sum_{i=1}^n\\sum_{j=1}^n\n        \\mbox{cov}(Y_i,Y_j )  \\\\\n        = & \\sum_{i=1}^n Var(Y_i)   + \\sum_{i=1}^n\\sum_{j=1}^n I(j\\neq i) \\mbox{cov}(Y_i, Y_j )  \\\\\n        = & \\sum_{i=1}^n Var(Y_i) + 2\\sum_{i=1}^n \\sum_{j=i+1}^n\n        \\mbox{cov}(Y_i, Y_j )\n        \\end{split}\\] if \\(Y_1,\\ldots,Y_n\\) are mutually independent, then \\(Var\\left(\\sum_{i=1}^n Y_i\\right) = \\sum_{i=1}^n Var(Y_i)\\)\n\n0.4\n\n\n\n\nEstimator of Mean Suppose we obtained a simple random sample from some underlying population, then we can derive sample estimates of each of the population quantities defined previously Suppose \\(Y_1,\\ldots,Y_n\\) are iid with mean \\(\\mu_Y\\) and variance \\(\\sigma^2_Y\\)\n\n\n0.6 Estimator of mean: \\[\\widehat{\\mu}_Y = \\frac{1}{n} \\sum_{i=1}^n Y_i =\n            \\overline{Y}\\]\n\\(E[\\overline{Y}]= \\frac{1}{n} \\sum_{i=1}^n E[Y_i] = \\mu_Y\\)\n\\(Var(\\overline{Y})= n^{-2} \\sum_{i=1}^n Var(Y_i) = \\sigma_Y^2/n\\)\n\n0.37\n\n\n\n\nVariance and Covariance Estimator\n\n\n0.6\nEstimators of variance:\n\\(\\widehat{\\sigma}^2_Y = \\frac{1}{n} \\sum_{i=1}^n (Y_i-E[Y_i])^2\\)\nif population mean is known \\(\\widehat{\\sigma}^2_Y = \\frac{1}{n-1} \\sum_{i=1}^n  (Y_i-\\overline{Y})^2\\)\nif population mean is unknown\nEstimator of covariance:\nSuppose pairs \\((Y_1,X_1),\\ldots,(Y_n,X_n)\\) are iid. \\(\\widehat{\\mbox{cov}} (X,Y) = \\frac{1}{n-1} \\sum_{i=1}^n  (Y_i-\\overline{Y})(X_i-\\overline{X})\\) \\(\\widehat{\\mbox{corr}} (X,Y) =\\) ?\n\n0.4\n\n\n\n\nDistributions that will be used in this class Normal distribution Chi-square distribution t distribution F distribution\n\n\nNormal Distribution\nDensity: \\(Y\\sim N(\\mu,\\sigma^2)\\), $$\n\\[\\begin{aligned}\n        f_Y(y) & = &\n        \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left\\{\\frac{-1}{2}\\left(\\frac{y-\\mu}{\\sigma}\n        \\right)^2\\right\\} \\nonumber\n        \n\\end{aligned}\\]\n$$ If we know \\(E(Y)=\\mu\\), \\(Var(Y)=\\sigma^2\\) then\n/3 of \\(Y\\)’s distribution lies within 1 \\(\\sigma\\) of \\(\\mu\\) % \\(\\ldots\\) \\(\\ldots\\) is within \\(\\mu\\pm 2\\sigma\\) \\(&gt;99\\)% \\(\\ldots\\) \\(\\ldots\\) lies within \\(\\mu\\pm 3\\sigma\\)\nArguably, the most important distribution in statistics\nLinear combinations of Normals are Normal\ne.g., \\((aY+b)\\sim \\mbox{N}(a\\mu+b,\\;a^2\\sigma^2)\\)\nStandard normal: $$\n\\[\\begin{aligned}\n        Z=\\frac{Y-\\mu}{\\sigma} \\sim \\mbox{N}(0,1) \\nonumber\n        \n\\end{aligned}\\]\n$$\n\n\nChi-square Distribution Notation: \\(X \\sim \\chi^2_{df}\\) \\(df=\\) degrees of freedom \\(E[X]=df\\) \\(X\\) takes on only positive values If \\(Z_i\\sim \\mbox{N}(0,1)\\), then \\(Z_i^2\\sim \\chi^2_1\\)\nIf \\(Z_1,\\ldots,Z_n\\) are independent, with \\(Z_i\\sim\\mbox{N}(0,1)\\), then $$\n\\[\\begin{aligned}\n        \\sum_{i=1}^n Z_i^2 & \\sim & \\chi^2_n \\nonumber\n        \n\\end{aligned}\\]\n$$\nUsed in hypothesis testing and CI’s involving variance\n\n\nt Distribution\nIf \\(Z\\sim \\mbox{N}(0,1)\\) and \\(S^2\\sim \\chi^2_{df}\\) and \\(Z\\) and \\(S^2\\) are independent,\n$$\n\\[\\begin{aligned}\n        \\frac{Z}{S/\\sqrt{df}} & \\sim & t_{df} \\nonumber\n        \n\\end{aligned}\\]\n$$\nSymmetric, bell-shaped; tails heavier than Normal \\(E[t_{df}]=0\\); \\(Var(t_{df})\\) greater than 1 \\(\\lim_{df\\rightarrow \\infty}t_{df} \\rightarrow \\mbox{N}(0,1)\\) for \\(df&gt;30\\), the \\(t_{df}\\) closely resembles the \\(\\mbox{N}(0,1)\\) distribution\nIn linear modeling, used for inference on individual regression parameters\n\n\nF Distribution\nIf \\(X_1^2\\sim \\chi^2_{df1}\\) and \\(X_2^2\\sim \\chi^2_{df2}\\), where \\(X_1^2\\perp X_2^2\\), then: $$\n\\[\\begin{aligned}\n        \\frac{X_1^2/df1}{X_2^2/df2} & \\sim & F_{df1,df2} \\nonumber\n        \n\\end{aligned}\\]\n$$\nonly takes on positive values\nconnection to \\(t\\) distribution:\n$$\n\\[\\begin{aligned}\n            \\{ t_{df} \\}^2 & \\stackrel{{\\cal D}}{=} & F_{1,df} \\nonumber\n            \n\\end{aligned}\\]\n$$\nUsed extensively in linear regression (hypothesis testing)\n\n\nQuestions?\n\n\n\nIntro"
  },
  {
    "objectID": "slides/Module_A.html#what-is-linear-regression-regression-a-technique-to",
    "href": "slides/Module_A.html#what-is-linear-regression-regression-a-technique-to",
    "title": "Module A",
    "section": "What is Linear Regression? Regression: a technique to",
    "text": "What is Linear Regression? Regression: a technique to\nstudy the association between two variables Response variable (outcome, dependent variable) Blood pressure Grouping variable (predictor, independent variable, explanatory variable) Male vs female – within each group, the value of the grouping variable is constant Drug dosage – continuous predictor of interest, infinitely many groups Adjustment for other variables\nLinear model: for our purposes, refers to linearity w.r.t. the parameters\nResponse variable is a linear function of parameters\nRegression models describe association, not causality"
  },
  {
    "objectID": "slides/Module_A.html#why-should-i-care",
    "href": "slides/Module_A.html#why-should-i-care",
    "title": "Module A",
    "section": "Why should I care?",
    "text": "Why should I care?\nMost widely used and most developed method in statistics Appropriate in many practical settings Important to understand limitations Easy to interpret\nFun fact: one of the most frequently asked data scientist interview question What are the assumptions underlying linear regression?"
  },
  {
    "objectID": "slides/Module_A.html#why-should-i-care-1",
    "href": "slides/Module_A.html#why-should-i-care-1",
    "title": "Module A",
    "section": "Why should I care?",
    "text": "Why should I care?\nMost importantly, it serves as a building block Essential concepts and ideas extend well to other regression methods and other areas e.g. you will see the following generic equation frequently:\n\\(\\sum_{i=1}^nX_i\\trans(Y_i-\\mu_i)=0\\) where \\(\\mu_i=X_i\\trans\\beta\\) in linear regression\nIt says “the residuals are orthogonal to the covariates”\nTechniques used in linear regression apply to other regression methods e.g. estimation, hypothesis testing, model diagnosis"
  },
  {
    "objectID": "slides/Module_A.html#linear-regression-objectives",
    "href": "slides/Module_A.html#linear-regression-objectives",
    "title": "Module A",
    "section": "Linear Regression: Objectives",
    "text": "Linear Regression: Objectives\nObjectives of any data analysis can generally be categorized as either inference or prediction\nrare that only one objective of interest in practice, both are usually of various degrees of importance\nInference:\nEstimation Hypothesis testing"
  },
  {
    "objectID": "slides/Module_A.html#inference-estimation",
    "href": "slides/Module_A.html#inference-estimation",
    "title": "Module A",
    "section": "Inference: Estimation",
    "text": "Inference: Estimation\nIncludes both point and interval estimation\nSign of regression coefficient may be of interest; or, both sign and magnitude e.g., estimate mean change in serum cholesterol per unit increase in BMI model parameters must have clear interpretation (limits complexity of model)"
  },
  {
    "objectID": "slides/Module_A.html#inference-hypothesis-testing",
    "href": "slides/Module_A.html#inference-hypothesis-testing",
    "title": "Module A",
    "section": "Inference: Hypothesis Testing",
    "text": "Inference: Hypothesis Testing\nWe observe the data in the study sample; what can we infer about the underlying population of interest?\nHypothesis testing reduces results of study down to a sequence of yes/no answers\nModel parameters must be interpretable for inference to be meaningful\ne.g., on average, does serum cholesterol change as BMI (body mass index) increases? what about each of the following: age, gender, race, SBP (systolic blood pressure)?"
  },
  {
    "objectID": "slides/Module_A.html#prediction",
    "href": "slides/Module_A.html#prediction",
    "title": "Module A",
    "section": "Prediction",
    "text": "Prediction\nUsing regression model to predict response for yet unobserved subjects Accuracy and precision of predictions take precedence over interpretability of regression parameters\ne.g., develop a linear regression model to predict serum cholesterol given a set of patient characteristics (age, gender, race, BMI, SBP, etc)"
  },
  {
    "objectID": "slides/Module_A.html#data-analysis-process-overview",
    "href": "slides/Module_A.html#data-analysis-process-overview",
    "title": "Module A",
    "section": "Data Analysis Process: Overview",
    "text": "Data Analysis Process: Overview\nDescriptive analysis often skipped or done carelessly\nVERY important first step\nPropose model often done in close consultation with investigators\nEstimate model parameters\nAssess underlying assumptions of model \\(\\longrightarrow\\) return to (1)?\nHypothesis testing and/or prediction\nInterpretation, conclusions"
  },
  {
    "objectID": "slides/Module_A.html#simple-linear-regression-one-predictor",
    "href": "slides/Module_A.html#simple-linear-regression-one-predictor",
    "title": "Module A",
    "section": "Simple Linear Regression: one predictor",
    "text": "Simple Linear Regression: one predictor\nSLR features one response variable and a single covariate\nModel: \\[Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i \\nonumber\\]\n\\(Y_i\\): response \\(\\beta_0\\), \\(\\beta_1\\): parameters \\(X_i\\): covariate \\(\\epsilon_i\\): error\n“Simple”: one covariate only\nRather restrictive since only one covariate is involved\noften, interest lies in several covariates if only interested in one certain covariate, may need to adjust for other covariates"
  },
  {
    "objectID": "slides/Module_A.html#multiple-linear-regression-multiple-predictors",
    "href": "slides/Module_A.html#multiple-linear-regression-multiple-predictors",
    "title": "Module A",
    "section": "Multiple Linear Regression: multiple predictors",
    "text": "Multiple Linear Regression: multiple predictors\nMultiple Regression: \\(q(&gt;1)\\) covariates Model \\[Y_i  =  \\beta_0 + \\beta_1X_{i1} + \\beta_2X_{i2} +\\ldots +\n        \\beta_qX_{iq} +  \\epsilon_i\\]\n\n\n\nFor compactness, often use matrix notation Compared to simple linear regression \\(\\beta_j\\)’s have much different interpretation\nMuch more complicated than SLR;\nMuch greater chance to mis-model the data set\n\n\n\n\n\nimage"
  },
  {
    "objectID": "slides/Module_A.html#residual-diagnostics",
    "href": "slides/Module_A.html#residual-diagnostics",
    "title": "Module A",
    "section": "Residual Diagnostics",
    "text": "Residual Diagnostics\nMost of the assumptions underlying linear regression model are about the error term: \\[\\begin{split}\n            \\epsilon_i & \\sim  N(0,\\sigma^2)  \\\\\n            \\epsilon_i & \\perp \\epsilon_j,\\; \\forall i, \\;j,\\; i\\neq j\n        \\end{split}\\] Failure of any of these assumptions to hold could invalidate various aspects of the analysis\nResiduals = estimated errors: \\(\\widehat{\\epsilon}_i\\)\nResidual diagnostics aims to check validity of error assumptions after model fitting\nresults of residual diagnostics could imply that modifications to model are required"
  },
  {
    "objectID": "slides/Module_A.html#transformations-of-the-outcome",
    "href": "slides/Module_A.html#transformations-of-the-outcome",
    "title": "Module A",
    "section": "Transformations of the outcome",
    "text": "Transformations of the outcome\nConsider the following SLR model: \\[Y_i = \\beta_0 + \\beta_1X_{i} +  \\epsilon_i\\] It is possible that, instead, some function of \\(Y_i\\), say \\(h(Y_i)\\), should be modeled: \\[h(Y_i) =\\beta_0 + \\beta_1X_{i} +  \\epsilon_i\\] Possible choices for \\(h(\\cdot)\\): $$\n\\[\\begin{aligned}\n            h(Y_i) & = & \\log(Y_i) \\nonumber \\\\\n            h(Y_i) & = & \\log_{10}(Y_i) \\nonumber \\\\\n            h(Y_i) & = & \\sqrt{Y_i} \\nonumber \\\\\n            h(Y_i) & = & 1/Y_i \\nonumber\n            \n\\end{aligned}\\]\n$$"
  },
  {
    "objectID": "slides/Module_A.html#transformations-of-the-covariates",
    "href": "slides/Module_A.html#transformations-of-the-covariates",
    "title": "Module A",
    "section": "Transformations of the covariate(s)",
    "text": "Transformations of the covariate(s)\nConsider the following SLR model: $$\n\\[\\begin{aligned}\n        Y_i & = & \\beta_0 + \\beta_1X_{i} +  \\beta_2 X^2_{i} + \\epsilon_i \\nonumber\n        \n\\end{aligned}\\]\n$$\nThis is still a linear model! “Linear” refers to being linear in the coefficients Transformation of the covariate can include $$\n\\[\\begin{aligned}\n            &   &  \\log(X_i) \\nonumber \\\\\n            &   &X^2_{i}, \\cdots, X^q_{i}   \\nonumber \\\\\n            &   &\\sqrt{X_i} \\nonumber \\\\\n            &   & \\mbox{splines:} ~~~ (X_i-a)_+\\nonumber\n            \n\\end{aligned}\\]\n$$"
  },
  {
    "objectID": "slides/Module_A.html#transformations",
    "href": "slides/Module_A.html#transformations",
    "title": "Module A",
    "section": "Transformations",
    "text": "Transformations\nNeed to be very careful when using transformations\ninterpretation of parameters changes completely transforming the outcome alters assumptions regarding error structure"
  },
  {
    "objectID": "slides/Module_A.html#outliersinfluence-diagnostics",
    "href": "slides/Module_A.html#outliersinfluence-diagnostics",
    "title": "Module A",
    "section": "Outliers/Influence Diagnostics",
    "text": "Outliers/Influence Diagnostics\nConsider the fitted model: \\[\\widehat{Y}_i = \\widehat{\\beta}_0 + \\widehat{\\beta}_1X_{i}\\]\nWhat impact does \\((X_i,Y_i)\\) have on \\(\\widehat{Y}_i\\)? How much does the \\(i\\)’th subject influence \\(\\widehat{\\beta}_0\\)? By what amount would \\(\\widehat{\\beta}_1\\) change if the \\(i\\)’th subject were deleted? If the \\(i\\)’th observation heavily influences \\(\\widehat{\\beta}_1\\), should it be removed?"
  },
  {
    "objectID": "slides/Module_A.html#multicollinearity",
    "href": "slides/Module_A.html#multicollinearity",
    "title": "Module A",
    "section": "Multicollinearity",
    "text": "Multicollinearity\nConsider: linear regression model with covariates \\(X_1,\\ldots,X_q\\) Covariates are not assumed to be independent (e.g., age, height, weight, etc) However, extreme correlations among the covariates interferes with the model fitting:\nmay be impossible to compute \\(\\widehat{\\beta}_j\\)’s computed \\(\\widehat{\\beta}_j\\)’s may have extremely large standard errors fitted model may be quite unreliable"
  },
  {
    "objectID": "slides/Module_A.html#model-selection",
    "href": "slides/Module_A.html#model-selection",
    "title": "Module A",
    "section": "Model Selection",
    "text": "Model Selection\nConsider: state-wide survey, wherein information on 30 covariates collected\nWhen objective is to find the ‘best’ model, several algorithms may simplify the process\nForward Selection: start with 0 covariates add (most significant) covariates one at a time until further addition does not improve the model’s fit\nBackward Elimination: start with full model successively delete (least significant) covariates, until such deletions results in marked decrease in model’s adequacy\nStepwise Selection: combination of forward selection and backward elimination"
  },
  {
    "objectID": "slides/Module_A.html#model-validation",
    "href": "slides/Module_A.html#model-validation",
    "title": "Module A",
    "section": "Model Validation",
    "text": "Model Validation\nConcept: how accurate is the fitted model on new data (not used to compute the parameter estimates)\ne.g., data splitting:\nsplit data set in two fit model to first half of data set, \\(\\widehat{\\beta}_1^*,\\dots,\\widehat{\\beta}_p^*\\) compare \\(Y_i\\) and \\(\\widehat{Y}_i^*\\), in second half of data set"
  },
  {
    "objectID": "slides/Module_A.html#weighted-regression-units-i-are-not-always-sampled-completely-at",
    "href": "slides/Module_A.html#weighted-regression-units-i-are-not-always-sampled-completely-at",
    "title": "Module A",
    "section": "Weighted Regression Units \\(i\\) are not always sampled completely at",
    "text": "Weighted Regression Units \\(i\\) are not always sampled completely at\nrandom Surveys may oversample certain subpopulations\nSome units are given more weight during the estimation process"
  },
  {
    "objectID": "slides/Module_A.html#linear-vs.-generalized-linear-models",
    "href": "slides/Module_A.html#linear-vs.-generalized-linear-models",
    "title": "Module A",
    "section": "Linear vs. Generalized Linear Models",
    "text": "Linear vs. Generalized Linear Models\nLinear regression: \\(Y_i\\) assumed to be continuous\n(and \\(\\epsilon_i\\) is normally distributed)\nSuppose \\(Y_i\\) is an indicator variable (e.g., 1=cancer; 0=cancer-free)\n\\(Y_i\\) follows a Bernoulli distribution assumptions of linear regression blatantly violated\nGeneralized Linear Model (GLM): used to model non-Normal responses; e.g.,\n\\(Y_i\\sim\\) Bernoulli/Binomial: logistic regression \\(Y_i\\) is a count: Poisson regression\nWill study GLM extensively in BIOSTAT 651"
  },
  {
    "objectID": "slides/Module_A.html#multiple-vs.-multivariate-regression",
    "href": "slides/Module_A.html#multiple-vs.-multivariate-regression",
    "title": "Module A",
    "section": "Multiple vs. Multivariate regression",
    "text": "Multiple vs. Multivariate regression\nSimple linear regression (this course): one outcome \\(Y\\), one predictor variable \\(X\\)\nMultiple linear regression (this course): one outcome \\(Y\\), multiple predictor variables \\(X\\)\nMultivariate regression: multiple outcome variables \\(Y\\), e.g. same outcome measured repeatedly over time multiple related outcomes (e.g., height and weight) considered simultaneously as outcome can be of any distribution, i.e., multivariate GLM\nWill study multivariate regression extensively in BIOSTAT 653"
  },
  {
    "objectID": "slides/Module_A.html#background",
    "href": "slides/Module_A.html#background",
    "title": "Module A",
    "section": "Background",
    "text": "Background\nLead (Pb) is a neurotoxicant It is associated with decreased mental development (in children), and accelerated mental decline in the elderly.\nStudies typically measure lead concentrations in blood, and correlate them (e.g., linear regression) with measurements of intelligence (e.g., BAYLEY mental development index, IQ tests)\nPrenatal exposure measurements typically assessed by amount of lead in umbilical cord\nNovel biomarker is bone lead concentration—premise is that lead leaches out of the mother’s bones throughout pregnancy"
  },
  {
    "objectID": "slides/Module_A.html#gomaa-et-al.-study-objective-and-design",
    "href": "slides/Module_A.html#gomaa-et-al.-study-objective-and-design",
    "title": "Module A",
    "section": "Gomaa et al. Study Objective and Design",
    "text": "Gomaa et al. Study Objective and Design\nProspective Study: Children-mothers recruited at birth, followed until children are 24 months old\nResearch question: is lead exposure associated with mental development?\nLead exposure is measured by: Lead concentration in umbilical blood Lead concentration in maternal bones\nMental development Is measured by: BAYLEY’s index of mental development (MDI)\nStatistical question: Test if umbilical cord blood lead and bone lead concentration are predictors of BAYLEY’s MDI"
  },
  {
    "objectID": "slides/Module_A.html#confounding-variables",
    "href": "slides/Module_A.html#confounding-variables",
    "title": "Module A",
    "section": "Confounding Variables",
    "text": "Confounding Variables\nWhat are confounders? A confounder can make the observed association appear stronger than the true association, weaker than the true association, or even the reverse of the true association\nConfounders in this case:\ndemographics (age, gender, education, marital status) Breastfeeding duration Maternal IQ\nSometimes confounders and predictor variables are called “covariates”"
  },
  {
    "objectID": "slides/Module_A.html#acknowledgement",
    "href": "slides/Module_A.html#acknowledgement",
    "title": "Module A",
    "section": "Acknowledgement",
    "text": "Acknowledgement\n\n\n\n\n\n\n\n\n\n\n\nMousumi Banerjee\nBrisa N. Sánchez\n\n\nUniversity of Michigan\nDrexel University\n\n\n\nThank you for your slides!"
  },
  {
    "objectID": "slides/Module_A.html#basic-statistics",
    "href": "slides/Module_A.html#basic-statistics",
    "title": "Module A",
    "section": "Basic Statistics",
    "text": "Basic Statistics\n\n\n0.5\nRandom variable \\(Y\\) Sample \\(Y_i, i=1,\\dots, n\\)\nSummation: \\(\\sum_{i=1}^n Y_i =Y_1 + Y_2 + \\ldots + Y_n\\)\nProduct: \\(\\prod_{i=1}^n Y_i = Y_1 \\times Y_2 \\times \\ldots \\times Y_n\\)\nExpected Value (or mean): \\(\\mu_Y= E[Y] = \\int_{-\\infty}^\\infty y f(y) dy\\) reflects ‘center’ of \\(Y\\)’s distribution\n\n0.5"
  },
  {
    "objectID": "slides/Module_A.html#rules-of-expected-values",
    "href": "slides/Module_A.html#rules-of-expected-values",
    "title": "Module A",
    "section": "Rules of Expected Values",
    "text": "Rules of Expected Values\n\n\n0.5 Expectation of sum: \\(E\\left[\\sum_{i=1}^n Y_i \\right] = \\sum_{i=1}^n E[Y_i] \\nonumber\\) No assumption of independence required\nLet \\(a_1,\\ldots,a_n\\) be constants \\(E[a_iY_i] = a_iE[Y_i]\\)\n\\(E\\left[\\sum_{i=1}^n a_iY_i \\right] = \\sum_{i=1}^n a_iE[Y_i]\\)\nExpectation of product: \\(E[Y_iY_j] = E[Y_i]E[Y_j]\\)\nif \\(Y_i\\) and \\(Y_j\\) are independent\n\n0.5\n\n\n:::"
  },
  {
    "objectID": "slides/Module_A.html#variance-and-standard-deviation",
    "href": "slides/Module_A.html#variance-and-standard-deviation",
    "title": "Module A",
    "section": "Variance and standard deviation",
    "text": "Variance and standard deviation\n\n\n0.5\nVariance: \\[\\begin{split}\n        &Var(Y) =  E[(Y-\\mu_Y)^2]\\\\\n        = &\\int_{-\\infty}^\\infty (y-\\mu_Y)^2 f(y) dy\n        %=  E[Y^2] - \\mu_Y^2\n        \\end{split}\\] reflects spread of \\(Y\\)’s distribution units: (units of \\(Y\\))\\(^2\\)\nStandard deviation: \\[\\begin{split}\n        SD(Y)  = &\\; \\sqrt{Var(Y)}  \\\\\n        SD(aY)  = &\\; aSD(Y)\n        \\end{split}\\]\nreflects dispersion in \\(Y\\)’s distribution measured in same unit as \\(Y\\)\n\n0.5\n\n\n:::"
  },
  {
    "objectID": "slides/Module_A.html#rules-of-variances",
    "href": "slides/Module_A.html#rules-of-variances",
    "title": "Module A",
    "section": "Rules of Variances",
    "text": "Rules of Variances\n\n\n0.5 Variance\n\\(Var(Y)=E[(Y-\\mu_Y)^2]\\)\n\\({\\color{white}{Var(Y)}} =E[Y^2] - \\mu_Y^2\\) Variance of linear combination: \\[\\begin{split}\n        &~Var(aY+b)\\\\\n         = &~ Var(aY) \\\\\n         = &~ E[(aY-E[aY])^2]\\\\\n         = &~ a^2 E[(Y-E[Y])^2]\\\\\n         = &~ a^2 Var(Y)\n        \\end{split}\\] \n\n0.5\n\n\n:::"
  },
  {
    "objectID": "slides/Module_A.html#covariance",
    "href": "slides/Module_A.html#covariance",
    "title": "Module A",
    "section": "Covariance",
    "text": "Covariance\n\n\n0.6 \\(X\\), \\(Y\\): random variables Covariance: \\(\\mbox{cov}(Y,X)= E[(Y-\\mu_Y)(X-\\mu_X)]\\)\nMeasures (linear) association between \\(X\\), \\(Y\\)\n\\(&gt;0\\), large values of \\(X\\) tend to occur with large values of \\(Y\\)\n\\(&lt;0\\), large values of \\(X\\) tend to coincide with small values of \\(Y\\)\n\\(=0\\), size of \\(X\\) provides no information on size of \\(Y\\) When the covariance is calculated, the data are not standardized Not scale-invariant: can interpret direction but not magnitude\n\n0.4\n\n\n:::"
  },
  {
    "objectID": "slides/Module_A.html#correlation",
    "href": "slides/Module_A.html#correlation",
    "title": "Module A",
    "section": "Correlation",
    "text": "Correlation\n\n\n0.5 \\(X\\), \\(Y\\): random variables Correlation: \\(\\mbox{corr}(X,Y) = \\frac{\\mbox{cov}(X,Y)}{SD(X)SD(Y)}\\)\nScaled measure of linear association,\n\\(-1 \\leq \\mbox{corr}(X,Y) \\leq 1\\) easier to interpret than covariance\n\n0.5"
  },
  {
    "objectID": "slides/Module_A.html#rules-of-covariance",
    "href": "slides/Module_A.html#rules-of-covariance",
    "title": "Module A",
    "section": "Rules of covariance",
    "text": "Rules of covariance\n\\(\\mbox{cov}(Y,X)= E[(Y-\\mu_Y)(X-\\mu_X)]= E[XY]-E[X]E[Y]\\) \\(\\mbox{cov} (Y,Y) = \\mbox{var} (Y)\\) Independent \\(\\stackrel{\\Rightarrow}{\\not\\Leftarrow}\\) uncorrelated If \\(X\\) and \\(Y\\) are independent, \\(\\mbox{cov}(X,Y)=0\\) If \\(\\mbox{cov}(X,Y)=0\\) and \\((X,Y)\\sim \\text{Bivariate Normal}\\), then \\(X\\) and \\(Y\\) are independent Covariance is symmetric, additive, and scale preserving \\[\\begin{aligned}\n\\mbox{cov} (X,Y) & = & \\mbox{cov} (Y,X) \\nonumber \\\\\n\\mbox{cov} (X,Y_1+Y_2) & = & \\mbox{cov} (X,Y_1)+\\mbox{cov} (X,Y_2) \\nonumber \\\\\n\\mbox{cov} (X,aY) & = & a\\;\\mbox{cov} (X,Y) \\nonumber\n%\\mbox{cov} (Y,Y) & = & \\mbox{var} (Y) \\nonumber\n\\end{aligned}\\] :::"
  },
  {
    "objectID": "slides/Module_A.html#rules-of-variance",
    "href": "slides/Module_A.html#rules-of-variance",
    "title": "Module A",
    "section": "Rules of variance",
    "text": "Rules of variance\n\n\n0.6\nVariance of sum: \\[\\setlength{\\jot}{1pt}\n        \\begin{split}\n        &Var\\left(\\sum_{i=1}^n Y_i\\right)\n        =  \\sum_{i=1}^n\\sum_{j=1}^n\n        \\mbox{cov}(Y_i,Y_j )  \\\\\n        = & \\sum_{i=1}^n Var(Y_i)   + \\sum_{i=1}^n\\sum_{j=1}^n I(j\\neq i) \\mbox{cov}(Y_i, Y_j )  \\\\\n        = & \\sum_{i=1}^n Var(Y_i) + 2\\sum_{i=1}^n \\sum_{j=i+1}^n\n        \\mbox{cov}(Y_i, Y_j )\n        \\end{split}\\] if \\(Y_1,\\ldots,Y_n\\) are mutually independent, then \\(Var\\left(\\sum_{i=1}^n Y_i\\right) = \\sum_{i=1}^n Var(Y_i)\\)\n\n0.4\n\n\n:::"
  },
  {
    "objectID": "slides/Module_A.html#estimator-of-mean",
    "href": "slides/Module_A.html#estimator-of-mean",
    "title": "Module A",
    "section": "Estimator of Mean",
    "text": "Estimator of Mean\nSuppose we obtained a simple random sample from some underlying population, then we can derive sample estimates of each of the population quantities defined previously Suppose \\(Y_1,\\ldots,Y_n\\) are iid with mean \\(\\mu_Y\\) and variance \\(\\sigma^2_Y\\)\n\n\n0.6 Estimator of mean: \\[\\widehat{\\mu}_Y = \\frac{1}{n} \\sum_{i=1}^n Y_i =\n            \\overline{Y}\\]\n\\(E[\\overline{Y}]= \\frac{1}{n} \\sum_{i=1}^n E[Y_i] = \\mu_Y\\)\n\\(Var(\\overline{Y})= n^{-2} \\sum_{i=1}^n Var(Y_i) = \\sigma_Y^2/n\\)\n\n0.37\n\n\n:::"
  },
  {
    "objectID": "slides/Module_A.html#variance-and-covariance-estimator",
    "href": "slides/Module_A.html#variance-and-covariance-estimator",
    "title": "Module A",
    "section": "Variance and Covariance Estimator",
    "text": "Variance and Covariance Estimator\n\n\n0.6\nEstimators of variance:\n\\(\\widehat{\\sigma}^2_Y = \\frac{1}{n} \\sum_{i=1}^n (Y_i-E[Y_i])^2\\)\nif population mean is known \\(\\widehat{\\sigma}^2_Y = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i-\\overline{Y})^2\\)\nif population mean is unknown\nEstimator of covariance:\nSuppose pairs \\((Y_1,X_1),\\ldots,(Y_n,X_n)\\) are iid. \\(\\widehat{\\mbox{cov}} (X,Y) = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i-\\overline{Y})(X_i-\\overline{X})\\) \\(\\widehat{\\mbox{corr}} (X,Y) =\\) ?\n\n0.4\n\n\n:::"
  },
  {
    "objectID": "slides/Module_A.html#distributions-that-will-be-used-in-this-class",
    "href": "slides/Module_A.html#distributions-that-will-be-used-in-this-class",
    "title": "Module A",
    "section": "Distributions that will be used in this class",
    "text": "Distributions that will be used in this class\nNormal distribution Chi-square distribution t distribution F distribution"
  },
  {
    "objectID": "slides/Module_A.html#normal-distribution",
    "href": "slides/Module_A.html#normal-distribution",
    "title": "Module A",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nDensity: \\(Y\\sim N(\\mu,\\sigma^2)\\), $$\n\\[\\begin{aligned}\n        f_Y(y) & = &\n        \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left\\{\\frac{-1}{2}\\left(\\frac{y-\\mu}{\\sigma}\n        \\right)^2\\right\\} \\nonumber\n        \n\\end{aligned}\\]\n$$ If we know \\(E(Y)=\\mu\\), \\(Var(Y)=\\sigma^2\\) then\n/3 of \\(Y\\)’s distribution lies within 1 \\(\\sigma\\) of \\(\\mu\\) % \\(\\ldots\\) \\(\\ldots\\) is within \\(\\mu\\pm 2\\sigma\\) \\(&gt;99\\)% \\(\\ldots\\) \\(\\ldots\\) lies within \\(\\mu\\pm 3\\sigma\\)\nArguably, the most important distribution in statistics\nLinear combinations of Normals are Normal\ne.g., \\((aY+b)\\sim \\mbox{N}(a\\mu+b,\\;a^2\\sigma^2)\\)\nStandard normal: $$\n\\[\\begin{aligned}\n        Z=\\frac{Y-\\mu}{\\sigma} \\sim \\mbox{N}(0,1) \\nonumber\n        \n\\end{aligned}\\]\n$$"
  },
  {
    "objectID": "slides/Module_A.html#chi-square-distribution",
    "href": "slides/Module_A.html#chi-square-distribution",
    "title": "Module A",
    "section": "Chi-square Distribution",
    "text": "Chi-square Distribution\nNotation: \\(X \\sim \\chi^2_{df}\\) \\(df=\\) degrees of freedom \\(E[X]=df\\) \\(X\\) takes on only positive values If \\(Z_i\\sim \\mbox{N}(0,1)\\), then \\(Z_i^2\\sim \\chi^2_1\\)\nIf \\(Z_1,\\ldots,Z_n\\) are independent, with \\(Z_i\\sim\\mbox{N}(0,1)\\), then $$\n\\[\\begin{aligned}\n        \\sum_{i=1}^n Z_i^2 & \\sim & \\chi^2_n \\nonumber\n        \n\\end{aligned}\\]\n$$\nUsed in hypothesis testing and CI’s involving variance"
  },
  {
    "objectID": "slides/Module_A.html#t-distribution",
    "href": "slides/Module_A.html#t-distribution",
    "title": "Module A",
    "section": "t Distribution",
    "text": "t Distribution\nIf \\(Z\\sim \\mbox{N}(0,1)\\) and \\(S^2\\sim \\chi^2_{df}\\) and \\(Z\\) and \\(S^2\\) are independent,\n$$\n\\[\\begin{aligned}\n        \\frac{Z}{S/\\sqrt{df}} & \\sim & t_{df} \\nonumber\n        \n\\end{aligned}\\]\n$$\nSymmetric, bell-shaped; tails heavier than Normal \\(E[t_{df}]=0\\); \\(Var(t_{df})\\) greater than 1 \\(\\lim_{df\\rightarrow \\infty}t_{df} \\rightarrow \\mbox{N}(0,1)\\) for \\(df&gt;30\\), the \\(t_{df}\\) closely resembles the \\(\\mbox{N}(0,1)\\) distribution\nIn linear modeling, used for inference on individual regression parameters"
  },
  {
    "objectID": "slides/Module_A.html#f-distribution",
    "href": "slides/Module_A.html#f-distribution",
    "title": "Module A",
    "section": "F Distribution",
    "text": "F Distribution\nIf \\(X_1^2\\sim \\chi^2_{df1}\\) and \\(X_2^2\\sim \\chi^2_{df2}\\), where \\(X_1^2\\perp X_2^2\\), then: $$\n\\[\\begin{aligned}\n        \\frac{X_1^2/df1}{X_2^2/df2} & \\sim & F_{df1,df2} \\nonumber\n        \n\\end{aligned}\\]\n$$\nonly takes on positive values\nconnection to \\(t\\) distribution:\n$$\n\\[\\begin{aligned}\n            \\{ t_{df} \\}^2 & \\stackrel{{\\cal D}}{=} & F_{1,df} \\nonumber\n            \n\\end{aligned}\\]\n$$\nUsed extensively in linear regression (hypothesis testing)\n\n\nClass 1 Slides"
  },
  {
    "objectID": "slides/Module_A.html#what-is-linear-regression",
    "href": "slides/Module_A.html#what-is-linear-regression",
    "title": "Module A",
    "section": "What is Linear Regression?",
    "text": "What is Linear Regression?\n\nRegression: a technique to study the association between two variables Response variable (outcome, dependent variable) Blood pressure Grouping variable (predictor, independent variable, explanatory variable) Male vs female – within each group, the value of the grouping variable is constant Drug dosage – continuous predictor of interest, infinitely many groups Adjustment for other variables\nLinear model: for our purposes, refers to linearity w.r.t. the parameters\nResponse variable is a linear function of parameters\nRegression models describe association, not causality"
  },
  {
    "objectID": "slides/Module_A.html#learning-objectives",
    "href": "slides/Module_A.html#learning-objectives",
    "title": "Module A",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nLearning 1\nLearning 2\n\n\n\nLearning 3\n\n\n\nLearning 4"
  },
  {
    "objectID": "slides/Module_N.html",
    "href": "slides/Module_N.html",
    "title": "Linear Regression",
    "section": "",
    "text": "BIOSTAT 650\nTheory and Application of Linear Regression\nModule N: Model Selection\n\n\nOutline\nTopics:\nprediction\nmaximum model\ncriteria for comparing models\nautomated model selection\nexamples\nText (MPV): Chapter 10 Reading: An Introduction to Statistical Learning with Applications in R (ISLR) Chapter 6\n\n\nModel Selection for Inference vs Prediction Model selection for Inference: we want \\(\\widehat{\\beta}\\) to be close to \\(\\beta\\) requires pre-specified scientific knowledge about the known or hypothesized causal/biological mechanisms unbiased point estimation & valid inference (interval estimation and hypothesis testing) Model selection for Prediction: we want the best model for predicting future responses The focus is more on the fitted model than on the individual parameters: \\(\\widehat{\\beta}\\) can even be biased If \\(p\\) is too large, then there can be overfitting (model follows the noise in current observations too closely) and consequently poor predictions on future observations not used in model training\n\n\nModel Complexity vs Parsimony Suppose we have p = 30 covariates (in the true model) and n = 50 observations. We could consider the following two alternatives: We could fit a model using all of the covariates. In this case, \\(\\widehat{\\beta}\\) is unbiased for \\({\\beta}\\), but it has very high variance. We could fit a model using the five strongest predictors. In this case, \\(\\widehat{\\beta}\\) will be biased for \\({\\beta}\\), but it will have lower variance. For prediction, either approach 1 or approach 2 could perform better, depending on the circumstances\n\n\nTraining vs Test error\n\n\n\n\nimage\n\n\n\n\n\nModel Selection for Prediction: Big Picture\n\\(\\bullet~~\\)Model selection methods generally consist of the same essential steps:\nSpecify maximum/full model construct a list of all candidate covariates Specify criterion for comparing competing models how well the model fits current data (training error) how well the model predicts future responses (test error) Select best (sequence of) model(s) where “best\" is defined by (2) All-Possible-subsets Regression (APR) forward, backward, hybrid Test error estimation and model validation Accuracy of the predictions when we apply our model to previously unseen test data not used to train the model indirectly estimate test error: criteria in (2) directly estimate test error: cross-validation\n\n\nStep 1: Specifying Maximum Model Maximum model: all covariates which are candidates for inclusion in final model\nNecessary to inspect data carefully before choosing candidate covariates: covariates must be scored on a meaningful scale covariates must have sufficient variability no covariate should be highly predicted by remaining covariates (i.e., beware of potential high \\(VIF_j=1/(1-R^2_j)\\) ahead of time)\n“Size” of maximum model (\\(p\\)) can be constrained by sample size (e.g., \\(\\geq\\)5 subjects per parameter)\nStatisticians and investigators should work closely together in constructing maximum model\n\n\nStep 3: Select Model Given a Criterion\nWe will introduce the approaches taking \\(p\\)-value as a criterion Selection by \\(p\\)-value is a commonly used and traditional method We will introduce other criteria (Step 2) in detail later\nAll-Possible-subsets Regression (APR) having chosen criterion for comparing models, fit models using all possible combinations of covariates final model is the one judged to be the best based on the specified criterion\nThere are many (\\(2^p-1\\)) possible combinations of covariates we want to avoid fitting and comparing all possible models desirable to apply computationally efficient selection methods\n\n\nStep 3: Classical Automated Selection Three “classical\" variations on theme: Forward Selection: start with null model (\\(\\beta_0\\) only); add covariates one at a time\nBackward Elimination: start with full model; delete covariates one at a time\nStepwise Regression (hybrid): combination of forward selection and backward elimination\nOther methods (not covered in 650), e.g., the LASSO\n\n\nAlgorithm 1: Forward Selection Pre-specify p-value threshold for inclusion: \\(p_{\\scriptscriptstyle\\text{$I$}}\\) (e.g., 0.05)\nBegin with null model (\\(\\beta_0\\) only) \\(\\mathcal{M}_0\\)\nAt each step, add the most significant covariate, provided \\(p&lt;p_{\\scriptscriptstyle\\text{$I$}}\\) for \\(k\\!=\\!0,\\dots,p\\!-\\!1\\), fit \\(p\\!-\\!k\\) models that add 1 predictor to \\(\\mathcal{M}_k\\) e.g., in the first step, \\(k=0\\), fit \\(p\\) SLRs covariate with lowest \\(p\\)-value (\\(p&lt;p_{\\scriptscriptstyle\\text{$I$}}\\)) gets entered into model \\(\\mathcal{M}_{k\\!+\\!1}\\)\nProcedure terminates when no more covariate meets the \\(p_{\\scriptscriptstyle\\text{$I$}}\\)-rule (\\(p&lt;p_{\\scriptscriptstyle\\text{$I$}}\\)) or all covariates have been added\n\n\nAlgorithm 2: Backward Elimination Pre-specify p-value for omitting: \\(p_{\\scriptscriptstyle\\text{$O$}}\\) (e.g., 0.05)\nBegin with maximum model \\(\\mathcal{M}_p\\)\nAt each step, eliminate least significant covariate, provided \\(p\\!&gt;\\!p_{\\scriptscriptstyle\\text{$O$}}\\) for \\(k\\!=\\!p,\\dots,1\\), fit \\(k\\) models that remove 1 predictor from \\(\\mathcal{M}_k\\) e.g., in the first step, \\(k=p\\), fit \\(p\\) models each w/ \\(p-1\\) predictors covariate with highest \\(p\\)-value (\\(p\\!&gt;\\!p_{\\scriptscriptstyle\\text{$O$}}\\)) gets removed to obtain \\(\\mathcal{M}_{k\\!-\\!1}\\)\nProcedure terminates when no more covariate meets the \\(p_{\\scriptscriptstyle\\text{$O$}}\\)-rule (\\(p&gt;p_{\\scriptscriptstyle\\text{$O$}}\\)), i.e., all covariates are significant in the sense that \\(p&lt;p_{\\scriptscriptstyle\\text{$O$}}\\)\n\n\nAlgorithm 3: Stepwise Regression Pre-specify \\(p_{\\scriptscriptstyle\\text{$I$}}\\) and \\(p_{\\scriptscriptstyle\\text{$O$}}\\) satisfying \\(p_O\\geq p_I\\)\nBegin with null model (\\(\\beta_0\\) only)\nProceed as in forward selection. At each step:\nadd most significant covariate, provided \\(p&lt;p_{\\scriptscriptstyle\\text{$I$}}\\)\nthen, remove least significant covariate, if \\(p&gt;p_{\\scriptscriptstyle\\text{$O$}}\\)\nProcedure terminates when no more covariates added or deleted\nIdea: After adding each new variable, seek to remove one variable that no longer provide an improvement in the model fit Attempts to more closely mimic APR while retaining the computational advantages\n\n\nAlgorithm 3: Stepwise Regression (continued) Opinion quite varied regarding appropriate \\(p_{\\scriptscriptstyle\\text{$O$}}\\) e.g., \\(p_{\\scriptscriptstyle\\text{$O$}}=0.10\\) or \\(p_O=0.25\\) \\(p_{\\scriptscriptstyle\\text{$I$}}\\) often set to 0.05\nWhy higher \\(p_{\\scriptscriptstyle\\text{$O$}}\\): test statistics involve \\(\\widehat{\\sigma}^2\\) in current model, which may be an overestimate if too few covariates in the model consequently, \\(p\\)-values may be inflated and artificially exceed \\(p_{\\scriptscriptstyle\\text{$O$}}\\)\n\n\nLimitations of Classical Automated Selection Greedy search and not necessarily find the optimal: e.g., best \\(\\mathcal{M}_1\\) includes \\(\\{X_1\\}\\) but \\(\\mathcal{M}_2\\) includes \\(\\{X_2,X_3\\}\\) sometimes, covariate is only significant in the presence of others Tend to break down when: \\(p\\) is very large (e.g., \\(p&gt;n\\), can’t do backward elimination) multicollinearity: large VIFs thus questionable \\(p\\)-values\nF-tests are problematic both during and after selection: In forward selection \\(F\\)-tests are conservative for early stages at each step, \\(\\widehat{\\sigma}^2\\) in denominator of F-statistic is not \\(\\widehat{\\sigma}_{full}^2\\) Multiple comparison problem during selection we ask the same dataset too many questions (hypotheses) and can get a small \\(p\\)-value simply by chance Post-selection inference: F-tests in the final model are not valid theoretical results for F-test assume \\(p\\) is fixed, but with automated selection we are also “estimating” \\(p\\)\n\n\nImplementation of Automated Selection Straightforward in SAS PROC REG are specified with the SELECTION= option in the MODEL statement In R The olsrr package, e.g., ols_step_forward_p(), ols_step_backward_p()\nFunction stepwise() writen by Dr. Paul A. Rubin: https://rubin.msu.domains/code/stepwise_demo.nb.html\n(demo.Rmd uploaded to Canvas, helpful for optional hw11)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraining vs Test error\n\n\n\n\nimage\n\n\n\n\n\nModel Selection for Prediction: Big Picture\n\\(\\bullet~~\\)Model selection methods for the purpose of prediction generally consist of the same essential steps:\nSpecify maximum/full model construct a list of all candidate covariates Specify criterion for comparing competing models how well the model fits current data (training error) how well the model predicts future responses (test error) Select best (sequence of) model(s) where “best\" is defined by (2) All-Possible-subsets Regression (APR) forward, backward, hybrid Test error estimation and model validation Accuracy of the predictions when we apply our model to previously unseen test data not used to train the model indirectly estimate test error directly estimate test error: cross-validation\n\n\nStep 2: Criteria for Comparing Models \\(R^2\\)\\(=\\widehat{corr}(\\widehat{Y},Y)^2\\): nondecreasing when covariates are added\n\\(R_a^2\\)\\(= 1-\\frac{\\widehat{\\sigma}^2}{SSY/(n-1)}\\): increase or decrease when covariates added \\(R_a^2\\)-based model selection equivalent to MSE-based (\\(\\widehat{\\sigma}^2\\)) \\(\\widehat{\\sigma}^2\\): when we include \\(X_{p+1}\\), \\(\\widehat{\\sigma}^2_p=\\frac{SSE_p}{n-p}\\) vs \\(\\widehat{\\sigma}^2_{p+1}=\\frac{SSE_{p+1}\\downarrow}{n-p-1\\downarrow}\\) decrease in \\(SSE\\) is not offset by corresponding loss of \\(df_E\\)\n\\(PRESS\\)\nMallows \\(C_p\\) Others: e.g., Akaike information criterion (AIC), Bayesian information criterion (BIC)\n\n\nStep 2: Criteria for Comparing Models\n\\(R^2=\\widehat{corr}(\\widehat{Y},Y)^2\\): nondecreasing when covariates are added\n\\(R_a^2\\)\\(= 1-\\frac{\\widehat{\\sigma}^2}{SSY/(n-1)}\\): increase or decrease when covariates added \\(R_a^2\\)-based model selection equivalent to MSE-based (\\(\\widehat{\\sigma}^2\\)) \\(\\widehat{\\sigma}^2\\): when we include \\(X_{p+1}\\), \\(\\widehat{\\sigma}^2_p=\\frac{SSE_p}{n-p}\\) vs \\(\\widehat{\\sigma}^2_{p+1}=\\frac{SSE_{p+1}\\downarrow}{n-p-1\\downarrow}\\) decrease in \\(SSE\\) is not offset by corresponding loss of \\(df_E\\)\n\\(PRESS\\)\nMallows \\(C_p\\) Others: e.g., Akaike information criterion (AIC), Bayesian information criterion (BIC)\n\n\nStep 2: Criteria for Comparing Models\n\\(R^2=\\widehat{corr}(\\widehat{Y},Y)^2\\): nondecreasing when covariates are added\n\\(R_a^2= 1-\\frac{\\widehat{\\sigma}^2}{SSY/(n-1)}\\): increase or decrease when covariates added \\(R_a^2\\)-based model selection equivalent to MSE-based (\\(\\widehat{\\sigma}^2\\)) \\(\\widehat{\\sigma}^2\\): when we include \\(X_{p+1}\\), \\(\\widehat{\\sigma}^2_p=\\frac{SSE_p}{n-p}\\) vs \\(\\widehat{\\sigma}^2_{p+1}=\\frac{SSE_{p+1}\\downarrow}{n-p-1\\downarrow}\\) decrease in \\(SSE\\) is not offset by corresponding loss of \\(df_E\\)\n\\(PRESS\\)\nMallows \\(C_p\\) Others: e.g., Akaike information criterion (AIC), Bayesian information criterion (BIC)\n\n\nStep 2: Criteria for Comparing Models\n\\(R^2=\\widehat{corr}(\\widehat{Y},Y)^2\\): nondecreasing when covariates are added\n\\(R_a^2= 1-\\frac{\\widehat{\\sigma}^2}{SSY/(n-1)}\\): increase or decrease when covariates added \\(R_a^2\\)-based model selection equivalent to \\(\\widehat{\\sigma}^2\\)-based \\(\\widehat{\\sigma}^2\\): when we include \\(X_{p+1}\\), \\(\\widehat{\\sigma}^2_p=\\frac{SSE_p}{n-p}\\) vs \\(\\widehat{\\sigma}^2_{p+1}=\\frac{SSE_{p+1}\\downarrow}{n-p-1\\downarrow}\\) decrease in \\(SSE\\) is not offset by corresponding loss of \\(df_E\\)\n\\(PRESS\\)\nMallows \\(C_p\\) Others: e.g., Akaike information criterion (AIC), Bayesian information criterion (BIC)\n\n\nFit v.s. Predictive Criteria \\(R^2\\), \\(R^2_a\\), \\(\\widehat{\\sigma}^2\\): all are functions of \\(\\widehat{\\epsilon}_i\\)’s: reflect how well the model fits current data (training error) do not reflect how well the model predicts future responses (test error)\nResiduals \\(\\widehat{\\epsilon}_i^2\\)’s may underestimate true errors \\(\\epsilon_i^2\\)’s \\(\\widehat{Y}_i\\) is not independent of \\(Y_i\\) and may be artificially drawn towards it (particularly for high influence points) In fact, one can show that \\(SSE=\\|\\widehat{\\boldepsilon}\\|^2\\leq \\|\\boldepsilon\\|^2\\): “The training error is often overly optimistic – it underestimates the true error\"\nResiduals \\(\\widehat{\\epsilon}_i^2\\)’s (training error) also underestimate the test errors\n\n\nModel Selection for Prediction: Big Picture\n\\(\\bullet~~\\)Model selection methods for the purpose of prediction generally consist of the same essential steps:\nSpecify maximum/full model Specify criterion for comparing competing models how well the model fits current data (training error) \\(R^2,R^2_{adj},\\widehat{\\sigma}^2\\) how well the model predicts future responses (test error) Select best (sequence of) model(s) where “best\" is defined by (2) Test error estimation and model validation indirectly estimate test error directly estimate test error: cross-validation\n\n\nModel Selection for Prediction: Big Picture\n\\(\\bullet~~\\)Model selection methods for the purpose of prediction generally consist of the same essential steps:\nSpecify maximum/full model Specify criterion for comparing competing models how well the model fits current data (training error) \\(R^2,R^2_{adj},\\widehat{\\sigma}^2\\) how well the model predicts future responses (test error) Select best (sequence of) model(s) where “best\" is defined by (2) Test error estimation and model validation indirectly estimate test error directly estimate test error: cross-validation\n\n\nPrediction error residuals Deleted residuals (or prediction error residuals)\n_i(-i)=Y_i-_i(-i)= where \\(\\widehat{Y}_{i(-i)}\\) is the predicted value for the \\(i^{th}\\) observation from a fitted model where the \\(i^{th}\\) observation was left out Note: now \\(\\widehat{Y}_{i(-i)}\\) is independent of \\(Y_i\\)\n\\(\\widehat{\\epsilon}_{i(-i)}\\) also known as “\\(PRESS\\)\" residual, denoted as \\(PRESS_i\\) Rationale: [leave-one-out] systematically remove each observation, pretend it is future data and measure performance of prediction Instead of defining criteria (\\(\\widehat{\\sigma}^2\\) and \\(R^2\\)) based on \\(\\widehat{\\epsilon_i}^2\\), we can use the prediction error residual \\(\\widehat{\\epsilon}_{i(-i)}\\) Prediction counterparts of \\(SSE\\) and \\(R^2\\): the \\(PRESS\\) and \\(R^2_{pred}\\)\n\n\nCriterion 4. Prediction Sum of Squares (PRESS) Define the \\(PRESS\\) (prediction sum of squares) statistic: PRESS & = & _i=1^n _i(-i)^2= _i=1^n {}^2 Not necessary to re-fit model Accounted for high leverage \\(h_{ii}\\) but not high residual Reasonable to select model with lowest \\(PRESS\\)\nAnother measure, prediction \\(R^2\\): R^2_pred & = & 1 - \\(R^2_{pred}\\) measures ability to predict future responses \\(R^2\\) and \\(R_a^2\\) relate to model’s ability to predict current data\nThis is also known as “leave one out” cross-validation!\n\n\nResidual taxonomy\\(^1\\)\n\n\n\n\n\nCriterion 5. Mallows’ \\(C_p\\) Total variation in prediction \\(\\widehat{Y}\\) is due to bias and variance: _p =_i=1^n { _ + _} \\(\\Gamma_p\\) corresponds to a specific model (with \\(p\\) parameters) Mallows’ \\(C_p\\) is an estimate of \\(\\Gamma_p\\): C_p = _p =(_+_) \\(SSE_p\\): from the model being evaluated, underestimates test error \\(\\widehat{\\sigma}_{full}^2=SSE_{\\scriptscriptstyle full} /(n-p_{\\scriptscriptstyle full})\\): from full (maximum) model Mallows’ \\(C_p\\) strikes a balance between bias and variance Recall: \\(p\\uparrow\\), Var(\\(\\widehat{Y}\\))\\(\\uparrow\\). In \\(C_p\\): when \\(p\\uparrow\\), \\(SSE_p\\downarrow\\) but \\(2p\\widehat{\\sigma}_{full}^2\\uparrow\\) (penalty) The model with the smallest \\(C_p\\) is selected\n\n\nOther Criterion: e.g. AIC and BIC\nRecall Mallows’ \\(C_p\\)\n\\(C_p = \\widehat{\\Gamma}_p =\\frac{1}{n}(\\underbracket{SSE_p}_\\text{training error of current model}+\\underbracket{2p\\widehat{\\sigma}_{full}^2}_\\text{adjustment for underestimation})\\)\nAkaike information criterion (AIC): \\(2\\log \\mathcal{L}+2p\\)\n\\(AIC = \\frac{1}{n{\\color{royalblue}\\widehat{\\sigma}_{full}^2}}(\\underbracket{SSE_p}_\\text{training error of current model}+\\underbracket{2p\\widehat{\\sigma}_{full}^2}_\\text{adjustment for underestimation})+c\\) Equivalent to Mallows’ \\(C_p\\) in MLR with Normal data Bayesian information criterion (BIC)\n\\(BIC = \\frac{1}{n{\\color{royalblue}\\widehat{\\sigma}_{full}^2}}(\\underbracket{SSE_p}_\\text{training error of current model}+\\underbracket{{\\color{royalblue}\\log(n)}p\\widehat{\\sigma}_{full}^2}_\\text{adjustment for underestimation})+c %\\nonumber\\ee\\) Places a heavier penalty on models with large \\(p\\) because \\(\\log(n)&gt;2\\) for any \\(n&gt;7\\)\n\n\nModel Selection for Prediction: Big Picture\n\\(\\bullet~~\\)Model selection methods for the purpose of prediction generally consist of the same essential steps:\nSpecify maximum/full model Specify criterion for comparing competing models how well the model fits current data (training error) \\(R^2,R^2_{adj},\\widehat{\\sigma}^2\\) how well the model predicts future responses (test error) \\(C_p\\), AIC, BIC, etc. Select best (sequence of) model(s) where “best\" is defined by (2) Test error estimation and model validation indirectly estimate test error via an adjustment to the training error to account for overfitting directly estimate test error: cross-validation\n\n\nUse of Criteria: Example True model: \\(Y=1 + 0.1 *X_1 + 0.2*X_2 + 0.01*X_3 + 0.4*X_4 + \\epsilon\\), \\(\\epsilon \\sim N(0,0.2)\\) Suppose true model is unknown, select best predictive model Measures for 3 possible models:\n\n\n\n\n\\(X\\)’s\n\\(R^2\\)\n\\(\\widehat{\\sigma}^2\\)\n\\(R^2_a\\)\n\\(R^2_{pred}\\)\n\\(C_p\\)\n\n\n\n\n2,4\n0.2896\n0.04186\n0.2882\n0.2852\n34.4\n\n\n2,4,1\n0.3123\n0.04057\n0.3102\n0.3065\n3.3\n\n\n2,4,1,3\n0.3125\n0.04059\n0.3098\n0.3055\n5.0\n\n\n\n\nNote that even though \\(X_3\\) is in the true model, its effect is not large enough to offset the ‘costs’ to estimate it\n\n\nStep 4: Model Validation Ultimately, desirable to test final model on external data set or newly collected data Use existing data to develop model Assess model’s predictive ability in new data is a useful alternative\n\n\nStep 4: Model Validation: K-fold cross-validation Split data into \\(K\\) equally sized data sets called \\(\\boldD_1,\\dots,\\boldD_K\\) For \\(j=1,\\dots,K\\), train model on \\(\\boldD_{(-j)}\\) data; test on \\(\\boldD_j\\); Average the measures of predictive ability across the \\(K\\) pieces\n\n\n\n\nimage\n\n\n\n\\(K=n\\): “leave one out” cross-validation, e.g., \\(PRESS\\) statistic \\(K=2\\): “data spiting\": half training and half testing data\n\n\nModel Selection for Prediction: Big Picture\n\\(\\bullet~~\\)Model selection methods for the purpose of prediction generally consist of the same essential steps:\nSpecify maximum/full model\nSpecify criterion for comparing competing models how well the model fits current data (training error) \\(R^2,R^2_{adj},\\widehat{\\sigma}^2\\)\nhow well the model predicts future responses (test error) \\(PRESS,~C_p\\), AIC, BIC Select best (sequence of) model(s) where “best\" is defined by (2) Test error estimation and model validation indirectly estimate test error via an adjustment to the training error to account for overfitting \\(C_p\\), AIC, BIC, etc. directly estimate test error: cross-validation \\(PRESS\\) & k-fold cross validation\n\n\n\n\n\nimage\n\n\n\n\nOptional Readings: True Errors vs. Residuals Claim: \\(||\\widehat{\\boldepsilon} ||^2 \\leq ||{\\boldepsilon} ||^2\\) Proof: & = & (I - )\n& = & (I - ) (+ )\n& = & - + (I - )\n& = & (I - ) Therefore, || ||^2 & = & {(I - ) }^T (I - )\n& = & ^T (I - )\n& = & || ||^2 - ^T Note: \\({\\boldepsilon}^T {\\boldH}{\\boldepsilon}={\\boldepsilon}^T {\\boldH^T\\boldH}{\\boldepsilon} = ({\\boldH}{\\boldepsilon )}^T ({\\boldH}{\\boldepsilon}) ={(\\boldepsilon^*)}^T (\\boldepsilon^*) \\geq 0\\) where \\(\\boldepsilon^* = {\\boldH} \\boldepsilon\\)\n\n\nOptional Readings: Justification of Mallows’ \\(C_p\\) _p &= & { _i=1^n [E(_i - Y_i)]^2 + _i=1^n Var( _i)}\n&= &{_i=1^n [E(_i)]^2 + ^2 p}\nRecall \\(\\frac{SSE_p}{\\sigma^2}\\sim \\chi^2_{n-p,\\lambda}\\) with mean = \\(n-p + \\lambda\\), i.e., \\[E\\left[\\frac{SSE_p}{\\sigma^2}\\right] = (n-p) + \\frac{\\sum_{i=1}^n [E(\\widehat{\\epsilon}_i)]^2}{\\sigma^2}\\]\nThus, we can re-write: _p &= &E- (n-p) + p\n\n\nOptional Readings: Justification of Mallows’ \\(C_p\\) (continued) _p &= &E- (n-p) + p\nMallows’ \\(C_p\\) is a plug-in estimator: C_p _p&=& -(n-p)+ p\n&= &-(n-p)+ p\n& = & p + { -1 }(n-p)\n\n\nQuestions?"
  },
  {
    "objectID": "slides/Module_M_example.html",
    "href": "slides/Module_M_example.html",
    "title": "Module M",
    "section": "",
    "text": "A data set is assembled from (n=17) hospitals in order to construct a model to predict manpower requirements (MANPOWER) as a function of the following factors: average number of patients admitted per day (PAT-DAYS), number of x- rays taken (X-RAYS), total number of days patients spent in bed (BED-DAYS), and average number of days stay per admission (AVG-STAY). One month’s worth of experience is recorded for each hospital.\nRead in the data file (systolic1.csv).\n\n\nrm(list=ls())\ndata = read.csv(file=\"hosp1.csv\",header=T)\nattach(data)\nhead(data)\n\n  X pat_days x_rays bed_days avg_stay manpower\n1 1    15.57   2463   472.92     4.45   566.52\n2 2    44.02   2048  1339.75     6.92   696.82\n3 3    20.42   3940   620.25     4.28  1033.15\n4 4    18.74   6505   568.33     3.90  1603.62\n5 5    49.20   5723  1497.60     5.50  1611.37\n6 6    44.92  11520  1365.83     4.60  1613.27"
  },
  {
    "objectID": "slides/Module_M_example.html#example",
    "href": "slides/Module_M_example.html#example",
    "title": "Module M",
    "section": "",
    "text": "A data set is assembled from (n=17) hospitals in order to construct a model to predict manpower requirements (MANPOWER) as a function of the following factors: average number of patients admitted per day (PAT-DAYS), number of x- rays taken (X-RAYS), total number of days patients spent in bed (BED-DAYS), and average number of days stay per admission (AVG-STAY). One month’s worth of experience is recorded for each hospital.\nRead in the data file (systolic1.csv).\n\n\nrm(list=ls())\ndata = read.csv(file=\"hosp1.csv\",header=T)\nattach(data)\nhead(data)\n\n  X pat_days x_rays bed_days avg_stay manpower\n1 1    15.57   2463   472.92     4.45   566.52\n2 2    44.02   2048  1339.75     6.92   696.82\n3 3    20.42   3940   620.25     4.28  1033.15\n4 4    18.74   6505   568.33     3.90  1603.62\n5 5    49.20   5723  1497.60     5.50  1611.37\n6 6    44.92  11520  1365.83     4.60  1613.27"
  },
  {
    "objectID": "slides/Module_M_example.html#compute-the-correlation-matrix-of-the-four-covariates.",
    "href": "slides/Module_M_example.html#compute-the-correlation-matrix-of-the-four-covariates.",
    "title": "Module M",
    "section": "Compute the correlation matrix of the four covariates.",
    "text": "Compute the correlation matrix of the four covariates.\n\nDo you have any concerns? Which pair-wise correlation appears to be the most problematic?\n\n\ncor(data[c(\"pat_days\", \"x_rays\", \"bed_days\", \"avg_stay\")])\n\n          pat_days    x_rays  bed_days  avg_stay\npat_days 1.0000000 0.9073795 0.9999039 0.6711974\nx_rays   0.9073795 1.0000000 0.9071492 0.4466496\nbed_days 0.9999039 0.9071492 1.0000000 0.6711098\navg_stay 0.6711974 0.4466496 0.6711098 1.0000000\n\n# psych::pairs.panels(data[,\n#     c(\"pat_days\", \"x_rays\", \"bed_days\", \"avg_stay\")])"
  },
  {
    "objectID": "slides/Module_M_example.html#what-are-the-limitations-of-your-assessment-via-bivariate-analysis",
    "href": "slides/Module_M_example.html#what-are-the-limitations-of-your-assessment-via-bivariate-analysis",
    "title": "Module M",
    "section": "What are the limitations of your assessment via bivariate analysis?",
    "text": "What are the limitations of your assessment via bivariate analysis?"
  },
  {
    "objectID": "slides/Module_M_example.html#fit-a-model-containing-each-of-the-afore-listed-factors.-compute-the-vifs.",
    "href": "slides/Module_M_example.html#fit-a-model-containing-each-of-the-afore-listed-factors.-compute-the-vifs.",
    "title": "Module M",
    "section": "Fit a model containing each of the afore-listed factors. Compute the VIFs.",
    "text": "Fit a model containing each of the afore-listed factors. Compute the VIFs.\n\nm = lm(manpower~pat_days+x_rays+bed_days+avg_stay)\ncar::vif(m)\n\n   pat_days      x_rays    bed_days    avg_stay \n5234.696180    7.778477 5210.637545    2.499282 \n\n\n\nWhich covariate has the highest % of its variation explained by other covariates in the mode?"
  },
  {
    "objectID": "slides/Module_M_example.html#re-fit-the-model-without-bed-days.-compare-the-r2-to-that-of-the-original-model.",
    "href": "slides/Module_M_example.html#re-fit-the-model-without-bed-days.-compare-the-r2-to-that-of-the-original-model.",
    "title": "Module M",
    "section": "Re-fit the model without BED-DAYS. Compare the R\\(^2\\) to that of the original model.",
    "text": "Re-fit the model without BED-DAYS. Compare the R\\(^2\\) to that of the original model.\n\nm2 = lm(manpower~pat_days+x_rays+avg_stay)\nc(summary(m)$r.squared, summary(m)$adj.r.squared)\n\n[1] 0.9905451 0.9873935\n\nc(summary(m2)$r.squared, summary(m2)$adj.r.squared)\n\n[1] 0.9894044 0.9869592"
  },
  {
    "objectID": "slides/Module_M_example.html#re-fit-the-model-without-pat-days.-compare-the-r2-to-that-of-the-original-model.",
    "href": "slides/Module_M_example.html#re-fit-the-model-without-pat-days.-compare-the-r2-to-that-of-the-original-model.",
    "title": "Module M",
    "section": "Re-fit the model without PAT-DAYS. Compare the R\\(^2\\) to that of the original model.",
    "text": "Re-fit the model without PAT-DAYS. Compare the R\\(^2\\) to that of the original model.\n\nm3 = lm(manpower~bed_days+x_rays+avg_stay)\nc(summary(m)$r.squared, summary(m)$adj.r.squared)\n\n[1] 0.9905451 0.9873935\n\nc(summary(m2)$r.squared, summary(m2)$adj.r.squared)\n\n[1] 0.9894044 0.9869592\n\nc(summary(m3)$r.squared, summary(m3)$adj.r.squared)\n\n[1] 0.9900682 0.9877763"
  },
  {
    "objectID": "slides/Module_M_example.html#based-on-your-work-thus-far-what-is-a-solution-to-the-collinearity-issue-previously-identified",
    "href": "slides/Module_M_example.html#based-on-your-work-thus-far-what-is-a-solution-to-the-collinearity-issue-previously-identified",
    "title": "Module M",
    "section": "Based on your work thus far, what is a solution to the collinearity issue previously identified?",
    "text": "Based on your work thus far, what is a solution to the collinearity issue previously identified?\n\ncar::vif(m)\n\n   pat_days      x_rays    bed_days    avg_stay \n5234.696180    7.778477 5210.637545    2.499282 \n\ncar::vif(m2)\n\n pat_days    x_rays  avg_stay \n11.321381  7.771393  2.498503 \n\ncar::vif(m3)\n\n bed_days    x_rays  avg_stay \n11.269348  7.737331  2.492904"
  },
  {
    "objectID": "slides/Module_J.html",
    "href": "slides/Module_J.html",
    "title": "Linear Regression",
    "section": "",
    "text": "BIOSTAT 650\nTheory and Application of Linear Regression\nModule J: General Linear Hypothesis\n\n\nOutline\nTopics:\nGLH framework\nTesting equality of regression coefficients\nExamples\n\n\nGeneral Linear Hypothesis (GLH) To date, we have focused on testing hypotheses through the Extra SS principle. e.g.,\n\\({\\boldY }={\\boldX}\\boldbeta+{\\boldepsilon}\\) \\(\\boldbeta=(\\boldbeta_1^T,\\boldbeta_2^T)^T\\)\nAll null hypotheses took the form: \\(H_0:\\boldbeta_2={\\boldzero }\\) \\(F = \\frac{SS(\\boldbeta_2\\mid \\boldbeta_1)/p_2}{\\widehat{\\sigma}_{\\scriptscriptstyle \\text{$1$} } } \\sim F_{p_2,n-p}\\) \\(SS(\\boldbeta_2\\mid \\boldbeta_1)=SSR(\\boldbeta_1,\\boldbeta_2)-SSR(\\boldbeta_1)\\)\nOften, it is of interest to test more general hypotheses: e.g., \\(H_0: \\beta_{1}=\\beta_{2}=\\beta_{3}\\) (recall cell means coding) Using the GLH principle, we have more flexibility to specify hypotheses\n\n\nExample Example: consider a study designed to assess the relationship between resting heart rate (\\(HR\\)) and age (\\(A\\)) among 30-54 year olds.\nin order to avoid assuming that \\(E(HR)\\) is linear in age, the following model is specified: HR_i & = & _0 + _1AG_1i + _2AG_2i +_3AG_3i + _4AG_4i + _i where: AG_1i & = & I(30 A_i )\nAG_2i & = & I(35 A_i )\nAG_3i & = & I(40 A_i )\nAG_4i & = & I(45 A_i )\nAG_5i & = & I(50 A_i )\n\n\nExample HR_i & = & _0 + _1AG_1i + _2AG_2i +_3AG_3i + _4AG_4i + _i\nHowever, the investigator hypothesizes that only four age groups may be necessary, as mean heart rate in the 30-34 and 35-39 age groups are equal This implies the following hypotheses: \\(H_0:\\beta_1=\\beta_2\\), \\(H_1:\\beta_1 \\neq \\beta_2\\)\nThis test can easily be formulated as a linear function of \\(\\beta\\)’s \\(H_0:\\beta_1-\\beta_2=0\\), \\(H_1:\\beta_1 - \\beta_2\\neq 0\\)\n\n\nGLH method\nAny null hypothesis expressed as \\(H_0: {\\boldT}{\\boldbeta}={\\boldcc}\\) is a GLH Entries in \\({\\boldT}\\) and \\({\\boldcc}\\) are known constants \\({\\boldT}\\) is often referred to as the contrast matrix\nMain idea of GLH: Find \\({\\boldT\\ktimesp}\\) s.t. the linear functions \\({\\boldT\\ktimesp}{\\boldbeta\\ptimesone}=\\boldcc\\) gives the stated \\(H_0\\) \\(k\\) = number of equations simultaneously being tested \\(p\\) = dimension of \\(\\boldbeta\\) \\({\\boldT\\ktimesp}\\) is needed for constructing a test statistic\nIn the example \\(H_0:\\beta_1=\\beta_2\\), \\(H_1:\\beta_1 \\neq \\beta_2\\) equivalent to \\(H_0:\\beta_1-\\beta_2=0\\), \\(H_1:\\beta_1 - \\beta_2\\neq 0\\) \\({\\boldT\\onetimesp}=[\\begin{array}{ccccc}0 & 1 & -1 & 0 & 0  \\end{array}]\\), s.t. \\({\\boldT}{\\boldbeta}=\\beta_1-\\beta_2\\) and \\(\\boldcc=0\\)\n\n\nConstructing Test Statistic \\(H_0:\\boldT\\ktimesp\\boldbeta\\ptimesone=\\boldcc\\ktimesone\\) vs \\(H_1:\\boldT\\ktimesp\\boldbeta\\ptimesone\\neq \\boldcc\\ktimesone\\) F-test for GLH \\[\\boxed{F=\\frac{ ({\\boldT}\\widehat{\\boldbeta}-{\\boldcc})^T \\{{\\boldT}({\\boldX}^T{\\bf\n        X})^{-1}{\\boldT}^T\\}^{-1} ({\\boldT}\\widehat{\\boldbeta}-{\\boldcc})/rank(\\boldT) }{ \\widehat{\\sigma}^2_{\\scriptscriptstyle \\text{$1$}}}\n\\stackrel{H_0}{\\sim}  F_{rank({\\bf\n        T}),n-p}\n}\\] For a well defined \\(H_0\\), \\(rank(\\boldT)\\) = number of rows in \\(\\boldT\\), i.e., how many equations (at most \\(p\\)) are we simultaneously testing\n\\(\\widehat{\\sigma}^2_{\\scriptscriptstyle \\text{$1$}}\\): obtained from the unrestricted model, i.e., under \\(H_1\\)\nDerivation provided at the end of the slides Rationale: \\(\\underbrace{\\boldT \\widehat{\\boldbeta}-\\boldcc}_\\text{denoted as $\\boldZ$} \\stackrel{H_0}{\\sim} N\\{ \\;\\boldzero,\\;\\; \\underbrace{\\sigma^2 \\boldT \\xtx^{-1} \\boldT^T}_\\text{denoted as $\\boldSigma$} \\;\\}\\) Under the null, \\(\\boldZ^\\top \\boldSigma^{-1} \\boldZ\\) should be small\n\n\nExample 1 Suppose the investigators want to examine whether the two lowest and two highest age intervals could be combined HR_i & = & _0 + _1AG_1i + _2AG_2i +_3AG_3i + _4AG_4i + _i\nthe pertinent hypotheses can be listed as: \\(H_0: \\beta_1=\\beta_2\\), \\(\\beta_4=0\\) \\(H_1: \\beta_1 \\neq \\beta_2\\), or \\(\\beta_4 \\neq 0\\) re-casting \\(H_0\\) in terms of the GLH, _ & = &\n\\(H_0: {\\boldT_{\\!\\sf\\scriptscriptstyle{2\\times 5}}}\\boldbeta_{\\!\\sf\\scriptscriptstyle{5\\times1}}={\\boldzero }_2\\) vs. \\(H_1: {\\boldT}\\boldbeta\\neq {\\boldzero }_2\\) test statistic: F = ^2 F_2,n-5\n\n\nExample 2 \\(n=26\\) subjects selected to participate in a study designed to examine the effects of weight and activity level on cholesterol levels (HDL)\nSubjects were placed into one of three groups: Group 1: control (n=8) Group 2: running (n=8) Group 3: running and weight training (n=10) Response: HDL (mg/dl) Covariates: group, weight (lbs) Does the association between weight and HDL differ by group?\n\n\nExample 2, Stratified SLR models It is common in practice to fit “stratified” models: Group 1: \\(HDL_i, = \\beta_1 + \\beta_4 W_i + \\epsilon_i\\) Group 2: \\(HDL_i = \\beta_2 + \\beta_5W_i + \\epsilon_i\\) Group 3: \\(HDL_i = \\beta_3 + \\beta_6W_i + \\epsilon_i\\) Models are fitted separately to “three datasets\" (each group is treated as a separate dataset).\nSince there are three distinct regression lines, we have distinct slopes\ndistinct intercepts\n\n\nExample 2 (From 3 SLR to 1 MLR) separate SLR models can be fitted on three datasets\nUltimately we wish to see if the set of models can be simplified, i.e., are the 3 slopes the same? if the slopes are the same, are the intercepts also the same? Fitting models separately does not readily allow us to test differences in parameters\nWe can represent the previous set of group-specific models in a single, more compact MLR model: \\({\\boldY } = {\\boldX}\\boldbeta + {\\boldepsilon}\\) where \\(\\boldbeta^T=(\\beta_1,\\ldots,\\beta_6)\\). What should \\({\\boldX}\\) be?\n\n\nExample 2: From Group-specific SLRs to MLR Group 1: \\({\\boldY }_1 = {\\boldX}_1\\boldbeta_1 + {\\boldepsilon}_1\\) = +\nGroup 2: \\({\\boldY }_2 = {\\boldX}_2\\boldbeta_2 + {\\boldepsilon}_2\\) = +\nGroup 3: \\({\\boldY }_3 = {\\boldX}_3\\boldbeta_3 + {\\boldepsilon}_3\\) = +\n\n\nExample 2: From Group-specific SLRs to MLR Group 1: \\({\\boldY }_1 = {\\boldX}_1\\boldbeta_1 + {\\boldepsilon}_1\\) = +\nGroup 2: \\({\\boldY }_2 = {\\boldX}_2\\boldbeta_2 + {\\boldepsilon}_2\\) = +\nGroup 3: \\({\\boldY }_3 = {\\boldX}_3\\boldbeta_3 + {\\boldepsilon}_3\\) = +\n\n\nExample 2 (MLR model) Using the typical MLR \\({\\boldY } = {\\boldX}\\boldbeta + {\\bf \\epsilon}\\), where = = =\n= \\(HDL=\\beta_1G_{1}+\\beta_2G_{2}+\\beta_3G_{3}+\\beta_4G_{1}W+\\beta_5G_{2}W+\\beta_6G_{3}W+\\epsilon\\), where \\(G_j=I(\\text{group } j),j=1,\\dots,3\\) and \\(W=(W_1,\\dots,W_{26})\\) Note: the above \\(\\boldX\\) spans, but does not contain, an intercept\n\n\nExample 2: parallelism \\(HDL=\\underbrace{\\left(\\beta_1G_{1}+\\beta_2G_{2}+\\beta_3G_{3}\\right)}_\\text{intercept}+\\underbrace{\\left(\\beta_4G_{1}+\\beta_5G_{2}+\\beta_6G_{3}\\right)}_\\text{slope}W+\\epsilon\\) Using the GLH approach, we can test whether the slopes of the group-specific regression lines are equal \\(H_0: \\beta_4=\\beta_5=\\beta_6\\) (lines are parallel),\n\\(H_1:\\) at least one of \\(\\beta_j\\), \\(j=4,5,6\\), is different from the others\n(at least one line is not parallel to the others) : \\(H_0: \\beta_4-\\beta_5=0\\) and \\(\\beta_5-\\beta_6=0\\),\nEquivalently: \\(H_1:\\beta_4 - \\beta_5 \\neq 0\\) or \\(\\beta_5 - \\beta_6 \\neq 0\\) Note: third contrast is redundant Re-framing \\(H_0\\) in terms of the GLH, = \\(H_0: {\\boldT}\\boldbeta={\\boldzero }_2\\) vs. \\(H_1: {\\boldT}\\boldbeta\\neq {\\boldzero }_2\\)\n\n\nExample 2: parallelism Test statistic: F = & & F_2,20 see R code and output: \\(F=2.95\\) \\(p=P(F_{2,20}&gt;2.95)=0.075\\)\nThis data is consistent with the parallelism hypothesis (null).\nWe have insufficient evidence to conclude the associations between weight and HDL differ across exercise groups (p=0.075).\n\n\n\n\n\n\n\n\n\n\n\nHome Exercise: equality of intercepts\n\\(HDL=\\underbrace{\\left(\\beta_1G_{1}+\\beta_2G_{2}+\\beta_3G_{3}\\right)}_\\text{intercept}+\\underbrace{\\left(\\beta_4G_{1}+\\beta_5G_{2}+\\beta_6G_{3}\\right)}_\\text{slope}W+\\epsilon\\) We can also test the equality of intercepts of the group-specific regression lines \\(H_0: \\beta_1=\\beta_2=\\beta_3\\) Re-write hypotheses find \\({\\boldT}\\) in GLH \\(H_0: {\\boldT}\\boldbeta= {\\boldzero }_2\\) vs. \\(H_1: {\\boldT}\\boldbeta\\neq {\\boldzero }_2\\) =\nTest statistic:\n\\(F=~~~~~~~~~~~~~\\stackrel{H_0}{\\sim} F_{2,20}\\) \\(p=P(F_{2,20}&gt;~~~~~~~~~~~)=\\)\n\n\n\n\n\nHome Exercise Answer Key: equality of intercepts\n\\(HDL=\\underbrace{\\left(\\beta_1G_{1}+\\beta_2G_{2}+\\beta_3G_{3}\\right)}_\\text{intercept}+\\underbrace{\\left(\\beta_4G_{1}+\\beta_5G_{2}+\\beta_6G_{3}\\right)}_\\text{slope}W+\\epsilon\\) We can also test the equality of intercepts of the group-specific regression lines \\(H_0: \\beta_1=\\beta_2=\\beta_3\\) Re-write hypotheses \\(H_0: \\beta_1-\\beta_2=0, \\beta_2-\\beta_3=0\\)\n(many different ways, e.g.,) \\(H_0: \\beta_3-\\beta_1=0, \\beta_2-\\beta_1=0\\) find \\({\\boldT}\\) in GLH \\(H_0: {\\boldT}\\boldbeta= {\\boldzero }_2\\) vs. \\(H_1: {\\boldT}\\boldbeta\\neq {\\boldzero }_2\\) =\nTest statistic:\n\\(F=~~~3.12~~~~\\stackrel{H_0}{\\sim} F_{2,20}\\) \\(p=P(F_{2,20}&gt;~~~3.12~~~~)=0.066\\)\n\n\nExample 2: Connection to reference cell coding and SS \\(\\boxed{HDL=\\underbrace{\\left(\\beta_1G_{1}+\\beta_2G_{2}+\\beta_3G_{3}\\right)}_\\text{intercept}+\\underbrace{\\left(\\beta_4G_{1}+\\beta_5G_{2}+\\beta_6G_{3}\\right)}_\\text{slope}W+\\epsilon}\\) Cell means coding: \\(H_0: \\underbrace{\\beta_5-\\beta_4}_\\text{2 vs 1}=0; \\underbrace{\\beta_6-\\beta_4}_\\text{3 vs 1}=0\\) (GLH) Re-parameterize the model: Reference cell coding: directly parameterize \\(\\beta_5-\\beta_4\\) and \\(\\beta_6-\\beta_4\\) Slope of weight for each group: \\(H_0:\\) Extra SS test: \\(F~~=~~ \\frac{SS(~~~~~~~~~~~~~\\mid ~~~~~~~~~~~~~)}{\\widehat{\\sigma}^2_{\\scriptstyle 1}}\\stackrel{H_0}{\\sim} F_{~~~~,~~~~}\\)\n\n\nExample 2: Extra SS Test of interactions \\(HDL=\\gamma_1+\\gamma_2G_{2}+\\gamma_3G_{3}+\\gamma_4W+\\gamma_5G_{2}W+\\gamma_6G_{3}W+\\epsilon\\) Test the equality of slopes using extra SS & reference cell coding\nEquality of slopes: are interactions significant given that main effects are in the model?\nExtra SS test for equal slopes: F& = &   =  2.95     F_  ,  \ni.e., same result as GLH test of equal slopes\n\n\n\n\n\nExample 2: Extra SS Test of interactions\n\\(HDL=\\gamma_1+\\gamma_2G_{2}+\\gamma_3G_{3}+\\gamma_4W+\\gamma_5G_{2}W+\\gamma_6G_{3}W+\\epsilon\\) Test the equality of slopes using extra SS & reference cell coding\nEquality of slopes: are interactions significant given that main effects are in the model?\nExtra SS test for equal slopes: F   =      =   2.95     F_2,20\ni.e., same result as GLH test of equal slopes\n\n\nHome Exercise: Extra SS Test of Intercepts\n\\(HDL=\\gamma_1+\\gamma_2G_{2}+\\gamma_3G_{3}+\\gamma_4W+\\gamma_5G_{2}W+\\gamma_6G_{3}W+\\epsilon\\) Test the equality of intercepts using extra SS & reference cell coding\nEquality of slopes: are intercepts significant given that slopes are different?\nExtra SS test for equal intercepts: F & = &   =   3.12    F_  ,  \ni.e., same result as GLH test of equal intercepts Note: GLH gives partial test of intercepts, assuming slopes are different (i.e., assuming group x weight interactions are in the model).\n\n\n\n\n\nHome Exercise Answer Key: Extra SS Test of Intercepts\n\\(HDL=\\gamma_1+\\gamma_2G_{2}+\\gamma_3G_{3}+\\gamma_4W+\\gamma_5G_{2}W+\\gamma_6G_{3}W+\\epsilon\\) Test the equality of intercepts using extra SS & reference cell coding\nEquality of slopes: are intercepts significant given that slopes are different?\nExtra SS test for equal intercepts: F & = &   =   3.12  ~  F_2,20\ni.e., same result as GLH test of equal intercepts Note: GLH gives partial test of intercepts, assuming slopes are different (i.e., assuming group x weight interactions are in the model).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstructing Test Statistic (proof)\nRecall: \\(\\widehat{\\boldbeta} \\sim N(\\boldbeta, \\sigma^2 \\xtx^{-1} )\\)\ntherefore, \\(\\boldT \\widehat{\\boldbeta} \\sim N\\{ \\;E[\\boldT \\widehat{\\boldbeta}],\\;\\; Var(\\boldT \\widehat{\\boldbeta}) \\;\\}\\), where E[] & = &\nVar()& & Var() ^T\n& = & ^2 ^-1 ^T\nUnder the null hypothesis \\(E[\\boldT \\widehat{\\boldbeta} - {\\boldcc}] =\\boldT \\boldbeta - {\\boldcc}= {\\boldzero }\\)\nTherefore, \\(\\underbrace{\\boldT \\widehat{\\boldbeta}-\\boldcc}_\\text{$\\boldY$} \\stackrel{H_0}{\\sim} N\\{ \\;\\boldzero,\\;\\; \\underbrace{\\sigma^2 \\boldT \\xtx^{-1} \\boldT^T}_\\text{$\\boldSigma$} \\;\\}\\)\nApplying Results 1-2 in the footnote \\[\\boxed{\n    (\\boldT \\widehat{\\boldbeta}-{\\boldcc} )^T \\{\\sigma^2 \\boldT \\xtx^{-1} \\boldT^T \\}^{-1}   (\\boldT \\widehat{\\boldbeta}-{\\boldcc}) \\sim \\chi^2_{\\scriptstyle \\text{rank($\\boldT$), $\\lambda=0$}}\n}\\]\n\n\nConstructing Test Statistic (proof continued) We have \\((\\boldT \\widehat{\\boldbeta}-{\\boldcc} )^T \\{\\sigma^2 \\boldT \\xtx^{-1} \\boldT^T \\}^{-1} (\\boldT \\widehat{\\boldbeta}-{\\boldcc}) \\stackrel{H_0}{\\sim} \\chi^2_{\\scriptstyle \\text{rank($\\boldT$), $\\lambda=0$}}\\) \\(\\frac{SSE}{\\sigma^2 } \\sim \\chi^2_{\\text{$n\\!-\\!p,\\lambda \\stackrel{\\scriptscriptstyle \\text{LINE}}{=}0$} }\\) and \\(\\widehat{\\boldbeta}\\ind SSE\\) (Module F)\nTo derive a test statistic, we take their ratio (divide each by df)\nF & = & (SSE/^2)/(n-p)\n& = &\n& & F_rank( T),n-p\n\n\nQuestions?\n\n\nGroup project Group assignments available on Canvas “People\" page Presentation on December 6th and 8th Presentation order randomly assigned. Please email us if you are not in the US time zone and have time constraints Project report due at 11:59pm on December 10th Sample project report\n\n\nConfounding Definition: a pre-exposure variable that, conditional on other covariates, is associated with outcome conditional on exposure associated with exposure/treatment/POI\n\n\n0.5\n\n0.5\n\n\nWe adjust for confounders when studying the association between the predictor of interest (POI) and the outcome Crude treatment effect is biased unless treatment is randomized\n\n\nGroup project\nDetermine question of interest (X and Y) via literature review hypothesis generation via e.g., model selection is not necessary model selection for inference questions is not recommended\nDetermine confounders to adjust via literature review"
  },
  {
    "objectID": "slides/Module_K.html",
    "href": "slides/Module_K.html",
    "title": "Linear Regression",
    "section": "",
    "text": "BIOSTAT 650\nTheory and Application of Linear Regression\nModule K: Model Diagnosis\n\n\nOutline\nTopics:\nPurpose Residuals and Properties of residuals Review of model assumptions Impact of violating assumptions Use of residuals in model diagnostics Correction strategies Outliers Examples\nMPV 5th edition: Chapter 4 and 5\n\n\nRegression Diagnostics Regression diagnostics includes assessment of: Model assumptions (LINE) Influential observations/outliers Multicollinearity\n\n\nLinear Model: Assumptions\nModel: \\({\\boldY} = \\boldX\\boldbeta + \\boldepsilon\\) Assumptions: \\({\\boldY}\\sim N(\\boldX\\boldbeta,\\sigma^2{\\boldI})\\)\nLinearity: \\(E[Y_i]=\\beta_0 + \\beta_1X_{i1} + \\ldots + \\beta_{p-1}X_{i,p-1}\\) Linearity w.r.t. \\(\\beta\\)’s Functional form of \\(\\boldX\\): often the focus of diagnostics for linearity Independence: \\(\\epsilon_i \\perp \\epsilon_j\\), for \\(i\\neq j\\) Normality: \\(\\epsilon_i\\sim N(0,\\sigma^2)\\) Equal variance (homogeneity): \\(Var(\\epsilon_i)=\\sigma^2\\), for all \\(i\\) Assumptions mainly about \\(\\epsilon_i\\) and will be checked using residuals Since we cannot observe the true \\(\\epsilon_i\\)’s, we infer their behavior via the \\(\\widehat{\\epsilon}_i\\)’s Residual is a measure of the variability of the outcome not explained by the regression model\n\n\nViolation of Assumptions Possible consequences of assumptions being violated: \\(\\widehat{\\beta}_j\\) biased \\(SE(\\widehat{\\beta}_j)\\) inaccurate CI’s for \\(\\beta_j\\) inaccurate hypothesis tests invalid Impact depends on which assumption is violated and the extent\n\n\nRegression Diagnostics: Objectives Identify violation of model assumptions Identify observations that may have too much influence on the results Understand the impact of violating the assumption e.g., impact on confidence intervals or coefficients Assumptions will never hold perfectly: degree of validity of model results depends on degree to which assumptions hold\nBe able to suggest potential corrective action e.g., transformation of response\nRegression diagnostics can involve an “iterative process” because violation of one assumption can mask a violation of another assumption\n\n\nTypes of Residuals\n\n\nConventional Residuals: Properties (review) Assume: \\(\\boldepsilon\\sim N({\\boldzero},\\sigma^2{\\boldI})\\) Errors: \\(\\boldepsilon={\\boldY}-E[{\\boldY}]\\) Residuals: & = & -\n& = & -\n& = & (-)\n\nE[] & = & (-)E[]\n& = & (-)\n& = & -\n& = & - (^T)^-1^T\n& = &\n\n\nResiduals: Properties (continued) Var() & = & Var({-} )\n& = & (-) ^2 (-)^T\n& = & ^2(-)^2\n& = & ^2(-) Therefore, \\(\\widehat{\\boldepsilon}\\sim N({\\boldzero},\\sigma^2\\{{\\boldI}-{\\boldH}\\})\\), since \\(\\widehat{\\boldepsilon}\\) is a linear combination of Normals\n\n\nResiduals: Properties (cont’d) Therefore, if \\(\\boldepsilon \\sim\\) Normal, then \\(\\widehat{\\boldepsilon}\\sim\\) Normal if \\(E[{\\boldepsilon}]={\\boldzero}\\), then \\(E[\\widehat{\\boldepsilon}]={\\boldzero}\\) even if \\(\\{\\epsilon_1,\\ldots,\\epsilon_n\\}\\) are mutually independent,\n\\(\\{\\widehat{\\epsilon}_1,\\ldots,\\widehat{\\epsilon}_n\\}\\) are not independent cov\\((\\widehat{\\epsilon}_i,\\widehat{\\epsilon}_j)=-h_{ij}\\sigma^2\\) because \\(Var(\\widehat{\\boldepsilon})=\\sigma^2({\\boldI}-{\\boldH})\\) even if \\(Var(\\epsilon_i)=\\sigma^2\\) for all \\(i\\), \\(Var(\\widehat{\\epsilon}_i)\\neq \\sigma^2\\) for any \\(i\\) in fact \\(Var(\\widehat{\\epsilon}_i)=(1-h_{ii})\\sigma^2\\leq\\sigma^2\\) (\\(h_{ii}\\geq0\\) since \\(\\boldH\\) is positive definite)\n\n\nStandardized Residuals Standardized residuals (imperfect): _i & = & Rationale: \\(\\widehat{\\epsilon}_i\\)’s are unit-dependent (e.g., changing units of \\(Y_i\\) will change \\(\\widehat{\\epsilon}_i\\))\nStandardizing with \\(\\widehat{\\sigma}\\) is very easy to do.\nPatterns in \\(\\widehat{z}_i\\)’s will be the same as \\(\\widehat{\\epsilon}_i\\)’s, but easier to judge the magnitude of \\(\\widehat{\\epsilon}_i\\) because it is “standardized”\nMore meaningful to judge the magnitude of \\(\\widehat{\\epsilon}_i\\) relative to its standard deviation\n\n\nStandardized Residuals (continued)\n\\(\\widehat{z}_i\\)’s have mean \\(\\approx 0\\) and variance \\(\\approx 1\\)\nIf model assumptions are correct, \\(\\widehat{z}_i\\stackrel{\\cdot}{\\sim} N(0,1)\\).\nTherefore \\(\\widehat{z}_i\\)’s are more readily interpreted: P(|_i| ) & & 0.67\nP(|_i| ) & & 0.95\nP(|_i| ) & & 0.99 Advantage of \\(\\widehat{z}\\) over \\(\\widehat{\\epsilon}\\) is that we have a “rule of thumb\" to identify large value: \\(|\\widehat{z}_i| \\geq 2.5\\)\nHistogram, Q-Q (quantile-to-quantile) plot, box/whisker plot will have same pattern as for \\(\\widehat{\\epsilon}_i\\)’s (to be introduced soon)\n\n\nInternally Studentized Residuals Recall: \\(\\widehat{\\sigma}^2(1-h_{ii})\\), not \\(\\widehat{\\sigma}^2\\), is an unbiased estimator of \\(Var(\\widehat{\\epsilon}_i)\\) Internally studentized residuals: _i & = & where \\(h_{ii}=\\text{diag}(\\boldH)_i=\\) leverage for \\(i\\)’th individual (the \\(i\\)-th element of the diagonal of the hat matrix)\n\\(h_{ii}=\\boldX_i^T (\\boldX^T\\boldX)^{-1} \\boldX_i\\); Special case: in SLR h_ii & = & +\nReflects outlyingness in \\(\\boldX\\) space\n\\(E[\\widehat{r}_i]= 0\\), \\(Var(\\widehat{r}_i)\\approx 1\\), \\(\\widehat{r}_i\\sim t_{df SSE}\\). Note: when \\(df SSE\\) (or sample size) is large: \\(t_{df SSE}\\approx N(0,1)\\), \\(|t_{df SSE, 0.025}|\\approx 2\\)\n\n\nExternally Studentized Residuals\nExternally studentized residuals: _(-i) & = & \\(\\widehat{\\sigma}_{(-i)}\\) is an estimator of \\(\\sigma^2\\), with \\(i\\)’th individual deleted\nRationale:\nif \\(|\\widehat{\\epsilon}_i|\\) is large, \\(\\widehat{\\sigma}^2\\) may over-estimate \\(\\sigma^2\\) \\(\\widehat{\\epsilon}_i\\) can serve to mask its own outlyingness by inflating \\(\\widehat{\\sigma}^2\\) hence remove influence of \\(\\widehat{\\epsilon}_i\\) on \\(\\widehat{\\sigma}^2\\) by removing the data point\n\\(E[\\widehat{r}_{(-i)}]= 0\\), \\(Var(\\widehat{r}_{(-i)})\\approx 1\\), \\(\\widehat{r}_{(-i)}\\sim t_{dfSSE-1}\\)\nMost sensitive residuals for detecting outliers\nAlso known as “leave-one-out/Jackknife” residuals\n\n\nComparing Residual Types\nFor large samples, \\(\\widehat{\\epsilon}_i\\), \\(\\widehat{z}_i\\), \\(\\widehat{r}_i\\), \\(\\widehat{r}_{(-i)}\\) tend to provide similar information\nFor large samples, \\(\\widehat{r}_{(-i)}\\), \\(\\widehat{r}_i\\), \\(\\widehat{z}_i\\) follow, approximately, a standard normal distribution For small to moderate samples, a rank, in decreasing order of sensitivity: \\(\\widehat{r}_{(-i)}\\) \\(\\widehat{r}_i\\) \\(\\widehat{z}_i\\) \\(\\widehat{\\epsilon}_i\\)\n\n\nChecking functional form of continuous predictor (linearity)\n\n\nFunctional form of continuous predictor Continuous covariates may have nonlinear functional form of relationship with the outcome e.g. SBP vs age Several approaches to check Approach 1: Partial regression plots Approach 2: Categorizing predictor Approach 3: Testing and smoothing approaches (future lecture)\n\n\nResidual vs. covariate plots in SLR and MLR\nIn MLR: conditional association; in SLR, marginal=conditional. In simple linear regression, can plot \\(\\widehat{\\epsilon}\\) versus \\(X\\) (or \\(\\widehat{Y}\\)) to assess linearity of \\((X,Y)\\) relationship can detect departures from linearity, and nature of non-linear relationships If the current functional form has captured the effect of \\(X\\), then \\(\\widehat{\\epsilon}_i\\)’s should be randomly scattered and show no trend with \\(X\\) For multiple linear regression, situation is more complicated Plot of \\(\\widehat{\\epsilon}\\) versus \\(X_k\\) can be impacted other covariates\" If \\(X_k\\) is correlated with \\(X_j\\), and \\(X_j\\) has a non-linear association with \\(Y\\), then plot of \\(\\widehat{\\boldepsilon}\\) vs \\(X_k\\) will partially reflect non-linear association of \\(Y\\) and \\(X_j\\). Solution: Partial regression plots\n\n\nApproach 1: Partial Regression Plots Design matrix \\(\\boldX=[{\\boldone}_n, X_1,\\ldots, X_p]\\) \\(\\boldX_{-k}\\) contains all covariates, except \\(X_{k}\\)\nRegress \\({\\boldY}\\) on \\(\\boldX_{-k}\\) and get residual \\(\\widehat{\\boldepsilon}({\\boldY}|\\boldX_{-k})\\) \\(\\boldY=\\boldX_{-k}\\alpha%_{\\scriptscriptstyle {\\boldY}|\\boldX_{-k} }  +\\epsilon({\\boldY}|\\boldX_{-k})\\) Regress \\(X_{k}\\) on \\(\\boldX_{-k}\\) and get residual \\(\\widehat{\\boldepsilon}(\\boldX_{k}|\\boldX_{-k})\\) \\(X_{k}=\\boldX_{-k}  \\boldbeta%_{\\scriptscriptstyle\\boldX_{k}|\\boldX_{-k}}  +\\epsilon(\\boldX_{k} |\\boldX_{-k})\\) Plot \\(\\widehat{\\boldepsilon}(X_{k}|\\boldX_{-k})\\) vs. \\(\\widehat{\\boldepsilon}({\\boldY}|\\boldX_{-k})\\) both sets of residuals are covariate-adjusted (and hence model dependent): remove information/contribution from \\(\\boldX_{-k}\\) if linear, then shows the adjusted effect of \\(X_k\\); if nonlinear, then suggests a functional form of \\(X_k\\) (see also partial residual plot) can also help to spot outliers (extreme residuals in the Y direction) and “leverage points” (extreme residuals in the X direction)\n\n\n\n\nimage\n\n\n\n\n\nPartial Regression Plots–Example Example: Suppose we want to study association between Sytolic blood pressure (SBP) and covariates Age (\\(A_{i}\\)), Quetlet intex (\\(Q_i\\)), and smoking \\(S_{i}\\). \\(SBP_i = \\beta_0 + \\beta_A A_i + \\beta_Q Q_i + \\beta_S S_i + \\epsilon_i\\)\nWe want to assess functional relationship between \\(SBP\\) and \\(Age\\) Fit first model: \\(SBP_i = \\gamma_0 + \\gamma_1 Q_{i} + \\gamma_3 S_i +\\epsilon_{i(SBP|Q,S)}\\)\nobtain residuals, \\(\\widehat{\\epsilon}_{i(SBP|Q,S)}\\)’s Fit second model: \\(A_{i} = \\alpha_0 + \\alpha_1 Q_{i} + \\alpha_2 S_i +\\epsilon_{i(Age|Q,S)}\\) obtain residuals \\(\\widehat{\\epsilon}_{i(A|Q,S)}\\)’s Plot \\(\\widehat{\\epsilon}_{i(SBP|Q,S)}\\) vs. \\(\\widehat{\\epsilon}_{i(Age|Q,S)}\\) pattern in plot describes association between \\(Age\\) and \\(SBP\\), adjusting for \\(Q\\) and \\(S\\)\n\n\nApproach 2: Categorize Continuous Predictor\nReplace continuous with categorical covariates, then examine pattern in coefficients of indicator variables Functional form of indicator variables can’t be misspecified e.g., blood pressure data: \\(SBP_i = \\beta_0 + \\beta_A A_i + \\beta_Q Q_i + \\beta_S S_i + \\epsilon_i\\) We want to assess functional relationship between \\(SBP\\) and \\(Age\\) Eliminate the linearity assumption by treating age as categorical: Break age into groups containing (approximately) equal numbers of subjects and set up indicator covariates: AG_1i & = & I(41 A_i &lt; 48)\nAG_2i & = & I(48 A_i &lt; 54)\nAG_3i & = & I(54 A_i &lt; 59)\nAG_4i & = & I(59 A_i)\n\n\nCategorizing approach, continued (1) Revised model: E[SBP_i] & = & _0 + _A2AG_2i + _A3AG_3i +_A4AG_4i + _Q Q_i + _S S_i Now, plot \\(\\widehat{\\beta}_{A1}\\), \\(\\widehat{\\beta}_{A2}\\) \\(\\dots\\), \\(\\widehat{\\beta}_{A4}\\) against group-specific medians set \\(\\widehat{\\beta}_{A1}\\equiv0\\); \\(\\widehat{\\beta}_{A1}\\) \\(\\dots\\), \\(\\widehat{\\beta}_{A4}\\) are adjusted group mean differences Plot reflects true nature of association between \\(A_i\\) and \\(E[SBP_i]\\) linear? quadratic? U-shaped? threshold? If plot approximately linear: evidence in favor of linearity assumption\n\n\nViolation of Linearity Assumption If linearity fails \\(\\ldots\\) \\(\\widehat{\\boldbeta}\\): \\(\\widehat{\\boldY}\\): \\(\\widehat{\\sigma}^2\\): \\(\\widehat{Var}(\\widehat{\\boldbeta})\\): confidence intervals: hypothesis tests:\nPossible solutions: modify the model \\(\\ldots\\) additional covariates transform \\({\\boldY}\\); e.g., \\(log({\\boldY})\\), \\(\\sqrt{{\\boldY}}\\) transform certain \\(\\boldX_k\\)’s\n\n\nViolation of Linearity Assumption If linearity fails \\(\\ldots\\) \\(\\widehat{\\boldbeta}\\): biased \\(\\widehat{\\boldY}\\): biased \\(\\widehat{\\sigma}^2\\): biased \\(\\widehat{Var}(\\widehat{\\boldbeta})\\): biased confidence intervals: invalid hypothesis tests: wrong inference\nPossible solutions: modify the model additional covariates transform certain \\(\\boldX_k\\)’s based on the plots transform \\({\\boldY}\\); e.g., \\(log({\\boldY})\\), \\(\\sqrt{{\\boldY}}\\)\n\n\nIndependence Assumption\n\n\nIndependence Assumption Independence: (multivariate normal + ) \\(E[\\epsilon_i \\epsilon_j]=0\\) for \\(i\\neq j\\)\nimplies: \\(Y_i\\) independent of \\(Y_j\\), \\(i\\neq j\\)\nto assess validity of independence assumption, careful consideration of study design is essential\nviolations of independence often clear from sampling scheme\ne.g., if \\(Y_i\\)’s are time-ordered, may be serial correlation; \\(E[\\epsilon_i \\epsilon_{i+1}]\\neq 0\\)\ne.g., subjects in a study are clustered\ne.g., response measured repeatedly on each subject\nNote: recall that residuals are never independent\n\n\nIndependence Assumption: Autocorrelation : errors are correlated (sequenced) often occurs when response is measured over time \\(\\mbox{cov}(\\epsilon_i \\epsilon_{i+\\ell})\\neq 0\\), for some \\(\\ell\\) (lag) e.g., lag-2 autocorrelation: \\(E[\\epsilon_i \\epsilon_{i+1}]\\neq 0\\) \\(E[\\epsilon_i \\epsilon_{i+2}]\\neq 0\\) \\(E[\\epsilon_i \\epsilon_{i+k}]=0\\), for \\(k&gt;2\\)\n\n\nIndependence: Detecting Autocorrelation\nplot \\(\\widehat{\\epsilon}_i\\)’s versus \\(i\\) (index) positive autocorrelation: adjacent residuals have same sign negative autocorrelation: sign of residuals alternates Note: only if index \\(i\\) has a meaningful order, e.g. time plot \\(\\widehat{\\epsilon}_i\\) vs. \\(\\widehat{\\epsilon}_{i-1}\\) positive correlation: positive trend negative correlation: negative trend\n\n\nAutocorrelation: Durbin-Watson Test (Chap 14) consider: departure from independence in form of lag 1 autocorrelation (first order) \\(\\mbox{corr}(\\epsilon_i, \\epsilon_{i+1})=\\rho\\), \\(i=1,\\ldots,n-1\\) Durbin-Watson Test: hypotheses: \\(H_0: \\rho=0\\) vs. \\(H_1:\\rho &gt; 0\\) test statistic: DW & = & (1-) 2 Distribution depends on \\(\\boldX\\), but bounds are available (Table A.6) reject \\(H_0\\) if \\(DW &lt; DW_L\\) fail to reject \\(H_0\\) if \\(DW &gt; DW_U\\) inconclusive if \\(DW_L \\leq DW \\leq DW_U\\) to test \\(H_0\\) vs. \\(H_1:\\rho &lt;0\\), use \\((4-DW)\\) as test statistic\n\n\nImpact of Lack of Independence if \\(e_i\\) and \\(e_j\\) are correlated (\\(i\\neq j\\)): \\(\\widehat{\\boldbeta}:\\) \\(\\widehat{\\sigma}^2:\\) \\(Var({\\widehat{\\boldbeta}}):\\) CI’s, hypothesis tests:\n\n\nImpact of Lack of Independence if \\(e_i\\) and \\(e_j\\) are correlated (\\(i\\neq j\\)): \\(\\widehat{\\boldbeta}:\\) unbiased, normally distributed \\(\\widehat{\\sigma}^2:\\) biased The conclusion that \\(E[\\widehat{\\sigma}^2]=\\sigma^2\\) depends on independence (\\(n\\) is no longer the effective sample size) \\(Var({\\widehat{\\boldbeta}}):\\) \\(Var\\{(\\boldX^T\\boldX)^{-1}\\boldX^T\\boldY\\}=(\\boldX^T\\boldX)^{-1}\\boldX^T{\\color{royalblue}\\boldsymbol{\\Sigma}}\\boldX(\\boldX^T\\boldX)^{-1}\\) where \\(\\boldSigma\\) is not a diagonal matrix CI’s, hypothesis tests: invalid\n\n\nIndependence: Remedies In BIOSTAT 653 conditional approach: random effects, mixed models let \\(Y_{ij}=\\) response, \\(j\\)’th subject in \\(i\\)’th cluster e.g, \\(Y_{ij} = \\beta_{0i} + \\beta_1 X_{ij} + \\epsilon_{ij}\\), where \\(\\beta_{0i}\\sim N(\\beta_0,\\sigma^2_0)\\) dependence among subjects captured by \\(\\sigma^2_0\\) \\(Y_{ij}\\) conditionally independent of \\(Y_{ik}\\), given \\(\\beta_{0i}\\) marginal approach: Use a “working\" correlation structure model: unchanged from the independence case compute \\(\\widehat{\\boldbeta}\\) as if subjects were independent use adjusted (robust) version of variance estimator\n\n\nIndependence: Remedies (continued) e.g., time-ordered data: include time as covariate need to ensure that effect of time is modelled correctly may or may not solve problem; need to examine residuals may need to depart from linear regression altogether appeal to time series analysis (regression methods specially developed for time-ordered data)\n\n\nConstant Variance Assumption\n\n\nAssessing Constant Variance Plot \\(\\widehat{\\boldepsilon}\\) vs. \\(\\widehat{\\boldY}\\) to assess homogeneity assumption\nshould be a random scatter\ncommon departure: \\(|\\widehat{\\epsilon}_i|\\) increases with \\(\\widehat{Y}_i\\) (cone shape), implying that the variance is an increasing function of the mean common in linear modelling of count/rate data\nNote: residuals are heterogeneous, i.e., \\(Var(\\widehat{\\epsilon}_i)\\neq\\sigma^2\\), but shouldn’t have patterns\n\n\n\n\nimage\n\n\n\n\n\nModel Assumptions: Constant Variance If homogeneity fails \\(\\ldots\\) \\(\\widehat{\\boldbeta}\\): \\(\\widehat{\\sigma}^2\\): \\(\\widehat{Var}(\\widehat{\\boldbeta})\\): hypothesis tests, CI’s: Possible solutions: weighted least squares (Chapter 5.5.2 and 5.5.3) variance stabilizing transformations (Chapter 5.2) robust regression (Chapter 15.1) robust standard errors\n\n\nModel Assumptions: Constant Variance If homogeneity fails \\(\\ldots\\) \\(\\widehat{\\boldbeta}\\): remain valid \\(\\widehat{\\sigma}^2\\): not well defined \\(\\widehat{Var}(\\widehat{\\boldbeta})\\): invalid \\(Var\\{(\\boldX^T\\boldX)^{-1}\\boldX^T\\boldY\\}=(\\boldX^T\\boldX)^{-1}\\boldX^T{\\color{royalblue}Var(\\boldY)}\\boldX(\\boldX^T\\boldX)^{-1}\\) \\({\\color{white}{Var\\{(\\boldX^T\\boldX)^{-1}\\boldX^T\\boldY\\}}}\\neq (\\boldX^T\\boldX)^{-1}\\boldX^T{\\color{royalblue}\\boldsymbol{\\sigma^2\\boldI}}\\boldX(\\boldX^T\\boldX)^{-1}\\) hypothesis tests, CI’s: invalid because SE(\\(\\widehat{\\beta}\\)) invalid Possible solutions: weighted least squares (Chapter 5.5.2 and 5.5.3) variance stabilizing transformations (Chapter 5.2) robust regression (Chapter 15.1) robust standard errors\n\n\nWeighted Least Squares\nSuppose constant variance is violated, but the responses are uncorrelated, i.e., \\({\\boldepsilon}\\sim N({\\boldzero}, {\\boldW})\\), where \\({\\boldW}=\\mbox{diag}\\{\\boldsymbol{w}_1,\\ldots,\\boldsymbol{w}_n\\}\\) where \\(\\boldsymbol{w}_i\\neq \\boldsymbol{w}_j\\) for some \\(i\\neq j\\) \\(Var\\{(\\boldX^T\\boldX)^{-1}\\boldX^T\\boldY\\}=(\\boldX^T\\boldX)^{-1}\\boldX^T{\\color{royalblue}\\boldsymbol{\\boldW}}\\boldX(\\boldX^T\\boldX)^{-1}\\) We can estimate:\n_W &=& (^T^-1)^-1^T^-1\nVar(_W) & =& (^T^-1)^-1\nTypically, \\(\\boldW\\) is unknown and needs to be estimated from \\(\\widehat{\\epsilon}_i\\)’s\n\n\nVariance-Stabilizing Transformations\nVariance-stabilizing transformations (VST) can be used when strong evidence against the constant variance assumption exists\nIdea: often, when \\(Var(Y_i)\\) is not constant, it is a function of \\(E[Y_i]\\). Thus we: choose a function \\(g(\\cdot)\\) s.t. \\(Var(g(Y_i))\\) is not a function of \\(E[Y_i]\\) fit \\(g(\\boldY)=\\boldX\\boldgamma+\\bolddelta\\)\nCaveat: \\(\\boldgamma\\) has different interpretation than \\(\\boldbeta\\) in \\(\\boldY=\\boldX\\boldbeta+\\boldepsilon\\)\n\n\nNon-Constant Variance: Example\nSuppose \\(Y_i\\) follows a Poisson distribution From BIOS 601 we know \\(E[Y_i]=Var(Y_i)=\\boldX_i^T\\boldbeta\\) (non-constant!)\nSet \\(g(x)=\\sqrt{x}\\) due to the following approximation: \\[Var(g(Y_i)) \\approx  %Var\\{\\left.\\frac{\\partial g(x)}{\\partial x}\\right|_{x=E[Y_i]}   (Y_i)\\} =\n         \\left\\{ \\left.\\frac{\\partial g(x)}{\\partial\n            x} \\right|_{x=E[Y_i]} \\right\\}^2 Var(Y_i)\\]\nthis result is exact only when \\(g(x)\\) is linear here, \\(\\{\\partial g/\\partial x\\}^2=(4x)^{-1}\\), such that \\(Var(\\sqrt{Y_i})=1/4\\)\nTherefore, although \\(Var(Y_i)\\) is non-constant, \\(Var(\\sqrt{Y_i})\\) is a constant\n\n\nCommon VST’s\nExamples of variance-stabilizing transforms:\n\n\n\n\n\\(Var(Y_i)\\)\n\\(g(Y_i)\\)\n\n\n\n\n\\(\\sigma^2\\)\n\\(Y_i\\)\n\n\n\\(E[Y_i]\\)\n\\(\\sqrt{Y_i}\\)\n\n\n\\(E[Y_i]^2\\)\n\\(\\log(Y_i)\\)\n\n\n\\(E[Y_i]^3\\)\n\\(1/\\sqrt{Y_i}\\)\n\n\n\\(E[Y_i]^4\\)\n\\(1/Y_i\\)\n\n\n\n\nThese are ordered from weakest to strongest \\(\\ldots\\) We don’t know exactly which one to choose. So: Plot residuals vs fitted values Use prior experience Involves some trial and error\n\n\nRobust standard errors\nRobust standard errors correctly estimate variability of parameter estimates even under non-constant variance Use empirical estimates of the variance in \\(Y\\) at each \\(X\\) value rather than assuming this variance is the same for all \\(X\\) values Regression point estimates will be unchanged Robust or empirical standard errors will give correct confidence intervals and p-values In R: lmtest::coeftest()\n\n\nNormality Assumption\n\n\nNormality Assumption Several ways to check assumption that \\(\\epsilon_i\\sim N(0,\\sigma^2)\\) normality: histogram (stem & leaf plots)\nbox-whisker plots (boxplots)\nquantile-to-quantile (Q-Q) plots\nShapiro-Wilks Test (among other tests for normal distribution)\n\n\nApproach 1: Histogram\nHistogram of \\(\\widehat{\\epsilon}_i\\)’s: should approximate the shape of a zero-mean normal distribution; i.e., symmetric bell-shaped light tailed\nCaveat: Need a fairly large number of individuals to get reliable information from histogram Histograms of the same data but using different bin sizes (breaks) and/or different cut-points may look quite different\nQ: Why not simply plot histogram of \\(Y_i\\)’s? The distribution of \\(Y\\) might look very non-bell shaped yet normality of errors may still hold – e.g., predictor itself might be highly skewed\n\n\nApproach 2: Box-Whisker Plot Box-whisker plots (Boxplot): provides information on symmetry of distribution\nsymmetric distribution: terminology: \\(q\\%\\) of the \\(\\widehat{\\epsilon}_i\\)’s are \\(\\leq\\) the \\(q\\)’th percentile mean equals median 25th and 75th percentiles are equal distance from median median of \\(\\widehat{\\epsilon}_i\\)’s should be \\(\\approx\\) 0\n\n\n\n\nimage\n\n\n\n\n\nApproach 3: Q-Q plot Normal probability plot: rank the \\(\\widehat{z}_i\\)’s in ascending order: _(1) &lt; _(2) &lt; …&lt; _(n) if the \\(\\epsilon_i\\)’s are truly normal, then \\(\\widehat{z}_{(i)}\\)’s should resemble order statistics from a size \\(n\\) standard normal sample plot \\(\\widehat{z}_{(i)}\\)’s against the i-th quantile \\(\\Phi^{-1}(\\frac{i-1/2}{n})\\), where \\(\\Phi^{-1}(\\cdot)\\) is inverse of standard normal cumulative distribution function (cdf)\nA special case of the quantile-to-quantile (Q–Q) plot: for a normal distribution Plot should be straight line\n\n\nApproach 3: Q-Q plot \n\n\nShapiro-Wilks Test Shapiro-Wilks Test: formally examines correlation between \\(\\widehat{z}_{(i)}\\)’s and their expected values under normality \\(H_0: \\epsilon_i\\sim N(0,\\sigma^2)\\); \\(H_1:\\overline{H}_0\\) under \\(H_0\\), E[_(i)|H_0] & = & ^-1() set: \\(\\widehat{\\boldZ}_{(\\cdot)}=[\\widehat{z}_{(1)},\\ldots,\\widehat{z}_{(n)}]\\)\ntest statistic: \\(\\widehat{\\rho}^2(\\widehat{\\boldZ}_{(\\cdot)},E[\\widehat{\\boldZ}_{(\\cdot)}|H_0])\\), ^2(_(),E[_()|H_0]) & = & { }^2\nlow values: evidence against \\(H_0\\) In R: shapiro.test(). If \\(p&gt;0.05\\): we can assume normality\n\n\nModel Assumptions: Normality If Normality does not hold \\(\\ldots\\) \\(\\widehat{\\boldbeta}\\): \\(\\widehat{\\sigma}^2\\): \\(\\widehat{Var}(\\widehat{\\boldbeta})\\): hypothesis tests, CI’s: Possible solution: transform \\({\\boldY}\\) Note: OLS is quite robust to departures from normality By CLT: even if violation of normality, sample mean of variables tends towards a normal distribution as sample size grows\n\n\nModel Assumptions: Normality If Normality does not hold \\(\\ldots\\) \\(\\widehat{\\boldbeta}\\): remains unbiased (does not rely on normality) \\(\\widehat{\\sigma}^2\\): remains unbiased (does not rely on normality) \\(Var(\\widehat{\\boldbeta})=\\sigma^2(\\boldX^T\\boldX)^{-1}\\): still valid formula (only requires uncorrelated and homogeneity) \\(\\widehat{Var}(\\widehat{\\boldbeta})\\): unbiased hypothesis tests, CI’s: invalid under small sample size; valid if sample size is large Possible solution: transform \\({\\boldY}\\) (\\(\\sqrt{\\boldY}, \\log(\\boldY)\\)) Note: OLS is quite robust to departures from normality By CLT: even if violation of normality, sample mean of variables tends towards a normal distribution as sample size grows\n\n\nSummary\n\n\n\n\nCheck\nEstimates\nTests/CIs\nCorrect\n\n\n\n\nL\nPartial regression plot;\nProblematic\nProblematic\nTransform X or Y\n\n\n\nCategorize (step-wise)\n\n\n\n\n\nI\nDesign\nValid\nProblematic\nBIOS 653\n\n\nE\nPlot \\(\\widehat{{\\epsilon}}\\sim\\widehat{{Y}}\\)\nValid\nProblematic\nWeighted Least Squares\n\n\n\n\n\n\nTransform Y; Robust SE\n\n\nN\nHist; boxplot; QQ plot\nValid\nProblematic\nTransform Y\n\n\n\nShapiro-Wilks Test\n\nif \\(n\\) small\n\n\n\n\n\n\nAll models are wrong but some are useful \\(E(\\boldY)\\! =\\! \\boldX\\boldbeta\\) is a convenient way to measure the association that I’m interested in (“useful\"), but I don’t believe the model (”wrong\"). Since I have a random sample, I’m comfortable assuming that my errors are uncorrelated (by design). But why should I believe that my errors are homoscedastic? Maybe the instrument that measures the outcome is less accurate for larger outcome values. My errors are not really normal, but if my sample is large then I don’t need to worry about that. (And most of this class did not rely on normality anyway!)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutliers\n\n\nOutliers We observe data points of the form: (Y_i,X_i1,…,X_ik)\n“Outliers” \\(\\longrightarrow\\) extreme values Consider the \\(i\\)’th individual; can be extreme in several ways: \\(Y_i\\), i.e., “outlying in \\({\\boldY}\\)”\n\\(x_{ij}\\), outlying w.r.t. \\(\\boldX_j\\) row \\(\\boldX_i^T\\), outlying w.r.t \\(\\boldX\\)\n\\(\\widehat{\\epsilon}_i\\) outlying relative to \\(\\widehat{\\boldepsilon}\\): outliers\n\n\nImpact of Outliers Outliers can distort \\(\\widehat{\\beta}_j\\)’s recall: sample means are sensitive to outliers \\(\\widehat{\\beta}_j\\) is a weighted sample mean of \\(Y_i\\)’s hence can be distorted Outliers may also distort \\(\\widehat{\\sigma}^2\\) \\(\\widehat{\\epsilon}_i\\) outlier \\(\\Rightarrow \\widehat{\\sigma}^2=\\frac{1}{n-p}\\sum_{i=1}^n\\widehat{\\epsilon}_i^2\\) Often difficult to detect outliers in \\(\\boldX\\)-space visually (unless SLR)\n\n\nLeverage: Hat Diagonals \\(h_{ii}=\\) leverage for \\(i\\)’th individual \\((i,i)\\)’th element of the \\({\\boldH}\\) matrix Reflects outlyingness in \\(\\boldX\\) space measures distance between \\(\\boldX_i^T\\) and \\(\\overline\\boldX^T\\)\n\\(\\widehat{Y}_i\\) and hence \\(\\widehat{\\epsilon}_i\\) will be driven by the units with large \\(h_{ii}\\)\nCalculation: \\(h_{ii}=\\boldX_i^T (\\boldX^T\\boldX)^{-1} \\boldX_i\\)\nspecial case: SLR, h_ii & = & +\n\n\nLeverage: Interpretation\nIndividuals with large \\(h_{ii}\\) may have disproportionate impact on the \\(\\widehat{\\beta}_j\\)’s\nVarious criteria for “large” \\(h_{ii}&gt;2\\times \\overline{h}\\), where \\(\\overline{h}=\\mbox{\\# parameters}/n\\) \\(0.2 \\leq h_i \\leq 0.5\\): moderate; \\(h_i&gt;0.5\\): large\nOften useful to rank \\(h_{ii}\\)’s, in addition to applying the criteria\nNote: \\(0 \\leq h_{ii} \\leq 1\\)\n\n\nOutliers, summary\nImportant to detect outliers\nGenerally, not interested in formal test of outlyingness power of existing tests is driven by \\(n\\)\nbut, small samples are where outliers may have the greatest impact!\nRarely should outliers be discarded\nappropriate efforts should be made to ensure that the outliers really do represent the process under study\nnot the result of data collection or coding error\ndiscarding outliers may change the population to which the analysis conclusions can generalize\n\n\nQuestions?"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#basic-statistics",
    "href": "slides/01_Reviewqmd.html#basic-statistics",
    "title": "Review",
    "section": "Basic Statistics",
    "text": "Basic Statistics\n\n\n0.5\nRandom variable \\(Y\\) Sample \\(Y_i, i=1,\\dots, n\\)\nSummation: \\(\\sum_{i=1}^n Y_i =Y_1 + Y_2 + \\ldots + Y_n\\)\nProduct: \\(\\prod_{i=1}^n Y_i = Y_1 \\times Y_2 \\times \\ldots \\times Y_n\\)\nExpected Value (or mean): \\(\\mu_Y= E[Y] = \\int_{-\\infty}^\\infty y f(y) dy\\) reflects ‘center’ of \\(Y\\)’s distribution\n\n0.5"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#rules-of-expected-values",
    "href": "slides/01_Reviewqmd.html#rules-of-expected-values",
    "title": "Review",
    "section": "Rules of Expected Values",
    "text": "Rules of Expected Values\n\n\n0.5 Expectation of sum: \\(E\\left[\\sum_{i=1}^n Y_i \\right] = \\sum_{i=1}^n E[Y_i] \\nonumber\\) No assumption of independence required\nLet \\(a_1,\\ldots,a_n\\) be constants \\(E[a_iY_i] = a_iE[Y_i]\\)\n\\(E\\left[\\sum_{i=1}^n a_iY_i \\right] = \\sum_{i=1}^n a_iE[Y_i]\\)\nExpectation of product: \\(E[Y_iY_j] = E[Y_i]E[Y_j]\\)\nif \\(Y_i\\) and \\(Y_j\\) are independent\n\n0.5\n\n\n:::"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#variance-and-standard-deviation",
    "href": "slides/01_Reviewqmd.html#variance-and-standard-deviation",
    "title": "Review",
    "section": "Variance and standard deviation",
    "text": "Variance and standard deviation\n\n\n0.5\nVariance: \\[\\begin{split}\n        &Var(Y) =  E[(Y-\\mu_Y)^2]\\\\\n        = &\\int_{-\\infty}^\\infty (y-\\mu_Y)^2 f(y) dy\n        %=  E[Y^2] - \\mu_Y^2\n        \\end{split}\\] reflects spread of \\(Y\\)’s distribution units: (units of \\(Y\\))\\(^2\\)\nStandard deviation: \\[\\begin{split}\n        SD(Y)  = &\\; \\sqrt{Var(Y)}  \\\\\n        SD(aY)  = &\\; aSD(Y)\n        \\end{split}\\]\nreflects dispersion in \\(Y\\)’s distribution measured in same unit as \\(Y\\)\n\n0.5\n\n\n:::"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#rules-of-variances",
    "href": "slides/01_Reviewqmd.html#rules-of-variances",
    "title": "Review",
    "section": "Rules of Variances",
    "text": "Rules of Variances\n\n\n0.5 Variance\n\\(Var(Y)=E[(Y-\\mu_Y)^2]\\)\n\\({\\color{white}{Var(Y)}} =E[Y^2] - \\mu_Y^2\\) Variance of linear combination: \\[\\begin{split}\n        &~Var(aY+b)\\\\\n         = &~ Var(aY) \\\\\n         = &~ E[(aY-E[aY])^2]\\\\\n         = &~ a^2 E[(Y-E[Y])^2]\\\\\n         = &~ a^2 Var(Y)\n        \\end{split}\\] \n\n0.5\n\n\n:::"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#covariance",
    "href": "slides/01_Reviewqmd.html#covariance",
    "title": "Review",
    "section": "Covariance",
    "text": "Covariance\n\n\n0.6 \\(X\\), \\(Y\\): random variables Covariance: \\(\\mbox{cov}(Y,X)= E[(Y-\\mu_Y)(X-\\mu_X)]\\)\nMeasures (linear) association between \\(X\\), \\(Y\\)\n\\(&gt;0\\), large values of \\(X\\) tend to occur with large values of \\(Y\\)\n\\(&lt;0\\), large values of \\(X\\) tend to coincide with small values of \\(Y\\)\n\\(=0\\), size of \\(X\\) provides no information on size of \\(Y\\) When the covariance is calculated, the data are not standardized Not scale-invariant: can interpret direction but not magnitude\n\n0.4\n\n\n:::"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#correlation",
    "href": "slides/01_Reviewqmd.html#correlation",
    "title": "Review",
    "section": "Correlation",
    "text": "Correlation\n\n\n0.5 \\(X\\), \\(Y\\): random variables Correlation: \\(\\mbox{corr}(X,Y) = \\frac{\\mbox{cov}(X,Y)}{SD(X)SD(Y)}\\)\nScaled measure of linear association,\n\\(-1 \\leq \\mbox{corr}(X,Y) \\leq 1\\) easier to interpret than covariance\n\n0.5"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#rules-of-covariance",
    "href": "slides/01_Reviewqmd.html#rules-of-covariance",
    "title": "Review",
    "section": "Rules of covariance",
    "text": "Rules of covariance\n\\(\\mbox{cov}(Y,X)= E[(Y-\\mu_Y)(X-\\mu_X)]= E[XY]-E[X]E[Y]\\) \\(\\mbox{cov} (Y,Y) = \\mbox{var} (Y)\\) Independent \\(\\stackrel{\\Rightarrow}{\\not\\Leftarrow}\\) uncorrelated If \\(X\\) and \\(Y\\) are independent, \\(\\mbox{cov}(X,Y)=0\\) If \\(\\mbox{cov}(X,Y)=0\\) and \\((X,Y)\\sim \\text{Bivariate Normal}\\), then \\(X\\) and \\(Y\\) are independent Covariance is symmetric, additive, and scale preserving \\[\\begin{aligned}\n\\mbox{cov} (X,Y) & = & \\mbox{cov} (Y,X) \\nonumber \\\\\n\\mbox{cov} (X,Y_1+Y_2) & = & \\mbox{cov} (X,Y_1)+\\mbox{cov} (X,Y_2) \\nonumber \\\\\n\\mbox{cov} (X,aY) & = & a\\;\\mbox{cov} (X,Y) \\nonumber\n%\\mbox{cov} (Y,Y) & = & \\mbox{var} (Y) \\nonumber\n\\end{aligned}\\] :::"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#rules-of-variance",
    "href": "slides/01_Reviewqmd.html#rules-of-variance",
    "title": "Review",
    "section": "Rules of variance",
    "text": "Rules of variance\n\n\n0.6\nVariance of sum: \\[\\setlength{\\jot}{1pt}\n        \\begin{split}\n        &Var\\left(\\sum_{i=1}^n Y_i\\right)\n        =  \\sum_{i=1}^n\\sum_{j=1}^n\n        \\mbox{cov}(Y_i,Y_j )  \\\\\n        = & \\sum_{i=1}^n Var(Y_i)   + \\sum_{i=1}^n\\sum_{j=1}^n I(j\\neq i) \\mbox{cov}(Y_i, Y_j )  \\\\\n        = & \\sum_{i=1}^n Var(Y_i) + 2\\sum_{i=1}^n \\sum_{j=i+1}^n\n        \\mbox{cov}(Y_i, Y_j )\n        \\end{split}\\] if \\(Y_1,\\ldots,Y_n\\) are mutually independent, then \\(Var\\left(\\sum_{i=1}^n Y_i\\right) = \\sum_{i=1}^n Var(Y_i)\\)\n\n0.4\n\n\n:::"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#estimator-of-mean",
    "href": "slides/01_Reviewqmd.html#estimator-of-mean",
    "title": "Review",
    "section": "Estimator of Mean",
    "text": "Estimator of Mean\nSuppose we obtained a simple random sample from some underlying population, then we can derive sample estimates of each of the population quantities defined previously Suppose \\(Y_1,\\ldots,Y_n\\) are iid with mean \\(\\mu_Y\\) and variance \\(\\sigma^2_Y\\)\n\n\n0.6 Estimator of mean: \\[\\widehat{\\mu}_Y = \\frac{1}{n} \\sum_{i=1}^n Y_i =\n            \\overline{Y}\\]\n\\(E[\\overline{Y}]= \\frac{1}{n} \\sum_{i=1}^n E[Y_i] = \\mu_Y\\)\n\\(Var(\\overline{Y})= n^{-2} \\sum_{i=1}^n Var(Y_i) = \\sigma_Y^2/n\\)\n\n0.37\n\n\n:::"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#variance-and-covariance-estimator",
    "href": "slides/01_Reviewqmd.html#variance-and-covariance-estimator",
    "title": "Review",
    "section": "Variance and Covariance Estimator",
    "text": "Variance and Covariance Estimator\n\n\n0.6\nEstimators of variance:\n\\(\\widehat{\\sigma}^2_Y = \\frac{1}{n} \\sum_{i=1}^n (Y_i-E[Y_i])^2\\)\nif population mean is known \\(\\widehat{\\sigma}^2_Y = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i-\\overline{Y})^2\\)\nif population mean is unknown\nEstimator of covariance:\nSuppose pairs \\((Y_1,X_1),\\ldots,(Y_n,X_n)\\) are iid. \\(\\widehat{\\mbox{cov}} (X,Y) = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i-\\overline{Y})(X_i-\\overline{X})\\) \\(\\widehat{\\mbox{corr}} (X,Y) =\\) ?\n\n0.4\n\n\n:::"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#distributions-that-will-be-used-in-this-class",
    "href": "slides/01_Reviewqmd.html#distributions-that-will-be-used-in-this-class",
    "title": "Review",
    "section": "Distributions that will be used in this class",
    "text": "Distributions that will be used in this class\nNormal distribution Chi-square distribution t distribution F distribution"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#normal-distribution",
    "href": "slides/01_Reviewqmd.html#normal-distribution",
    "title": "Review",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nDensity: \\(Y\\sim N(\\mu,\\sigma^2)\\), $$\n\\[\\begin{aligned}\n        f_Y(y) & = &\n        \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left\\{\\frac{-1}{2}\\left(\\frac{y-\\mu}{\\sigma}\n        \\right)^2\\right\\} \\nonumber\n        \n\\end{aligned}\\]\n$$ If we know \\(E(Y)=\\mu\\), \\(Var(Y)=\\sigma^2\\) then\n/3 of \\(Y\\)’s distribution lies within 1 \\(\\sigma\\) of \\(\\mu\\) % \\(\\ldots\\) \\(\\ldots\\) is within \\(\\mu\\pm 2\\sigma\\) \\(&gt;99\\)% \\(\\ldots\\) \\(\\ldots\\) lies within \\(\\mu\\pm 3\\sigma\\)\nArguably, the most important distribution in statistics\nLinear combinations of Normals are Normal\ne.g., \\((aY+b)\\sim \\mbox{N}(a\\mu+b,\\;a^2\\sigma^2)\\)\nStandard normal: $$\n\\[\\begin{aligned}\n        Z=\\frac{Y-\\mu}{\\sigma} \\sim \\mbox{N}(0,1) \\nonumber\n        \n\\end{aligned}\\]\n$$"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#chi-square-distribution",
    "href": "slides/01_Reviewqmd.html#chi-square-distribution",
    "title": "Review",
    "section": "Chi-square Distribution",
    "text": "Chi-square Distribution\nNotation: \\(X \\sim \\chi^2_{df}\\) \\(df=\\) degrees of freedom \\(E[X]=df\\) \\(X\\) takes on only positive values If \\(Z_i\\sim \\mbox{N}(0,1)\\), then \\(Z_i^2\\sim \\chi^2_1\\)\nIf \\(Z_1,\\ldots,Z_n\\) are independent, with \\(Z_i\\sim\\mbox{N}(0,1)\\), then $$\n\\[\\begin{aligned}\n        \\sum_{i=1}^n Z_i^2 & \\sim & \\chi^2_n \\nonumber\n        \n\\end{aligned}\\]\n$$\nUsed in hypothesis testing and CI’s involving variance"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#t-distribution",
    "href": "slides/01_Reviewqmd.html#t-distribution",
    "title": "Review",
    "section": "t Distribution",
    "text": "t Distribution\nIf \\(Z\\sim \\mbox{N}(0,1)\\) and \\(S^2\\sim \\chi^2_{df}\\) and \\(Z\\) and \\(S^2\\) are independent,\n$$\n\\[\\begin{aligned}\n        \\frac{Z}{S/\\sqrt{df}} & \\sim & t_{df} \\nonumber\n        \n\\end{aligned}\\]\n$$\nSymmetric, bell-shaped; tails heavier than Normal \\(E[t_{df}]=0\\); \\(Var(t_{df})\\) greater than 1 \\(\\lim_{df\\rightarrow \\infty}t_{df} \\rightarrow \\mbox{N}(0,1)\\) for \\(df&gt;30\\), the \\(t_{df}\\) closely resembles the \\(\\mbox{N}(0,1)\\) distribution\nIn linear modeling, used for inference on individual regression parameters"
  },
  {
    "objectID": "slides/01_Reviewqmd.html#f-distribution",
    "href": "slides/01_Reviewqmd.html#f-distribution",
    "title": "Review",
    "section": "F Distribution",
    "text": "F Distribution\nIf \\(X_1^2\\sim \\chi^2_{df1}\\) and \\(X_2^2\\sim \\chi^2_{df2}\\), where \\(X_1^2\\perp X_2^2\\), then: $$\n\\[\\begin{aligned}\n        \\frac{X_1^2/df1}{X_2^2/df2} & \\sim & F_{df1,df2} \\nonumber\n        \n\\end{aligned}\\]\n$$\nonly takes on positive values\nconnection to \\(t\\) distribution:\n$$\n\\[\\begin{aligned}\n            \\{ t_{df} \\}^2 & \\stackrel{{\\cal D}}{=} & F_{1,df} \\nonumber\n            \n\\end{aligned}\\]\n$$\nUsed extensively in linear regression (hypothesis testing)\n\n\nIntro"
  },
  {
    "objectID": "slides/01_Review.html#basic-statistics",
    "href": "slides/01_Review.html#basic-statistics",
    "title": "Review",
    "section": "Basic Statistics",
    "text": "Basic Statistics\n\n\n\nRandom variable \\(Y\\)\n\nSample \\(Y_i, i=1,\\dots, n\\)\n\nSummation:\n\\(\\sum_{i=1}^n Y_i =Y_1 + Y_2 + \\ldots + Y_n\\)\nProduct:\n\\(\\prod_{i=1}^n Y_i = Y_1 \\times Y_2 \\times \\ldots \\times Y_n\\)\nSample mean:\n\\(\\mu_Y= E[Y] = \\int_{-\\infty}^\\infty y f(y) dy\\)\n\nReflects ‘center’ of \\(Y\\)’s distribution"
  },
  {
    "objectID": "slides/01_Review.html#rules-of-expected-values",
    "href": "slides/01_Review.html#rules-of-expected-values",
    "title": "Review",
    "section": "Rules of Expected Values",
    "text": "Rules of Expected Values\n\n\nExpectation of sum: \\(E\\left[\\sum_{i=1}^n Y_i \\right] = \\sum_{i=1}^n E[Y_i] \\nonumber\\) No assumption of independence required\nLet \\(a_1,\\ldots,a_n\\) be constants \\(E[a_iY_i] = a_iE[Y_i]\\)\n\\(E\\left[\\sum_{i=1}^n a_iY_i \\right] = \\sum_{i=1}^n a_iE[Y_i]\\)\nExpectation of product: \\(E[Y_iY_j] = E[Y_i]E[Y_j]\\)\nif \\(Y_i\\) and \\(Y_j\\) are independent"
  },
  {
    "objectID": "slides/01_Review.html#variance-and-standard-deviation",
    "href": "slides/01_Review.html#variance-and-standard-deviation",
    "title": "Review",
    "section": "Variance and standard deviation",
    "text": "Variance and standard deviation\n\n\nVariance: \\[\\begin{split}\n        &Var(Y) =  E[(Y-\\mu_Y)^2]\\\\\n        = &\\int_{-\\infty}^\\infty (y-\\mu_Y)^2 f(y) dy\n        %=  E[Y^2] - \\mu_Y^2\n        \\end{split}\\] reflects spread of \\(Y\\)’s distribution units: (units of \\(Y\\))\\(^2\\)\nStandard deviation: \\[\\begin{split}\n        SD(Y)  = &\\; \\sqrt{Var(Y)}  \\\\\n        SD(aY)  = &\\; aSD(Y)\n        \\end{split}\\]\nreflects dispersion in \\(Y\\)’s distribution measured in same unit as \\(Y\\)"
  },
  {
    "objectID": "slides/01_Review.html#rules-of-variances",
    "href": "slides/01_Review.html#rules-of-variances",
    "title": "Review",
    "section": "Rules of Variances",
    "text": "Rules of Variances\n\n\n0.5 Variance\n\\(Var(Y)=E[(Y-\\mu_Y)^2]\\)\n\\({\\color{white}{Var(Y)}} =E[Y^2] - \\mu_Y^2\\) Variance of linear combination: \\[\\begin{split}\n        &~Var(aY+b)\\\\\n         = &~ Var(aY) \\\\\n         = &~ E[(aY-E[aY])^2]\\\\\n         = &~ a^2 E[(Y-E[Y])^2]\\\\\n         = &~ a^2 Var(Y)\n        \\end{split}\\] \n\n0.5\n\n\n:::"
  },
  {
    "objectID": "slides/01_Review.html#covariance",
    "href": "slides/01_Review.html#covariance",
    "title": "Review",
    "section": "Covariance",
    "text": "Covariance\n\n\n\n\\(X\\), \\(Y\\): random variables\nCovariance: \\(\\mbox{cov}(Y,X)= E[(Y-\\mu_Y)(X-\\mu_X)]\\)\nMeasures (linear) association between \\(X\\), \\(Y\\)\n\n\\(&gt;0\\), large values of \\(X\\) tend to occur with large values of \\(Y\\)\n\\(&lt;0\\), large values of \\(X\\) tend to coincide with small values of \\(Y\\)\n\\(=0\\), size of \\(X\\) provides no information on size of \\(Y\\)\n\nWhen the covariance is calculated, the data are not standardized\nNot scale-invariant: can interpret direction but not magnitude"
  },
  {
    "objectID": "slides/01_Review.html#correlation",
    "href": "slides/01_Review.html#correlation",
    "title": "Review",
    "section": "Correlation",
    "text": "Correlation\n\n\n\n\\(X\\), \\(Y\\): random variables\nCorrelation: \\(\\mbox{corr}(X,Y) = \\frac{\\mbox{cov}(X,Y)}{SD(X)SD(Y)}\\)\nScaled measure of linear association,\n\n\\(-1 \\leq \\mbox{corr}(X,Y) \\leq 1\\)\nEasier to interpret than covariance\n\n\n\n0.5"
  },
  {
    "objectID": "slides/01_Review.html#rules-of-covariance",
    "href": "slides/01_Review.html#rules-of-covariance",
    "title": "Review",
    "section": "Rules of covariance",
    "text": "Rules of covariance\n\\(\\mbox{cov}(Y,X)= E[(Y-\\mu_Y)(X-\\mu_X)]= E[XY]-E[X]E[Y]\\) \\(\\mbox{cov} (Y,Y) = \\mbox{var} (Y)\\) Independent \\(\\stackrel{\\Rightarrow}{\\not\\Leftarrow}\\) uncorrelated If \\(X\\) and \\(Y\\) are independent, \\(\\mbox{cov}(X,Y)=0\\) If \\(\\mbox{cov}(X,Y)=0\\) and \\((X,Y)\\sim \\text{Bivariate Normal}\\), then \\(X\\) and \\(Y\\) are independent Covariance is symmetric, additive, and scale preserving \\[\\begin{aligned}\n\\mbox{cov} (X,Y) & = & \\mbox{cov} (Y,X) \\nonumber \\\\\n\\mbox{cov} (X,Y_1+Y_2) & = & \\mbox{cov} (X,Y_1)+\\mbox{cov} (X,Y_2) \\nonumber \\\\\n\\mbox{cov} (X,aY) & = & a\\;\\mbox{cov} (X,Y) \\nonumber\n%\\mbox{cov} (Y,Y) & = & \\mbox{var} (Y) \\nonumber\n\\end{aligned}\\] :::"
  },
  {
    "objectID": "slides/01_Review.html#rules-of-variance",
    "href": "slides/01_Review.html#rules-of-variance",
    "title": "Review",
    "section": "Rules of variance",
    "text": "Rules of variance\n\n\n0.6\nVariance of sum: \\[\\setlength{\\jot}{1pt}\n        \\begin{split}\n        &Var\\left(\\sum_{i=1}^n Y_i\\right)\n        =  \\sum_{i=1}^n\\sum_{j=1}^n\n        \\mbox{cov}(Y_i,Y_j )  \\\\\n        = & \\sum_{i=1}^n Var(Y_i)   + \\sum_{i=1}^n\\sum_{j=1}^n I(j\\neq i) \\mbox{cov}(Y_i, Y_j )  \\\\\n        = & \\sum_{i=1}^n Var(Y_i) + 2\\sum_{i=1}^n \\sum_{j=i+1}^n\n        \\mbox{cov}(Y_i, Y_j )\n        \\end{split}\\] if \\(Y_1,\\ldots,Y_n\\) are mutually independent, then \\(Var\\left(\\sum_{i=1}^n Y_i\\right) = \\sum_{i=1}^n Var(Y_i)\\)\n\n0.4\n\n\n:::"
  },
  {
    "objectID": "slides/01_Review.html#estimator-of-mean",
    "href": "slides/01_Review.html#estimator-of-mean",
    "title": "Review",
    "section": "Estimator of Mean",
    "text": "Estimator of Mean\nSuppose we obtained a simple random sample from some underlying population, then we can derive sample estimates of each of the population quantities defined previously Suppose \\(Y_1,\\ldots,Y_n\\) are iid with mean \\(\\mu_Y\\) and variance \\(\\sigma^2_Y\\)\n\n\n0.6 Estimator of mean: \\[\\widehat{\\mu}_Y = \\frac{1}{n} \\sum_{i=1}^n Y_i =\n            \\overline{Y}\\]\n\\(E[\\overline{Y}]= \\frac{1}{n} \\sum_{i=1}^n E[Y_i] = \\mu_Y\\)\n\\(Var(\\overline{Y})= n^{-2} \\sum_{i=1}^n Var(Y_i) = \\sigma_Y^2/n\\)\n\n0.37\n\n\n:::"
  },
  {
    "objectID": "slides/01_Review.html#variance-and-covariance-estimator",
    "href": "slides/01_Review.html#variance-and-covariance-estimator",
    "title": "Review",
    "section": "Variance and Covariance Estimator",
    "text": "Variance and Covariance Estimator\n\n\n0.6\nEstimators of variance:\n\\(\\widehat{\\sigma}^2_Y = \\frac{1}{n} \\sum_{i=1}^n (Y_i-E[Y_i])^2\\)\nif population mean is known \\(\\widehat{\\sigma}^2_Y = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i-\\overline{Y})^2\\)\nif population mean is unknown\nEstimator of covariance:\nSuppose pairs \\((Y_1,X_1),\\ldots,(Y_n,X_n)\\) are iid. \\(\\widehat{\\mbox{cov}} (X,Y) = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i-\\overline{Y})(X_i-\\overline{X})\\) \\(\\widehat{\\mbox{corr}} (X,Y) =\\) ?\n\n0.4\n\n\n:::"
  },
  {
    "objectID": "slides/01_Review.html#distributions-that-will-be-used-in-this-class",
    "href": "slides/01_Review.html#distributions-that-will-be-used-in-this-class",
    "title": "Review",
    "section": "Distributions that will be used in this class",
    "text": "Distributions that will be used in this class\n\nNormal distribution\nChi-square distribution\nt distribution\nF distribution"
  },
  {
    "objectID": "slides/01_Review.html#normal-distribution",
    "href": "slides/01_Review.html#normal-distribution",
    "title": "Review",
    "section": "Normal Distribution",
    "text": "Normal Distribution\n\n\n\nNotation: \\(Y\\sim N(\\mu,\\sigma^2)\\)\nArguably, the most important distribution in statistics\nIf we know \\(E(Y)=\\mu\\), \\(Var(Y)=\\sigma^2\\) then\n\n2/3 of \\(Y\\)’s distribution lies within 1 \\(\\sigma\\) of \\(\\mu\\)\n95% \\(\\ldots\\) \\(\\ldots\\) is within \\(\\mu\\pm 2\\sigma\\)\n\\(&gt;99\\)% \\(\\ldots\\) \\(\\ldots\\) lies within \\(\\mu\\pm 3\\sigma\\)\n\nLinear combinations of Normal’s are Normal\ne.g., \\((aY+b)\\sim \\mbox{N}(a\\mu+b,\\;a^2\\sigma^2)\\)\nStandard normal: \\(Z=\\frac{Y-\\mu}{\\sigma} \\sim \\mbox{N}(0,1)\\)"
  },
  {
    "objectID": "slides/01_Review.html#chi-square-distribution",
    "href": "slides/01_Review.html#chi-square-distribution",
    "title": "Review",
    "section": "Chi-square Distribution",
    "text": "Chi-square Distribution\n\nNotation: \\(X \\sim \\chi^2_{df}\\)\n\n\\(df=\\) degrees of freedom\n\\(E[X]=df\\)\n\\(X\\) takes on only positive values\n\nIf \\(Z_i\\sim \\mbox{N}(0,1)\\), then \\(Z_i^2\\sim \\chi^2_1\\)\nIf \\(Z_1,\\ldots,Z_n\\) are independent, with \\(Z_i\\sim\\mbox{N}(0,1)\\), then\n\n\\[\\begin{aligned}\n        \\sum_{i=1}^n Z_i^2 & \\sim & \\chi^2_n \\nonumber\n        \n\\end{aligned}\\]\n\nUsed in hypothesis testing and CI’s involving variance"
  },
  {
    "objectID": "slides/01_Review.html#t-distribution",
    "href": "slides/01_Review.html#t-distribution",
    "title": "Review",
    "section": "t Distribution",
    "text": "t Distribution\n\n\n\nNotation: \\(T \\sim t_{df}\\) OR \\(T \\sim t_{n-1}\\)\n\nDegrees of freedom (df): \\(df=n-1\\)\n\\(T = \\dfrac{\\bar{x} - \\mu_x}{\\dfrac{s}{\\sqrt{n}}}\\sim t_{n-1}\\)\n\nIn linear modeling, used for inference on individual regression parameters\n\nThink: our estimated coefficients (\\(\\hat{\\beta}\\))"
  },
  {
    "objectID": "slides/01_Review.html#f-distribution",
    "href": "slides/01_Review.html#f-distribution",
    "title": "Review",
    "section": "F-Distribution",
    "text": "F-Distribution\n\n\n\nModel ratio of sample variances\n\nRatio of variances is important for hypothesis testing of regression models\n\nIf \\(X_1^2\\sim \\chi^2_{df1}\\) and \\(X_2^2\\sim \\chi^2_{df2}\\), where \\(X_1^2\\perp X_2^2\\), then:\n\n\\[\\dfrac{X_1^2/df1}{X_2^2/df2} \\sim F_{df1,df2}\\] - only takes on positive values\n\nImportant relationship with \\(t\\) distribution: \\(T^2 \\sim F_{1,\\nu}\\)\n\nThe square of a t-distribution with \\(df=\\nu\\)\nis an F-distribution with numerator df (\\(df_1 = 1\\)) and denominator df (\\(df_2 = \\nu\\))"
  },
  {
    "objectID": "Class_dictionary.html",
    "href": "Class_dictionary.html",
    "title": "Stat Talk",
    "section": "",
    "text": "Name\nNormal Speak Examples\nFormula\n\n\n\n\nRandom variable \\(Y\\)\n\n“If we look at Y…”\n\nSample \\(Y_i, i=1,\\dots, n\\)\n\n\nSummation\n\n“Sum over the Y’s”\n\n\\(\\sum_{i=1}^n Y_i =Y_1 + Y_2 + \\ldots + Y_n\\)\n\n\nProduct\n\n“Take the product of the Y’s”\n\n\\(\\prod_{i=1}^n Y_i = Y_1 \\times Y_2 \\times \\ldots \\times Y_n\\)"
  },
  {
    "objectID": "slides/01_Review.html#some-basic-statistics-talk",
    "href": "slides/01_Review.html#some-basic-statistics-talk",
    "title": "Review",
    "section": "Some Basic Statistics “Talk”",
    "text": "Some Basic Statistics “Talk”\n\n\n\nRandom variable \\(Y\\)\n\nSample \\(Y_i, i=1,\\dots, n\\)\n\nSummation:\n\\(\\sum_{i=1}^n Y_i =Y_1 + Y_2 + \\ldots + Y_n\\)\nProduct:\n\\(\\prod_{i=1}^n Y_i = Y_1 \\times Y_2 \\times \\ldots \\times Y_n\\)"
  },
  {
    "objectID": "slides/01_Review.html#descriptive-statistics-continuous-variables",
    "href": "slides/01_Review.html#descriptive-statistics-continuous-variables",
    "title": "Review",
    "section": "Descriptive Statistics: continuous variables",
    "text": "Descriptive Statistics: continuous variables\n\n\nMeasures of central tendency\n\nSample mean\n\\[\n\\bar{x} = \\dfrac{x_1+x_2+...+x_n}{n}=\\dfrac{\\sum_{i=1}^nx_i}{n}\n\\]\nMedian\n\n\nMeasures of variability (or dispersion)\n\nSample variance\n\nAverage of the squared deviations from the sample mean\n\nSample standard deviation\n\\[\ns = \\sqrt{\\dfrac{(x_1-\\bar{x})^2+(x_2-\\bar{x})^2+...+(x_n-\\bar{x})^2}{n-1}}=\\sqrt{\\dfrac{\\sum_{i=1}^n(x_i-\\bar{x})^2}{n-1}}\n\\]\nIQR\n\nRange from 1st to 3rd quartile"
  },
  {
    "objectID": "slides/01_Review.html#data-visualization",
    "href": "slides/01_Review.html#data-visualization",
    "title": "Review",
    "section": "Data visualization",
    "text": "Data visualization\n\nUsing the library ggplot2 to visualize data\nWe will load the package:\n\n\nlibrary(ggplot2)"
  },
  {
    "objectID": "slides/01_Review.html#where-are-we",
    "href": "slides/01_Review.html#where-are-we",
    "title": "Review",
    "section": "Where are we?",
    "text": "Where are we?\n\nReview\nIntro to SLR: estimation and testing\nIntro to MLR: estimation and testing\nDiving into our predictors: categorical variables, interactions between variable\nKey ingredients: model evaluation, diagnostics, selection, and building"
  },
  {
    "objectID": "slides/01_Review.html#confidence-interval-for-one-mean",
    "href": "slides/01_Review.html#confidence-interval-for-one-mean",
    "title": "Review",
    "section": "Confidence interval for one mean",
    "text": "Confidence interval for one mean\n\n\nThe confidence interval for population mean \\(\\mu\\):\n\\[\n\\bar{x} \\pm t^{*}\\dfrac{s}{\\sqrt{n}}\n\\]\n\nwhere \\(t^*\\) is the critical value for the 95% (or other percent) corresponding to the t-distribution and dependent on \\(df=n-1\\)\n\n\n\nWe can use R to find the critical t-value, \\(t^*\\)\n\n\nFor example the critical value for the 95% CI with \\(n=10\\) subjects is…\n\nqt(0.975, df=9)\n\n[1] 2.262157\n\n\n\nRecall, that as the \\(df\\) increases, the t-distribution converges towards the Normal distribution"
  },
  {
    "objectID": "slides/01_Review.html#confidence-interavl-for-two-independent-means",
    "href": "slides/01_Review.html#confidence-interavl-for-two-independent-means",
    "title": "Review",
    "section": "Confidence interavl for two independent means",
    "text": "Confidence interavl for two independent means"
  },
  {
    "objectID": "slides/01_Review.html#steps-in-hypothesis-testing",
    "href": "slides/01_Review.html#steps-in-hypothesis-testing",
    "title": "Review",
    "section": "Steps in hypothesis testing",
    "text": "Steps in hypothesis testing"
  },
  {
    "objectID": "slides/01_Review.html#example-one-sample-t-test-using-p-value-approach",
    "href": "slides/01_Review.html#example-one-sample-t-test-using-p-value-approach",
    "title": "Review",
    "section": "Example: one sample t-test using p-value approach",
    "text": "Example: one sample t-test using p-value approach\nWe want to see what the mean population body temperature is.\n\nState the null and alternative hypotheses:\n\n\n\n\n\n\n\n\\(H_0: \\mu = 98.6\\)\n\\(H_0\\): The population mean body temperature is 98.6 degrees F\n\n\n\\(H_A: \\mu \\neq 98.6\\)\n\\(H_A\\): The population mean body temperature is not 98.6 degrees F\n\n\n\nThe significance level is \\(\\alpha = 0.05\\)\nThe test statistic, \\(t_{\\bar{x}}\\) follows a student’s t-distribution with \\(df = n-1 = 129\\)\nThe test statistic is: \\(t_{\\bar{x}} = \\dfrac{\\bar{x}-\\mu_0}{\\dfrac{s}{\\sqrt{n}}}\\) and with the data: \\(t_{\\bar{x}} = \\dfrac{98.25-98.6}{\\dfrac{0.73}{\\sqrt{130}}} = -5.45\\)\nCalculate the p-value: \\(p-value = P(t \\leq -5.45) + P(t \\geq 5.45)\\)\n\n2*pt(-5.4548, df = 130-1, lower.tail=T)\n\n[1] 2.410889e-07\n\n\nConclusion: We reject the null hypothesis. There is sufficient evidence that the (population) mean body temperature after is different from 98.6 degree ( \\(p-value &lt; 0.001\\))."
  },
  {
    "objectID": "slides/01_Review.html#example-one-sample-t-test-using-critical-values-approach",
    "href": "slides/01_Review.html#example-one-sample-t-test-using-critical-values-approach",
    "title": "Review",
    "section": "Example: one sample t-test using critical values approach",
    "text": "Example: one sample t-test using critical values approach\nWe want to see what the mean population body temperature is.\n\nState the null and alternative hypotheses:\n\n\n\n\n\n\n\n\\(H_0: \\mu = 98.6\\)\n\\(H_0\\): The population mean body temperature is 98.6 degrees F\n\n\n\\(H_A: \\mu \\neq 98.6\\)\n\\(H_A\\): The population mean body temperature is not 98.6 degrees F\n\n\n\nThe significance level is \\(\\alpha = 0.05\\)\nThe test statistic, \\(t_{\\bar{x}}\\) follows a student’s t-distribution with \\(df = n-1 = 129\\)\nDecision rule (critical value): For \\(\\alpha=0.05\\) , \\(2*P(t \\geq t^*) = 0.05\\)\n\nqt(0.05/2, df = 130-1, lower.tail=F)\n\n[1] 1.978524\n\n\nThe test statistic is: \\(t_{\\bar{x}} = \\dfrac{\\bar{x}-\\mu_0}{\\dfrac{s}{\\sqrt{n}}}\\) and with the data: \\(t_{\\bar{x}} = \\dfrac{98.25-98.6}{\\dfrac{0.73}{\\sqrt{130}}} = -5.45\\)\nConclusion: We reject the null hypothesis. There is sufficient evidence that the (population) mean body temperature after is different from 98.6 degree ( 95% CI: \\(98.12, 98.38\\))."
  },
  {
    "objectID": "slides/01_Review.html#type-1-and-2-errors",
    "href": "slides/01_Review.html#type-1-and-2-errors",
    "title": "Review",
    "section": "Type 1 and 2 errors",
    "text": "Type 1 and 2 errors"
  },
  {
    "objectID": "slides/01_Review.html#power",
    "href": "slides/01_Review.html#power",
    "title": "Review",
    "section": "Power",
    "text": "Power\n\nPower is \\(1-\\beta\\)\n\nThe probability of correctly rejecting the null hypothesis\n\n\n\n\n\nReview"
  },
  {
    "objectID": "slides/01_Review.html#confidence-interval-for-two-independent-means",
    "href": "slides/01_Review.html#confidence-interval-for-two-independent-means",
    "title": "Review",
    "section": "Confidence interval for two independent means",
    "text": "Confidence interval for two independent means\n\n\nThe confidence interval for difference in independent population means, \\(\\mu_1\\) and \\(\\mu_2\\):\n\\[\n\\bar{x}_1 - \\bar{x}_2 \\pm t^{*}\\sqrt{\\dfrac{s_1^2}{n_1} + \\dfrac{s_2^2}{n_2}}\n\\]\n\nwhere \\(t^*\\) is the critical value for the 95% (or other percent) corresponding to the t-distribution and dependent on \\(df=n_1 + n_2 -2\\)"
  },
  {
    "objectID": "slides/01_Review.html#before-we-begin",
    "href": "slides/01_Review.html#before-we-begin",
    "title": "Review",
    "section": "Before we begin",
    "text": "Before we begin\n\nMeike has some really good online notes, code, and work on her BSTA 511 page"
  },
  {
    "objectID": "slides/Module_B.html",
    "href": "slides/Module_B.html",
    "title": "Linear Models",
    "section": "",
    "text": "BIOSTAT 650\nTheory and Application of Linear Regression\nModule B: Simple Linear Regression\n\n\nOutline Announcements Module B Topics: Simple linear regression (SLR) model\nInterpretation of parameters\nParameter estimation\nProperties of least squares estimators\nEstimation of variance\nRelevant readings from Textbook: Chapters 1 and 2\n\n\nSimple Linear Regression (SLR) Model\n\n\nSimple Linear Regression Model: \\[\\begin{aligned}\nY_i & = & \\beta_0 + \\beta_1X_i + \\epsilon_i \\nonumber\n\\end{aligned}\\] \\(Y_i\\): response, dependent variable\n\\(\\beta_0\\): intercept (fixed, unknown)\n\\(\\beta_1\\): slope (fixed, unknown)\n\\(X_i\\): covariate, predictor variable (fixed)\n\\(\\epsilon_i\\): error term (random, unobservable)\nObserved are the ordered pairs: (\\(X_i,Y_i\\)), for \\(i=1,\\ldots,n\\)\n\n\n“Linear” Models “Linearity” refers to the fact that the mean can be written as a weighted sum of parameters:\ni.e., \\(E[Y_i|X_i]=\\sum_{k=1}^q w_k\\beta_k\\)\nExamples of linear models (covered in more detail later): \\(E[Y_i|X_i] = \\beta_0+ \\beta_1X_i^2\\)\n\\(E[Y_i|X_i] = \\beta_0+ \\beta_1\\exp(X_i)\\)\n\\(E[Y_i|X_i] = \\beta_0+ \\beta_1\\log(1+X_i)\\)\nExamples of non-linear models (not covered in this class):\n\\(E[Y_i|X_i] = \\exp\\{\\beta_0+ \\beta_1X_i\\}\\)\n\\(E[Y_i|X_i] = [1+ \\exp\\{-(\\beta_0+ \\beta_1X_i)\\}]^{-1}\\)\n\\(E[Y_i|X_i] = \\beta_0+ \\exp\\{\\beta_1X_i\\}\\)\n\n\nAssumptions for estimation (not sufficient for inference)\nAssumptions about errors: First and second moment: \\(\\epsilon_i\\sim (0,\\sigma^2)\\) for all \\(i\\) Uncorrelated: \\(cov(\\epsilon_i,\\epsilon_j)=E[\\epsilon_i\\epsilon_j] =0\\), for all \\(i\\), \\(j\\), \\(i\\neq j\\) Uncorrelated \\(\\not\\Rightarrow\\) independence Later we will consider inference (hypothesis testing), and we will further assume that \\(\\epsilon_i\\stackrel{i.i.d}{\\sim} N(0,\\sigma^2)\\) (independence and normality)\nThese imply assumptions about distribution of \\(Y_i\\) at each \\(X_i\\) \\(E[Y_i\\mid X_i]=\\beta_0+\\beta_1X_i\\) (depends on \\(X_i\\)) \\(Var(Y_i\\mid X_i)=Var(Y_i)=\\sigma^2\\) (does not depend on \\(X_i\\)) \\(Y_i\\) and \\(Y_j\\) are uncorrelated, \\(i\\neq j\\)\n\n\nA full list of assumptions (LINE) for estimation and inference\n\\(Y_i=\\beta_0+\\beta_1X_i+\\epsilon_i\\) \"Linearity\": the model is correctly specified \\(E[Y_i|X_i]=\\beta_0+\\beta_1X_i\\)\n\\(\\epsilon_i \\ind \\epsilon_j\\), \\(i\\neq j\\) \"Independence\" hence \\(Y_i \\ind Y_j\\), \\(i\\neq j\\)\n\\(\\epsilon_i\\sim N(0,\\sigma^2)\\) \"Normality\": errors follow normal distribution w/ mean \\(0\\), variance \\(\\sigma^2\\) hence \\(Y_i\\mid X_i\\sim N(\\beta_0+\\beta_1X_i,\\sigma^2)\\)\n\\(\\sigma^2_i=Var[Y_i|X_i]=\\sigma^2&lt;\\infty\\) \"Equal variance\": errors have equal variance \\(\\sigma^2\\)\n\n\nFixed Design \\(X_i\\)’s treated as fixed constants, throughout this course Think of sampling \\(Y\\) at each level of \\(X\\) In reality, \\(X_i\\) may be random: measurement error (e.g., body weight)\nscale not perfectly balanced and/or natural fluctuation (e.g., body weight; water retention)\nPreferably, randomness in \\(X_i\\) is small (negligible)\n\n\nModel Components\nRelationship between \\(X\\) and mean of \\(Y\\) is described by a line: \\[E[Y_i|X_i]=\\beta_0+\\beta_1X_i \\;\\;(\\epsilon_i=Y_i-E[Y_i|X_i])\\]\nA line is determined by two numbers: intercept and slope\n\\(\\beta_0=E[Y_i|X_i=0]\\) = intercept of regression line “Mean weight for individuals at age zero\" \\(\\beta_1=\\Delta E[Y] /\\Delta X\\)= slope of regression line Change in mean of \\(Y\\) per unit increase in \\(X\\) \\[\\beta_1 = \\frac{E[Y_i|X_i=x_2]-E[Y_i|X_i=x_1]}{x_2-x_1}\\]\n\n\nModel Components\nSuppose two subjects (e.g., \\(i\\)=1, \\(i\\)=2) differ by 1 unit of \\(X_1\\) (age); the difference in \\(E[Y]\\) (mean weight) will be \\(\\beta_1\\), since e.g. \\(E[Y_1|X_1=7] = \\beta_0 + \\beta_1 7\\)\n\\(E[Y_1|X_1=6] = \\beta_0 + \\beta_1 6\\) subtracting the right and left sides gives \\(\\beta_1\\) Are the above results dependent on the specific \\(X_i\\) values used? Linearity assumes: “for every unit change in \\(X\\), the mean difference in \\(Y\\) is constant\", regardless of the value of \\(X\\)\n\n\nModel Components \\(\\beta_0\\), \\(\\beta_1\\) are scale-dependent when interpreting \\(\\beta_0\\) and \\(\\beta_1\\), units are considered \\(\\beta_1\\) reflects the magnitude of the (\\(X_i,Y_i\\)) association; often of much greater inherent interest than \\(\\beta_0\\) Notwithstanding, a useful interpretation of \\(\\beta_0\\) is preferable\n\n\nInterpretation example 1 \\(Y_i=\\) serum cholesterol (mg/dL)\n\\(X_i=\\) systolic blood pressure (SBP; mm Hg)\nModel: \\(Y_i = \\beta_0+\\beta_1X_i+\\epsilon_i\\)\n\\(\\beta_1=\\) mean difference in serum cholesterol (mg/dL) per one unit higher in SBP (mm Hg)\n\\(\\beta_0=\\) mean serum cholesterol (mg/dL) for patients with SBP=0 (is zero SBP possible for live persons?)\n\n\nInterpretation example 2 e.g., study of adult males age 20-39\n\\(Y_i=\\) weight (kg)\n\\(X_i=\\) age (years)\nModel: \\(Y_i = \\beta_0+\\beta_1X_i+\\epsilon_i\\)\n\\(\\beta_1=\\) mean change in weight (kg) per year increase in age\n\\(\\beta_0=\\)\n\n\nRegression: Extrapolation Generally, inference/conclusions should respect the range of observed covariate values\ne.g., return to the age/weight example\\(\\ldots\\)\nAge/weight model which applies to\n\\(20\\leq age \\leq 39\\) may be quite different from that which applies to someone age 65 Relationship may no longer be linear\nPredictions should generally not be made outside the observed range of the \\(X_i\\)’s \n\n\nCentering Covariate to make intercept interpretable Original model: \\(Y_i=\\beta_0+\\beta_1 X_i +\\epsilon_i\\) Define \\(X_i^*=X_i-\\overline{X}\\), where \\(\\overline{X}=n^{-1}\\sum_{i=1}^nX_i\\)\nRevised Model: \\(Y_i=\\beta_0^*+\\beta_1^*X_i^*+\\epsilon_i^*\\)\nWe still have: \\(\\epsilon_i^*\\sim N(0,\\sigma^2)\\) The error is unchanged, i.e., \\(\\epsilon_i^* = \\epsilon_i\\) Graphically we have a shift in axis:\n\n\nCentering Covariate: Interpretation of Intercept Recall: interpretation of \\(\\beta_0\\) in original model: \\(E[Y_i|X_i]=\\beta_0+\\beta_1X_i\\), thus, \\(\\beta_0=E[Y_i|X_i=0]\\) “Mean weight for individuals at age zero\" For the revised model: \\(E[Y_i|X_i^*]=\\beta_0^*+\\beta_1^*X_i^*\\), thus, \\(\\beta_0^*=E[Y_i|X_i^*=0]=E[Y_i|X_i=\\overline{X}]\\)\n“Mean weight for individuals with average age\"\n\n\nCentering Covariate: Slope Interpretation is unchanged Original model: \\[\\begin{aligned}\n\\beta_1 &  = & \\frac{E[Y_i|X_i=x_2 ]-E[Y_i|X_i=x_1]}{x_2-x_1 }\n\\nonumber\n\\end{aligned}\\]\nCentered model: \\[\\begin{aligned}\n\\beta_1^* &  = & \\frac{E[Y_i|X_i^*=x_2\n]-E[Y_i|X_i^*=x_1]}{x_2-x_1 }\n\\nonumber \\\\\n&  \\stackrel{X_i^*=X_i-\\overline{X}}{\\longeq} & \\frac{E[Y_i|X_i=\\overline{X}+x_2\n]-E[Y_i|X_i=\\overline{X}+x_1]}{x_2-x_1 }\n\\nonumber \\\\\n&  = & \\frac{E[Y_i|X_i=\\overline{X}+x_2\n    ]-E[Y_i|X_i=\\overline{X}+x_1]}{(\\overline{X}+x_2)-(\\overline{X}+x_1) }\n\\nonumber\n\\end{aligned}\\]\n\n\nParameter Estimation\n\n\nParameter Estimation: Preliminaries Truth \\(\\beta_0\\), \\(\\beta_1\\): true parameters, fixed, unknown \\(E[Y_i|X_i]=\\beta_0+\\beta_1X_i\\): true mean is not observable \\(\\epsilon_i=Y_i-E[Y_i|X_i]\\): true errors, unobservable Estimators \\(\\widehat{\\beta}_0\\), \\(\\widehat{\\beta}_1\\): estimators, computed using observables \\(\\widehat{Y}_i=\\widehat{E}[Y_i|X_i]=\\widehat{\\beta}_0+\\widehat{\\beta}_1X_i\\), estimated mean (fitted value) \\(\\widehat{\\epsilon}_i=Y_i-\\widehat{Y}_i\\), estimated errors (residuals) Note: textbook uses \\(e_i\\) to denote estimated errors. I prefer using the hat notation, \\(\\widehat{\\epsilon}_i\\), to emphasize it is an \\(estimated\\) error.\n\n\nParameter Estimation: Deterministic Model Consider a model for temperature : \\(C=\\) degrees Celsius \\(F=\\) Fahrenheit \\(F_i = \\beta_0 + \\beta_1C_i\\) at day \\(i\\)\nIf I give you data about two days: \\((C=10, F=50)\\) and \\((C=20,F=68)\\), can you determine \\(\\beta_0\\) and \\(\\beta_1\\)?\n\n\nParameter Estimation when there is noise SLR: \\(Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i\\)\n\\(\\beta_0 + \\beta_1 X_i\\): mean component (deterministic)\n\\(\\epsilon_i\\): error component (random)\nImpact of noise If there was no \\(\\epsilon_i\\), we could use any two \\((X_i,Y_i)\\) pairs to estimate \\(\\beta_0\\) and \\(\\beta_1\\)\nDue to presence of \\(\\epsilon_i\\), estimation is more complicated\nRequire a method to estimate our parameters which uses all data points\n\n\nMethod of Estimation Scatter plot of data:\n\n\n\n\nimage\n\n\n\nAn infinite number of lines of the form \\(E[Y_i|X_i]=\\beta_0+\\beta_1X_i\\) are available Need to find the line which best fits the data \\(\\ldots\\) Need to select ‘best’ version of (\\(\\widehat{\\beta}_0,\\widehat{\\beta}_1\\))\n\n\nMethod of Estimation How to find a best-fitting line?\n\n\n\n\nimage\n\n\n\nMethod: Least Squares Estimation (or OLS: ordinary least squares) Idea: chooses the line that minimizes the sum of squares of the vertical distances from the observed points to the line.\n\n\nLeast Squares Method The Least Squares Estimators (LSEs) of \\(\\beta_0\\) and \\(\\beta_1\\) are the estimators which minimize the sum of squares error (SSE): \\[\\begin{aligned}\nSSE & = & \\sum_{i=1}^n \\widehat{\\epsilon}_i^2 ~~ = ~~~~~~~~~~~~~~\\nonumber \\\\\n&  & \\nonumber \\\\\n& = & \\nonumber\n\\end{aligned}\\] To minimize \\(SSE\\), find the values of \\(\\widehat{\\beta}_0\\) and \\(\\widehat{\\beta}_1\\) which solve the following system of equations: \\[\\begin{aligned}\n\\frac{\\partial SSE}{\\partial\\widehat{\\beta}_0} =0  & &\n\\frac{\\partial SSE}{\\partial\\widehat{\\beta}_1} =0 \\nonumber\n\\end{aligned}\\]\n\n\nLeast Squares Estimators\n\\[0=\\frac{\\partial SSE}{\\partial\\widehat{\\beta}_0} =\n-2\\sum_{i=1}^n (Y_i-\\widehat{\\beta}_0-\\widehat{\\beta}_1X_i)\n\\label{eq:derbeta0}\\] \\[0=\\frac{\\partial SSE}{\\partial\\widehat{\\beta}_1} =\n-2\\sum_{i=1}^n X_i(Y_i-\\widehat{\\beta}_0-\\widehat{\\beta}_1X_i)\n\\label{eq:derbeta1}\\]\n\n\nLeast Squares Estimators From ([eq:derbeta0]) we have: \\[\\boxed{\\widehat{\\beta}_0 =\\overline{Y}-\\widehat{\\beta}_1\\overline{X}}\\label{beta0}\\]\nSubstitute \\(\\widehat{\\beta}_0\\) into ([eq:derbeta1]) we get \\[\\sum_{i=1}^nX_i(Y_i {\\color{red}{ -\\overline{Y}+\\widehat{\\beta}_1\\overline{X}}} -\n\\widehat{\\beta}_1X_i) = 0\\] Thus \\[\\begin{aligned}\n\\sum_{i=1}^nX_i(Y_i-\\overline{Y}) & = & \\widehat{\\beta}_1\n\\sum_{i=1}^nX_i(X_i-\\overline{X}) \\nonumber\n\\end{aligned}\\] Which gives: \\[\\boxed{\\widehat{\\beta}_1 = \\frac{SSXY}{SSX}},\\label{beta1}\\] where \\(SSXY = {\\sum_{i=1}^n X_i(Y_i-\\overline{Y}), \\;\\;SSX = \\sum_{i=1}^n X_i(X_i-\\overline{X})}\\)\n\n\nA little more on \\(SSXY\\) and \\(SSX\\)\n\n\\(SSXY = {\\sum_{i=1}^n X_i(Y_i-\\overline{Y}), \\;\\;SSX = \\sum_{i=1}^n X_i(X_i-\\overline{X})}\\)\n\nHome exercise: Show that \\[\\begin{split}\nSSXY &= \\sum_{i=1}^n(Y_i-\\overline{Y})(X_i-\\overline{X})= n\\left\\{\\overline{X\\cdot Y}-\\overline{X}\\cdot\\overline{Y}\\right\\}\\\\\nSSX &= \\sum_{i=1}^n(X_i-\\overline{X})^2= n\\left\\{\\overline{X^2}-\\overline{X}^2\\right\\}\n\\end{split}\\] “The slope is the sample covariance of \\(X\\) and \\(Y\\), divided by the sample variance of \\(X\\)\" Recall \\(\\text{cov}(X,Y)=E[(X-E[X])(Y-E[Y])]=E[XY]-E[X]E[Y]\\) Recall\\(Var(X)=E[(X-E[X])^2]=E[X^2]-E[X]^2\\)\nTurns out this applies to sample variance and covariance as well. Helpful to keep in mind that”sum of centered variables is zero\":\n\n\nA little more on \\(SSXY\\) and \\(SSX\\)\nHome exercise: Show that\n“The slope is the sample covariance of \\(X\\) and \\(Y\\), divided by the sample variance of \\(X\\)\", i.e., \\(\\widehat{\\beta}_1=\\frac{\\frac{1}{n-1}SSXY}{\\frac{1}{n-1}SSX}\\), where \\(\\frac{1}{n-1}SSXY = \\frac{1}{n-1}\\sum_{i=1}^n(Y_i-\\overline{Y})(X_i-\\overline{X})\\) is the sample covariance \\(\\frac{1}{n-1}SSX = \\frac{1}{n-1}\\sum_{i=1}^n(X_i-\\overline{X})^2\\) is the sample variance Recall \\(\\text{cov}(X)=E[(X-E[X])(Y-E[Y])]\\)\nRecall\\(Var(X)=E[(X-E[X])^2]\\) Helpful to keep in mind that”sum of centered variables is zero\": \\(\\sum_i (Y_i-\\overline{Y})=\\sum_i (X_i-\\overline{X})=0\\)\n\n\nReview and Preview Suppose we have \\(n\\) (sample size) pairs of data \\((X_i,Y_i),i=1\\dots,n\\) \\(X\\)’s are fixed values \\(Y\\)’s are randomly selected from the population at a given \\(X\\) value We assume a linear relationship \\(Y_i=\\beta_0+\\beta_1X_i+\\epsilon_i\\), \\(\\epsilon_i\\sim (0,\\sigma^2)\\) The errors \\(\\epsilon_i\\) are at least uncorrelated Given the data we can estimate \\(\\beta_0,\\beta_1\\) \\(\\widehat{\\beta}_0 =\\overline{Y}-\\widehat{\\beta}_1\\overline{X}\\) \\(\\widehat{\\beta}_1 = \\frac{SSXY}{SSX}\\) Because the values of \\(\\widehat{\\beta}_0,\\widehat{\\beta}_1\\) depend on the particular random sample drawn from the population, these quantities are considered random variables (estimators). Once we “plug in\" observed data, we have estimates.\n\n\nReview and Preview A typical goal of the analysis is to infer (draw inference on) the values of \\(\\beta_0,\\beta_1\\) supported by the data (point and interval estimates), as well as test if particular values of \\(\\beta_0,\\beta_1\\) are consistent with the data (hypothesis testing where e.g., \\(H_0:\\beta_1=b_1\\), and \\(b_1\\) is a given constant such as 0). To draw inference (interval estimates or tests) we need to know the sampling distribution of the estimators \\(\\widehat{\\beta}_0,\\widehat{\\beta}_1\\), i.e., What are the average values of \\(\\widehat{\\beta}_0,\\widehat{\\beta}_1\\) if we were able to take repeated samples of the population How much variation is there in the values of \\(\\widehat{\\beta}_0,\\widehat{\\beta}_1\\) from one random sample to another Given the model assumptions, we can derive Average values: \\(E[\\widehat{\\beta}_0]=\\beta_0\\), \\(E[\\widehat{\\beta}_1]=\\beta_1\\) Variation: \\(Var(\\widehat{\\beta}_0)=\\sigma^2(\\frac{1}{n}+\\frac{\\bar{X}^2}{SSX})\\), \\(Var(\\widehat{\\beta}_1)=\\frac{\\sigma^2}{SSX}\\)\n\n\nReview and Preview Since \\(E[\\widehat{\\beta}_0]=\\beta_0\\) and \\(E[\\widehat{\\beta}_1]=\\beta_1\\), we know that the estimators (formulas) will give estimates that are centered at the true values.\n\n\n0.3\n\n\n\n\nimage\n\n\n\n\n0.7 Histogram of observed values of \\(\\widehat{\\beta}_1\\) if we took many repeated samples from the population Since we have only one particular dataset (sample), we are only able to observe one value of the slope, not the whole distribution\n\n\nThe formulas for \\(Var(\\widehat{\\beta}_0),Var(\\widehat{\\beta}_1)\\) tell us how much spread there is in this histogram. However, the formulas also involve \\(\\sigma^2\\) (the variance of errors). So we further estimate \\(\\sigma^2\\) before drawing inference. We do this by “plug in\" an estimate of \\(\\sigma^2\\), specifically \\(\\widehat{\\sigma}^2=MSE=\\frac{\\sum_{i=1}^n(Y_i-\\widehat{Y}_i)^2}{n-2}\\) Hence \\(\\widehat{Var}(\\widehat{\\beta}_0)=\\widehat{\\sigma}^2(\\frac{1}{n}+\\frac{\\bar{X}^2}{SSX})=MSE(\\frac{1}{n}+\\frac{\\bar{X}^2}{SSX})\\) Hence \\(\\widehat{Var}(\\widehat{\\beta}_1)=\\frac{\\widehat{\\sigma}^2}{SSX}=\\frac{MSE}{SSX}\\)\n\n\nProperties of Least Squares Estimators\n\n\nProperties of Estimators (Definitions) Suppose \\(\\widehat{\\theta}\\) is an estimator of \\(\\theta\\) \\(\\widehat{\\theta}\\): estimator (random, depends on random sample of data);\n\\(\\theta\\): estimand (fixed, generally unknown true value)\nVarious criteria used to evaluate estimators: Bias: \\(\\mbox{bias}(\\widehat{\\theta})=E[\\widehat{\\theta}]-\\theta\\) We say \\(\\widehat{\\theta}\\) is an unbiased estimator if \\(E[\\widehat{\\theta}]=\\theta\\)\nSampling variance: \\(Var(\\widehat{\\theta})=E[\\widehat{\\theta}-E(\\widehat{\\theta})]^2\\)\nMean squared error: \\(mse(\\widehat{\\theta})=Var(\\widehat{\\theta}) + \\mbox{bias}(\\widehat{\\theta})^2\\) Often there is a trade-off between bias and sampling variance, which is measured by the MSE\nOur goal in the next few slides is to find: \\(E(\\widehat{\\beta}_0),~E(\\widehat{\\beta}_1),~Var(\\widehat{\\beta}_0),~Var(\\widehat{\\beta}_1)\\)\n\n\nRecall the expected value of sums of random variables, from Module A: Let \\(a_1,\\ldots,a_n\\) be constants. Recall:\n\\(E[a_iY_i]=a_iE[Y_i]\\) \\[E\\left[\\sum_{i=1}^n a_i Y_i \\right] = \\sum_{i=1}a_i E[Y_i]\\label{sumofrv}\\] Note: result does not require independence among the \\(Y_i\\)’s\n\n\nExpected value of \\(\\widehat{\\beta}_1\\) Claim: \\(\\widehat{\\beta}_1\\) is an unbiased estimator of \\(\\beta_1\\), i.e., \\(E(\\widehat{\\beta}_1)=\\beta_1\\) Proof:\n\n\nExpected value of \\(\\widehat{\\beta}_0\\) Claim: \\(\\widehat{\\beta}_0\\) is an unbiased estimator of \\(\\beta_0\\), i.e., \\(E(\\widehat{\\beta}_0)=\\beta_0\\) Proof: \\[\\begin{aligned}\nE[\\widehat{\\beta}_0] & \\stackrel{(\\ref{beta0})}{\\longeq} &\nE[\\overline{Y}-\\widehat{\\beta}_1\\overline{X}]\\stackrel{ \\text{E(sum)=sum(E)} }{\\longeq}E[\\overline{Y}] - E[\\widehat{\\beta}_1\\overline{X}]   \\\\\n& \\longeq &\nn^{-1}\\sum_{i=1}^nE[Y_i] - E[\\widehat{\\beta}_1\\overline{X}]  \\\\\n& \\stackrel{\\text{model def}}{\\longeq} &\nn^{-1}\\sum_{i=1}^n E[\\beta_0+\\beta_1 X_i+\\epsilon_i]-\\beta_1\\overline{X} \\\\\n& \\stackrel{E[\\epsilon_i]=0}{\\longeq} & n^{-1}\\sum_{i=1}^n\n(\\beta_0+\\beta_1X_i)-\\beta_1\\overline{X}  \\\\\n& \\longeq & \\beta_0\n\\end{aligned}\\]\n\n\nRecall the variance of sums of random variables, from Module A:\nLet \\(a_1,\\ldots,a_n\\) be constants. Recall: \\(Var(a_iY_i)=a_i^2Var(Y_i)\\) \\(\\mbox{cov}(X,aY)=a\\mbox{cov}(X,Y)\\)\n\\(\\mbox{cov}(X,Y_1+Y_2)=\\mbox{cov}(X,Y_1)+\\mbox{cov}(X,Y_2)\\) \\(Var\\left( \\sum_{i=1}^n a_iY_i \\right) = \\sum_{i=1}^n  \\sum_{j=1}^n a_i a_j \\mbox{cov}(Y_i,Y_j)\\)\n\\({\\color{white}{Var\\left( \\sum_{i=1}^n a_iY_i \\right)}}=\\sum_{i=1}^{n}a_i^2Var(Y_i) +2 \\sum_{i=1}^{n-1}  \\sum_{j=i+1}^n a_i a_j \\mbox{cov}(Y_i,Y_j)\\) In particular \\[\\boxed{\n        Var(a_1Y_1+a_2Y_2)=a_1^2Var(Y_1)+a_2^2Var(Y_2)+2a_1a_2\\text{cov}(Y_1,Y_2)\n    }\\label{varof2sum}\\]\nIf \\(Y_i\\)’s are uncorrelated, then \\[\\boxed{Var\\left(\\sum_{i=1}^n a_iY_i\\right) = \\sum_{i=1}^n a_i^2Var(Y_i)}\\label{varofsum}\\]\n\n\nVariance of \\(\\widehat{\\boldbeta}_1\\) Claim: \\(Var(\\widehat{\\beta}_1)=\\sigma^2/SSX\\) Proof:\n\\[\\begin{aligned}\nVar(\\widehat{\\beta_1}) & \\longeq & Var\\left(  \\frac{SSXY}{SSX} \\right) \\stackrel[\\text{constant}]{SSX\\text{ is a}}{\\longeq} SSX^{-2}Var(SSXY) \\\\\n& \\longeq & SSX^{-2}Var\\left\\{ \\sum_{i=1}^n Y_i (X_i-\\overline{X}) \\right\\}\\\\\n& \\stackrel{(\\ref{varofsum}) \\text{ w/ } a_i=X_i-\\overline{X}}{\\longeq} & SSX^{-2}\\sum_{i=1}^n \\left\\{(X_i-\\overline{X})^2 Var(Y_i) \\right\\}\\\\\n& \\longeq & SSX^{-1} \\sigma^2\n\\nonumber\n\\end{aligned}\\]\n\n\nVariance of \\(\\widehat{\\boldbeta}_0\\) Claim: \\(Var(\\widehat{\\beta}_0) = \\sigma^2 \\left\\{\\frac{1}{n} + \\frac{\\overline{X}^2}{SSX} \\right\\}\\) Proof: \\[\\begin{aligned}\nVar(\\widehat{\\beta}_0) & = & Var(\\overline{Y} - \\widehat{\\beta}_1\\overline{X} ) \\\\\n&& \\mbox{Here $\\overline{Y}$ and $\\widehat{\\beta}$ are random, $\\overline{X}$ is fixed}\\\\\n& \\stackrel{(\\ref{varof2sum})}{\\longeq} & Var(\\overline{Y}) + \\overline{X}^2 Var(\\widehat{\\beta}_1) - 2\\overline{X}\\mbox{cov}(\\overline{Y},\\widehat{\\beta}_1)\\\\\n&& \\mbox{Next slide shows that cov}(\\overline{Y},\\widehat{\\beta}_1) =0\\mbox{, thus,}\\\\\n& = & \\frac{\\sigma^2}{n} + \\overline{X}^2 \\frac{\\sigma^2}{SSX}\n\\end{aligned}\\]\n\n\nCovariance: \\(\\overline{Y},\\widehat{\\boldbeta}_1\\) Claim: \\(\\mbox{cov}(\\overline{Y},\\widehat{\\beta}_1)=0\\) Proof:\n$$\n\\[\\begin{aligned}\n%       &&\\mbox{cov}(\\overline{Y},\\widehat{\\beta}_1) \\\\\n        \\mbox{cov}(\\overline{Y},\\widehat{\\beta}_1) & \\stackrel{ (\\ref{beta1}) }{\\longeq} & \\mbox{cov}\\big(\\overline{Y},\\frac{\\sum_{i=1}^n (X_i-\\overline{X})Y_i }{SSX}\\big) \\\\\n        &\\stackrel[\\text{cov(a)=a(cov)}]{ \\text{cov(sum)=sum(cov)} }{\\longeq} & \\frac{1}{SSX}\n        \\sum_{i=1}^n    (X_i-\\overline{X})\\mbox{cov}(\\overline{Y}, Y_i)\\\\\n        &{\\longeq} & \\frac{1}{SSX}\n        \\sum_{i=1}^n    (X_i-\\overline{X})\\mbox{cov}(\\frac{1}{n}\\sum_{\\myi=1}^nY_\\myi, Y_i)\\\\\n        %%%\n        &\\stackrel[\\text{for all $i\\neq j$}]{\\text{cov$(Y_i,Y_j)=0$}}{\\longeq}&\n        \\frac{1}{SSX}\n        \\sum_{i=1}^n    (X_i-\\overline{X})\\underbrace{cov(\\frac{1}{n}Y_i,Y_i)}_{\\text{$\\sigma^2/n$}}\\\\\n        &\\stackrel{\\text{$\\sum_{i=1}^n  (X_i-\\overline{X})\\sigma^2=0$}}{\\longeq}&0\n    \n\\end{aligned}\\]\n$$\n\n\nEstimating the sampling variance\nof the regression coefficients\n\n\nEstimating \\(Var(\\widehat{\\beta}_0)\\) and \\(Var(\\widehat{\\beta}_1)\\) We have shown that the true sampling variances of the regression coefficients are: \\(Var(\\widehat{\\beta}_1)=\\sigma^2/SSX\\) \\(Var(\\widehat{\\beta}_0)= \\sigma^2 \\left\\{\\frac{1}{n} + \\frac{\\overline{X}^2}{SSX} \\right\\}\\) However, \\(\\sigma^2\\) is generally unknown. In SLR we use the estimator: \\[\\boxed{\\widehat{\\sigma}^2 =\\frac{1}{n-2} \\sum_{i=1}^n \\widehat{\\epsilon}_i^2}\\stackrel{\\text{def}}{\\longeq}\\frac{SSE}{n-2}\\stackrel{\\text{def}}{\\longeq}MSE\\]\nwhere \\(\\widehat{\\epsilon}_i=Y_i-\\widehat{Y}_i\\) is the residual (estimated errors)\n\\(\\widehat{\\sigma}^2\\) reflects average squared distance between \\(Y_i\\)’s and \\(\\widehat{Y}_i\\)’s\nLarge \\(\\widehat{\\sigma}^2\\) implies large amount of scatter in \\(Y_i\\)’s around estimated regression line\n\n\nEstimating \\(Var(\\widehat{\\beta}_0)\\) and \\(Var(\\widehat{\\beta}_1)\\) (continued) Recall sample variance when \\(\\mu\\) is unknown (module A) Sample: \\(Y_1,\\ldots,Y_n\\)\nEstimated mean: \\(\\widehat{E}[Y_i]=\\overline{Y}\\) for all \\(i\\)\nSample variance: \\[\\widehat{Var}(Y_i) = \\frac{1}{  {\\color{red}n-1}  } \\sum_{i=1}^n\n(Y_i-\\overline{Y})^2\\] Estimating sample variance of error \\(\\ldots\\) Sample: \\((X_1,Y_1),\\ldots,(X_n,Y_n)\\)\nEstimated mean: \\(\\widehat{E}[Y_i|X_i]=\\widehat{\\beta}_0+\\widehat{\\beta}_1X_i\\)\nSample variance: \\[\\widehat{Var}(Y_i) =\\widehat{\\sigma}^2=  \\frac{1}{  {\\color{red}n-2}  } \\sum_{i=1}^n\n(Y_i-\\widehat{Y}_i)^2\\] Note: difference in divisor (Q: Why?)\n\n\nEstimator of \\(\\boldsigma^2\\) in SLR\nThe \\(-2\\) in the denominator comes from the number of degrees of freedom \\(df\\) in the \\(SSE\\) \\(df =\\) the number of observations that are free to vary\n\\(df\\) \\(=\\) number of contributions (\\(n\\))- number of constraints Example for \\(df\\) in SSE: Suppose we observe \\(Y_1,\\dots,Y_n\\) and \\(\\mu_Y\\) is known, then \\(df = n\\) \\(Y_1\\), \\(Y_2\\) (\\(n=2\\)) and \\(\\mu_Y\\) is unknown and estimated by \\(\\overline{Y}\\), then once \\(Y_1\\) and \\(\\overline{Y}\\) are known, \\(Y_2\\) is not free to vary. There is 1 df lost in SSE due to estimation of \\(\\overline{Y}\\), \\(df = n-1\\) \\((X_1,Y_1),\\ldots,(X_n,Y_n)\\) and estimated \\(\\widehat{\\beta}_0,\\widehat{\\beta}_1\\). There are 2 df lost in SSE due to estimation of \\(\\widehat{\\beta}_0,\\widehat{\\beta}_1\\), \\(df = n-2\\) For \\(\\widehat{\\sigma}^2\\): two constraints from the two estimated parameters \\(\\widehat{\\beta}_0\\), \\(\\widehat{\\beta}_1\\) It can be shown that \\(\\widehat{\\sigma}^2\\) as defined in previous slide is an unbiased estimator of \\(\\sigma^2\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation Interpretation check list: Units, direction (for slope not intercept), magnitude, “average/mean\", “estimated\"\n\\(\\widehat{\\beta}_0 = 646.483\\)\n\\(\\widehat{\\beta}_1=-14.041\\)\n\n\nInterpretation Interpretation check list: Units, direction, magnitude, “estimated\", “average/mean\", in which population\n\\(\\widehat{\\beta}_0 = 646.483\\) The estimated mean sleep time for someone who is age 0 (a newborn) is 646.483 minutes\n\\(\\widehat{\\beta}_1=-14.041\\) The estimated mean difference in sleep time for one year increase in age is -14.041 minutes Comparing two children who differ in age by one year, the older individual has an estimated mean sleep time that is 14.041 minutes lower. We estimated that children who are one year older sleep, on average, 14.041 minutes less.\n\n\nAcknowledgement\n\n\n\n\n\n\nLan Luo\n\n\nUniversity of Iowa\n\n\n\nThank you for your notes!\n\n\nQuestions?"
  },
  {
    "objectID": "slides/01_SLR.html#lets-start-with-an-example",
    "href": "slides/01_SLR.html#lets-start-with-an-example",
    "title": "Simple Linear Regression (SLR)",
    "section": "Let’s start with an example",
    "text": "Let’s start with an example\n\n\n\n\n\n\n\n\nAverage life expectancy vs. female literacy rate\n\nEach point on the plot is for a different country\n\\(x\\) = country’s adult female literacy rate\n\\(y\\) = country’s average life expectancy (years)\nData are from Gapminder (2011)\n\n\n\n\n\\[\\begin{aligned}\n\\hat{\\text{life expectancy}} & =  50.9 + 0.232\\cdot\\text{female literacy rate}\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/01_SLR.html#questions-we-can-ask-with-this-model",
    "href": "slides/01_SLR.html#questions-we-can-ask-with-this-model",
    "title": "Simple Linear Regression (SLR)",
    "section": "Questions we can ask with this model",
    "text": "Questions we can ask with this model"
  },
  {
    "objectID": "slides/01_SLR.html#dependent-vs.-independent-variables",
    "href": "slides/01_SLR.html#dependent-vs.-independent-variables",
    "title": "Simple Linear Regression (SLR)",
    "section": "Dependent vs. Independent Variables",
    "text": "Dependent vs. Independent Variables"
  },
  {
    "objectID": "slides/01_SLR.html#association-vs.-prediction",
    "href": "slides/01_SLR.html#association-vs.-prediction",
    "title": "Simple Linear Regression (SLR)",
    "section": "Association vs. prediction",
    "text": "Association vs. prediction"
  },
  {
    "objectID": "slides/01_SLR.html#study-design",
    "href": "slides/01_SLR.html#study-design",
    "title": "Simple Linear Regression (SLR)",
    "section": "Study Design",
    "text": "Study Design"
  },
  {
    "objectID": "slides/data/NHANES_EDA.html",
    "href": "slides/data/NHANES_EDA.html",
    "title": "NHANES",
    "section": "",
    "text": "NHANES\n\nlibrary(NHANES)\nlibrary(skimr)\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(broom)\ndata(\"NHANES\")\n\n\nskim(NHANES)\n\n\nData summary\n\n\nName\nNHANES\n\n\nNumber of rows\n10000\n\n\nNumber of columns\n76\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n31\n\n\nnumeric\n45\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nSurveyYr\n0\n1.00\nFALSE\n2\n200: 5000, 201: 5000\n\n\nGender\n0\n1.00\nFALSE\n2\nfem: 5020, mal: 4980\n\n\nAgeDecade\n333\n0.97\nFALSE\n8\n40: 1398, 0-: 1391, 10: 1374, 20: 1356\n\n\nRace1\n0\n1.00\nFALSE\n5\nWhi: 6372, Bla: 1197, Mex: 1015, Oth: 806\n\n\nRace3\n5000\n0.50\nFALSE\n6\nWhi: 3135, Bla: 589, Mex: 480, His: 350\n\n\nEducation\n2779\n0.72\nFALSE\n5\nSom: 2267, Col: 2098, Hig: 1517, 9 -: 888\n\n\nMaritalStatus\n2769\n0.72\nFALSE\n6\nMar: 3945, Nev: 1380, Div: 707, Liv: 560\n\n\nHHIncome\n811\n0.92\nFALSE\n12\nmor: 2220, 750: 1084, 250: 958, 350: 863\n\n\nHomeOwn\n63\n0.99\nFALSE\n3\nOwn: 6425, Ren: 3287, Oth: 225\n\n\nWork\n2229\n0.78\nFALSE\n3\nWor: 4613, Not: 2847, Loo: 311\n\n\nBMICatUnder20yrs\n8726\n0.13\nFALSE\n4\nNor: 805, Obe: 221, Ove: 193, Und: 55\n\n\nBMI_WHO\n397\n0.96\nFALSE\n4\n18.: 2911, 30.: 2751, 25.: 2664, 12.: 1277\n\n\nDiabetes\n142\n0.99\nFALSE\n2\nNo: 9098, Yes: 760\n\n\nHealthGen\n2461\n0.75\nFALSE\n5\nGoo: 2956, Vgo: 2508, Fai: 1010, Exc: 878\n\n\nLittleInterest\n3333\n0.67\nFALSE\n3\nNon: 5103, Sev: 1130, Mos: 434\n\n\nDepressed\n3327\n0.67\nFALSE\n3\nNon: 5246, Sev: 1009, Mos: 418\n\n\nSleepTrouble\n2228\n0.78\nFALSE\n2\nNo: 5799, Yes: 1973\n\n\nPhysActive\n1674\n0.83\nFALSE\n2\nYes: 4649, No: 3677\n\n\nTVHrsDay\n5141\n0.49\nFALSE\n7\n2_h: 1275, 1_h: 884, 3_h: 836, 0_t: 638\n\n\nCompHrsDay\n5137\n0.49\nFALSE\n7\n0_t: 1409, 0_h: 1073, 1_h: 1030, 2_h: 589\n\n\nAlcohol12PlusYr\n3420\n0.66\nFALSE\n2\nYes: 5212, No: 1368\n\n\nSmokeNow\n6789\n0.32\nFALSE\n2\nNo: 1745, Yes: 1466\n\n\nSmoke100\n2765\n0.72\nFALSE\n2\nNo: 4024, Yes: 3211\n\n\nSmoke100n\n2765\n0.72\nFALSE\n2\nNon: 4024, Smo: 3211\n\n\nMarijuana\n5059\n0.49\nFALSE\n2\nYes: 2892, No: 2049\n\n\nRegularMarij\n5059\n0.49\nFALSE\n2\nNo: 3575, Yes: 1366\n\n\nHardDrugs\n4235\n0.58\nFALSE\n2\nNo: 4700, Yes: 1065\n\n\nSexEver\n4233\n0.58\nFALSE\n2\nYes: 5544, No: 223\n\n\nSameSex\n4232\n0.58\nFALSE\n2\nNo: 5353, Yes: 415\n\n\nSexOrientation\n5158\n0.48\nFALSE\n3\nHet: 4638, Bis: 119, Hom: 85\n\n\nPregnantNow\n8304\n0.17\nFALSE\n3\nNo: 1573, Yes: 72, Unk: 51\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nID\n0\n1.00\n61944.64\n5871.17\n51624.00\n56904.50\n62159.50\n67039.00\n71915.00\n▇▇▇▇▇\n\n\nAge\n0\n1.00\n36.74\n22.40\n0.00\n17.00\n36.00\n54.00\n80.00\n▇▇▇▆▅\n\n\nAgeMonths\n5038\n0.50\n420.12\n259.04\n0.00\n199.00\n418.00\n624.00\n959.00\n▇▇▇▆▃\n\n\nHHIncomeMid\n811\n0.92\n57206.17\n33020.28\n2500.00\n30000.00\n50000.00\n87500.00\n100000.00\n▃▆▃▁▇\n\n\nPoverty\n726\n0.93\n2.80\n1.68\n0.00\n1.24\n2.70\n4.71\n5.00\n▅▅▃▃▇\n\n\nHomeRooms\n69\n0.99\n6.25\n2.28\n1.00\n5.00\n6.00\n8.00\n13.00\n▂▆▇▂▁\n\n\nWeight\n78\n0.99\n70.98\n29.13\n2.80\n56.10\n72.70\n88.90\n230.70\n▂▇▂▁▁\n\n\nLength\n9457\n0.05\n85.02\n13.71\n47.10\n75.70\n87.00\n96.10\n112.20\n▁▃▆▇▃\n\n\nHeadCirc\n9912\n0.01\n41.18\n2.31\n34.20\n39.58\n41.45\n42.92\n45.40\n▁▂▇▇▅\n\n\nHeight\n353\n0.96\n161.88\n20.19\n83.60\n156.80\n166.00\n174.50\n200.40\n▁▁▁▇▂\n\n\nBMI\n366\n0.96\n26.66\n7.38\n12.88\n21.58\n25.98\n30.89\n81.25\n▇▆▁▁▁\n\n\nPulse\n1437\n0.86\n73.56\n12.16\n40.00\n64.00\n72.00\n82.00\n136.00\n▂▇▃▁▁\n\n\nBPSysAve\n1449\n0.86\n118.15\n17.25\n76.00\n106.00\n116.00\n127.00\n226.00\n▃▇▂▁▁\n\n\nBPDiaAve\n1449\n0.86\n67.48\n14.35\n0.00\n61.00\n69.00\n76.00\n116.00\n▁▁▇▇▁\n\n\nBPSys1\n1763\n0.82\n119.09\n17.50\n72.00\n106.00\n116.00\n128.00\n232.00\n▂▇▂▁▁\n\n\nBPDia1\n1763\n0.82\n68.28\n13.78\n0.00\n62.00\n70.00\n76.00\n118.00\n▁▁▇▆▁\n\n\nBPSys2\n1647\n0.84\n118.48\n17.49\n76.00\n106.00\n116.00\n128.00\n226.00\n▃▇▂▁▁\n\n\nBPDia2\n1647\n0.84\n67.66\n14.42\n0.00\n60.00\n68.00\n76.00\n118.00\n▁▁▇▆▁\n\n\nBPSys3\n1635\n0.84\n117.93\n17.18\n76.00\n106.00\n116.00\n126.00\n226.00\n▃▇▂▁▁\n\n\nBPDia3\n1635\n0.84\n67.30\n14.96\n0.00\n60.00\n68.00\n76.00\n116.00\n▁▁▇▇▁\n\n\nTestosterone\n5874\n0.41\n197.90\n226.50\n0.25\n17.70\n43.82\n362.41\n1795.60\n▇▂▁▁▁\n\n\nDirectChol\n1526\n0.85\n1.36\n0.40\n0.39\n1.09\n1.29\n1.58\n4.03\n▅▇▂▁▁\n\n\nTotChol\n1526\n0.85\n4.88\n1.08\n1.53\n4.11\n4.78\n5.53\n13.65\n▂▇▁▁▁\n\n\nUrineVol1\n987\n0.90\n118.52\n90.34\n0.00\n50.00\n94.00\n164.00\n510.00\n▇▅▂▁▁\n\n\nUrineFlow1\n1603\n0.84\n0.98\n0.95\n0.00\n0.40\n0.70\n1.22\n17.17\n▇▁▁▁▁\n\n\nUrineVol2\n8522\n0.15\n119.68\n90.16\n0.00\n52.00\n95.00\n171.75\n409.00\n▇▆▃▂▁\n\n\nUrineFlow2\n8524\n0.15\n1.15\n1.07\n0.00\n0.48\n0.76\n1.51\n13.69\n▇▁▁▁▁\n\n\nDiabetesAge\n9371\n0.06\n48.42\n15.68\n1.00\n40.00\n50.00\n58.00\n80.00\n▁▂▆▇▂\n\n\nDaysPhysHlthBad\n2468\n0.75\n3.33\n7.40\n0.00\n0.00\n0.00\n3.00\n30.00\n▇▁▁▁▁\n\n\nDaysMentHlthBad\n2466\n0.75\n4.13\n7.83\n0.00\n0.00\n0.00\n4.00\n30.00\n▇▁▁▁▁\n\n\nnPregnancies\n7396\n0.26\n3.03\n1.80\n1.00\n2.00\n3.00\n4.00\n32.00\n▇▁▁▁▁\n\n\nnBabies\n7584\n0.24\n2.46\n1.32\n0.00\n2.00\n2.00\n3.00\n12.00\n▇▅▁▁▁\n\n\nAge1stBaby\n8116\n0.19\n22.65\n4.77\n14.00\n19.00\n22.00\n26.00\n39.00\n▆▇▅▂▁\n\n\nSleepHrsNight\n2245\n0.78\n6.93\n1.35\n2.00\n6.00\n7.00\n8.00\n12.00\n▁▅▇▁▁\n\n\nPhysActiveDays\n5337\n0.47\n3.74\n1.84\n1.00\n2.00\n3.00\n5.00\n7.00\n▇▇▃▅▅\n\n\nTVHrsDayChild\n9347\n0.07\n1.94\n1.43\n0.00\n1.00\n2.00\n3.00\n6.00\n▇▆▂▂▂\n\n\nCompHrsDayChild\n9347\n0.07\n2.20\n2.52\n0.00\n0.00\n1.00\n6.00\n6.00\n▇▁▁▁▃\n\n\nAlcoholDay\n5086\n0.49\n2.91\n3.18\n1.00\n1.00\n2.00\n3.00\n82.00\n▇▁▁▁▁\n\n\nAlcoholYear\n4078\n0.59\n75.10\n103.03\n0.00\n3.00\n24.00\n104.00\n364.00\n▇▁▁▁▁\n\n\nSmokeAge\n6920\n0.31\n17.83\n5.33\n6.00\n15.00\n17.00\n19.00\n72.00\n▇▂▁▁▁\n\n\nAgeFirstMarij\n7109\n0.29\n17.02\n3.90\n1.00\n15.00\n16.00\n19.00\n48.00\n▁▇▂▁▁\n\n\nAgeRegMarij\n8634\n0.14\n17.69\n4.81\n5.00\n15.00\n17.00\n19.00\n52.00\n▂▇▁▁▁\n\n\nSexAge\n4460\n0.55\n17.43\n3.72\n9.00\n15.00\n17.00\n19.00\n50.00\n▇▅▁▁▁\n\n\nSexNumPartnLife\n4275\n0.57\n15.09\n57.85\n0.00\n2.00\n5.00\n12.00\n2000.00\n▇▁▁▁▁\n\n\nSexNumPartYear\n5072\n0.49\n1.34\n2.78\n0.00\n1.00\n1.00\n1.00\n69.00\n▇▁▁▁▁\n\n\n\n\n# 16 Depressed             3327         0.667 FALSE          3 \"Non: 5246, Sev: 1009, Mos: 418\"            \n# 17 SleepTrouble          2228         0.777 FALSE          2 \"No: 5799, Yes: 1973\"                       \n# 18 PhysActive            1674         0.833 FALSE          2 \"Yes: 4649, No: 3677\"          \n\n\nNHANES18 &lt;- NHANES %&gt;% dplyr::filter(Age &gt;= 18)\nNHANES18 %&gt;% tabyl(Depressed, PhysActive)\n\n Depressed   No  Yes\n      None 2297 2949\n   Several  538  471\n      Most  275  143\n      &lt;NA&gt;  423  385\n\nNHANES18 %&gt;% drop_na(Depressed) %&gt;% tabyl(Depressed, PhysActive)\n\n Depressed   No  Yes\n      None 2297 2949\n   Several  538  471\n      Most  275  143\n\nNHANES18Dep &lt;- NHANES18 %&gt;% drop_na(Depressed)\nNHANES18Dep %&gt;% \n  tabyl(Depressed, PhysActive) %&gt;% \n  adorn_totals()\n\n Depressed   No  Yes\n      None 2297 2949\n   Several  538  471\n      Most  275  143\n     Total 3110 3563\n\nchisq_Dep_Phys&lt;- chisq.test(NHANES18Dep$Depressed, NHANES18Dep$PhysActive)\ntidy(chisq_Dep_Phys)\n\n# A tibble: 1 × 4\n  statistic  p.value parameter method                    \n      &lt;dbl&gt;    &lt;dbl&gt;     &lt;int&gt; &lt;chr&gt;                     \n1      96.9 9.26e-22         2 Pearson's Chi-squared test\n\nchisq_Dep_Phys$expected\n\n                     NHANES18Dep$PhysActive\nNHANES18Dep$Depressed        No       Yes\n              None    2444.9363 2801.0637\n              Several  470.2518  538.7482\n              Most     194.8119  223.1881\n\nchisq_Dep_Phys$observed\n\n                     NHANES18Dep$PhysActive\nNHANES18Dep$Depressed   No  Yes\n              None    2297 2949\n              Several  538  471\n              Most     275  143\n\nlibrary(moderndive)\nset.seed(5348)\n# 5347\nNHANES18Dep200 &lt;- NHANES18Dep %&gt;%\n  rep_sample_n(size = 200, reps = 1, replace = FALSE)\n\nNHANES18Dep200 %&gt;% \n  tabyl(Depressed, PhysActive) %&gt;% \n  adorn_totals()\n\n Depressed No Yes\n      None 63  79\n   Several 19  18\n      Most 10  11\n     Total 92 108\n\nchisq_Dep_Phys200&lt;- chisq.test(NHANES18Dep200$Depressed, NHANES18Dep200$PhysActive)\ntidy(chisq_Dep_Phys200)\n\n# A tibble: 1 × 4\n  statistic p.value parameter method                    \n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;int&gt; &lt;chr&gt;                     \n1     0.601   0.740         2 Pearson's Chi-squared test\n\nchisq_Dep_Phys200$expected\n\n                        NHANES18Dep200$PhysActive\nNHANES18Dep200$Depressed    No   Yes\n                 None    65.32 76.68\n                 Several 17.02 19.98\n                 Most     9.66 11.34\n\nchisq_Dep_Phys200$observed\n\n                        NHANES18Dep200$PhysActive\nNHANES18Dep200$Depressed No Yes\n                 None    63  79\n                 Several 19  18\n                 Most    10  11\n\n#------------\nset.seed(5349)\nNHANES18Dep400 &lt;- NHANES18Dep %&gt;%\n  rep_sample_n(size = 400, reps = 1, replace = FALSE)\n\nNHANES18Dep400 %&gt;% \n  tabyl(PhysActive, Depressed) %&gt;% \n  adorn_totals(where = c(\"row\", \"col\")) %&gt;% \n  adorn_title \n\n            Depressed                   \n PhysActive      None Several Most Total\n         No       115      32   27   174\n        Yes       199      26    1   226\n      Total       314      58   28   400\n\nchisq_Dep_Phys400&lt;- chisq.test(NHANES18Dep400$Depressed, NHANES18Dep400$PhysActive)\ntidy(chisq_Dep_Phys400)\n\n# A tibble: 1 × 4\n  statistic       p.value parameter method                    \n      &lt;dbl&gt;         &lt;dbl&gt;     &lt;int&gt; &lt;chr&gt;                     \n1      41.2 0.00000000115         2 Pearson's Chi-squared test\n\nchisq_Dep_Phys400$observed\n\n                        NHANES18Dep400$PhysActive\nNHANES18Dep400$Depressed  No Yes\n                 None    115 199\n                 Several  32  26\n                 Most     27   1\n\nchisq_Dep_Phys400$expected\n\n                        NHANES18Dep400$PhysActive\nNHANES18Dep400$Depressed     No    Yes\n                 None    136.59 177.41\n                 Several  25.23  32.77\n                 Most     12.18  15.82\n\nset.seed(5349)\nNHANES18Dep_PAy100 &lt;- NHANES18Dep %&gt;% filter(PhysActive == \"Yes\") %&gt;% \n  rep_sample_n(size = 100, reps = 1, replace = FALSE)\nNHANES18Dep_PAy100 %&gt;% tabyl(Depressed)\n\n Depressed  n percent\n      None 85    0.85\n   Several 12    0.12\n      Most  3    0.03\n\nNHANES18Dep_PAn100 &lt;- NHANES18Dep %&gt;% filter(PhysActive == \"No\") %&gt;% \n  rep_sample_n(size = 100, reps = 1, replace = FALSE)\nNHANES18Dep_PAn100 %&gt;% tabyl(Depressed)\n\n Depressed  n percent\n      None 78    0.78\n   Several 17    0.17\n      Most  5    0.05\n\n(DepPA200_table &lt;- matrix(c(83, 12, 5, 78, 16, 6), nrow = 2, ncol = 3, byrow = T))\n\n     [,1] [,2] [,3]\n[1,]   83   12    5\n[2,]   78   16    6\n\ndimnames(DepPA200_table) &lt;- list(\"PA\" = c(\"Yes\", \"No\"),   # row names\n                              \"Depression\" = c(\"None\", \"Several\", \"Most\"))  # column names\nDepPA200_table\n\n     Depression\nPA    None Several Most\n  Yes   83      12    5\n  No    78      16    6\n\nchisq.test(DepPA200_table) \n\n\n    Pearson's Chi-squared test\n\ndata:  DepPA200_table\nX-squared = 0.81762, df = 2, p-value = 0.6644\n\nchisq.test(DepPA200_table)$expected\n\n     Depression\nPA    None Several Most\n  Yes 80.5      14  5.5\n  No  80.5      14  5.5\n\nset.seed(5349)\nNHANES18Dep_PAy50 &lt;- NHANES18Dep %&gt;% filter(PhysActive == \"Yes\") %&gt;% \n  rep_sample_n(size = 50, reps = 1, replace = FALSE)\nNHANES18Dep_PAy50 %&gt;% tabyl(Depressed)\n\n Depressed  n percent\n      None 43    0.86\n   Several  6    0.12\n      Most  1    0.02\n\nNHANES18Dep_PAn50 &lt;- NHANES18Dep %&gt;% filter(PhysActive == \"No\") %&gt;% \n  rep_sample_n(size = 50, reps = 1, replace = FALSE)\nNHANES18Dep_PAn50 %&gt;% tabyl(Depressed)\n\n Depressed  n percent\n      None 30    0.60\n   Several 14    0.28\n      Most  6    0.12"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project Central",
    "section": "",
    "text": "{css, echo=FALSE} .title{   font-size: 40px;   color: #213c96;   background-color: #fff;   padding: 0px; }"
  },
  {
    "objectID": "project.html#labs",
    "href": "project.html#labs",
    "title": "Project Central",
    "section": "Labs",
    "text": "Labs\n\n\n\nLab\nDue Date\nTopics\n\n\n\n\nLab 1\n1/18\nExploring the question\n\n\nLab 2\n2/8\nExploring the data\n\n\nLab 3\n2/29\nFitting and interpreting the model\n\n\nLab 4\n3/14\nBuilding a model"
  },
  {
    "objectID": "project.html#report",
    "href": "project.html#report",
    "title": "Project Central",
    "section": "Report",
    "text": "Report\nReport Instructions\nDue 3/21/2024"
  },
  {
    "objectID": "labs/Lab_01.html",
    "href": "labs/Lab_01.html",
    "title": "Lab 1",
    "section": "",
    "text": "Please turn in your .html file on Sakai. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\n\n\nThis lab will serve as an introduction to our quarter long project.\nThere will be no analysis in this lab. Instead, we are building our knowledge around the research question.\n\n\n\nEach lab will have a slightly different grading rubric. Since this lab does not include coding nor analysis, this portion of the rubric is excluded.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\n\n\nAnswers\nAnswers demonstrate completion and understanding of the needed activity*. Answers are thoughtful and can be easily integrated into the final report.\nAnswers demonstrate completion and understanding of the needed activity*. Answers are thoughtful, but lack the clarity needed to easily integrate into the final report.\nAnswers demonstrate completion and minimal understanding of the needed activity*. Answers are fairly thoughtful, but lack connection to the research.\nAnswers demonstrate completion of needed activities*, although evidently rushed through. Answers seem rushed and with minimal thought.\nIt is evident that the needed activities* were not completed. Answers seem rushed and without thought.\n\n\nFormatting\nLab submitted on Sakai with .html file. Answers are written in complete sentences with no major grammatical nor spelling errors. With little editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with grammatical or spelling errors. With editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with major grammatical or spelling errors. With major editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are bulletted or do not use complete sentences.\nLab not submitted on Sakai with .html file.\n\n\n\n*Example of needed activity: if asked to read something, answers reflect the gained knowledge from the reading."
  },
  {
    "objectID": "labs/Lab_01.html#directions",
    "href": "labs/Lab_01.html#directions",
    "title": "Lab 1",
    "section": "",
    "text": "Please turn in your .html file on Sakai. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\n\n\nThis lab will serve as an introduction to our quarter long project.\nThere will be no analysis in this lab. Instead, we are building our knowledge around the research question.\n\n\n\nEach lab will have a slightly different grading rubric. Since this lab does not include coding nor analysis, this portion of the rubric is excluded.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\n\n\nAnswers\nAnswers demonstrate completion and understanding of the needed activity*. Answers are thoughtful and can be easily integrated into the final report.\nAnswers demonstrate completion and understanding of the needed activity*. Answers are thoughtful, but lack the clarity needed to easily integrate into the final report.\nAnswers demonstrate completion and minimal understanding of the needed activity*. Answers are fairly thoughtful, but lack connection to the research.\nAnswers demonstrate completion of needed activities*, although evidently rushed through. Answers seem rushed and with minimal thought.\nIt is evident that the needed activities* were not completed. Answers seem rushed and without thought.\n\n\nFormatting\nLab submitted on Sakai with .html file. Answers are written in complete sentences with no major grammatical nor spelling errors. With little editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with grammatical or spelling errors. With editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with major grammatical or spelling errors. With major editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are bulletted or do not use complete sentences.\nLab not submitted on Sakai with .html file.\n\n\n\n*Example of needed activity: if asked to read something, answers reflect the gained knowledge from the reading."
  },
  {
    "objectID": "homework/HW1.html#section",
    "href": "homework/HW1.html#section",
    "title": "Homework 1",
    "section": "5.1",
    "text": "5.1\n\nLoad the dataset using the readxl package.\n\nThis readxl package was installed as a part of the tidyverse, however it does not get loaded when you load the tidyverse package and thus you need to do that separately.\nUse the command read_excel(), as shown below\n\n\n\nlibrary(readxl)\n# you might need to update the location of the data file\n# you can choose whatever name you like for the tibble when loading it into R's workspace \nch05q01 &lt;- read_excel(\"data/CH05Q01.xls\")\n\n\n(a)\nAdditional instructions: Create the scatterplots in R using ggplot, in addition to describing the relationships in the book’s instructions.\n\n\n(b)\nNote: This is asking for the regression models BEFORE you find the values of the coefficients.\n\n\n(c)\nNote: Now get the regression coefficients using R and plug them into the regression models from (b). You can get the coefficients from the R output - you don’t have to use the formulas.\n\n\n(d)\nNote: Instead of sketching the lines, create them using ggplot.\n\n\n(e)\nNote: You can get the CI’s from the R output - you don’t have to use the formulas.\n\n\n(f)\nNote: Instead of sketching, make the figure using ggplot. Get the asked for CI using R instead of estimating it based on the sketch."
  },
  {
    "objectID": "homework/HW1.html#section-1",
    "href": "homework/HW1.html#section-1",
    "title": "Homework 1",
    "section": "3.5",
    "text": "3.5"
  },
  {
    "objectID": "homework/HW1.html#section-2",
    "href": "homework/HW1.html#section-2",
    "title": "Homework 1",
    "section": "3.10",
    "text": "3.10"
  },
  {
    "objectID": "homework/HW1.html#section-3",
    "href": "homework/HW1.html#section-3",
    "title": "Homework 1",
    "section": "3.11",
    "text": "3.11"
  },
  {
    "objectID": "homework/HW1.html#section-4",
    "href": "homework/HW1.html#section-4",
    "title": "Homework 1",
    "section": "3.13",
    "text": "3.13"
  },
  {
    "objectID": "homework/HW1.html#section-5",
    "href": "homework/HW1.html#section-5",
    "title": "Homework 1",
    "section": "3.14",
    "text": "3.14"
  },
  {
    "objectID": "homework/HW1.html#section-6",
    "href": "homework/HW1.html#section-6",
    "title": "Homework 1",
    "section": "3.15",
    "text": "3.15\nAdditional instructions: Do the problem with both the p-value and critical value approaches."
  },
  {
    "objectID": "homework/HW1.html#section-7",
    "href": "homework/HW1.html#section-7",
    "title": "Homework 1",
    "section": "3.16",
    "text": "3.16\nAdditional instructions: You do not need to use the formula to do this problem. You can run it in R using the given data.\n\ngrp1 &lt;- c(132, 145, 124, 122, 165, 144, 151)\ngrp2 &lt;- c(141, 139, 172, 131, 150, 125)"
  },
  {
    "objectID": "homework/HW1.html#section-8",
    "href": "homework/HW1.html#section-8",
    "title": "Homework 1",
    "section": "3.17",
    "text": "3.17"
  },
  {
    "objectID": "homework/HW1.html#section-9",
    "href": "homework/HW1.html#section-9",
    "title": "Homework 1",
    "section": "3.20",
    "text": "3.20"
  },
  {
    "objectID": "homework/HW1.html#section-10",
    "href": "homework/HW1.html#section-10",
    "title": "Homework 1",
    "section": "3.21",
    "text": "3.21"
  },
  {
    "objectID": "homework/HW1.html#section-11",
    "href": "homework/HW1.html#section-11",
    "title": "Homework 1",
    "section": "3.22",
    "text": "3.22"
  },
  {
    "objectID": "homework/HW1.html#section-12",
    "href": "homework/HW1.html#section-12",
    "title": "Homework 1",
    "section": "3.23",
    "text": "3.23"
  },
  {
    "objectID": "homework/HW1.html#section-13",
    "href": "homework/HW1.html#section-13",
    "title": "Homework 1",
    "section": "3.25",
    "text": "3.25"
  },
  {
    "objectID": "homework/HW1.html#section-14",
    "href": "homework/HW1.html#section-14",
    "title": "Homework 1",
    "section": "5.1",
    "text": "5.1\n\nLoad the dataset using the readxl package.\n\nThis readxl package was installed as a part of the tidyverse, however it does not get loaded when you load the tidyverse package and thus you need to do that separately.\nUse the command read_excel(), as shown below\n\n\n\nlibrary(readxl)\n# you might need to update the location of the data file\n# you can choose whatever name you like for the tibble when loading it into R's workspace \nch05q01 &lt;- read_excel(\"data/CH05Q01.xls\")\n\n\n(a)\nAdditional instructions: Create the scatterplots in R using ggplot, in addition to describing the relationships in the book’s instructions.\n\n\n(b)\nNote: This is asking for the regression models BEFORE you find the values of the coefficients.\n\n\n(c)\nNote: Now get the regression coefficients using R and plug them into the regression models from (b). You can get the coefficients from the R output - you don’t have to use the formulas.\n\n\n(d)\nNote: Instead of sketching the lines, create them using ggplot.\n\n\n(e)\nNote: You can get the CI’s from the R output - you don’t have to use the formulas.\n\n\n(f)\nNote: Instead of sketching, make the figure using ggplot. Get the asked for CI using R instead of estimating it based on the sketch."
  },
  {
    "objectID": "homework/HW1.html#a---g",
    "href": "homework/HW1.html#a---g",
    "title": "Homework 1",
    "section": "5.4 (a - g)",
    "text": "5.4 (a - g)\n\nch05q04 &lt;- read_excel(\"./data/CH05Q04.xls\")\n\n\n(a)\nAdditional instructions: Run the model to get the regression coefficients and create a scatterplot with the regression line using ggplot.\n\n\n(b)\n\n\n(c)\nAdditional instructions: Calculate the CI using the formula. The problem gives the values for \\(S_{Y|X}\\) and \\(S_X\\). Verify these values using R.\n\n\n(d)\n\n\n(e)\nAdditional instructions: Create a new dataset without the outlier. Verify the regression coefficients using R and create a new scatterplot with regression line for the dataset without the outlier. Then “decide whether this outlier has any effect on your estimate of the IQ–DI relationship.”\n\n\n(f)\nAdditional instructions: Calculate the test statistic using the formula and find the p-value using the test statistic value. The problem gives the values for \\(S_{Y|X}\\) and \\(S_X\\). Verify these values using R. Check your work by comparing your answers to the linear model output. \n\n\n(g)"
  },
  {
    "objectID": "homework/HW1.html#questions",
    "href": "homework/HW1.html#questions",
    "title": "Homework 1",
    "section": "Questions",
    "text": "Questions\nThe following questions were adapted from this textbook.\n\nDownload the datasets from Sakai - see Week 2"
  },
  {
    "objectID": "homework/HW2.html#section",
    "href": "homework/HW2.html#section",
    "title": "Homework 2",
    "section": "(1)",
    "text": "(1)\nCreate a scatterplot of the dependent and independent variables, and in words describe the their relationship. Is it reasonable to use a linear regression to model the relationship?"
  },
  {
    "objectID": "homework/HW2.html#section-1",
    "href": "homework/HW2.html#section-1",
    "title": "Homework 2",
    "section": "(2)",
    "text": "(2)\nFind the correlation coefficient between the two variables. Is the value consistent with your description of the relationship in the previous question? Why or why not?"
  },
  {
    "objectID": "homework/HW2.html#section-2",
    "href": "homework/HW2.html#section-2",
    "title": "Homework 2",
    "section": "(3)",
    "text": "(3)\nTest whether the two variables are significantly correlated. Do this using the formula and then check your work with R’s test for correlations. Make sure to include the hypotheses and a conclusion."
  },
  {
    "objectID": "homework/HW2.html#section-3",
    "href": "homework/HW2.html#section-3",
    "title": "Homework 2",
    "section": "(4)",
    "text": "(4)\nCalculate the confidence interval for \\(\\rho\\) using the formula and verify that it matches the confidence interval in R’s test output. Include an interpretation of the confidence interval and also explain why the confidence interval is consistent with the p-value."
  },
  {
    "objectID": "homework/HW2.html#section-4",
    "href": "homework/HW2.html#section-4",
    "title": "Homework 2",
    "section": "(5)",
    "text": "(5)\nCalculate the coefficient of determination using the ANOVA table output, and confirm that it matches the value in the R output (what R output shows this and what is it labeled as?)."
  },
  {
    "objectID": "homework/HW2.html#section-5",
    "href": "homework/HW2.html#section-5",
    "title": "Homework 2",
    "section": "(6)",
    "text": "(6)\nWhat is another way to calculate the coefficient of determination? Do the calculation and verify that you have the same answer."
  },
  {
    "objectID": "homework/HW2.html#section-6",
    "href": "homework/HW2.html#section-6",
    "title": "Homework 2",
    "section": "(7)",
    "text": "(7)\nGive an interpretation of the coefficient of determination in the context of the study.\nNote: the question numbers below do not refer to questions from the textbook. Complete the problems below instead of the ones in the book."
  },
  {
    "objectID": "homework/HW2.html#section-7",
    "href": "homework/HW2.html#section-7",
    "title": "Homework 2",
    "section": "(1)",
    "text": "(1)\nCreate a scatterplot of the dependent and independent variables with both the best-fit line and a smoothed curve through the points. Describe the relationship between the dependent and independent variables, and also comment on whether you think it is reasonable to use a linear regression to model the relationship. Are their any outliers in the data? If so, describe the points and why you think they are outliers."
  },
  {
    "objectID": "homework/HW2.html#section-8",
    "href": "homework/HW2.html#section-8",
    "title": "Homework 2",
    "section": "(2)",
    "text": "(2)\nWrite out the regression equation for the simple linear regression model."
  },
  {
    "objectID": "homework/HW2.html#section-9",
    "href": "homework/HW2.html#section-9",
    "title": "Homework 2",
    "section": "(3)",
    "text": "(3)\nAssess the normality of the model’s (ordinary) residuals by creating a histogram, density plot, and boxplot of the residuals to visually inspect the distribution of the residuals, and describe any deviations from normality."
  },
  {
    "objectID": "homework/HW2.html#section-10",
    "href": "homework/HW2.html#section-10",
    "title": "Homework 2",
    "section": "(4)",
    "text": "(4)\nAssess the normality of the model’s (ordinary) residuals by creating a normal probability plot of the residuals. Compare the normality probability plot to 8 such plots simulated from normal data, and discuss why or why not the residuals could have come from a normal distribution."
  },
  {
    "objectID": "homework/HW2.html#section-11",
    "href": "homework/HW2.html#section-11",
    "title": "Homework 2",
    "section": "(5)",
    "text": "(5)\nTest the normality of the model’s (ordinary) residuals and comment on whether the test’s conclusion is consistent with your visual inspection or not. Make sure to include the hypotheses and a conclusion to the test based on the p-value."
  },
  {
    "objectID": "homework/HW2.html#section-12",
    "href": "homework/HW2.html#section-12",
    "title": "Homework 2",
    "section": "(6)",
    "text": "(6)\nCreate a residual plot using ggplot and the standardized residuals and discuss what this shows us in terms of whether the model assumptions have been met or not."
  },
  {
    "objectID": "homework/HW2.html#section-13",
    "href": "homework/HW2.html#section-13",
    "title": "Homework 2",
    "section": "(7)",
    "text": "(7)\nDetermine whether there are any observations with high leverage. If there are observations with high leverage, identify their coordinates and describe how they relate to the other observations. Why would these points have high leverage compared to the other observations? Do you think removing the points would change the linear model much? (you do not need to remove the points and rerun the model, just comment on whether you think they are influential)"
  },
  {
    "objectID": "homework/HW2.html#section-14",
    "href": "homework/HW2.html#section-14",
    "title": "Homework 2",
    "section": "(8)",
    "text": "(8)\nDetermine whether there are any observations with high Cook’s distance. If there are observations with high Cook’s distance, identify their coordinates and describe how they relate to the other observations. Why would these points have high Cook’s distance compared to the other observations? Do you think removing the points would change the linear model much? (you do not need to remove the points and rerun the model, just comment on whether you think they are influential)"
  },
  {
    "objectID": "homework/HW2.html#section-15",
    "href": "homework/HW2.html#section-15",
    "title": "Homework 2",
    "section": "(9)",
    "text": "(9)\nCreate histograms and density plots of the dependent and independent variables and describe their distribution shapes."
  },
  {
    "objectID": "homework/HW2.html#section-16",
    "href": "homework/HW2.html#section-16",
    "title": "Homework 2",
    "section": "(10)",
    "text": "(10)\nUse Tukey’s ladder of transformations to choose two possible transformations for the dependent variable. Explain why you chose them. Note: questions below will ask about model fit with the transformations. For now, just explain why you chose the ones that you did."
  },
  {
    "objectID": "homework/HW2.html#section-17",
    "href": "homework/HW2.html#section-17",
    "title": "Homework 2",
    "section": "(11)",
    "text": "(11)\nUse Tukey’s ladder of transformations to choose two possible transformations for the independent variable. Explain why you chose them. Note: questions below will ask about model fit with the transformations. For now, just explain why you chose the ones that you did."
  },
  {
    "objectID": "homework/HW2.html#section-18",
    "href": "homework/HW2.html#section-18",
    "title": "Homework 2",
    "section": "(12)",
    "text": "(12)\nAdd the 4 transformations you chose above (2 for the dependent variable and 2 for the independent variable) to the dataset."
  },
  {
    "objectID": "homework/HW2.html#section-19",
    "href": "homework/HW2.html#section-19",
    "title": "Homework 2",
    "section": "(13)",
    "text": "(13)\nCreate scatterplots using the transformed variables and discuss whether any of the transformations improve the model fit and why (or why not). Include plots with just the x or y variables transformed, and at least one plot with both the x and y variables transformed."
  },
  {
    "objectID": "homework/HW2.html#section-20",
    "href": "homework/HW2.html#section-20",
    "title": "Homework 2",
    "section": "(14)",
    "text": "(14)\nRun the various transformed models and save the output to use for the diagnostic questions below."
  },
  {
    "objectID": "homework/HW2.html#section-21",
    "href": "homework/HW2.html#section-21",
    "title": "Homework 2",
    "section": "(15)",
    "text": "(15)\nCompare the normal QQ plots of the different models and discuss whether any of the transformations improve the model fit and why (or why not)."
  },
  {
    "objectID": "homework/HW2.html#section-22",
    "href": "homework/HW2.html#section-22",
    "title": "Homework 2",
    "section": "(16)",
    "text": "(16)\nCompare the residual plots of the different models and discuss whether any of the transformations improve the model fit and why (or why not)."
  },
  {
    "objectID": "homework/HW2.html#section-23",
    "href": "homework/HW2.html#section-23",
    "title": "Homework 2",
    "section": "(17)",
    "text": "(17)\nCompare the leverage & Cook’s distance of the different models and discuss whether any of the transformations improve the model fit and why (or why not)."
  },
  {
    "objectID": "homework/HW2.html#section-24",
    "href": "homework/HW2.html#section-24",
    "title": "Homework 2",
    "section": "(18)",
    "text": "(18)\nCompare the \\(R^2\\) values and F-test p-values of the different models and discuss whether any of the transformations improve the model fit and why (or why not)."
  },
  {
    "objectID": "homework/HW2.html#section-25",
    "href": "homework/HW2.html#section-25",
    "title": "Homework 2",
    "section": "(19)",
    "text": "(19)\nWhich of the models would you recommend using for analyses? Discuss why you chose the model and why you did not choose the other models."
  },
  {
    "objectID": "homework/HW2.html#section-26",
    "href": "homework/HW2.html#section-26",
    "title": "Homework 2",
    "section": "(14)",
    "text": "(14)\nRun the various transformed models and save the output to use for the diagnostic questions below."
  },
  {
    "objectID": "homework/HW2.html#section-27",
    "href": "homework/HW2.html#section-27",
    "title": "Homework 2",
    "section": "(15)",
    "text": "(15)\nCompare the normal QQ plots of the different models and discuss whether any of the transformations improve the model fit and why (or why not)."
  },
  {
    "objectID": "homework/HW2.html#section-28",
    "href": "homework/HW2.html#section-28",
    "title": "Homework 2",
    "section": "(16)",
    "text": "(16)\nCompare the residual plots of the different models and discuss whether any of the transformations improve the model fit and why (or why not)."
  },
  {
    "objectID": "homework/HW2.html#section-29",
    "href": "homework/HW2.html#section-29",
    "title": "Homework 2",
    "section": "(17)",
    "text": "(17)\nCompare the leverage & Cook’s distance of the different models and discuss whether any of the transformations improve the model fit and why (or why not)."
  },
  {
    "objectID": "homework/HW2.html#section-30",
    "href": "homework/HW2.html#section-30",
    "title": "Homework 2",
    "section": "(18)",
    "text": "(18)\nCompare the \\(R^2\\) values and F-test p-values of the different models and discuss whether any of the transformations improve the model fit and why (or why not)."
  },
  {
    "objectID": "homework/HW2.html#section-31",
    "href": "homework/HW2.html#section-31",
    "title": "Homework 2",
    "section": "(19)",
    "text": "(19)\nWhich of the models would you recommend using for analyses? Discuss why you chose the model and why you did not choose the other models."
  },
  {
    "objectID": "labs/Project_report_instructions.html",
    "href": "labs/Project_report_instructions.html",
    "title": "Project Report Instructions",
    "section": "",
    "text": "Important\n\n\n\nTHIS PAGE IS UNDER CONSTRUCTION!!"
  },
  {
    "objectID": "labs/Project_report_instructions.html#sections",
    "href": "labs/Project_report_instructions.html#sections",
    "title": "Project Report Instructions",
    "section": "Sections",
    "text": "Sections\n\nIntroduction\n\nLength: 1-2 paragraphs\nIntroduce the research question and why it is important to study\nThis section is non-technical. By reading just the introduction and conclusion, someone without a technical background should have an idea of what they study was about, why it is important, and what the main results are\n\n\n\nStatistical Methods\n\nLength: at least 3 paragraphs\nDescribe the analyses that were conducted and methods used to select variables and check diagnostics.\nThis includes a description of analyses for Table 1 and what statistics were used to summarize the variables\n\n\n\nResults\n\nLength: at least 3 paragraphs\nInclude a brief description of the sample’s characteristics\nInterpret the model coefficients in the context of the research question.\nTables & figures\n\nTable 1 summarizing participant characteristics both overall and stratified by your primary independent variable\nTable 2 with regression results\n\nCan also be a forest plot\n\n1-3 figures that you think are helpful in understanding the results\n\n\n\n\nDiscussion\n\nLength: 2-3 paragraphs\nDiscuss the results. See the paper cited above as an example.\nInclude a paragraph on the limitations of the results\n\n\n\nConclusion\n\nLength: 1 paragraph\nDescribe the main conclusions to a non-technical audience\n\n\n\nReferences\n\nIf you cited any papers or websites, include their references here.\nNote: it is not required to do a literature search"
  },
  {
    "objectID": "homework/HW5.html#a",
    "href": "homework/HW5.html#a",
    "title": "Homework 5",
    "section": "a)",
    "text": "a)\nCreate a figure with pairwise scatter plots of the variables. Note that depression index (DEP) is the outcome measure (or response variable, Y).\n\nDo you see any signs of the linearity assumption not being met? If so, for which variables?\nDo you see any strong correlations between independent variables that could potentially cause collinearity problems? Confirm your observations by calculating pairwise correlations among the predictors."
  },
  {
    "objectID": "homework/HW5.html#b",
    "href": "homework/HW5.html#b",
    "title": "Homework 5",
    "section": "b)",
    "text": "b)\nCheck if the DEP data are normally distributed. If needed, what would be an appropriate transformation for this variable?"
  },
  {
    "objectID": "homework/HW5.html#c",
    "href": "homework/HW5.html#c",
    "title": "Homework 5",
    "section": "c)",
    "text": "c)\nTest whether the association between DEP and WP is significant using alpha = .05."
  },
  {
    "objectID": "homework/HW5.html#d",
    "href": "homework/HW5.html#d",
    "title": "Homework 5",
    "section": "d)",
    "text": "d)\nSuppose researchers would like to use a log transformation for the MC variable, based on what has been done in other studies. Do you agree with this choice? Why or why not? Whether or not you agree, test whether the association between DEP and log(MC) is significant, using alpha = .05, and use log(MC) instead of MC for the remainder of the assignment."
  },
  {
    "objectID": "homework/HW5.html#e",
    "href": "homework/HW5.html#e",
    "title": "Homework 5",
    "section": "e)",
    "text": "e)\nTest whether SEX is an effect modifier that changes the association between DEP and WP. Use alpha = .10."
  },
  {
    "objectID": "homework/HW5.html#f",
    "href": "homework/HW5.html#f",
    "title": "Homework 5",
    "section": "f)",
    "text": "f)\nTest whether SEX is an effect modifier that changes the association between DEP and log(MC). Use alpha = .10."
  },
  {
    "objectID": "homework/HW5.html#g",
    "href": "homework/HW5.html#g",
    "title": "Homework 5",
    "section": "g)",
    "text": "g)\nFrom the results obtained in parts (e) and (f), should we further check whether SEX is a confounder? Why or why not? If yes, determine whether SEX is a confounder for the associations between DEP and WP and between DEP and log(MC)"
  },
  {
    "objectID": "homework/HW5.html#h",
    "href": "homework/HW5.html#h",
    "title": "Homework 5",
    "section": "h)",
    "text": "h)\nDetermine whether AGE is a confounder for the associations between DEP and WP and between DEP and log(MC)."
  },
  {
    "objectID": "homework/HW5.html#i",
    "href": "homework/HW5.html#i",
    "title": "Homework 5",
    "section": "i)",
    "text": "i)\nWhat is your final association model based on the results from the previous questions?"
  },
  {
    "objectID": "homework/HW5.html#j",
    "href": "homework/HW5.html#j",
    "title": "Homework 5",
    "section": "j)",
    "text": "j)\nPerform model diagnostics for your final association model. Use the steps outlined below.\n\nj1)\nDetermine whether the independence assumption has been met.\n\n\nj2)\nDetermine whether the linearity assumption has been met.\n\n\nj3)\nDetermine whether the homoscedasticity assumption has been met.\n\n\nj4)\nDetermine whether the normality assumption has been met.\n\n\nj5)\nDetermine whether there any outliers (e.g., high leverage, lack of fit) or influential points (e.g., dffits, Cook’s distance, dfbetas)?\n\n\nj6)\nIs there evidence of collinearity in the model? If there is collinearity, make changes to your model to reduce the collinearity and justify your method."
  },
  {
    "objectID": "homework/HW5.html#k",
    "href": "homework/HW5.html#k",
    "title": "Homework 5",
    "section": "k)",
    "text": "k)\nUsing the final association model obtained from part (j5), interpret the (adjusted) association between DEP and MC."
  },
  {
    "objectID": "homework/HW5.html#l",
    "href": "homework/HW5.html#l",
    "title": "Homework 5",
    "section": "l)",
    "text": "l)\nWhat is the R-squared value for your final association model? Explain it in the context of study."
  },
  {
    "objectID": "homework/HW5.html#m",
    "href": "homework/HW5.html#m",
    "title": "Homework 5",
    "section": "m)",
    "text": "m)\nFor your final association model, run a hypothesis test and report the 95% CI for the slope of the WP variable. Interpret the results (both test and CI)."
  },
  {
    "objectID": "homework/HW5.html#a-1",
    "href": "homework/HW5.html#a-1",
    "title": "Homework 5",
    "section": "a)",
    "text": "a)\nRun the four automatic selection procedures discussed in class (forward selection, backward elimination, forward stepwise, and backward stepwise) using all the independent variables and the interactions listed above. What are the parsimonious models from the different procedures? How are they similar or different? If the results are different, provide some reasons as to why they are different.\n\nForward Selection\n\n\nBackwards Selection\n\n\nForward Stepwise\n\n\nBackwards Stepwise\n\n\nComparison of models"
  },
  {
    "objectID": "homework/HW5.html#b-1",
    "href": "homework/HW5.html#b-1",
    "title": "Homework 5",
    "section": "b)",
    "text": "b)\nRestricting to just the variables that appeared in any of the prediction models obtained in the previous part, use Mallow’s \\(C_p\\) and the models’ adjusted R-squared values to decide on a parsimonious final prediction model. Include an explanation on how you chose your final prediction model."
  },
  {
    "objectID": "homework/HW3.html#directions---important",
    "href": "homework/HW3.html#directions---important",
    "title": "Homework 3",
    "section": "Directions - important!!!",
    "text": "Directions - important!!!\n\nHypothesis tests\n\nFor every hypothesis test make sure to include the following:\n\nNull & alternative hypotheses\nCalculation of test statistic using the formula\nCalculate the p-value directly using its probability distribution\nRunning the test using R\nConclusion in the context of the research problem. This includes referring to variables by what they actually are and not \\(X_1\\), \\(X_2\\), etc.\n\n\n\nSee additional instructions/ clarifications in green."
  },
  {
    "objectID": "homework/HW3.html#tips",
    "href": "homework/HW3.html#tips",
    "title": "Homework 3",
    "section": "Tips",
    "text": "Tips\n\nYou will be running a lot of different tests below. I highly recommend coming up with a naming convention that will easily help you keep track of what variables are being included in which models.\n\nThe names model1, model2, etc. will not be helpful."
  },
  {
    "objectID": "homework/HW3.html#a",
    "href": "homework/HW3.html#a",
    "title": "Homework 3",
    "section": "(a)",
    "text": "(a)\n\nConduct the overall regression F test for the model where \\(Y\\) is regressed on \\(X_1, X_2\\), and \\(X_3\\). Use alpha = 0.05. Interpret your result."
  },
  {
    "objectID": "homework/HW3.html#b",
    "href": "homework/HW3.html#b",
    "title": "Homework 3",
    "section": "(b)",
    "text": "(b)\n\nProvide variables-added-in-order tests for the order \\(X_2, X_1\\), and \\(X_3\\).\n\nThis means that there are 3 tests: (1) test model with just \\(X_2\\), (2) test adding \\(X_1\\) to the model given that \\(X_2\\) is already in the model, and (3) test adding \\(X_3\\) to the model given that \\(X_2, X_1\\) are already in the model. See the subsections below to divide up the work.\n\nTest model with just \\(X_2\\)\n\n\nAdding \\(X_1\\) to the model given that \\(X_2\\) is already in the model\n\n\nAdding \\(X_3\\) to the model given that \\(X_2, X_1\\) are already in the model"
  },
  {
    "objectID": "homework/HW3.html#e",
    "href": "homework/HW3.html#e",
    "title": "Homework 3",
    "section": "(e)",
    "text": "(e)\n\nProvide variables-added-last tests for \\(X_1, X_2\\), and \\(X_3\\).\n\nThis means that there are 3 tests: (1) test adding \\(X_1\\) to the model given that \\(X_2, X_3\\) are already in the model, (2) test adding \\(X_2\\) to the model given that \\(X_1, X_3\\) are already in the model, and (3) test adding \\(X_3\\) to the model given that \\(X_1, X_2\\) are already in the model. See the subsections below to divide up the work. \n\nFor adding \\(X_2\\) and \\(X_3\\) last to the model, you do not need to calculate the test statistic using the formula or the p-value directly using its probability distribution. You can instead run the appropriate tests in R.\n\n\nAdding \\(X_1\\) to the model given that \\(X_2, X_3\\) are already in the model\n\n\nAdding \\(X_2\\) to the model given that \\(X_1, X_3\\) are already in the model\n\n\nAdding \\(X_3\\) to the model given that \\(X_1, X_2\\) are already in the model"
  },
  {
    "objectID": "homework/HW3.html#f",
    "href": "homework/HW3.html#f",
    "title": "Homework 3",
    "section": "(f)",
    "text": "(f)\n\nProvide the variables-added-last test for \\(X_4 = X_2 X_3\\) given that \\(X_2\\) and \\(X_3\\) are already in the model. Does \\(X_4\\) significantly improve the prediction of \\(Y\\) given that \\(X_2\\) and \\(X_3\\) are already in the model?"
  },
  {
    "objectID": "homework/HW3.html#a-1",
    "href": "homework/HW3.html#a-1",
    "title": "Homework 3",
    "section": "(a)",
    "text": "(a)\nCalculate the coefficient of determination \\(r^2_{Y|X1,X2,X3}\\) and interpret this value in the context of the problem. Do the calculation using the formula and then check your answer with R. In particular, where in the R output do we find this value?"
  },
  {
    "objectID": "homework/HW3.html#b-1",
    "href": "homework/HW3.html#b-1",
    "title": "Homework 3",
    "section": "(b)",
    "text": "(b)\nCalculate the partial coefficient of determination \\(r^2_{YX1|X2}\\) and interpret this value in the context of the problem. Do the calculation using the formula and then check your answer with R."
  },
  {
    "objectID": "homework/HW3.html#c",
    "href": "homework/HW3.html#c",
    "title": "Homework 3",
    "section": "(c)",
    "text": "(c)\nUse \\(r^2_{YX1|X2}\\) to calculate \\(r_{YX1|X2}\\) and interpret this value in the context of the problem. Check your answer with R."
  },
  {
    "objectID": "homework/HW3.html#d",
    "href": "homework/HW3.html#d",
    "title": "Homework 3",
    "section": "(d)",
    "text": "(d)\nExplain how the interpretations of \\(r^2_{YX1|X2}\\) and \\(r_{YX1|X2}\\). In particular, what information do each of these values tell us that the other does not?"
  },
  {
    "objectID": "homework/HW3.html#e-1",
    "href": "homework/HW3.html#e-1",
    "title": "Homework 3",
    "section": "(e)",
    "text": "(e)\nCalculate the partial coefficient of determination \\(r^2_{YX1|X2X3}\\) and interpret this value in the context of the problem. Do the calculation using the formula and then check your answer with R."
  },
  {
    "objectID": "homework/HW3.html#f-1",
    "href": "homework/HW3.html#f-1",
    "title": "Homework 3",
    "section": "(f)",
    "text": "(f)\nUse \\(r^2_{YX1|X2X3}\\) to calculate \\(r_{YX1|X2X3}\\) and interpret this value in the context of the problem. Check your answer with R."
  },
  {
    "objectID": "homework/HW3.html#g",
    "href": "homework/HW3.html#g",
    "title": "Homework 3",
    "section": "(g)",
    "text": "(g)\nUse your answers to parts (b, c, e, f), to discuss the change in the first-order partial correlation to the second-order partial correlation."
  },
  {
    "objectID": "homework/HW3.html#penguins-flipper-length-vs.-species",
    "href": "homework/HW3.html#penguins-flipper-length-vs.-species",
    "title": "Homework 3",
    "section": "Penguins: Flipper length vs. species",
    "text": "Penguins: Flipper length vs. species\nFor this problem we will be using the penguins dataset from the palmerpenguins R package.\nDescription from help file:\n\nIncludes measurements for penguin species, island in Palmer Archipelago, size (flipper length, body mass, bill dimensions), and sex.\n\nMore info about the data are at https://allisonhorst.github.io/palmerpenguins/.\n\n# first install the palmerpenguins package\n# install.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\ndata(penguins)\n\n# run the command below to learn more about the variables in the penguins dataset\n# ?penguins\n\n\n(1) Outcome averages stratified by category levels\nCalculate the average flipper lengths stratified by each of the penguin species.\n\n\n(2) Visualize the “regression”\nMake a scatterplot of flipper lengths by species, and include diamond-shape points for the averages of the flipper lengths for each of the species.\n\n\n(3) Regression equations\nBefore running the regression in R, we are going to find the regression equation”manually.”\nWrite out the regression equation using LaTeX math markup (see class notes) that models the flipper length by penguin species. Do not yet insert values for the regression coefficients, i.e. us the generic coefficients \\(\\widehat{\\beta}_0, \\widehat{\\beta}_1,\\) etc. Use Adelie as the reference level.\n\n\n(4) Interpret coefficients\nHow do we interpret each of the regression coefficients for this model? Write out a separate interpretation for each of the coefficients.\n\n\n(5) Regression coefficients “manually”\n“Manually” calculate the values for each of the coefficients, and update the regression model with the values inserted.\nYou must show your work for this. Do not run the linear model in this step to get the values.\n\n\n(6) Regression table with lm() function\nRun the linear regression of flipper lengths vs. species in R, and display the regression table output. Which species did R choose as the reference level, and how did you determine this?\n\n\n(7) Mean calculation using regression output\nCalculate the mean flipper length of penguins in the Chinstrap and Gentoo species using only the results from the regression table. You must show your work."
  },
  {
    "objectID": "homework/HW3.html#problem-9.7-c",
    "href": "homework/HW3.html#problem-9.7-c",
    "title": "Homework 3",
    "section": "Problem 9.7 (c)",
    "text": "Problem 9.7 (c)\nDo this problem after completing 9.7 (b) above\n\nProvide variables-added-in-order tests for the order \\(X_3, X_1\\), and \\(X_2\\).\n\nThis means that there are 3 tests: (1) test model with just \\(X_3\\), (2) test adding \\(X_1\\) to the model given that \\(X_3\\) is already in the model, and (3) test adding \\(X_2\\) to the model given that \\(X_3, X_1\\) are already in the model. See the subsections below to divide up the work.\n\nTest model with just \\(X_3\\)\n\n\nAdding \\(X_1\\) to the model given that \\(X_3\\) is already in the model\n\n\nAdding \\(X_2\\) to the model given that \\(X_3, X_1\\) are already in the model"
  },
  {
    "objectID": "homework/HW3.html#chapter-10-c-using-the-formula",
    "href": "homework/HW3.html#chapter-10-c-using-the-formula",
    "title": "Homework 3",
    "section": "Chapter 10 (c) using the formula",
    "text": "Chapter 10 (c) using the formula\nDo this after completing Chapter 10 (c) above.\nCalculate \\(r_{YX1|X2}\\) using the formula and check that your answer matches that of Chapter 10 (c) above."
  },
  {
    "objectID": "homework/HW3.html#regression-with-one-categorical-predictor-prequel-to-ch-11-12-change-the-reference-level-to-gentoo",
    "href": "homework/HW3.html#regression-with-one-categorical-predictor-prequel-to-ch-11-12-change-the-reference-level-to-gentoo",
    "title": "Homework 3",
    "section": "Regression with one categorical predictor (Prequel to Ch 11 & 12): Change the reference level to Gentoo",
    "text": "Regression with one categorical predictor (Prequel to Ch 11 & 12): Change the reference level to Gentoo\nAfter completing exercises (1) - (7) in the section Regression with one categorical predictor (Prequel to Ch 11 & 12), do the problems below.\n\n(8)\nWrite out the regression equation using LaTeX math markup (see class notes) that models the flipper length by penguin species. Do not yet insert values for the regression coefficients, i.e. us the generic coefficients \\(\\widehat{\\beta}_0, \\widehat{\\beta}_1,\\) etc. Use Gentoo as the reference level.\n\n\n(9)\nHow do we interpret each of the regression coefficients for this model? Write out a separate interpretation for each of the coefficients.\n\n\n(10)\n“Manually” calculate the values for each of the coefficients, and update the regression model with the values inserted. You must show your work for this. Do not run the linear model in this step to get the values."
  },
  {
    "objectID": "homework/HW2.html#question-1-chapter-6",
    "href": "homework/HW2.html#question-1-chapter-6",
    "title": "Homework 2",
    "section": "Question 1 (chapter 6)",
    "text": "Question 1 (chapter 6)\nUse the data from Chapter 5 Question 9 to answer the following questions. Use the log-transformed values as given in the dataset.\nNote: the question numbers below do not refer to questions from the textbook. Complete the problems below instead of the ones in the book."
  },
  {
    "objectID": "homework/HW4.html#question-1",
    "href": "homework/HW4.html#question-1",
    "title": "Homework 4",
    "section": "Question 1",
    "text": "Question 1\nUse the data from Chapter 12 Problem 3 to answer the questions below.\n\na)\na. How many dummy variable(s) do you need to create for the categorical variable Diet (protein-rich vs. protein-poor)? Create the dummy variable(s) with the reference cell coding approach{0,1}.\n\n\nb)\nb. At a level of significance alpha = .05, test whether if Age is significantly associated with Height. Would this association be modified depending on diet group (e.g., rich-protein or poor-protein)? In other words, is Diet an effect-modifier that changes the association between Height and Age? Justify your answer (e.g., perform a hypothesis test at a level of alpha =.1).\nNote: recall that an effect modifier is an interaction.\n\n\nc)\nc. From the results obtained in part b, should we perform an assessment of a confounder for Diet? Justify your answer. Perform such an assessment if needed.\n\n\nd)\nd. Perform a regression analysis on the model obtained from the results obtained from parts a- c. Write down a general regression equation that is applicable to both groups—rich-protein vs.poor-protein. Write down regression lines for each specific groups—rich-protein or poor-protein."
  },
  {
    "objectID": "homework/HW4.html#question-2",
    "href": "homework/HW4.html#question-2",
    "title": "Homework 4",
    "section": "Question 2",
    "text": "Question 2\nUse the data from Chapter 9 Problem 5 to answer the questions below.\n\na)\na. Use \\(\\alpha= 0.05\\), test whether the (crude) association between Y and X1 could be established.\n\n\nb)\nb. Use\\(\\alpha= 0.1\\), test whether X3 is an effect modifier of the association between Y and X1.\nNote: To identify effect modifiers, we perform a hypothesis test of interaction term, e.g.,X1X3. That is: The full model includes X1, X3, X1X3. the reduced model includes X1 and X3\n\n\nc)\nc. From the result obtained in part b, do we need to perform an assessment of a confounder for X3? Justify your answer. Perform such an assessment if needed.\n\n\nd)\nd. Perform an assessment of a confounder for X2 which potentially changes the association between Y and X1.\n\n\ne)\ne. From the results in parts a-d, what is your final association model?"
  },
  {
    "objectID": "homework/HW4.html#a-2",
    "href": "homework/HW4.html#a-2",
    "title": "Homework 4",
    "section": "a)",
    "text": "a)\na. Obtain scatter plot: Y vs. X. Does linear trend support the relationship between Y and X?"
  },
  {
    "objectID": "homework/HW4.html#b-2",
    "href": "homework/HW4.html#b-2",
    "title": "Homework 4",
    "section": "b)",
    "text": "b)\nb. At the level alpha =.05, test whether the linear relationship could be established between Y and X."
  },
  {
    "objectID": "homework/HW4.html#c-2",
    "href": "homework/HW4.html#c-2",
    "title": "Homework 4",
    "section": "c)",
    "text": "c)\nc. At the level alpha =.05, test whether the quadratic term (\\(X^2\\)) should be included in the model to improve the prediction in Y, given the linear term (\\(X\\)) is already in the model."
  },
  {
    "objectID": "homework/HW4.html#d-2",
    "href": "homework/HW4.html#d-2",
    "title": "Homework 4",
    "section": "d)",
    "text": "d)\nd. From the result obtained from part c, should we test if the linear term (X) is necessary to be included in the model, given the quadratic term is already in the model? Explain your answer."
  },
  {
    "objectID": "homework/HW4.html#e-1",
    "href": "homework/HW4.html#e-1",
    "title": "Homework 4",
    "section": "e)",
    "text": "e)\ne. From the results you obtain from parts c-d, should we further examine whether cubic term (\\(X^3\\)) or fourth polynomial degree (i.e., \\(X^4\\)) to improve the prediction in Y? Explain your answer and report the result of such a test if needed."
  },
  {
    "objectID": "homework/HW4.html#f",
    "href": "homework/HW4.html#f",
    "title": "Homework 4",
    "section": "f)",
    "text": "f)\nf. From parts a – e, what is the final model that you have obtained? Interpret the R-square result from this model in the context of the study. Plot fitted value curve vs. X overlaid with scatter plot. Comments about the fitting model."
  },
  {
    "objectID": "weeks/week_01_sched.html#announcements",
    "href": "weeks/week_01_sched.html#announcements",
    "title": "Week 1",
    "section": "Announcements",
    "text": "Announcements\n\nMonday 1/8\n\nWe came from two different sections of the same course\n\nWhile I am confident we all learned a lot and mostly the same material\nWe definitely learned it in different ways\nThree components of 511/512/513\n\nTheory\nApplication\nCoding\n\n\nThere is a workshop on Friday, 1/12\n\nData Equity Primer from We All Count\nIf you attend, I will give you an extra 3% on your project report.\nUnfortunately, I was in contact with the workshop, but they cannot offer free seats to the whole class.\nI am attending, and will try to see if I can share a recording afterwards!\n\nHere are a few resources if you’d like to practice R:\n\nhttps://rladiessydney.org/courses/ryouwithme/\nhttps://r-bootcamp.netlify.app/\n\nThis is step by step, and lets you practice your code in real time\nWe will use ggplot2, dplyr, and tidyr extensively in this class!\nI am happy to help with coding, but during our class time our focus will by statistics topics\n\nCoding help will mostly be done outside of class time\n\n\n\nWe will also be using an attachment within Rstudio called Quarto\n\nHere is a great tutorial on Quarto: https://quarto.org/docs/get-started/hello/rstudio.html\n\nMine is the Quarto queen!\nThere is some expectation of knowledge with the above packages (ggplot2, dplyr, and tidyr)\n\n\n\n\n\nWednesday 1/10\n\nAha! I finally found the fun source on connecting tests from 511 to linear models!!\n\nHere is the site\nAnd here is the cheat sheet: \n\nWebsite updates\n\nPlease see the muddiest points below\n\nI try to elaborate/answer questions from your exit tickets\n\nSchedule updated to include Holidays\nNew resources tab that I will try to update after every class!\n\nAsking about getting a different room - seems like we’re cramped\nLab grading\n\nEach lab will be graded using a rubric (on each lab page)\nYou will need to hit specific points to get full credit for the lab\nThis is not a “turn in as is” assignment. You need to turn it in on time OR ask me for an extension.\n\nIt is likely that I can give you a few more days to finish\n\nFor labs, you will have ONE no-questions-asked, 3-day extension. Please use this wisely! You just need to send me a quick email saying “I am using my no-questions-asked extension for Lab __.”\n\nIf you need another extension, then you need to email me to ask"
  },
  {
    "objectID": "instructors.html#statistics-tutor-for-epidemiology-students",
    "href": "instructors.html#statistics-tutor-for-epidemiology-students",
    "title": "Instructors",
    "section": "Statistics Tutor for Epidemiology Students",
    "text": "Statistics Tutor for Epidemiology Students\n\nBecky Lanford\n\nEmail: lanford@ohsu.edu\nLink to Becky’s Calendly\n\nBecky can help with:\n\nStatistical coding support\nSupport with stats concepts you are learning in class\nData management and analysis plan scheming during your PE\n\nIntroduction from Becky:\n\nHello fellow MPH classmates! My name is Becky Lanford. I’m looking forward to helping support you in your coursework this quarter. A little about my background: I am currently in my final year in the MPH Epidemiology track and have completed most of my coursework including the biostatistics and epidemiology series (mostly working in R). I enrolled at the SPH as someone re-entering the workforce and quite new to statistical programming. Though I had previously completed a graduate degree (as a Physician Assistant/Associate), re-acclimating to graduate work and learning programming skills made for a steep learning curve my first academic year. I credit the collaborative learning environment at SPH - support of TA’s and classmates and availability of instructors - for helping me be successful. I hope I can help answer course-content questions, problem solve with you and find answers if I don’t have them myself. I know there are many challenges to being a graduate student and I am excited to help our public health student community grow stronger and more knowledgeable together."
  },
  {
    "objectID": "instructors.html#becky-lanford",
    "href": "instructors.html#becky-lanford",
    "title": "Instructors",
    "section": "Becky Lanford",
    "text": "Becky Lanford\nEmail: lanford@ohsu.edu\nHello fellow MPH classmates! My name is Becky Lanford. I’m looking forward to helping support you in your coursework this quarter. A little about my background: I am currently in my final year in the MPH Epidemiology track and have completed most of my coursework including the biostatistics and epidemiology series (mostly working in R). I enrolled at the SPH as someone re-entering the workforce and quite new to statistical programming. Though I had previously completed a graduate degree (as a Physician Assistant/Associate), re-acclimating to graduate work and learning programming skills made for a steep learning curve my first academic year. I credit the collaborative learning environment at SPH - support of TA’s and classmates and availability of instructors - for helping me be successful. I hope I can help answer course-content questions, problem solve with you and find answers if I don’t have them myself. I know there are many challenges to being a graduate student and I am excited to help our public health student community grow stronger and more knowledgeable together."
  },
  {
    "objectID": "labs/Lab_01.html#questions",
    "href": "labs/Lab_01.html#questions",
    "title": "Lab 1",
    "section": "Questions",
    "text": "Questions\n\nRead the article and collect other sources of information\n\n\nAnswer the following questions\n\n\nGet a sense of how you would like to analyze the data"
  },
  {
    "objectID": "labs/Lab_01.html#lab-activities",
    "href": "labs/Lab_01.html#lab-activities",
    "title": "Lab 1",
    "section": "Lab activities",
    "text": "Lab activities\n\n1. Reading and listening activities\n\n1.1 Article: Implicit and explicit anti-fat bias: The role of weight-related attitudes and beliefs\nThis article will serve as a reference point for our project. The article is meant to introduce social scientists’ approaches to research and analyses. However, the article is not meant to be a basis for which we perform our analysis.\n\n\n\n\n\n\nWarning\n\n\n\nThis article discusses anti-fat bias. It uses words that may be triggering to larger-bodied people.\n\n\nPlease read sections 1 - 2, through 2.2 (“Procedures and measures”). Answer the following questions:\n\nIn your own words, what is anti-fat bias?\nWhat were the three social theoretical models that the paper discusses? Which do you personally think is the biggest contributor to anti-fat bias and why?\nFrom the following measures in section 2.2, select two and discuss why the named measure may or may not accurately represent the italicized statement taken from the IAT questionnaire. Feel free to answer this question after taking the IAT yourself.\n\nSelf-perception of weight\nThin/fat group identity\nControllability of weight\nAwareness of societal standards\nInternalization of societal standards\n\n\n\n\n1.2 Podcast: Anti-Fat Bias by Maintenance Phase\n\n\n\n\n\n\nWarning\n\n\n\nThis podcast shares the experience of one of its hosts that involves anti-fat bias. This may be triggering if you have experienced this type of bias.\n\n\nThis is an optional listening for this lab, but I highly encourage you listen at some point this quarter. This is a really good way to see how research can be integrated into conversation and experience.\nIf you decide to listen, feel free to share a quote that most impacted you.\n\n\n\n2. Familiarizing ourselves with the Implicit Association Test (IAT)\n\n2.1 Learn more about the test\nVisit the Project Implicit site, and read about the test. What is your initial reaction to the test? What questions about the test do you have? Do you have any questions about the test’s validity? The point here is not to attempt to discredit the test itself, but see what specific questions the test can help us answer and what is outside the scope of our analysis. For example, are there any potential issues with the fact that people are self-selected to take the test? Does that mean our sample is representative of our population? Is it an issue that someone can take the test more than once?\nThis exercise will serve as a good starting point for the discussion section of our project report. The more effort you put in here and now, the more prepared you will be for the report.\n\n\n2.2 Take the test\nYou will spend 15 minutes taking the IAT. You can go to the Project Implicit website, register, and select a specific test to take. Once registered, you can click “Take a Test,” read the Preliminary Information, and then click “I wish to proceed” at the bottom. Then you can click the button “Weight IAT” to take this particular test.\nI will not check that you have completed this test, but it will help you understand the data you are analyzing.\n\n\n\n3. Get a sense of how you would like to analyze the data\nFor our project, we will examine the association betwen the IAT score and one other variable. From the above article, and the introduced variables in section 2.2, which association are you most interested in analyzing? Please write this in the form of a research question.\nWe will have a chance to adjust our research question once we have explored the data in Lab 2.\n\n\n4. Compile above work into an introduction\nAt this point, you have done a lot of the work needed to write an introduction for your report. Write a brief description of anti-fat bias, IAT, your research question, and the context for the question. This description should be in complete sentences and written as a single paragraph.\nIn the next lab, we will work on a summary of the dataset (e.g. where are the data from, when were they collected, how many subjects, what are the variables, what are the exposure and outcomes variables of interest, etc.)."
  },
  {
    "objectID": "slides/01_Review.html#data-visualization-2",
    "href": "slides/01_Review.html#data-visualization-2",
    "title": "Review",
    "section": "Data visualization 2",
    "text": "Data visualization 2\n\n\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_density()\n\n\n\n\n\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/01_Review.html#histogram-using-ggplot2",
    "href": "slides/01_Review.html#histogram-using-ggplot2",
    "title": "Review",
    "section": "Histogram using ggplot2",
    "text": "Histogram using ggplot2\nWe can make a basic graph for a continuous variable:\n\n\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\nggplot() +\n  geom_histogram(data = dds.discr, \n       aes(x = age))\n\n\n\n\n\n\n\n\n\n\nSome more information on histograms using ggplot2"
  },
  {
    "objectID": "slides/01_Review.html#histogram-using-ggplot2-1",
    "href": "slides/01_Review.html#histogram-using-ggplot2-1",
    "title": "Review",
    "section": "Histogram using ggplot2",
    "text": "Histogram using ggplot2\nWe can make a more formal, presentable graph:\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_histogram() +\n  theme(text = element_text(size=20)) +\n  labs(x = \"Age\", \n       y = \"Count\", \n       title = \"Distribution Age in Sample\")\n\n\nI would like you to turn in homework, labs, and project reports with graphs like these."
  },
  {
    "objectID": "slides/01_Review.html#other-basic-plots-from-ggplot2",
    "href": "slides/01_Review.html#other-basic-plots-from-ggplot2",
    "title": "Review",
    "section": "Other basic plots from ggplot2",
    "text": "Other basic plots from ggplot2\nWe can also make a density and boxplot for the continuous variable with ggplot2\n\n\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_density()\n\n\n\n\n\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/01_Review.html#where-are-we-1",
    "href": "slides/01_Review.html#where-are-we-1",
    "title": "Review",
    "section": "Where are we?",
    "text": "Where are we?\n\n\nReview\n\n\n\nIntro to SLR: estimation and testing\nIntro to MLR: estimation and testing\nDiving into our predictors: categorical variables, interactions between variable\nKey ingredient: model evaluation, diagnostics, selection, and building"
  },
  {
    "objectID": "slides/01_Review.html#spruced-up-histogram-using-ggplot2",
    "href": "slides/01_Review.html#spruced-up-histogram-using-ggplot2",
    "title": "Review",
    "section": "Spruced up histogram using ggplot2",
    "text": "Spruced up histogram using ggplot2\nWe can make a more formal, presentable graph:\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_histogram() +\n  theme(text = element_text(size=20)) +\n  labs(x = \"Age\", \n       y = \"Count\", \n       title = \"Distribution of Age in Sample\")\n\n\nI would like you to turn in homework, labs, and project reports with graphs like these."
  },
  {
    "objectID": "slides/01_Review.html#descriptive-statistics-continuous-variables-r-code",
    "href": "slides/01_Review.html#descriptive-statistics-continuous-variables-r-code",
    "title": "Review",
    "section": "Descriptive Statistics: continuous variables (R code)",
    "text": "Descriptive Statistics: continuous variables (R code)\n\n\nMeasures of central tendency\n\nSample mean\n\nmean( sample )\n\nMedian\n\nmedian( sample )\n\n\n\nMeasures of variability (or dispersion)\n\nSample variance\n\nvar( sample )\n\nSample standard deviation\n\nsd( sample )\n\nIQR\n\nIQR( sample )"
  },
  {
    "objectID": "slides/01_Review.html#what-will-this-class-cover",
    "href": "slides/01_Review.html#what-will-this-class-cover",
    "title": "Review",
    "section": "What will this class cover?",
    "text": "What will this class cover?"
  },
  {
    "objectID": "slides/01_Review.html#what-will-we-learn-in-this-class",
    "href": "slides/01_Review.html#what-will-we-learn-in-this-class",
    "title": "Review",
    "section": "What will we learn in this class?",
    "text": "What will we learn in this class?\n\nWe will be building towards models that can handle many variables!\n \n\nRegression is the building block for modeling multivariable relationships\n\n \nIn Linear Models we will build, interpret, and evaluate linear regression models"
  },
  {
    "objectID": "slides/01_Review.html#now",
    "href": "slides/01_Review.html#now",
    "title": "Review",
    "section": "NOW!!",
    "text": "NOW!!\nPreviously, if the exposure was:\n\nCategorical: we could run a t-test or ANOVA\nContinuous\n\nMain sections:\n\nIntro to SLR: estimation and testing\nIntro to MLR: estimation and testing\nDiving into our predictors: categorical variables, interactions between variable\nKey ingredients: model evaluation, diagnostics, selection, and building"
  },
  {
    "objectID": "slides/01_Review.html#what-did-we-learn-in-511",
    "href": "slides/01_Review.html#what-did-we-learn-in-511",
    "title": "Review",
    "section": "What did we learn in 511?",
    "text": "What did we learn in 511?\n\nIn 511, we talked about categorical and continuous outcomes (dependent variables)\n \nWe also talked about their relationship with 1-2 continuous or categorical exposure (independent variables or predictor)\n \nWe had many good ways to assess the relationship between an outcome and exposure:\n \n\n\n\n\n\n\n\n\n\n\nContinuous Outcome\nCategorical Outcome\n\n\nContinuous Exposure\nCorrelation, simple linear regression\n??\n\n\nCategorical Exposure\nt-tests, paired t-tests, 2 sample t-tests, ANOVA\nproportion t-test, Chi-squared goodness of fit test, Fisher’s Exact test, Chi-squared test of independence, etc."
  },
  {
    "objectID": "slides/01_Review.html#what-did-we-learn-in-511-1",
    "href": "slides/01_Review.html#what-did-we-learn-in-511-1",
    "title": "Review",
    "section": "What did we learn in 511?",
    "text": "What did we learn in 511?\n\nYou set up a really important foundation\n\nIncluding distributions, mathematical definitions, hypothesis testing, and more!\n\n \nTests and statistical approaches learned are incredibly helpful!\n \nWhile you had to learn a lot of different tests and approaches for each combination of categorical/continuous exposure with categorical/continuous outcome\n\nThose tests cannot handle more complicated data\n\n \nWhat happens when other variables influence the relationship between your exposure and outcome?\n\nDo we just ignore them?"
  },
  {
    "objectID": "slides/01_Review.html#process-of-regression-data-analysis",
    "href": "slides/01_Review.html#process-of-regression-data-analysis",
    "title": "Review",
    "section": "Process of regression data analysis",
    "text": "Process of regression data analysis"
  },
  {
    "objectID": "slides/01_Review.html#main-sections-of-the-course",
    "href": "slides/01_Review.html#main-sections-of-the-course",
    "title": "Review",
    "section": "Main sections of the course",
    "text": "Main sections of the course\n\nReview\nIntro to SLR: estimation and testing\n\nModel fitting\n\nIntro to MLR: estimation and testing\n\nModel fitting\n\nDiving into our predictors: categorical variables, interactions between variable\n\nModel fitting\n\nKey ingredients: model evaluation, diagnostics, selection, and building\n\nModel evaluation and Model selection"
  },
  {
    "objectID": "slides/01_Review.html",
    "href": "slides/01_Review.html",
    "title": "Review",
    "section": "",
    "text": "In 511, we talked about categorical and continuous outcomes (dependent variables)\nWe also talked about their relationship with 1-2 continuous or categorical exposure (independent variables or predictor)\nWe had many good ways to assess the relationship between an outcome and exposure:\n\n\n\n\n\n\n\n\n\n\nContinuous Outcome\nCategorical Outcome\n\n\nContinuous Exposure\nCorrelation, simple linear regression\n??\n\n\nCategorical Exposure\nt-tests, paired t-tests, 2 sample t-tests, ANOVA\nproportion t-test, Chi-squared goodness of fit test, Fisher’s Exact test, Chi-squared test of independence, etc."
  },
  {
    "objectID": "slides/01_Review.html#main-sections-of-the-course-1",
    "href": "slides/01_Review.html#main-sections-of-the-course-1",
    "title": "Review",
    "section": "Main sections of the course",
    "text": "Main sections of the course\n\n\nReview\n\n\n\nIntro to SLR: estimation and testing\n\nModel fitting\n\nIntro to MLR: estimation and testing\n\nModel fitting\n\nDiving into our predictors: categorical variables, interactions between variable\n\nModel fitting\n\nKey ingredients: model evaluation, diagnostics, selection, and building\n\nModel evaluation and Model selection"
  },
  {
    "objectID": "slides/00_Intro.html#positionality",
    "href": "slides/00_Intro.html#positionality",
    "title": "Welcome to BSTA 512/612!",
    "section": "Positionality",
    "text": "Positionality"
  },
  {
    "objectID": "syllabus.html#assessment-breakdown",
    "href": "syllabus.html#assessment-breakdown",
    "title": "BSTA 512/612 Syllabus",
    "section": "Assessment Breakdown",
    "text": "Assessment Breakdown\n\nGrading & Requirements\nLetter grades will be assigned roughly according to the following scheme: A (&gt;=93%), A- (90-92%), B+ (88-89%), B(83-87%), B- (82-80%), C+(78-79%), C(73-77%), C- (70-72%), D (60 – 69%), F(&lt;60%).\nGrades will be based on homework assignments, midterm exam, class “attendance”, and final exam, as follows:\n\n\n\n\n\n\n\n\n\n\nCourse activity\nType of Assessment\nDue Date\nPercentage of final grade (BSTA 512)\nPercentage of final grade (BSTA 612)\n\n\nHomework\nFormative\nEvery 1-2 weeks\n33%\n28%\n\n\nQuizzes\nSummative\n1/29, 2/19, 3/11\n25%\n25%\n\n\nProject Labs\nFormative\nEvery 2-3 weeks\n25%\n25%\n\n\nProject Report\nSummative\n3/21\n10%\n10%\n\n\nExit tickets (Attendance)\nN/A\nTwice Weekly\n5%\n5%\n\n\nMid-Quarter Feedback\nN/A\nTBD\n2%\n2%\n\n\n612 Readings\nFormative\nApprox. every other week\n0%\n5%\n\n\n\n\n\nHomework grading\nNo student has the same amount of time available to dedicate to homework. This class may not be a priority to you, you may be taking several other courses, or you may need to dedicate time to other activities. Homeworks are formative assessments, meaning its purpose is to help you learn and practice. To reduce the pressure on you to have perfect or complete homework, I have a very simple grading policy: Your homework will be given a check mark if you turn something in (whether it is incomplete, complete, correct, or wrong). I highly encourage you to stay up-to-date with the homeworks and put in as much effort as you can. This will be the most helpful work in this class!\nAfter the due date, the TAs will give you feedback (on one or more complete problems) and post the solutions.\n\n\nViewing Grades in Sakai\nPoints you receive for graded activities will be posted to the Sakai Gradebook. Click on the Gradebook link on the left navigation to view your points."
  },
  {
    "objectID": "slides/01_Review.html#confidence-interval-for-one-mean-1",
    "href": "slides/01_Review.html#confidence-interval-for-one-mean-1",
    "title": "Review",
    "section": "Confidence interval for one mean",
    "text": "Confidence interval for one mean\n\n\nThe confidence interval for population mean \\(\\mu\\):\n\\[\n\\bar{x} \\pm t^{*}\\dfrac{s}{\\sqrt{n}}\n\\]\n\nwhere \\(t^*\\) is the critical value for the 95% (or other percent) corresponding to the t-distribution and dependent on \\(df=n-1\\)\n\n\n\nWe can use R to find the critical t-value, \\(t^*\\)\n\n\nFor example the critical value for the 95% CI with \\(n=10\\) subjects is…\n\nqt(0.975, df=9)\n\n[1] 2.262157\n\n\n\nRecall, that as the \\(df\\) increases, the t-distribution converges towards the Normal distribution\n\n\n\n\nWe can also use t.test in R to calculate the confidence interval if we have a dataset.\n\nt.test(dds.discr$age)\n\n\n    One Sample t-test\n\ndata:  dds.discr$age\nt = 39.053, df = 999, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 21.65434 23.94566\nsample estimates:\nmean of x \n     22.8"
  },
  {
    "objectID": "slides/01_Review.html#vjsv",
    "href": "slides/01_Review.html#vjsv",
    "title": "Review",
    "section": "vjsv",
    "text": "vjsv\n\n\n\nWe can also use t.test in R to calculate the confidence interval if we have a dataset.\n\nt.test(dds.discr$age)\n\n\n    One Sample t-test\n\ndata:  dds.discr$age\nt = 39.053, df = 999, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 21.65434 23.94566\nsample estimates:\nmean of x \n     22.8"
  },
  {
    "objectID": "slides/01_Review.html#heres-a-decent-source-for-other-r-code-for-tests-in-511",
    "href": "slides/01_Review.html#heres-a-decent-source-for-other-r-code-for-tests-in-511",
    "title": "Review",
    "section": "Here’s a decent source for other R code for tests in 511",
    "text": "Here’s a decent source for other R code for tests in 511\nWebsite from UCLA"
  },
  {
    "objectID": "slides/01_Review.html#critical-region-method",
    "href": "slides/01_Review.html#critical-region-method",
    "title": "Review",
    "section": "Critical region method",
    "text": "Critical region method\n\nThe test statistic is: \\(t_{\\bar{x}} = \\dfrac{\\bar{x}-\\mu_0}{\\dfrac{s}{\\sqrt{n}}}\\)\n\nLet’s say we have data for: \\(t_{\\bar{x}} = \\dfrac{98.25-98.6}{\\dfrac{0.73}{\\sqrt{130}}} = -5.45\\)"
  },
  {
    "objectID": "slides/01_Review.html#how-did-we-get-the-95-ci",
    "href": "slides/01_Review.html#how-did-we-get-the-95-ci",
    "title": "Review",
    "section": "How did we get the 95% CI?",
    "text": "How did we get the 95% CI?\n\nThe t.test function can help us answer this, and give us the needed information for both approaches.\n\n\nBodyTemps = read.csv(\"data/BodyTemperatures.csv\")\n\nt.test(x = BodyTemps$Temperature, \n       # alternative = \"two-sided\", \n       mu = 98.6)\n\n\n    One Sample t-test\n\ndata:  BodyTemps$Temperature\nt = -5.4548, df = 129, p-value = 2.411e-07\nalternative hypothesis: true mean is not equal to 98.6\n95 percent confidence interval:\n 98.12200 98.37646\nsample estimates:\nmean of x \n 98.24923"
  },
  {
    "objectID": "slides/01_Review.html#learning-objectives",
    "href": "slides/01_Review.html#learning-objectives",
    "title": "Review",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nIdentify important descriptive statistics and visualize data from a continuous variable\nIdentify important distributions that will be used in 512/612\nUse our previous tools in 511 to estimate a parameter and construct a confidence interval\nUse our previous tools in 511 to conduct a hypothesis test\nDefine error rates and power"
  },
  {
    "objectID": "slides/01_Review.html#example-one-sample-t-test",
    "href": "slides/01_Review.html#example-one-sample-t-test",
    "title": "Review",
    "section": "Example: one sample t-test",
    "text": "Example: one sample t-test\n\nBodyTemps = read.csv(\"data/BodyTemperatures.csv\")\n\nggplot(data = BodyTemps, \n       aes(x = Temperature)) +\n  geom_histogram() +\n  theme(text = element_text(size=20)) +\n  labs(x = \"Temperature\", y = \"Count\", \n       title = \"Distribution of Body Temperature in Sample\") +\n  geom_vline(aes(xintercept = mean(BodyTemps$Temperature, na.rm = T)), \n             color = \"red\", linewidth = 2)"
  },
  {
    "objectID": "slides/01_Review.html#chi-squared-distribution-models-sampling-variance",
    "href": "slides/01_Review.html#chi-squared-distribution-models-sampling-variance",
    "title": "Review",
    "section": "Chi-squared distribution: models sampling variance",
    "text": "Chi-squared distribution: models sampling variance\n\n\n\nNotation: \\(X \\sim \\chi^2_{df}\\) OR \\(X \\sim \\chi^2_{\\nu}\\)\n\nDegrees of freedom (df): \\(df=n-1\\)\n\\(X\\) takes on only positive values\n\nIf \\(Z_i\\sim \\mbox{N}(0,1)\\), then \\(Z_i^2\\sim \\chi^2_1\\)\n\nA standard normal distribution squared is the Chi squared distribution with df of 1.\n\n\n\n\nUsed in hypothesis testing and CI’s for variance or standard deviation\n\nSample variance (and SD) is random and thus can be modeled by a probability distribution: Chi-sqaured\n\nChi-squared distribution used to model the ratio of the sample variance \\(s^2\\) to population variance \\(\\sigma^2\\):\n\n\\(\\dfrac{(n-1)s^2}{\\sigma^2}\\sim \\chi^2_{n-1}\\)"
  },
  {
    "objectID": "slides/01_Review.html#students-t-distribution",
    "href": "slides/01_Review.html#students-t-distribution",
    "title": "Review",
    "section": "Student’s t Distribution",
    "text": "Student’s t Distribution\n\n\n\nNotation: \\(T \\sim t_{df}\\) OR \\(T \\sim t_{n-1}\\)\n\nDegrees of freedom (df): \\(df=n-1\\)\n\\(T = \\dfrac{\\bar{x} - \\mu_x}{\\dfrac{s}{\\sqrt{n}}}\\sim t_{n-1}\\)\n\nIn linear modeling, used for inference on individual regression parameters\n\nThink: our estimated coefficients (\\(\\hat{\\beta}\\))"
  },
  {
    "objectID": "slides/01_Review.html#f-distribution-1",
    "href": "slides/01_Review.html#f-distribution-1",
    "title": "Review",
    "section": "F-Distribution",
    "text": "F-Distribution\n\n\n\nModel ratio of sample variances\n\nRatio of variances is important for hypothesis testing of regression models\n\nIf \\(X_1^2\\sim \\chi^2_{df1}\\) and \\(X_2^2\\sim \\chi^2_{df2}\\), where \\(X_1^2\\perp X_2^2\\), then:\n\n\\[\\dfrac{X_1^2/df1}{X_2^2/df2} \\sim F_{df1,df2}\\] - only takes on positive values\n\nImportant relationship with \\(t\\) distribution: \\(T^2 \\sim F_{1,\\nu}\\)\n\nThe square of a t-distribution with \\(df=\\nu\\)\nis an F-distribution with numerator df (\\(df_1 = 1\\)) and denominator df (\\(df_2 = \\nu\\))\n\n\n\n\n\n\nIs there a relationship between our chi-squared and F-distribution?\n\n\nRecall, \\(\\dfrac{(n-1)s^2}{\\sigma^2}\\sim \\chi^2_{n-1}\\).\nThe F-distribution for a ratio of variances between two models is: \\(F = \\dfrac{s_1^2\\sigma^2_2}{s_2^2\\sigma^2_1} \\sim F_{n_1-1, n_2-1}\\)"
  },
  {
    "objectID": "slides/01_Review.html#r-code-for-probability-distributions",
    "href": "slides/01_Review.html#r-code-for-probability-distributions",
    "title": "Review",
    "section": "R code for probability distributions",
    "text": "R code for probability distributions\n\n\nHere is a site with the various probability distributions and their R code.\n\nIt also includes practice with R code to see what each function outputs"
  },
  {
    "objectID": "slides/01_Review.html#learning-objectives-1",
    "href": "slides/01_Review.html#learning-objectives-1",
    "title": "Review",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\n\nIdentify important descriptive statistics and visualize data from a continuous variable\n\n\n\nIdentify important distributions that will be used in 512/612\nUse our previous tools in 511 to estimate a parameter and construct a confidence interval\nUse our previous tools in 511 to conduct a hypothesis test\nDefine error rates and power"
  },
  {
    "objectID": "slides/01_Review.html#learning-objectives-2",
    "href": "slides/01_Review.html#learning-objectives-2",
    "title": "Review",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nIdentify important descriptive statistics and visualize data from a continuous variable\n\n\n\nIdentify important distributions that will be used in 512/612\n\n\n\nUse our previous tools in 511 to estimate a parameter and construct a confidence interval\nUse our previous tools in 511 to conduct a hypothesis test\nDefine error rates and power"
  },
  {
    "objectID": "slides/01_Review.html#learning-objectives-3",
    "href": "slides/01_Review.html#learning-objectives-3",
    "title": "Review",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nIdentify important descriptive statistics and visualize data from a continuous variable\nIdentify important distributions that will be used in 512/612\n\n\n\nUse our previous tools in 511 to estimate a parameter and construct a confidence interval\n\n\n\nUse our previous tools in 511 to conduct a hypothesis test\nDefine error rates and power"
  },
  {
    "objectID": "slides/01_Review.html#learning-objectives-4",
    "href": "slides/01_Review.html#learning-objectives-4",
    "title": "Review",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nIdentify important descriptive statistics and visualize data from a continuous variable\nIdentify important distributions that will be used in 512/612\nUse our previous tools in 511 to estimate a parameter and construct a confidence interval\n\n\n\nUse our previous tools in 511 to conduct a hypothesis test\n\n\n\nDefine error rates and power"
  },
  {
    "objectID": "slides/01_Review.html#learning-objectives-5",
    "href": "slides/01_Review.html#learning-objectives-5",
    "title": "Review",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nIdentify important descriptive statistics and visualize data from a continuous variable\nIdentify important distributions that will be used in 512/612\nUse our previous tools in 511 to estimate a parameter and construct a confidence interval\nUse our previous tools in 511 to conduct a hypothesis test\n\n\n\nDefine error rates and power"
  },
  {
    "objectID": "slides/02_Data_Management.html#hello",
    "href": "slides/02_Data_Management.html#hello",
    "title": "Data Management with tidyr",
    "section": "Hello",
    "text": "Hello\nclass: middle, inverse"
  },
  {
    "objectID": "slides/02_Data_Management.html#what-is-the-tidyverse-1",
    "href": "slides/02_Data_Management.html#what-is-the-tidyverse-1",
    "title": "Data Management with tidyr",
    "section": "What is the tidyverse?",
    "text": "What is the tidyverse?\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.\n\nggplot2 - data visualisation\ndplyr - data manipulation\ntidyr - tidy data\nreadr - read rectangular data\npurrr - functional programming\ntibble - modern data frames\nstringr - string manipulation\nforcats - factors\nand many more …"
  },
  {
    "objectID": "slides/02_Data_Management.html#tidy-data",
    "href": "slides/02_Data_Management.html#tidy-data",
    "title": "Data Management with tidyr",
    "section": "Tidy data",
    "text": "Tidy data\n\n\n\n\n\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\n1\nSource: R for Data Science. Grolemund and Wickham."
  },
  {
    "objectID": "slides/02_Data_Management.html#tidy-data-tidyverse-references",
    "href": "slides/02_Data_Management.html#tidy-data-tidyverse-references",
    "title": "Data Management with the tidyverse",
    "section": "Tidy data + Tidyverse references",
    "text": "Tidy data + Tidyverse references\n\n\n\n\n\n\n\n\n\nWickham (2014). Tidy data. Journal of Statistical Software, 59(10), 1-23.\nWickham et al. (2019). Welcome to the Tidyverse. Journal of Open Source Software, 4(43), 1686."
  },
  {
    "objectID": "slides/02_Data_Management.html#pipe-operator-magrittr",
    "href": "slides/02_Data_Management.html#pipe-operator-magrittr",
    "title": "Data Management with the tidyverse",
    "section": "Pipe operator (magrittr)",
    "text": "Pipe operator (magrittr)\n\nThe pipe operator (%&gt;%) allows us to step through sequential functions in the same way we follow if-then statements or steps from instructions\n\n \n\nI want to find my keys, then start my car, then drive to work, then park my car.\n\n \n\n\nNested\n\npark(drive(start_car(find(\"keys\")), \n           to = \"work\"))\n\n\nPiped\n\nfind(\"keys\") %&gt;%\n  start_car() %&gt;%\n  drive(to = \"work\") %&gt;%\n  park()"
  },
  {
    "objectID": "slides/02_Data_Management.html#magrittr-vs-native-pipe",
    "href": "slides/02_Data_Management.html#magrittr-vs-native-pipe",
    "title": "Data Management with the tidyverse",
    "section": "magrittr vs native pipe",
    "text": "magrittr vs native pipe\n \nAs of R 4.1.0 there is now a native pipe operator in R (|&gt;) which is very similar to magrittr’s (%&gt;%).\n \nFor teaching purposes we would strongly recommend using magrittr for the foreseeable future.\n \n\n|&gt; only supports piping to the first argument (no support for .)\n \nFor most use cases, package dependencies are easier than R version dependencies"
  },
  {
    "objectID": "slides/02_Data_Management.html#recoding-a-binary-variable",
    "href": "slides/02_Data_Management.html#recoding-a-binary-variable",
    "title": "Data Management with the tidyverse",
    "section": "Recoding a binary variable",
    "text": "Recoding a binary variable\n \n\nLet’s say I want a variable transmission to show the category names that are assigned to numeric values in the code. I want 0 to be coded as automatic and 1 to be coded as manual.\n\n \n\n\nBase R:\n\nmtcars$transmission &lt;-\n  ifelse(\n    mtcars$am == 0,\n    \"automatic\",\n    \"manual\"\n  )\n\n\nTidyverse:\n\nmtcars &lt;- mtcars %&gt;%\n  mutate(\n    transmission = case_when(\n      am == 0 ~ \"automatic\",\n      am == 1 ~ \"manual\"\n    )\n  )\n\n \n\nmutate() creates new columns that are functions of existing variables"
  },
  {
    "objectID": "slides/02_Data_Management.html#recoding-a-multi-level-variable",
    "href": "slides/02_Data_Management.html#recoding-a-multi-level-variable",
    "title": "Data Management with the tidyverse",
    "section": "Recoding a multi-level variable",
    "text": "Recoding a multi-level variable\n \n\nLet’s say I want a variable gear to show the category names that are assigned to numeric values in the code. I want 3 to be coded as gear three, 4 to be coded as gear four, 5 to be coded as gear five.\n\n \n\n\nBase R:\n\nmtcars$gear_char &lt;-\n  ifelse(\n    mtcars$gear == 3,\n    \"three\",\n    ifelse(\n      mtcars$gear == 4,\n      \"four\",\n      \"five\"\n    )\n  )\n\n\nTidyverse:\n\nmtcars &lt;- mtcars %&gt;%\n  mutate(\n    gear_char = case_when(\n      gear == 3 ~ \"three\",\n      gear == 4 ~ \"four\",\n      gear == 5 ~ \"five\"\n    )\n  )"
  },
  {
    "objectID": "slides/02_Data_Management.html#visualising-multiple-variables",
    "href": "slides/02_Data_Management.html#visualising-multiple-variables",
    "title": "Data Management with tidyr",
    "section": "Visualising multiple variables",
    "text": "Visualising multiple variables\nTidyverse\n\nggplot(\n  mtcars,\n  aes(x = disp, y = mpg, color = transmission)\n) +\n  geom_point()"
  },
  {
    "objectID": "slides/02_Data_Management.html#visualising-even-more-variables",
    "href": "slides/02_Data_Management.html#visualising-even-more-variables",
    "title": "Data Management with tidyr",
    "section": "Visualising even more variables",
    "text": "Visualising even more variables\nTidyverse\n\nggplot(\n  mtcars,\n  aes(x = disp, y = mpg, color = transmission)\n) +\n  geom_point() +\n  facet_wrap(~ cyl)\n\n\n\n\nBase R\n\nmtcars$trans_color &lt;- ifelse(mtcars$transmission == \"automatic\", \"green\", \"blue\")\nmtcars_cyl4 = mtcars[mtcars$cyl == 4, ]\nmtcars_cyl6 = mtcars[mtcars$cyl == 6, ]\nmtcars_cyl8 = mtcars[mtcars$cyl == 8, ]\npar(mfrow = c(1, 3), mar = c(2.5, 2.5, 2, 0), mgp = c(1.5, 0.5, 0))\nplot(mpg ~ disp, data = mtcars_cyl4, col = trans_color, main = \"Cyl 4\")\nplot(mpg ~ disp, data = mtcars_cyl6, col = trans_color, main = \"Cyl 6\")\nplot(mpg ~ disp, data = mtcars_cyl8, col = trans_color, main = \"Cyl 8\")\nlegend(\"topright\", legend = c(\"automatic\", \"manual\"), pch = 1, col = c(\"green\", \"blue\"))\n\n\n\n\n]"
  },
  {
    "objectID": "slides/02_Data_Management.html#benefits-of-starting-with-the-tidyverse",
    "href": "slides/02_Data_Management.html#benefits-of-starting-with-the-tidyverse",
    "title": "Data Management with the tidyverse",
    "section": "Benefits of starting with the tidyverse",
    "text": "Benefits of starting with the tidyverse\n\nMore (human) readable syntax\nMore consistent syntax\nEase of multivariable visualizations\nData tidying/rectangling without advanced programming\nGrowth opportunities:\n\ndplyy \\(\\to\\) SQL / Spark / etc\npurrr \\(\\to\\) functional programming\nmodeling \\(\\to\\) tidymodels"
  },
  {
    "objectID": "slides/02_Data_Management.html#ggplot2-in-tidyverse",
    "href": "slides/02_Data_Management.html#ggplot2-in-tidyverse",
    "title": "Data Management with the tidyverse",
    "section": "ggplot2 in tidyverse",
    "text": "ggplot2 in tidyverse\n\n\n\n\n\n\n\n\n\nWe talked about this in our review notes\n\nI want to revisit it: always helps to have more examples!\nThis example is closer to the multivariable work we’ll do in this class!\n\n\n \n\nggplot2 is tidyverse’s data visualization package\n\n \n\nThe gg in “ggplot2” stands for Grammar of Graphics\n\n \n\nIt is inspired by the book Grammar of Graphics by Leland Wilkinson"
  },
  {
    "objectID": "slides/02_Data_Management.html#why-start-with-ggplot2",
    "href": "slides/02_Data_Management.html#why-start-with-ggplot2",
    "title": "Data Management with tidyr",
    "section": "Why start with ggplot2?",
    "text": "Why start with ggplot2?\n–\n\nStudents come in with intuition for being able to interpret data visualizations without needing much instructions.\n\n\nFocus the majority of class time initially on syntax and leave interpretations to students.\nLater on the scale tips – spend more class time on concepts and results interpretations and less on syntax.\n\n–\n\nIt can be easier for students to detect mistakes in visualizations compared to those in wrangling or modeling."
  },
  {
    "objectID": "slides/02_Data_Management.html#what-next",
    "href": "slides/02_Data_Management.html#what-next",
    "title": "Data Management with tidyr",
    "section": "What next?",
    "text": "What next?\nIt depends on the course and subject matter, but generally data munging with dplyr is a good next step.\nSome general guidance, - Start with a small subset of verbs (e.g. select(), filter(), mutate())\n\nAim to quickly get to group_by() and summarize() as this is where the action is.\nConnecting munging back to data visualization tends to be more motivating than generating numerical summaries.\nData cleaning provides opportunities to introduce additional packages (e.g. stringr, forcats)\n\nclass: middle, inverse"
  },
  {
    "objectID": "slides/02_Data_Management.html#instructional-staff-employment-trends",
    "href": "slides/02_Data_Management.html#instructional-staff-employment-trends",
    "title": "Data Management with the tidyverse",
    "section": "Instructional staff employment trends",
    "text": "Instructional staff employment trends\nThe American Association of University Professors (AAUP) is a nonprofit membership association of faculty and other academic professionals. This report by the AAUP shows trends in instructional staff employees between 1975 and 2011, and contains an image very similar to the one given below."
  },
  {
    "objectID": "slides/02_Data_Management.html#data",
    "href": "slides/02_Data_Management.html#data",
    "title": "Data Management with the tidyverse",
    "section": "Data",
    "text": "Data\nEach row in this dataset represents a faculty type, and the columns are the years for which we have data. The values are percentage of hires of that type of faculty for each year.\n   \n\n(staff &lt;- read_csv(\"data/instructional-staff.csv\"))\n\n# A tibble: 5 × 12\n  faculty_type    `1975` `1989` `1993` `1995` `1999` `2001` `2003` `2005` `2007`\n  &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Full-Time Tenu…   29     27.6   25     24.8   21.8   20.3   19.3   17.8   17.2\n2 Full-Time Tenu…   16.1   11.4   10.2    9.6    8.9    9.2    8.8    8.2    8  \n3 Full-Time Non-…   10.3   14.1   13.6   13.6   15.2   15.5   15     14.8   14.9\n4 Part-Time Facu…   24     30.4   33.1   33.2   35.5   36     37     39.3   40.5\n5 Graduate Stude…   20.5   16.5   18.1   18.8   18.7   19     20     19.9   19.5\n# ℹ 2 more variables: `2009` &lt;dbl&gt;, `2011` &lt;dbl&gt;"
  },
  {
    "objectID": "slides/02_Data_Management.html#recreate-the-visualization",
    "href": "slides/02_Data_Management.html#recreate-the-visualization",
    "title": "Data Management with the tidyverse",
    "section": "Recreate the visualization",
    "text": "Recreate the visualization\n \n\nIn order to recreate this visualization we need to first reshape the data:\n\none variable for faculty type\none variable for year\n\n\n \n\nConvert the data from the wide format to long format\n\npivot_longer()"
  },
  {
    "objectID": "slides/02_Data_Management.html#pivot_-functions",
    "href": "slides/02_Data_Management.html#pivot_-functions",
    "title": "Data Management with the tidyverse",
    "section": "pivot_*() functions",
    "text": "pivot_*() functions"
  },
  {
    "objectID": "slides/02_Data_Management.html#pivot-staff-data",
    "href": "slides/02_Data_Management.html#pivot-staff-data",
    "title": "Data Management with the tidyverse",
    "section": "Pivot staff data",
    "text": "Pivot staff data\n\n(staff_long &lt;- staff %&gt;%\n  pivot_longer(\n    cols = -faculty_type,    # columns to pivot\n    names_to = \"year\",       # name of new column for variable names\n    values_to = \"percentage\" # name of new column for values\n  ) %&gt;%\n  mutate(\n    percentage = as.numeric(percentage)\n  )\n)\n\n# A tibble: 55 × 3\n   faculty_type              year  percentage\n   &lt;chr&gt;                     &lt;chr&gt;      &lt;dbl&gt;\n 1 Full-Time Tenured Faculty 1975        29  \n 2 Full-Time Tenured Faculty 1989        27.6\n 3 Full-Time Tenured Faculty 1993        25  \n 4 Full-Time Tenured Faculty 1995        24.8\n 5 Full-Time Tenured Faculty 1999        21.8\n 6 Full-Time Tenured Faculty 2001        20.3\n 7 Full-Time Tenured Faculty 2003        19.3\n 8 Full-Time Tenured Faculty 2005        17.8\n 9 Full-Time Tenured Faculty 2007        17.2\n10 Full-Time Tenured Faculty 2009        16.8\n# ℹ 45 more rows\n\n\n]"
  },
  {
    "objectID": "slides/02_Data_Management.html#meh",
    "href": "slides/02_Data_Management.html#meh",
    "title": "Data Management with the tidyverse",
    "section": "Meh",
    "text": "Meh\n\nggplot(staff_long, aes(x = percentage, y = year, fill = faculty_type)) +\n  geom_col(position = \"dodge\")"
  },
  {
    "objectID": "slides/02_Data_Management.html#some-improvement",
    "href": "slides/02_Data_Management.html#some-improvement",
    "title": "Data Management with the tidyverse",
    "section": "Some improvement…",
    "text": "Some improvement…\n\nggplot(staff_long, aes(x = percentage, y = year, fill = faculty_type)) +\n  geom_col()"
  },
  {
    "objectID": "slides/02_Data_Management.html#more-improvement",
    "href": "slides/02_Data_Management.html#more-improvement",
    "title": "Data Management with the tidyverse",
    "section": "More improvement",
    "text": "More improvement\n\n\n\nstaff_long %&gt;%\n  mutate( \n    part_time = if_else(faculty_type == \"Part-Time Faculty\",\n                        \"Part-Time Faculty\", \"Other Faculty\"),\n    year = as.numeric(year)) %&gt;% \n  ggplot(\n    aes(x = year, y = percentage/100, group = faculty_type, color = part_time)) +\n  geom_line() +\n  scale_color_manual(values = c(\"gray\", \"red\")) + \n  scale_y_continuous(labels = label_percent(accuracy = 1)) + \n  theme_minimal() +\n  labs(\n    title = \"Instructional staff employment trends\",\n    x = \"Year\", y = \"Percentage\", color = NULL) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "slides/02_Data_Management.html#data-manipulation-with-purrr-or-not",
    "href": "slides/02_Data_Management.html#data-manipulation-with-purrr-or-not",
    "title": "Data Management with tidyr",
    "section": "Data manipulation with purrr (or not?)",
    "text": "Data manipulation with purrr (or not?)\n\npurrr is a package for functional programming with the tidyverse\nIf you picked up the tidyverse &gt;2 years ago, purrr was commonly used for data science tasks that involve iteration\nIn 2021, it’s possible to do many of these data science tasks with dplyr and tidyr, these approaches are often more approachable to new learners\n\n–\n.discussion[ How familiar are you with the purrr package? Have you taught purrr in your data science courses?]"
  },
  {
    "objectID": "slides/02_Data_Management.html#ex-1.-flattening-json-files",
    "href": "slides/02_Data_Management.html#ex-1.-flattening-json-files",
    "title": "Data Management with tidyr",
    "section": "Ex 1. Flattening JSON files",
    "text": "Ex 1. Flattening JSON files\nWe have data on lego sales and some information on the buyers in JSON format. We want to covert it into a tidy data frame.\n.tiny[\n\nsales &lt;- read_rds(\"data/lego_sales.rds\")\njsonlite::toJSON(sales[1], pretty = TRUE)\n\n[\n  {\n    \"gender\": [\"Female\"],\n    \"first_name\": [\"Kimberly\"],\n    \"last_name\": [\"Beckstead\"],\n    \"age\": [24],\n    \"phone_number\": [\"216-555-2549\"],\n    \"purchases\": [\n      {\n        \"SetID\": [24701],\n        \"Number\": [\"76062\"],\n        \"Theme\": [\"DC Comics Super Heroes\"],\n        \"Subtheme\": [\"Mighty Micros\"],\n        \"Year\": [2016],\n        \"Name\": [\"Robin vs. Bane\"],\n        \"Pieces\": [77],\n        \"USPrice\": [9.99],\n        \"ImageURL\": [\"http://images.brickset.com/sets/images/76062-1.jpg\"],\n        \"Quantity\": [1]\n      }\n    ]\n  }\n] \n\n\n]"
  },
  {
    "objectID": "slides/02_Data_Management.html#purrr-solution",
    "href": "slides/02_Data_Management.html#purrr-solution",
    "title": "Data Management with tidyr",
    "section": "purrr solution",
    "text": "purrr solution\n\nsales %&gt;%\n  purrr::map_dfr(\n    function(l) {\n      purchases &lt;- purrr::map_dfr(l$purchases, ~.)\n      l$purchases &lt;- NULL\n      \n      bind_cols(as_tibble(l), purchases)\n    }\n  )\n\n]"
  },
  {
    "objectID": "slides/02_Data_Management.html#purr-solution",
    "href": "slides/02_Data_Management.html#purr-solution",
    "title": "Data Management with tidyr",
    "section": "purr solution",
    "text": "purr solution\n\n\n# A tibble: 620 × 15\n   gender first_name last_name      age phone_number SetID Number Theme Subtheme\n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   \n 1 Female Kimberly   Beckstead       24 216-555-2549 24701 76062  DC C… \"Mighty…\n 2 Male   Neel       Garvin          35 819-555-3189 25626 70595  Ninj… \"Rise o…\n 3 Male   Neel       Garvin          35 819-555-3189 24665 21031  Arch… \"\"      \n 4 Female Chelsea    Bouchard        41 &lt;NA&gt;         24695 31048  Crea… \"\"      \n 5 Female Chelsea    Bouchard        41 &lt;NA&gt;         25626 70595  Ninj… \"Rise o…\n 6 Female Chelsea    Bouchard        41 &lt;NA&gt;         24721 10831  Duplo \"\"      \n 7 Female Bryanna    Welsh           19 &lt;NA&gt;         24797 75138  Star… \"Episod…\n 8 Female Bryanna    Welsh           19 &lt;NA&gt;         24701 76062  DC C… \"Mighty…\n 9 Male   Caleb      Garcia-Wide…    37 907-555-9236 24730 41115  Frie… \"\"      \n10 Male   Caleb      Garcia-Wide…    37 907-555-9236 25611 21127  Mine… \"Minifi…\n# ℹ 610 more rows\n# ℹ 6 more variables: Year &lt;int&gt;, Name &lt;chr&gt;, Pieces &lt;int&gt;, USPrice &lt;dbl&gt;,\n#   ImageURL &lt;chr&gt;, Quantity &lt;dbl&gt;\n\n\n]"
  },
  {
    "objectID": "slides/02_Data_Management.html#a-tidyr-solution",
    "href": "slides/02_Data_Management.html#a-tidyr-solution",
    "title": "Data Management with tidyr",
    "section": "A tidyr solution",
    "text": "A tidyr solution\n\ntibble(sales = sales) %&gt;%\n  unnest_wider(sales) %&gt;%\n  unnest_longer(purchases) %&gt;%\n  unnest_wider(purchases)\n\n# A tibble: 620 × 15\n   gender first_name last_name      age phone_number SetID Number Theme Subtheme\n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   \n 1 Female Kimberly   Beckstead       24 216-555-2549 24701 76062  DC C… \"Mighty…\n 2 Male   Neel       Garvin          35 819-555-3189 25626 70595  Ninj… \"Rise o…\n 3 Male   Neel       Garvin          35 819-555-3189 24665 21031  Arch… \"\"      \n 4 Female Chelsea    Bouchard        41 &lt;NA&gt;         24695 31048  Crea… \"\"      \n 5 Female Chelsea    Bouchard        41 &lt;NA&gt;         25626 70595  Ninj… \"Rise o…\n 6 Female Chelsea    Bouchard        41 &lt;NA&gt;         24721 10831  Duplo \"\"      \n 7 Female Bryanna    Welsh           19 &lt;NA&gt;         24797 75138  Star… \"Episod…\n 8 Female Bryanna    Welsh           19 &lt;NA&gt;         24701 76062  DC C… \"Mighty…\n 9 Male   Caleb      Garcia-Wide…    37 907-555-9236 24730 41115  Frie… \"\"      \n10 Male   Caleb      Garcia-Wide…    37 907-555-9236 25611 21127  Mine… \"Minifi…\n# ℹ 610 more rows\n# ℹ 6 more variables: Year &lt;int&gt;, Name &lt;chr&gt;, Pieces &lt;int&gt;, USPrice &lt;dbl&gt;,\n#   ImageURL &lt;chr&gt;, Quantity &lt;dbl&gt;\n\n\n]"
  },
  {
    "objectID": "slides/02_Data_Management.html#tidyr-solution-step-1",
    "href": "slides/02_Data_Management.html#tidyr-solution-step-1",
    "title": "Data Management with tidyr",
    "section": "tidyr solution (Step 1)",
    "text": "tidyr solution (Step 1)\n\ntibble(sales = sales)\n\n# A tibble: 250 × 1\n   sales           \n   &lt;list&gt;          \n 1 &lt;named list [6]&gt;\n 2 &lt;named list [6]&gt;\n 3 &lt;named list [5]&gt;\n 4 &lt;named list [5]&gt;\n 5 &lt;named list [6]&gt;\n 6 &lt;named list [6]&gt;\n 7 &lt;named list [6]&gt;\n 8 &lt;named list [6]&gt;\n 9 &lt;named list [6]&gt;\n10 &lt;named list [6]&gt;\n# ℹ 240 more rows\n\n\n]"
  },
  {
    "objectID": "slides/02_Data_Management.html#tidyr-solution-step-2",
    "href": "slides/02_Data_Management.html#tidyr-solution-step-2",
    "title": "Data Management with tidyr",
    "section": "tidyr solution (Step 2)",
    "text": "tidyr solution (Step 2)\n\ntibble(sales = sales) %&gt;%\n  unnest_wider(sales)\n\n# A tibble: 250 × 6\n   gender first_name last_name        age phone_number purchases \n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;        &lt;list&gt;    \n 1 Female Kimberly   Beckstead         24 216-555-2549 &lt;list [1]&gt;\n 2 Male   Neel       Garvin            35 819-555-3189 &lt;list [2]&gt;\n 3 Female Chelsea    Bouchard          41 &lt;NA&gt;         &lt;list [3]&gt;\n 4 Female Bryanna    Welsh             19 &lt;NA&gt;         &lt;list [2]&gt;\n 5 Male   Caleb      Garcia-Wideman    37 907-555-9236 &lt;list [2]&gt;\n 6 Male   Chase      Fortenberry       19 205-555-3704 &lt;list [2]&gt;\n 7 Male   Kevin      Cruz              20 947-555-7946 &lt;list [1]&gt;\n 8 Male   Connor     Brown             36 516-555-4310 &lt;list [3]&gt;\n 9 Female Toni       Borison           40 284-555-4560 &lt;list [2]&gt;\n10 Male   Daniel     Hurst             44 251-555-0845 &lt;list [2]&gt;\n# ℹ 240 more rows"
  },
  {
    "objectID": "slides/02_Data_Management.html#tidyr-solution-step-3",
    "href": "slides/02_Data_Management.html#tidyr-solution-step-3",
    "title": "Data Management with tidyr",
    "section": "tidyr solution (Step 3)",
    "text": "tidyr solution (Step 3)\n\ntibble(sales = sales) %&gt;%\n  unnest_wider(sales) %&gt;%\n  unnest_longer(purchases)\n\n# A tibble: 620 × 6\n   gender first_name last_name        age phone_number purchases        \n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;        &lt;list&gt;           \n 1 Female Kimberly   Beckstead         24 216-555-2549 &lt;named list [10]&gt;\n 2 Male   Neel       Garvin            35 819-555-3189 &lt;named list [10]&gt;\n 3 Male   Neel       Garvin            35 819-555-3189 &lt;named list [10]&gt;\n 4 Female Chelsea    Bouchard          41 &lt;NA&gt;         &lt;named list [10]&gt;\n 5 Female Chelsea    Bouchard          41 &lt;NA&gt;         &lt;named list [10]&gt;\n 6 Female Chelsea    Bouchard          41 &lt;NA&gt;         &lt;named list [10]&gt;\n 7 Female Bryanna    Welsh             19 &lt;NA&gt;         &lt;named list [10]&gt;\n 8 Female Bryanna    Welsh             19 &lt;NA&gt;         &lt;named list [10]&gt;\n 9 Male   Caleb      Garcia-Wideman    37 907-555-9236 &lt;named list [10]&gt;\n10 Male   Caleb      Garcia-Wideman    37 907-555-9236 &lt;named list [10]&gt;\n# ℹ 610 more rows"
  },
  {
    "objectID": "slides/02_Data_Management.html#tidyr-solution-step-4",
    "href": "slides/02_Data_Management.html#tidyr-solution-step-4",
    "title": "Data Management with tidyr",
    "section": "tidyr solution (Step 4)",
    "text": "tidyr solution (Step 4)\n\ntibble(sales = sales) %&gt;%\n  unnest_wider(sales) %&gt;%\n  unnest_longer(purchases) %&gt;%\n  unnest_wider(purchases)\n\n# A tibble: 620 × 15\n   gender first_name last_name      age phone_number SetID Number Theme Subtheme\n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   \n 1 Female Kimberly   Beckstead       24 216-555-2549 24701 76062  DC C… \"Mighty…\n 2 Male   Neel       Garvin          35 819-555-3189 25626 70595  Ninj… \"Rise o…\n 3 Male   Neel       Garvin          35 819-555-3189 24665 21031  Arch… \"\"      \n 4 Female Chelsea    Bouchard        41 &lt;NA&gt;         24695 31048  Crea… \"\"      \n 5 Female Chelsea    Bouchard        41 &lt;NA&gt;         25626 70595  Ninj… \"Rise o…\n 6 Female Chelsea    Bouchard        41 &lt;NA&gt;         24721 10831  Duplo \"\"      \n 7 Female Bryanna    Welsh           19 &lt;NA&gt;         24797 75138  Star… \"Episod…\n 8 Female Bryanna    Welsh           19 &lt;NA&gt;         24701 76062  DC C… \"Mighty…\n 9 Male   Caleb      Garcia-Wide…    37 907-555-9236 24730 41115  Frie… \"\"      \n10 Male   Caleb      Garcia-Wide…    37 907-555-9236 25611 21127  Mine… \"Minifi…\n# ℹ 610 more rows\n# ℹ 6 more variables: Year &lt;int&gt;, Name &lt;chr&gt;, Pieces &lt;int&gt;, USPrice &lt;dbl&gt;,\n#   ImageURL &lt;chr&gt;, Quantity &lt;dbl&gt;"
  },
  {
    "objectID": "slides/02_Data_Management.html#dplyr-improvements",
    "href": "slides/02_Data_Management.html#dplyr-improvements",
    "title": "Data Management with the tidyverse",
    "section": "dplyr improvements",
    "text": "dplyr improvements\nAnother common use case for purrr has been working across rows and/or columns of a data frames.\n \nMuch of this functionality is now available directly in dplyr via the across() and rowwise() functions. Additional details and examples are available in the vignettes:\n\ncolumn-wise operations vignette\nrow-wise operations vignette\n\n \nand the dplyr 1.0.0 release blog posts:\n\nworking across columns\nworking within rows"
  },
  {
    "objectID": "slides/02_Data_Management.html#recommended-reading",
    "href": "slides/02_Data_Management.html#recommended-reading",
    "title": "Data Management with tidyr",
    "section": "Recommended reading",
    "text": "Recommended reading\n\nKeep up to date with the tidyverse blog for packages you teach\nFour part blog series: Teaching the Tidyverse from 2020\n\nPart 1: Getting started\nPart 2: Data visualisation\nPart 3: Data wrangling and tidying\nPart 4: When to purrr?"
  },
  {
    "objectID": "slides/02_Data_Management.html#the-larger-tidy-ecosystem",
    "href": "slides/02_Data_Management.html#the-larger-tidy-ecosystem",
    "title": "Data Management with the tidyverse",
    "section": "The larger tidy ecosystem",
    "text": "The larger tidy ecosystem\nJust to name a few…\n\njanitor\nkableExtra\npatchwork\ngghighlight\ntidybayes"
  },
  {
    "objectID": "slides/02_Data_Management.html#credit-to-mine-çetinkaya-rundel",
    "href": "slides/02_Data_Management.html#credit-to-mine-çetinkaya-rundel",
    "title": "Data Management with the tidyverse",
    "section": "Credit to Mine Çetinkaya-Rundel",
    "text": "Credit to Mine Çetinkaya-Rundel\n\nThese notes were built from Mine’s notes\n\nMost pages and code were left as she made them\nI changed a few things to match our class\n\nPlease see her Github repository for the original notes\n\n\n\nData Management"
  },
  {
    "objectID": "slides/02_Data_Management.html#tidy-data1",
    "href": "slides/02_Data_Management.html#tidy-data1",
    "title": "Data Management with the tidyverse",
    "section": "Tidy data1",
    "text": "Tidy data1\n\n\n\n\n\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\nSource: R for Data Science. Grolemund and Wickham."
  },
  {
    "objectID": "slides/02_Data_Management.html#tidyverse-visualising-multiple-variables",
    "href": "slides/02_Data_Management.html#tidyverse-visualising-multiple-variables",
    "title": "Data Management with tidyr",
    "section": "Tidyverse: Visualising multiple variables",
    "text": "Tidyverse: Visualising multiple variables\n \n\nggplot(\n  mtcars,\n  aes(x = disp, y = mpg, color = transmission)\n) +\n  geom_point()"
  },
  {
    "objectID": "slides/02_Data_Management.html#poll-everywhere-question",
    "href": "slides/02_Data_Management.html#poll-everywhere-question",
    "title": "Data Management with tidyr",
    "section": "Poll Everywhere Question",
    "text": "Poll Everywhere Question\nWhat would you change on the following plot? click areas that you would make changes."
  },
  {
    "objectID": "slides/02_Data_Management.html#tidyverse-visualising-even-more-variables",
    "href": "slides/02_Data_Management.html#tidyverse-visualising-even-more-variables",
    "title": "Data Management with tidyr",
    "section": "Tidyverse: Visualising even more variables",
    "text": "Tidyverse: Visualising even more variables\n\nggplot(\n  mtcars,\n  aes(x = disp, y = mpg, color = transmission)\n) +\n  geom_point() +\n  facet_wrap(~ cyl)"
  },
  {
    "objectID": "slides/02_Data_Management.html#base-r-visualising-even-more-variables",
    "href": "slides/02_Data_Management.html#base-r-visualising-even-more-variables",
    "title": "Data Management with tidyr",
    "section": "Base R: Visualising even more variables",
    "text": "Base R: Visualising even more variables\n\nmtcars$trans_color &lt;- ifelse(mtcars$transmission == \"automatic\", \"green\", \"blue\")\nmtcars_cyl4 = mtcars[mtcars$cyl == 4, ]\nmtcars_cyl6 = mtcars[mtcars$cyl == 6, ]\nmtcars_cyl8 = mtcars[mtcars$cyl == 8, ]\npar(mfrow = c(1, 3), mar = c(2.5, 2.5, 2, 0), mgp = c(1.5, 0.5, 0))\nplot(mpg ~ disp, data = mtcars_cyl4, col = trans_color, main = \"Cyl 4\")\nplot(mpg ~ disp, data = mtcars_cyl6, col = trans_color, main = \"Cyl 6\")\nplot(mpg ~ disp, data = mtcars_cyl8, col = trans_color, main = \"Cyl 8\")\nlegend(\"topright\", legend = c(\"automatic\", \"manual\"), pch = 1, col = c(\"green\", \"blue\"))"
  },
  {
    "objectID": "slides/02_Data_Management.html#tidyverse-visualizing-multiple-variables",
    "href": "slides/02_Data_Management.html#tidyverse-visualizing-multiple-variables",
    "title": "Data Management with the tidyverse",
    "section": "Tidyverse: Visualizing multiple variables",
    "text": "Tidyverse: Visualizing multiple variables\n \n\nggplot(\n  mtcars,\n  aes(x = disp, y = mpg, color = transmission)) +\n  geom_point()"
  },
  {
    "objectID": "slides/02_Data_Management.html#poll-everywhere-question-1",
    "href": "slides/02_Data_Management.html#poll-everywhere-question-1",
    "title": "Data Management with the tidyverse",
    "section": "Poll Everywhere Question 1",
    "text": "Poll Everywhere Question 1"
  },
  {
    "objectID": "slides/02_Data_Management.html#tidyverse-visualizing-even-more-variables",
    "href": "slides/02_Data_Management.html#tidyverse-visualizing-even-more-variables",
    "title": "Data Management with the tidyverse",
    "section": "Tidyverse: Visualizing even more variables",
    "text": "Tidyverse: Visualizing even more variables\n\nggplot(\n  mtcars,\n  aes(x = disp, y = mpg, color = transmission)) +\n  geom_point() +\n  facet_wrap(~ cyl)"
  },
  {
    "objectID": "slides/02_Data_Management.html#base-r-visualizing-even-more-variables",
    "href": "slides/02_Data_Management.html#base-r-visualizing-even-more-variables",
    "title": "Data Management with the tidyverse",
    "section": "Base R: Visualizing even more variables",
    "text": "Base R: Visualizing even more variables\n\nmtcars$trans_color &lt;- ifelse(mtcars$transmission == \"automatic\", \"green\", \"blue\")\nmtcars_cyl4 = mtcars[mtcars$cyl == 4, ]\nmtcars_cyl6 = mtcars[mtcars$cyl == 6, ]\nmtcars_cyl8 = mtcars[mtcars$cyl == 8, ]\npar(mfrow = c(1, 3), mar = c(2.5, 2.5, 2, 0), mgp = c(1.5, 0.5, 0))\nplot(mpg ~ disp, data = mtcars_cyl4, col = trans_color, main = \"Cyl 4\")\nplot(mpg ~ disp, data = mtcars_cyl6, col = trans_color, main = \"Cyl 6\")\nplot(mpg ~ disp, data = mtcars_cyl8, col = trans_color, main = \"Cyl 8\")\nlegend(\"topright\", legend = c(\"automatic\", \"manual\"), pch = 1, col = c(\"green\", \"blue\"))"
  },
  {
    "objectID": "slides/02_Data_Management.html#ggplot2-in-tidyverse-1",
    "href": "slides/02_Data_Management.html#ggplot2-in-tidyverse-1",
    "title": "Data Management with tidyr",
    "section": "ggplot2 \\(\\in\\) tidyverse",
    "text": "ggplot2 \\(\\in\\) tidyverse\n\n\nggplot2 is tidyverse’s data visualization package - The gg in “ggplot2” stands for Grammar of Graphics - It is inspired by the book Grammar of Graphics by Leland Wilkinson]"
  },
  {
    "objectID": "slides/02_Data_Management.html#introduction-to-some-important-reshaping-functions",
    "href": "slides/02_Data_Management.html#introduction-to-some-important-reshaping-functions",
    "title": "Data Management with the tidyverse",
    "section": "Introduction to some important reshaping functions",
    "text": "Introduction to some important reshaping functions\n\npivot_longer() and pivot_wider()\nmutate()\nacross()\nfilter()\nselect()\nrename()\n\nSummarizing data\n\ntabyl() from janitor package to make frequency tables of categorical variables\ntbl_summary()\nsummarize() to get summary statistics of variables\ngroup_by() to group data by categorical variables before finding summaries"
  },
  {
    "objectID": "slides/02_Data_Management.html#poll-everywhere-question-2",
    "href": "slides/02_Data_Management.html#poll-everywhere-question-2",
    "title": "Data Management with the tidyverse",
    "section": "Poll Everywhere Question 2",
    "text": "Poll Everywhere Question 2"
  },
  {
    "objectID": "slides/02_Data_Management.html#footnotes",
    "href": "slides/02_Data_Management.html#footnotes",
    "title": "Data Management with tidyr",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSource: R for Data Science. Grolemund and Wickham.↩︎"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Here is a list of the major resources that have been mentioned in class:\n\nCourse sites\n\n\n\nResource\nLink\nClass Mentioned\n\n\n\n\nMeike’s 511 Website\n\nReview\n\n\nJessica’s R programming class site\n\nData Management\n\n\n\n\n\n\n\n\n\n\nR coding\n\n\n\nResource\nLink\nClass Mentioned\n\n\n\n\nggplot histograms\n\nReview\n\n\nProbability distributions and their R code\n\nReview\n\n\nVarious hypothesis tests and their R code\n\nReview\n\n\nJessica’s R programming class site\n\nData Management\n\n\n\n\n\n\n\n\n\n\nAcademic Help\n\n\n\nResource\nLink\nClass Mentioned\n\n\n\n\nStudent Academic Support Services\n\nIntro"
  },
  {
    "objectID": "resources.html#course-sites",
    "href": "resources.html#course-sites",
    "title": "Resources",
    "section": "Course sites:",
    "text": "Course sites:\n\n\n\nResource\nLink\nClass Mentioned\n\n\n\n\nMeike’s 511 Website\n\nReview\n\n\nJessica’s R programming class site\n\nData Management"
  },
  {
    "objectID": "resources.html#r-coding",
    "href": "resources.html#r-coding",
    "title": "Resources",
    "section": "R coding:",
    "text": "R coding:\n\n\n\nResource\nLink\nClass Mentioned\n\n\n\n\nggplot histograms\n\nReview\n\n\nProbability distributions and their R code\n\nReview\n\n\nVarious hypothesis tests and their R code\n\nReview\n\n\nJessica’s R programming class site\n\nData Management"
  },
  {
    "objectID": "resources.html#academic-help",
    "href": "resources.html#academic-help",
    "title": "Resources",
    "section": "Academic Help:",
    "text": "Academic Help:\n\n\n\nResource\nLink\nClass Mentioned\n\n\n\n\nStudent Academic Support Services\n\nIntro"
  },
  {
    "objectID": "slides/02_Data_Management.html#section",
    "href": "slides/02_Data_Management.html#section",
    "title": "Data Management with the tidyverse",
    "section": "",
    "text": "Artwork by @allison_horst"
  },
  {
    "objectID": "slides/02_Data_Management.html#what-is-the-tidyverse",
    "href": "slides/02_Data_Management.html#what-is-the-tidyverse",
    "title": "Data Management with the tidyverse",
    "section": "What is the tidyverse?",
    "text": "What is the tidyverse?\nThe tidyverse is a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.\n\n\n\nggplot2 - data visualisation\ndplyr - data manipulation\ntidyr - tidy data\nreadr - read rectangular data\npurrr - functional programming\ntibble - modern data frames\nstringr - string manipulation\nforcats - factors\nand many more …"
  },
  {
    "objectID": "slides/02_Data_Management.html#dplyr-resources",
    "href": "slides/02_Data_Management.html#dplyr-resources",
    "title": "Data Management with the tidyverse",
    "section": "dplyr resources",
    "text": "dplyr resources\n\nMore dpylr functions to reference!\n\nAdditional details and examples are available in the vignettes:\n\ncolumn-wise operations vignette\nrow-wise operations vignette\n\n \nand the dplyr 1.0.0 release blog posts:\n\nworking across columns\nworking within rows"
  },
  {
    "objectID": "slides/02_Data_Management.html#pivot-staff-data-and-mutate-percentage",
    "href": "slides/02_Data_Management.html#pivot-staff-data-and-mutate-percentage",
    "title": "Data Management with the tidyverse",
    "section": "Pivot staff data and mutate percentage",
    "text": "Pivot staff data and mutate percentage\n\n(staff_long &lt;- staff %&gt;%\n  pivot_longer(\n    cols = -faculty_type,    # columns to pivot\n    names_to = \"year\",       # name of new column for variable names\n    values_to = \"percentage\" # name of new column for values\n  ) %&gt;%\n  mutate(percentage = as.numeric(percentage))\n)\n\n# A tibble: 55 × 3\n   faculty_type              year  percentage\n   &lt;chr&gt;                     &lt;chr&gt;      &lt;dbl&gt;\n 1 Full-Time Tenured Faculty 1975        29  \n 2 Full-Time Tenured Faculty 1989        27.6\n 3 Full-Time Tenured Faculty 1993        25  \n 4 Full-Time Tenured Faculty 1995        24.8\n 5 Full-Time Tenured Faculty 1999        21.8\n 6 Full-Time Tenured Faculty 2001        20.3\n 7 Full-Time Tenured Faculty 2003        19.3\n 8 Full-Time Tenured Faculty 2005        17.8\n 9 Full-Time Tenured Faculty 2007        17.2\n10 Full-Time Tenured Faculty 2009        16.8\n# ℹ 45 more rows"
  },
  {
    "objectID": "slides/02_Data_Management.html#across",
    "href": "slides/02_Data_Management.html#across",
    "title": "Data Management with the tidyverse",
    "section": "across()",
    "text": "across()"
  },
  {
    "objectID": "slides/02_Data_Management.html#filter",
    "href": "slides/02_Data_Management.html#filter",
    "title": "Data Management with the tidyverse",
    "section": "filter()",
    "text": "filter()"
  },
  {
    "objectID": "slides/02_Data_Management.html#select",
    "href": "slides/02_Data_Management.html#select",
    "title": "Data Management with the tidyverse",
    "section": "select()",
    "text": "select()\nselect()"
  },
  {
    "objectID": "slides/02_Data_Management.html#rename",
    "href": "slides/02_Data_Management.html#rename",
    "title": "Data Management with the tidyverse",
    "section": "Rename",
    "text": "Rename\n\nrename()"
  },
  {
    "objectID": "slides/02_Data_Management.html#important-functions-for-data-management",
    "href": "slides/02_Data_Management.html#important-functions-for-data-management",
    "title": "Data Management with the tidyverse",
    "section": "Important functions for data management",
    "text": "Important functions for data management\n \nData manipulation\n\npivot_longer() and pivot_wider()\nrename()\nmutate()\nfilter()\nselect()\n\nSummarizing data\n\ntbl_summary()\ngroup_by()\nsummarize()\nacross()"
  },
  {
    "objectID": "slides/02_Data_Management.html#lets-look-back-at-the-dds.discr-dataset-that-i-birefly-used-last-class",
    "href": "slides/02_Data_Management.html#lets-look-back-at-the-dds.discr-dataset-that-i-birefly-used-last-class",
    "title": "Data Management with the tidyverse",
    "section": "Let’s look back at the dds.discr dataset that I birefly used last class",
    "text": "Let’s look back at the dds.discr dataset that I birefly used last class\n   \n\nWe will load the data (This is a special case! dds.discr is a built-in R dataset)\n\n\ndata(\"dds.discr\")\n\n\nNow, let’s take a glimpse at the dataset:\n\n\nglimpse(dds.discr)\n\nRows: 1,000\nColumns: 6\n$ id           &lt;int&gt; 10210, 10409, 10486, 10538, 10568, 10690, 10711, 10778, 1…\n$ age.cohort   &lt;fct&gt; 13-17, 22-50, 0-5, 18-21, 13-17, 13-17, 13-17, 13-17, 13-…\n$ age          &lt;int&gt; 17, 37, 3, 19, 13, 15, 13, 17, 14, 13, 13, 14, 15, 17, 20…\n$ gender       &lt;fct&gt; Female, Male, Male, Female, Male, Female, Female, Male, F…\n$ expenditures &lt;int&gt; 2113, 41924, 1454, 6400, 4412, 4566, 3915, 3873, 5021, 28…\n$ ethnicity    &lt;fct&gt; White not Hispanic, White not Hispanic, Hispanic, Hispani…"
  },
  {
    "objectID": "slides/02_Data_Management.html#important-functions-for-data-management-1",
    "href": "slides/02_Data_Management.html#important-functions-for-data-management-1",
    "title": "Data Management with the tidyverse",
    "section": "Important functions for data management",
    "text": "Important functions for data management\nData manipulation\n\npivot_longer() and pivot_wider()\nrename()\nmutate()\nfilter()\nselect()\n\nSummarizing data\n\ntabyl() from janitor package to make frequency tables of categorical variables\ntbl_summary()\nsummarize() to get summary statistics of variables\ngroup_by() to group data by categorical variables before finding summaries\nacross()"
  },
  {
    "objectID": "slides/02_Data_Management.html#rename-one-of-the-first-things-i-usually-do",
    "href": "slides/02_Data_Management.html#rename-one-of-the-first-things-i-usually-do",
    "title": "Data Management with the tidyverse",
    "section": "rename(): one of the first things I usually do",
    "text": "rename(): one of the first things I usually do\n\nI notice that two variables have values that don’t necessarily match the variable name\n\nFemale and male are not genders\n“White not Hispanic” combines race and ethnicity into one category\n\n\n\nI want to rename gender to SAB (sex assigned at birth) and rename ethnicity to R_E (race and ethnicity)\n\n \n\ndds.discr1 = dds.discr %&gt;% \n  rename(SAB = gender, \n         R_E = ethnicity)\n\nglimpse(dds.discr1)\n\nRows: 1,000\nColumns: 6\n$ id           &lt;int&gt; 10210, 10409, 10486, 10538, 10568, 10690, 10711, 10778, 1…\n$ age.cohort   &lt;fct&gt; 13-17, 22-50, 0-5, 18-21, 13-17, 13-17, 13-17, 13-17, 13-…\n$ age          &lt;int&gt; 17, 37, 3, 19, 13, 15, 13, 17, 14, 13, 13, 14, 15, 17, 20…\n$ SAB          &lt;fct&gt; Female, Male, Male, Female, Male, Female, Female, Male, F…\n$ expenditures &lt;int&gt; 2113, 41924, 1454, 6400, 4412, 4566, 3915, 3873, 5021, 28…\n$ R_E          &lt;fct&gt; White not Hispanic, White not Hispanic, Hispanic, Hispani…"
  },
  {
    "objectID": "slides/02_Data_Management.html#mutate-constructing-new-variables-from-what-you-have",
    "href": "slides/02_Data_Management.html#mutate-constructing-new-variables-from-what-you-have",
    "title": "Data Management with the tidyverse",
    "section": "mutate(): constructing new variables from what you have",
    "text": "mutate(): constructing new variables from what you have\n\nWe’ve seen a couple examples for mutate() so far (mostly because its used so often!)\nWe haven’t seen an example where we make a new variable from two variables\n\n\nI want to make a variable that is the ratio of expenditures over age\n\n \n\ndds.discr2 = dds.discr1 %&gt;%\n  mutate(exp_to_age = expenditures/age)\n\nglimpse(dds.discr2)\n\nRows: 1,000\nColumns: 7\n$ id           &lt;int&gt; 10210, 10409, 10486, 10538, 10568, 10690, 10711, 10778, 1…\n$ age.cohort   &lt;fct&gt; 13-17, 22-50, 0-5, 18-21, 13-17, 13-17, 13-17, 13-17, 13-…\n$ age          &lt;int&gt; 17, 37, 3, 19, 13, 15, 13, 17, 14, 13, 13, 14, 15, 17, 20…\n$ SAB          &lt;fct&gt; Female, Male, Male, Female, Male, Female, Female, Male, F…\n$ expenditures &lt;int&gt; 2113, 41924, 1454, 6400, 4412, 4566, 3915, 3873, 5021, 28…\n$ R_E          &lt;fct&gt; White not Hispanic, White not Hispanic, Hispanic, Hispani…\n$ exp_to_age   &lt;dbl&gt; 124.2941, 1133.0811, 484.6667, 336.8421, 339.3846, 304.40…"
  },
  {
    "objectID": "slides/02_Data_Management.html#poll-everywhere-question-3",
    "href": "slides/02_Data_Management.html#poll-everywhere-question-3",
    "title": "Data Management with the tidyverse",
    "section": "Poll Everywhere Question 3",
    "text": "Poll Everywhere Question 3"
  },
  {
    "objectID": "slides/02_Data_Management.html#tabyl",
    "href": "slides/02_Data_Management.html#tabyl",
    "title": "Data Management with the tidyverse",
    "section": "tabyl():",
    "text": "tabyl():\n\n\n\nlibrary(janitor)\n\ndds.discr2 %&gt;% \n  tabyl(R_E)  \n\n                R_E   n percent\n    American Indian   4   0.004\n              Asian 129   0.129\n              Black  59   0.059\n           Hispanic 376   0.376\n         Multi Race  26   0.026\n    Native Hawaiian   3   0.003\n              Other   2   0.002\n White not Hispanic 401   0.401\n\n\n\n\ndds.discr2 %&gt;% \n  tabyl(R_E) %&gt;%\n  adorn_totals(\"row\") %&gt;% \n  adorn_pct_formatting(digits=2)   \n\n                R_E    n percent\n    American Indian    4   0.40%\n              Asian  129  12.90%\n              Black   59   5.90%\n           Hispanic  376  37.60%\n         Multi Race   26   2.60%\n    Native Hawaiian    3   0.30%\n              Other    2   0.20%\n White not Hispanic  401  40.10%\n              Total 1000 100.00%"
  },
  {
    "objectID": "slides/02_Data_Management.html#tbl_summary",
    "href": "slides/02_Data_Management.html#tbl_summary",
    "title": "Data Management with the tidyverse",
    "section": "tbl_summary()",
    "text": "tbl_summary()"
  },
  {
    "objectID": "slides/02_Data_Management.html#summarize",
    "href": "slides/02_Data_Management.html#summarize",
    "title": "Data Management with the tidyverse",
    "section": "summarize()",
    "text": "summarize()"
  },
  {
    "objectID": "slides/02_Data_Management.html#group_by",
    "href": "slides/02_Data_Management.html#group_by",
    "title": "Data Management with the tidyverse",
    "section": "group_by()",
    "text": "group_by()"
  },
  {
    "objectID": "slides/02_Data_Management.html#r-programming-class-at-ohsu",
    "href": "slides/02_Data_Management.html#r-programming-class-at-ohsu",
    "title": "Data Management with the tidyverse",
    "section": "R programming class at OHSU!",
    "text": "R programming class at OHSU!\nYou can check out Dr. Jessica Minnier’s R class page if you want more notes, videos, etc."
  },
  {
    "objectID": "slides/02_Data_Management.html#lets-look-back-at-the-dds.discr-dataset-that-i-briefly-used-last-class",
    "href": "slides/02_Data_Management.html#lets-look-back-at-the-dds.discr-dataset-that-i-briefly-used-last-class",
    "title": "Data Management with the tidyverse",
    "section": "Let’s look back at the dds.discr dataset that I briefly used last class",
    "text": "Let’s look back at the dds.discr dataset that I briefly used last class\n   \n\nWe will load the data (This is a special case! dds.discr is a built-in R dataset)\n\n\ndata(\"dds.discr\")\n\n\nNow, let’s take a glimpse at the dataset:\n\n\nglimpse(dds.discr)\n\nRows: 1,000\nColumns: 6\n$ id           &lt;int&gt; 10210, 10409, 10486, 10538, 10568, 10690, 10711, 10778, 1…\n$ age.cohort   &lt;fct&gt; 13-17, 22-50, 0-5, 18-21, 13-17, 13-17, 13-17, 13-17, 13-…\n$ age          &lt;int&gt; 17, 37, 3, 19, 13, 15, 13, 17, 14, 13, 13, 14, 15, 17, 20…\n$ gender       &lt;fct&gt; Female, Male, Male, Female, Male, Female, Female, Male, F…\n$ expenditures &lt;int&gt; 2113, 41924, 1454, 6400, 4412, 4566, 3915, 3873, 5021, 28…\n$ ethnicity    &lt;fct&gt; White not Hispanic, White not Hispanic, Hispanic, Hispani…"
  },
  {
    "objectID": "slides/02_Data_Management.html#tbl_summary-table-summary",
    "href": "slides/02_Data_Management.html#tbl_summary-table-summary",
    "title": "Data Management with the tidyverse",
    "section": "tbl_summary() : table summary",
    "text": "tbl_summary() : table summary\n\nWhat if I want one of those fancy summary tables that are at the top of most research articles? (lovingly called “Table 1”)\n\n\n\n\nlibrary(gtsummary)\ntbl_summary(dds.discr2)\n\n\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 1,0001\n    \n  \n  \n    id\n55,385 (31,809, 76,135)\n    age.cohort\n\n        0-5\n82 (8.2%)\n        6-12\n175 (18%)\n        13-17\n212 (21%)\n        18-21\n199 (20%)\n        22-50\n226 (23%)\n        51+\n106 (11%)\n    age\n18 (12, 26)\n    SAB\n\n        Female\n503 (50%)\n        Male\n497 (50%)\n    expenditures\n7,026 (2,899, 37,713)\n    R_E\n\n        American Indian\n4 (0.4%)\n        Asian\n129 (13%)\n        Black\n59 (5.9%)\n        Hispanic\n376 (38%)\n        Multi Race\n26 (2.6%)\n        Native Hawaiian\n3 (0.3%)\n        Other\n2 (0.2%)\n        White not Hispanic\n401 (40%)\n    exp_to_age\n462 (274, 938)\n  \n  \n  \n    \n      1 Median (IQR); n (%)"
  },
  {
    "objectID": "slides/02_Data_Management.html#tbl_summary-table-summary-12",
    "href": "slides/02_Data_Management.html#tbl_summary-table-summary-12",
    "title": "Data Management with the tidyverse",
    "section": "tbl_summary() : table summary (1/2)",
    "text": "tbl_summary() : table summary (1/2)\n\nWhat if I want one of those fancy summary tables that are at the top of most research articles? (lovingly called “Table 1”)\n\n\n\n\nlibrary(gtsummary)\ntbl_summary(dds.discr2)\n\n\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 1,0001\n    \n  \n  \n    id\n55,385 (31,809, 76,135)\n    age.cohort\n\n        0-5\n82 (8.2%)\n        6-12\n175 (18%)\n        13-17\n212 (21%)\n        18-21\n199 (20%)\n        22-50\n226 (23%)\n        51+\n106 (11%)\n    age\n18 (12, 26)\n    SAB\n\n        Female\n503 (50%)\n        Male\n497 (50%)\n    expenditures\n7,026 (2,899, 37,713)\n    R_E\n\n        American Indian\n4 (0.4%)\n        Asian\n129 (13%)\n        Black\n59 (5.9%)\n        Hispanic\n376 (38%)\n        Multi Race\n26 (2.6%)\n        Native Hawaiian\n3 (0.3%)\n        Other\n2 (0.2%)\n        White not Hispanic\n401 (40%)\n    exp_to_age\n462 (274, 938)\n  \n  \n  \n    \n      1 Median (IQR); n (%)"
  },
  {
    "objectID": "slides/02_Data_Management.html#tbl_summary-table-summary-22",
    "href": "slides/02_Data_Management.html#tbl_summary-table-summary-22",
    "title": "Data Management with the tidyverse",
    "section": "tbl_summary() : table summary (2/2)",
    "text": "tbl_summary() : table summary (2/2)\n\nLet’s make this more presentable\n\n \n\n\n\ndds.discr2 %&gt;%\n  select(-id, -age.cohort, -exp_to_age) %&gt;%\n  tbl_summary(label = c(age ~ \"Age\", \n                        R_E ~ \"Race/Ethnicity\", \n                        SAB ~ \"Sex Assigned at Birth\", \n                        expenditures ~ \"Expenditures\") ,\n              statistic = list(all_continuous() ~ \"{mean} ({sd})\"))\n\n\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 1,0001\n    \n  \n  \n    Age\n23 (18)\n    Sex Assigned at Birth\n\n        Female\n503 (50%)\n        Male\n497 (50%)\n    Expenditures\n18,066 (19,543)\n    Race/Ethnicity\n\n        American Indian\n4 (0.4%)\n        Asian\n129 (13%)\n        Black\n59 (5.9%)\n        Hispanic\n376 (38%)\n        Multi Race\n26 (2.6%)\n        Native Hawaiian\n3 (0.3%)\n        Other\n2 (0.2%)\n        White not Hispanic\n401 (40%)\n  \n  \n  \n    \n      1 Mean (SD); n (%)"
  },
  {
    "objectID": "slides/02_Data_Management.html#filter-keep-rows-that-match-a-condition",
    "href": "slides/02_Data_Management.html#filter-keep-rows-that-match-a-condition",
    "title": "Data Management with the tidyverse",
    "section": "filter(): keep rows that match a condition",
    "text": "filter(): keep rows that match a condition\n\nWhat if I want to subset the data frame? (keep certain rows of observations)\n\n\nI want to look at the data for people who between 50 and 60 years old\n\n \n\ndds.discr3 = dds.discr2 %&gt;%\n  filter(age &gt;= 50 & age &lt;= 60)\n\nglimpse(dds.discr3)\n\nRows: 23\nColumns: 7\n$ id           &lt;int&gt; 15970, 19412, 29506, 31658, 36123, 39287, 39672, 43455, 4…\n$ age.cohort   &lt;fct&gt; 51+, 51+, 51+, 51+, 51+, 51+, 51+, 51+, 51+, 51+, 51+, 51…\n$ age          &lt;int&gt; 51, 60, 56, 60, 59, 59, 54, 57, 52, 57, 55, 52, 59, 54, 5…\n$ SAB          &lt;fct&gt; Female, Female, Female, Female, Male, Female, Female, Mal…\n$ expenditures &lt;int&gt; 54267, 57702, 48215, 46873, 42739, 44734, 52833, 48363, 5…\n$ R_E          &lt;fct&gt; White not Hispanic, White not Hispanic, White not Hispani…\n$ exp_to_age   &lt;dbl&gt; 1064.0588, 961.7000, 860.9821, 781.2167, 724.3898, 758.20…"
  },
  {
    "objectID": "slides/02_Data_Management.html#select-keep-or-drop-columns-using-their-names-and-types",
    "href": "slides/02_Data_Management.html#select-keep-or-drop-columns-using-their-names-and-types",
    "title": "Data Management with the tidyverse",
    "section": "select(): keep or drop columns using their names and types",
    "text": "select(): keep or drop columns using their names and types\n\nWhat if I want to remove or keep certain variables?\n\n\nI want to only have age and expenditure in my data frame\n\n \n\ndds.discr4 = dds.discr2 %&gt;%\n  select(age, expenditures)\n\nglimpse(dds.discr4)\n\nRows: 1,000\nColumns: 2\n$ age          &lt;int&gt; 17, 37, 3, 19, 13, 15, 13, 17, 14, 13, 13, 14, 15, 17, 20…\n$ expenditures &lt;int&gt; 2113, 41924, 1454, 6400, 4412, 4566, 3915, 3873, 5021, 28…"
  },
  {
    "objectID": "slides/02_Data_Management.html#summarize-summarize-your-data-or-grouped-data-into-one-row",
    "href": "slides/02_Data_Management.html#summarize-summarize-your-data-or-grouped-data-into-one-row",
    "title": "Data Management with the tidyverse",
    "section": "summarize(): summarize your data or grouped data into one row",
    "text": "summarize(): summarize your data or grouped data into one row\n\nWhat if I want to calculate specific descriptive statistics for my variables?\nThis function is often best used with group_by()\nIf only presenting the summaries, functions like tbl_summary() is better\nsummarize() creates a new data frame, which means you can plot and manipulate the summarized data\n\n \n\n\nOver whole sample:\n\ndds.discr2 %&gt;% \n  summarize(\n    ave = mean(expenditures),\n    SD = sd(expenditures),\n    med = median(expenditures))\n\n# A tibble: 1 × 3\n     ave     SD   med\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 18066. 19543.  7026\n\n\n\nGrouped by sex assigned at birth:\n\ndds.discr2 %&gt;% \n  group_by(SAB) %&gt;% \n  summarize(\n    ave = mean(expenditures),\n    SD = sd(expenditures),\n    med = median(expenditures))\n\n# A tibble: 2 × 4\n  SAB       ave     SD   med\n  &lt;fct&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;\n1 Female 18130. 20020.  6400\n2 Male   18001. 19068.  7219"
  },
  {
    "objectID": "slides/02_Data_Management.html#group_by-group-by-one-or-more-variables",
    "href": "slides/02_Data_Management.html#group_by-group-by-one-or-more-variables",
    "title": "Data Management with the tidyverse",
    "section": "group_by(): group by one or more variables",
    "text": "group_by(): group by one or more variables\n\nWhat if I want to quickly look at group differences?\nIt will not change how the data look, but changes the actions of following functions\n\n\nI want to group my data by sex assigned at birth.\n\n \n\ndds.discr5 = dds.discr2 %&gt;%\n  group_by(SAB)\nglimpse(dds.discr5)\n\nRows: 1,000\nColumns: 7\nGroups: SAB [2]\n$ id           &lt;int&gt; 10210, 10409, 10486, 10538, 10568, 10690, 10711, 10778, 1…\n$ age.cohort   &lt;fct&gt; 13-17, 22-50, 0-5, 18-21, 13-17, 13-17, 13-17, 13-17, 13-…\n$ age          &lt;int&gt; 17, 37, 3, 19, 13, 15, 13, 17, 14, 13, 13, 14, 15, 17, 20…\n$ SAB          &lt;fct&gt; Female, Male, Male, Female, Male, Female, Female, Male, F…\n$ expenditures &lt;int&gt; 2113, 41924, 1454, 6400, 4412, 4566, 3915, 3873, 5021, 28…\n$ R_E          &lt;fct&gt; White not Hispanic, White not Hispanic, Hispanic, Hispani…\n$ exp_to_age   &lt;dbl&gt; 124.2941, 1133.0811, 484.6667, 336.8421, 339.3846, 304.40…\n\n\n\nLet’s see how the groups change something like the summarize() function in the next slide"
  },
  {
    "objectID": "slides/02_Data_Management.html#across-apply-a-function-across-multiple-columns",
    "href": "slides/02_Data_Management.html#across-apply-a-function-across-multiple-columns",
    "title": "Data Management with the tidyverse",
    "section": "across(): apply a function across multiple columns",
    "text": "across(): apply a function across multiple columns\n\nLike group_by(), this function is often paired with another transformation function\n\n\nI want all my integer values to have two significant figures.\n\n \n\ndds.discr6 = dds.discr2 %&gt;%\n  mutate(across(where(is.integer), signif, digits = 2))\n\nglimpse(dds.discr6)\n\nRows: 1,000\nColumns: 7\n$ id           &lt;dbl&gt; 10000, 10000, 10000, 11000, 11000, 11000, 11000, 11000, 1…\n$ age.cohort   &lt;fct&gt; 13-17, 22-50, 0-5, 18-21, 13-17, 13-17, 13-17, 13-17, 13-…\n$ age          &lt;dbl&gt; 17, 37, 3, 19, 13, 15, 13, 17, 14, 13, 13, 14, 15, 17, 20…\n$ SAB          &lt;fct&gt; Female, Male, Male, Female, Male, Female, Female, Male, F…\n$ expenditures &lt;dbl&gt; 2100, 42000, 1500, 6400, 4400, 4600, 3900, 3900, 5000, 29…\n$ R_E          &lt;fct&gt; White not Hispanic, White not Hispanic, Hispanic, Hispani…\n$ exp_to_age   &lt;dbl&gt; 124.2941, 1133.0811, 484.6667, 336.8421, 339.3846, 304.40…"
  },
  {
    "objectID": "slides/02_Data_Management.html#recoding-a-binary-variable-with-pipe-operator",
    "href": "slides/02_Data_Management.html#recoding-a-binary-variable-with-pipe-operator",
    "title": "Data Management with the tidyverse",
    "section": "Recoding a binary variable with pipe operator",
    "text": "Recoding a binary variable with pipe operator\n \n\nLet’s say I want a variable transmission to show the category names that are assigned to numeric values in the code. I want 0 to be coded as automatic and 1 to be coded as manual.\n\n \n\n\nBase R:\n\nmtcars$transmission &lt;-\n  ifelse(\n    mtcars$am == 0,\n    \"automatic\",\n    \"manual\"\n  )\n\n\nTidyverse:\n\nmtcars &lt;- mtcars %&gt;%\n  mutate(\n    transmission = case_when(\n      am == 0 ~ \"automatic\",\n      am == 1 ~ \"manual\"\n    )\n  )\n\n \n\nmutate() creates new columns that are functions of existing variables"
  },
  {
    "objectID": "slides/02_Data_Management.html#example-for-pivot_longer-instructional-staff-employment-trends",
    "href": "slides/02_Data_Management.html#example-for-pivot_longer-instructional-staff-employment-trends",
    "title": "Data Management with the tidyverse",
    "section": "Example for pivot_longer(): Instructional staff employment trends",
    "text": "Example for pivot_longer(): Instructional staff employment trends\nThe American Association of University Professors (AAUP) is a nonprofit membership association of faculty and other academic professionals. This report by the AAUP shows trends in instructional staff employees between 1975 and 2011, and contains an image very similar to the one given below."
  },
  {
    "objectID": "slides/02_Data_Management.html#poll-everywhere-question-2-1",
    "href": "slides/02_Data_Management.html#poll-everywhere-question-2-1",
    "title": "Data Management with the tidyverse",
    "section": "Poll Everywhere Question 2",
    "text": "Poll Everywhere Question 2"
  },
  {
    "objectID": "slides/02_Data_Management.html#poll-everywhere-question-3-1",
    "href": "slides/02_Data_Management.html#poll-everywhere-question-3-1",
    "title": "Data Management with the tidyverse",
    "section": "Poll Everywhere Question 3",
    "text": "Poll Everywhere Question 3"
  },
  {
    "objectID": "slides/02_Data_Management.html#a-meh-plot-over-the-years",
    "href": "slides/02_Data_Management.html#a-meh-plot-over-the-years",
    "title": "Data Management with the tidyverse",
    "section": "A “meh” plot over the years",
    "text": "A “meh” plot over the years\n\nggplot(staff_long, aes(x = percentage, y = year, fill = faculty_type)) +\n  geom_col()"
  },
  {
    "objectID": "slides/02_Data_Management.html#all-that-just-to-show-one-helpful-function",
    "href": "slides/02_Data_Management.html#all-that-just-to-show-one-helpful-function",
    "title": "Data Management with the tidyverse",
    "section": "All that just to show one helpful function",
    "text": "All that just to show one helpful function\nNow we can move onto the other functions mentioned:\n \nData manipulation\n\npivot_longer() and pivot_wider()\nrename()\nmutate()\nfilter()\nselect()\n\nSummarizing data\n\ntbl_summary()\ngroup_by()\nsummarize()\nacross()"
  },
  {
    "objectID": "slides/02_Data_Management.html#poll-everywhere-question-4",
    "href": "slides/02_Data_Management.html#poll-everywhere-question-4",
    "title": "Data Management with the tidyverse",
    "section": "Poll Everywhere Question 4",
    "text": "Poll Everywhere Question 4"
  },
  {
    "objectID": "homework/HW1.html#question-1",
    "href": "homework/HW1.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1\nVisit this site on dplyr. https://dplyr.tidyverse.org/reference/index.html#groups\nFor one of the functions that we have not discussed in class, please use it on the dds.discr dataset.\n\nQuestion 1\nPlease use R code to determine the following answers. (adapted from problem 3.3)\n\n\n\n\n\n\nType ?pnorm in the console to get some information on a potentially helpful function.\n\n\n\n\nPart a\nFrom a normal distribution with mean 4 and standard deviation 6, what is \\(P(X&gt;2)\\)?\n\n\nPart b\nFrom a normal distribution with mean 4 and standard deviation 6, for what value (in place of ??) would \\(P(X&gt;??) = 0.1\\)?\n\n\n\nQuestion 2\nSuppose that the height (\\(H\\)) of assigned-male-at-birth (AMAB) patients registered at a clinic has the normal distribution with mean 70 inches and variance 4. (adapted from problem 3.11)\n\nPart a\nFor a random sample of patients of size \\(n = 25\\), the expression \\(P(\\bar{H} &lt; 65)\\), in which \\(\\bar{H}\\) denotes the sample mean height, is equivalent to saying \\(P(Z &lt; ?)\\)\n\n\n\n\n\n\n\\(Z\\) is a standard normal random variable.\n\n\n\n\n\nPart b\nUsing the pnorm function, show that the probability expressions in Part a are equal.\n\n\nPart c\nFind an interval \\((a, b)\\) such that \\(P(a&lt; \\bar{H} &lt;b) = 0.80\\) for the same random sample in Part a.\n\n\n\nQuestion 3\nTest the null hypothesis that the true population average height is the same for two independent groups from one hospital versus the alternative hypothesis that these two population averages are different, using the following data:\n\nGroup 1: [69.25, 72.80, 68.73, 72.01, 70.36, 71.49, 72.73]\nGroup 2: [67.54, 68.51, 71.84, 70.59, 71.52, 71.50]\n\nYou may assume that the populations from which the data come are each normally distributed, with equal population variances. What conclusion should be drawn, with \\(\\alpha = 0.05\\)?\n\n\n\n\n\n\nPlease attempt this problem using R. Take a look at the information for the t.test function. You will need to set x, y, alternative, and var.equal=T. You can use the below groups coded in R.\n\n\n\n\ngrp1 = c(69.25, 72.80, 68.73, 72.01, 70.36, 71.49, 72.73)\ngrp2 = c(67.54, 68.51, 71.84, 70.59, 71.52, 71.50)\n\n\n\nQuestion 4\nThe choice of an alternative hypothesis (\\(H_A\\) or \\(H_1\\)) should depend primarily on (choose all that apply)\n\nthe data obtained from the study.\nwhat the investigator is interested in determining.\nthe critical region.\nthe significance level.\nthe power of the test.\n\n\n\nQuestion 5\nThe accompanying table gives the dry weights (Y ) of 11 chick embryos ranging in age from 6 to 16 days (X ). Also given in the table are the values of the common logarithms of the weights (Z).\n\nLoad the dataset using the readxl package.\n\nThis readxl package was installed as a part of the tidyverse, however it does not get loaded when you load the tidyverse package and thus you need to do that separately.\nUse the command read_excel(), as shown below\n\n\n\nlibrary(readxl)\n# you might need to update the location of the data file\n# you can choose whatever name you like for the tibble when loading it into R's workspace \nch05q01 &lt;- read_excel(\"./data/CH05Q01.xls\")\n\n\n\nPart a\nCreate the scatterplots in R using ggplot the above dataset. Observe the following two scatter diagrams. Describe the relationships between age (X) and dry weight (Y) and between age and log10 dry weight (Z).\n\n\nPart b\nState the simple linear regression models for these two regressions: Y regressed on X and Z regressed on X.\n\n\n\n\n\n\nThis is asking for the regression models BEFORE you find the values of the coefficients.\n\n\n\n\n\nPart c\nDetermine the least-squares estimates of each of the regression lines in part (b).\n\n\n\n\n\n\nNow get the regression coefficients using R and plug them into the regression models from (b). You can get the coefficients from the R output - you don’t have to use the formulas.\n\n\n\n\n\nPart d\nCreate a line on your plots. Which of the two regression lines has the better fit? Based on your answers to parts (a)–(c), is it more appropriate to run a linear regression of Y on X or of Z on X? Explain.\n\n\nPart e\nFor the regression that you chose as being more appropriate in part (d), find 95% confidence intervals for the true slope and intercept. Interpret each interval with regard to the null hypothesis that the true value is 0.\n\n\n\n\n\n\nYou can get the CI’s from the R output - you don’t have to use the formulas.\n\n\n\n\n\nPart f\nFor the regression that you chose as being more appropriate in part (d), add 95% confidence and prediction bands. Using your sketch, find and interpret an approximate 95% confidence interval for the mean response of an 8-day-old chick."
  },
  {
    "objectID": "slides/01_Review.html#outcomes-of-our-hypothesis-test",
    "href": "slides/01_Review.html#outcomes-of-our-hypothesis-test",
    "title": "Review",
    "section": "Outcomes of our hypothesis test",
    "text": "Outcomes of our hypothesis test"
  },
  {
    "objectID": "slides/01_Review.html#prabilities-of-outcomes",
    "href": "slides/01_Review.html#prabilities-of-outcomes",
    "title": "Review",
    "section": "Prabilities of outcomes",
    "text": "Prabilities of outcomes\n\nType 1 error is \\(\\alpha\\)\n\nThe probability that we falsly reject the null hypothesis (but the null is true!!)\n\nPower is \\(1-\\beta\\)\n\nThe probability of correctly rejecting the null hypothesis"
  },
  {
    "objectID": "slides/01_Review.html#what-i-think-is-the-most-intuitive-way-to-look-at-it",
    "href": "slides/01_Review.html#what-i-think-is-the-most-intuitive-way-to-look-at-it",
    "title": "Review",
    "section": "What I think is the most intuitive way to look at it",
    "text": "What I think is the most intuitive way to look at it\n\n\n\nReview"
  },
  {
    "objectID": "weeks/week_02_sched.html#announcements",
    "href": "weeks/week_02_sched.html#announcements",
    "title": "Week 2",
    "section": "Announcements",
    "text": "Announcements\n\nWednesday\n\nWanted to clear something up about attendance\n\nIf you miss the exit tickets for less than or equal to 5 classes, your grade will not be impacted\nIf you miss more than 5 exit tickets, then your attendance grade will be affected"
  }
]