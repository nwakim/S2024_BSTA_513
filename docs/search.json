[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BSTA 513/613: Categorical Data Analysis",
    "section": "",
    "text": "BSTA 513/613: Categorical Data Analysis\n\nSpring 2024\n \nWelcome to BSTA 513/613! In this course, we will continue to learn about regression analysis, but not with categorical outcomes. We will build some theoretical understanding in order to interpret and apply logistic regression models appropriately. We will learn how to build a logistic regression model, interpret the model and coefficients, and diagnose potential issues with our model.  \n\n\n\n\n\n \nLink to Student Files OneDrive\n\n\nInstructor\n Dr. Nicky Wakim\n Vanport 622A\n wakim@ohsu.edu\n\n\nOffice Hours\nOH with Nicky\n F 2 - 3:30pm\nOH with Antara\n T 5:30 - 7pm\nOH with Ariel\n Th 3:30 - 5pm\n\n\nCourse details\n Mondays, Wednesdays\n April 1 - June 12\n 1:00 PM - 2:50 PM\n In-person, RPV Room B/C\n\n\nContacting me\nE-mail or Slack is the best way to get in contact with me. I will try to respond to all course-related e-mails within 24 hours Monday-Friday.\n\n\n\n\n\n\n\n\n View the source on GitHub"
  },
  {
    "objectID": "homeworks.html",
    "href": "homeworks.html",
    "title": "Homework Assignments and Solutions",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n4/11/24\n\n\nHomework 1\n\n\n6 min\n\n\n\n\n4/25/24\n\n\nHomework 2\n\n\n7 min\n\n\n\n\n5/9/24\n\n\nHomework 3\n\n\n5 min\n\n\n\n\n5/23/24\n\n\nHomework 4\n\n\n2 min\n\n\n\n\n6/6/24\n\n\nHomework 5\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homeworks.html#assignments",
    "href": "homeworks.html#assignments",
    "title": "Homework Assignments and Solutions",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n4/11/24\n\n\nHomework 1\n\n\n6 min\n\n\n\n\n4/25/24\n\n\nHomework 2\n\n\n7 min\n\n\n\n\n5/9/24\n\n\nHomework 3\n\n\n5 min\n\n\n\n\n5/23/24\n\n\nHomework 4\n\n\n2 min\n\n\n\n\n6/6/24\n\n\nHomework 5\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homeworks.html#solutions",
    "href": "homeworks.html#solutions",
    "title": "Homework Assignments and Solutions",
    "section": "Solutions",
    "text": "Solutions\nPlease note that you need to download the .html file to see the LaTeX math properly.\n\n\n\nHomework\n.qmd file\n.html file\n\n\n\n\n1\n\n\n\n\n2\n\n\n\n\n3\n\n\n\n\n4\n\n\n\n\n5"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Here is a list of the major resources that have been mentioned in class:\n\nExtra materials for the class\n\nTable for summary of hypothesis tests\nCoefficient interpretations\nLaTeX in .qmd formatting by Ariel\n\n\n\nCourse sites\n\n\n\nResource\nLink\nClass Mentioned\n\n\n\n\nMeike’s 511 Website\n\nReview\n\n\nJessica’s R programming class site\n\nData Management\n\n\n\n\n\n\n\n\n\n\nR coding\n\n\n\nResource\nLink\nClass Mentioned\n\n\n\n\nggplot histograms\n\nReview\n\n\nProbability distributions and their R code\n\nReview\n\n\nVarious hypothesis tests and their R code\n\nReview\n\n\nJessica’s R programming class site\n\nData Management\n\n\n\n\n\n\n\n\n\n\nAcademic Help\n\n\n\nResource\nLink\nClass Mentioned\n\n\n\n\nStudent Academic Support Services\n\nIntro"
  },
  {
    "objectID": "syllabus.html#description",
    "href": "syllabus.html#description",
    "title": "BSTA 513/613 Syllabus",
    "section": "Description",
    "text": "Description\nWelcome to BSTA 513/613! In this course, we will continue to learn about regression analysis, but not with categorical outcomes. We will build some theoretical understanding in order to interpret and apply logistic regression models appropriately. We will learn how to build a logistic regression model, interpret the model and coefficients, and diagnose potential issues with our model.\n\nCourse Learning Objectives\nAt the end of this course, students should be able to…\n\nApply and interpret a variety of hypothesis-testing procedures for two-way and three-way contingency tables\nCompute and interpret measures of association for binary and ordinal data.\nCalculate and correctly interpret odds ratios using logistic regression, make comparison across groups and examine relationship between binary outcome and predictor variables.\nApply appropriate model-building strategies for logistic regression. Effectively use statistical computing packages for contingency table and logistic regression procedures.\nPerform Poisson regression analysis using count data and interpret model estimates, make comparison across groups and examine relationship between outcome and predictor variables.\nCoherently summarize methods and results of data analyses, and discuss in context of original health-related research questions to audiences with varied statistical background."
  },
  {
    "objectID": "syllabus.html#instructors",
    "href": "syllabus.html#instructors",
    "title": "BSTA 513/613 Syllabus",
    "section": "Instructors",
    "text": "Instructors\nHere is the instructor page. This also has office hours!"
  },
  {
    "objectID": "syllabus.html#meeting-times",
    "href": "syllabus.html#meeting-times",
    "title": "BSTA 513/613 Syllabus",
    "section": "Meeting Times",
    "text": "Meeting Times\nMondays          1:00 PM – 2:50 PM PST in RPV Room A/B\nWednesdays    1:00 PM – 2:50 PM PST in RPV Room A/B"
  },
  {
    "objectID": "syllabus.html#materials",
    "href": "syllabus.html#materials",
    "title": "BSTA 513/613 Syllabus",
    "section": "Materials",
    "text": "Materials\n\nTextbooks\n\nApplied Logistic Regression by David Hosmer, Stanley Lemeshow, and Rodney Sturdivant\nAn Introduction to Categorical Data Analysis by Alan Agresti\nIntroduction to Regression Methods for Public Health Using R by Ramzi W. Nahhas\n\nSpecifically Chapter 6\n\n\n\nSupplemental Readings (Optional)\n\nAn Introduction to R (free pdf available)\n\n\n\n\nOnline Resources\n\nSlack\nWe will use Slack as our main form of communication for the class. If you are unsure how to do a homework problem or have other questions, please ask me by posting your question(s) on Slack. Please know that Slack is not guarded by the OSHU firewall, so if you have a question about accommodations or any sensitive topics, you may wish to message me via email. You can still message me regarding sensitive information on Slack, but I will not initiate those conversations on Slack.\n**Please use this invitation link for our Slack workspace!**\nTips on asking questions:\n\nWhen reaching out for help for a homework problem, please include some context on what you have already tried.\n\nFor example, including a photo of your work thus far with an explanation of where you think you might be wrong is a quick way for me to look over your work and help you troubleshoot. This helps me see what parts you already understand and which you need help with. If your question involves code, please include the copied code (not a screenshot) and an attachment to your full file. This way I can see the exact line you need help with and the full code in case the problem starts earlier.\nIf you are unsure how to start a problem, look through your notes and the book for examples that you think might be similar. When reaching out, mention these examples and why you think they might be helpful, but also why you are still unsure on how to proceed.\nIf you only write something similar to “I don’t know how to do problem xxx,” then my response will be to ask you what you tried so far. Thus, it will be quicker for you to let me know this information right away.\n\nIf asking for help about a specific example that you don’t understand, please also provide some detail beyond “I don’t understand example xxx.”\n\nWhich steps of the problem do you not understand? You can refer to a line number, for example.\nIf you don’t understand the first step, do you understand the ones following it?\n\nIn general, when asking a question, please provide the homework number it is from along with the chapter and problem number. If it’s an example from the notes or book, an example number or slide number will help finding it.\nWant more tips on asking questions? This list on this site will help!\nFinally, if I don’t respond within a day and you need a response soon, please remind me by emailing or messaging me again.\n\n\n\nSakai\nWhile most course materials will be delivered online through this website, assignments will be turned in through Sakai, OHSU’s course management system. I will include a link on this website to the Sakai assignment page. \n\n\nWebex\nWebex software will be used for virtual office hours. To give everyone the best possible experience with Webex, I recommend the following best practices:\n\nPlease stay muted until you want to participate\nDuring office hours, please send a message in chat with your question or with a statement like “I have a question.” This makes sure I or the TA can address everyone’s questions in order. \nI encourage you to attend office hours with your video on. This helps me recognize you, and keep mental notes on what techniques/concepts I emphasize to facilitate your specific understanding. \n\n\n\nPoll Everywhere\nWe will use the Poll Everywhere tool as an interactive feature of the course. Poll Everywhere is a web-based application that allows students to participate by responding via text messages or by visiting a web page on an internet-enabled device (smartphone, tablet, laptop). Instructions will be displayed on-screen. The poll that is embedded within the presentation will update in real time. While there is no cost to use this software, standard text messaging rates will apply if you use your phone. Please make sure that you have a Poll Everywhere account before our first class. You are not required to use your OHSU/PSU email to make an account. \nDuring lectures I will pose questions to the class. These questions are designed to provide real-time feedback to both students and the instructor on how well students are grasping the material. This is meant to be an interactive, learning activity with NO contribution to your grade. Your identity will never be connected to your answers, so I encourage you to answer honestly.\n\n\nPennState STAT 504 Website\nPennState has a class offered to online MS students that has some overlap with our class. They have all their course notes posted on this page. This is a great source if you would like to see class notes with different phrasing.\nNot all of our topics are covered in their notes, but the most important ones are. If you are having trouble finding our course’s concepts on their page, please make ask me at Office Hours, after class, or in a private meeting. I do not explicitly state corresponding sections under our schedule because I believe it is important for you to develop skills involving resources and learning key words that can help you find answers. \n\n\nR: Statistical Computing Software\nStudents will use statistical software to complete homework assignments. Students are required to use R/RStudio for this course. R can be freely downloaded. Helpful documentation on installing R is available. I encourage you to install R prior to attending our first lecture. Please email me if you need help installing R or RStudio.\nYou will need to download the following three things:\n\nR https://www.r-project.org/\nRstudio https://posit.co/download/rstudio-desktop/\nQuarto https://quarto.org/docs/get-started/\n\n\nAdditional R Resources\nYour learning and practicing of R will hopefully not be limited to this course. One of the best aspects of programming in R is that many resources are freely available online. Here are just a few additional resources you may explore beyond this class to continue your training in R.\n\n\nUseful online R resources\n\nR for the rest of us\nStatistical tools for high-throughput data analysis. ggplot2 essentials\nR-bloggers\nStack Overflow for troubleshooting\nR Graphical Manual\nQuick-R. Accessing the power of R\nR for SAS, STATA, and SPSS Users\nggplot2\nLearn R 4 free\nJoin a local R user groups\nLearning Machines\n\n\n\n\nOnline R courses to complement or refresh material from class\n\nR for the rest of us\nCoursera: R programming\nedX: R basics\nData Carpentry: For Biologists\nData Carpentry: For Ecologists\nPsychiatric R\nR coder"
  },
  {
    "objectID": "syllabus.html#assessment",
    "href": "syllabus.html#assessment",
    "title": "BSTA 513/613 Syllabus",
    "section": "Assessment",
    "text": "Assessment\nThe course is structured around the following four components:\n\n\n\n\n\n\n\n\n\nComponent\nModality\nFrequency\nDescription\n\n\nLecture\nIn person\nTwice, Weekly\nCourse content is provided through in-person lectures. Lectures will consist of didactic lessons, interactive examples, and PollEverywhere questions. Sessions will be recorded through Explain Everything and posted to Sakai. Attending or viewing the lecture within 7 days of the original lecture date is mandatory. Class attendance will be taken through an Exit Ticket. If viewing the lecture asynchronously, you must take the Exit Ticket to verify your attendance.\n\n\nHomework\nOnline\nWeekly\nThe course includes 7 homework assignments. They are an opportunity for you to engage with important concepts, practice coding, and apply calculating skills. Homework assignments should be submitted online, and will be graded by me. Students are encouraged to work in groups for homework assignments, but each person should do their own summary and hand in their work. Homework assignments will be due on Thursday at 11 PM.\n\n\nQuizzes\nIn person\nEvery 3 weeks\nThe purpose of the quizzes is to assess how well you have achieved the learning objectives through questions covering important concepts, conducting statistical processes, and interpreting output. We will have our quizzes in-class, and it will be open book. Students must work on the quizzes independently.\n\n\nProject (Labs and Report)\nOnline\n4 labs, 1 final report\nThe project will be a combination of submitted labs that will span the quarter and one final report submitted at the end of the quarter. This is meant to translate the tools learned in the course to the work one may do in the workforce. This will help instill the procedure for shaping research goals, model selection, analyzing data, and interpreting meaningful results. Labs will guide you through the needed analysis and background for the project. The final report will summarize your work over the labs and more closely align with a journal article. Students will work independently on each lab.\n\n\n\n\n\n\n\n\n\n\nTypes of assessments\nThis class will use a combination of formative and summative assessments to build and test our knowledge. Below I define each of these types of assessments:\n\nFormative assessment: Activity or work meant to help students learn and practice. Feedback on these assessments are meant to help the instructor and student identify gaps in knowledge and highlight accomplishments.\nSummative assessment: Work meant to test how well students have achieved learning objectives. Grading of these assessments are meant to gauge how well a student grasps the learning objectives and will be able to use their knowledge outside of the classroom."
  },
  {
    "objectID": "syllabus.html#assessment-breakdown",
    "href": "syllabus.html#assessment-breakdown",
    "title": "BSTA 513/613 Syllabus",
    "section": "Assessment Breakdown",
    "text": "Assessment Breakdown\n\nGrading & Requirements\nLetter grades will be assigned roughly according to the following scheme: A (&gt;=93%), A- (90-92%), B+ (88-89%), B(83-87%), B- (82-80%), C+(78-79%), C(73-77%), C- (70-72%), D (60 – 69%), F(&lt;60%).\nGrades will be based on homework assignments, midterm exam, class “attendance”, and final exam, as follows:\n\n\n\n\n\n\n\n\n\n\nCourse activity\nType of Assessment\nDue Date\nPercentage of final grade (BSTA 513)\nPercentage of final grade (BSTA 613)\n\n\nHomework\nFormative\nEvery 1-2 weeks\n33%\n28%\n\n\nQuizzes\nSummative\n4/22, 5/13, 6/3\n25%\n25%\n\n\nProject Labs\nFormative\nEvery 2-3 weeks\n25%\n25%\n\n\nProject Report\nSummative\n6/13\n10%\n10%\n\n\nExit tickets (Attendance)\nN/A\nTwice Weekly\n5%\n5%\n\n\nMid-Quarter Feedback\nN/A\n5/2\n2%\n2%\n\n\n613 Readings\nFormative\nApprox. every other week\n0%\n5%\n\n\n\n\n\nHomework grading\nNo student has the same amount of time available to dedicate to homework. This class may not be a priority to you, you may be taking several other courses, or you may need to dedicate time to other activities. Homeworks are formative assessments, meaning its purpose is to help you learn and practice. To reduce the pressure on you to have perfect or complete homework, I have a very simple grading policy: Your homework will be given a check mark if you turn in 50% of the questions parts completed (whether the 50% is correct or wrong). I highly encourage you to stay up-to-date with the homeworks and put in as much effort as you can. This will be the most helpful work in this class!\nIf you turn in the homework on time, the TAs will give you feedback (on one or more complete problems). There is no penalty for turning in the homework late, but you will not get feedback on your work. Please make sure to check the solutions or go to office hours to assess your work.\n\n\nLab grading\nWhile these are formative assignments, it is important to complete the whole lab and put in your best effort. Points will be deducted based on the rubric if it is clear that effort is not made or tasks are skipped.\n\n\nViewing Grades in Sakai\nPoints you receive for graded activities will be posted to the Sakai Gradebook. Click on the Gradebook link on the left navigation to view your points."
  },
  {
    "objectID": "syllabus.html#course-instructor-evaluations",
    "href": "syllabus.html#course-instructor-evaluations",
    "title": "BSTA 513/613 Syllabus",
    "section": "Course & Instructor Evaluations",
    "text": "Course & Instructor Evaluations\n\nOngoing Course Feedback\nThroughout the duration of the course, you are also welcome to informally and anonymously submit your feedback through this Microsoft Form or Class Exit Tickets. This form will be available on Sakai. Students can submit feedback at any time and this form will be reviewed regularly by me. Your responses will be anonymous unless you elect to leave your email address. If I have done anything to make you feel uncomfortable, please give me feedback so I can change my behavior. Ultimately, this class is for you, and my individual social identity/behavior should not inhibit your learning. Thank you for your help making BSTA 513/613 a more successful class! Examples of ongoing feedback are:\n\nNicky talks a little fast during lecture time. May you speak slower?\nDuring Office Hours, Dr. Wakim made a face when I asked a question. This face made me feel self-conscious about my question.\nDr. W asked me a question about my experience that made me feel like a monolith. Please do not assume I can speak on behalf of my social identity groups.\nThe in-class examples do not make me more interested in the material.\n\n\n\nMid-quarter Feedback\nDuring the middle of the quarter, I will ask you to submit guided, anonymous feedback. Completion of feedback will be count towards your grade. To insure anonymity, I will ask you to sign a separate, written statement that you completed the feedback.\n\n\nFinal Course Feedback\nAt the conclusion of the course, you will be asked to complete a formal online review of the course and the instructor. Your feedback on this University evaluation is critical to improving future student learning in this course as well as providing metrics relevant to the instructor’s career advancement (or lack of). Since our class is on the smaller side, everyone’s participation is needed for feedback to be released."
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "BSTA 513/613 Syllabus",
    "section": "Schedule",
    "text": "Schedule\nPlease refer to the Schedule page. I will make changes to this schedule if we need more or less time on a concept. You do not need to read the corresponding chapters in the textbook for each class."
  },
  {
    "objectID": "syllabus.html#how-to-succeed-in-this-course",
    "href": "syllabus.html#how-to-succeed-in-this-course",
    "title": "BSTA 513/613 Syllabus",
    "section": "How to succeed in this course",
    "text": "How to succeed in this course\nEvery professor has different expectations when assigning certain work or providing certain resources. I want to walk through each class resource and assignment so that you know what you can do to succeed in this class. For resources, I want you to optimize the opportunities to learn. For assignments, I want you to know the strategies that students can use to learn the most and prepare for future exams.\n\nResources\n\n\n\n\n\n\n\n\nResource\nWhat is it?\nHow do I use it?\n\n\nOffice Hours\nBlocks of time a professor or TA dedicates for questions. The teaching staff will be located in a specific room. Several students may enter the space at a time and will ask specific or broad questions. If many students attend office hours, a queue will be created so that students can be served equally.\nThe main use of office hours is to ask questions about an assignment or lecture notes. You are welcome to sit and do homework in office hours. OH are also an informal way of meeting fellow students to collaborate with.\n\n\nLectures and lecture recordings\nTime shared between the professor and students where the professor conveys important class material. Material discussed in lectures include concepts, calculations, code, and examples. Lectures are a mix of presentation of information, working through examples together, interactive activities, and in-class polls.\nStudents should attend lectures in person if possible. You should attempt to understand new material presented by following the presentation slides, taking notes on additional details that may conveyed verbally, and working through examples with the professor. Students are encouraged to ask questions when you don’t understand the material at any point in the lecture.\n\n\nTextbooks\nWritten and published material that explains concepts, steps through calculations, provides examples, and provides practice problems. The listed textbooks is the basis for this course. While I am to cover all topics in class, the textbook provides alternative explanations and additional examples.\nWhile coming to class having read the accompanying textbook chapters helps understanding during class, I do not expect students to have read it. I see the textbook as a good resource if you are struggling with a specific topic after class, in need of an example while working on homework, or want additional practice when studying for the exam.\n\n\nWebsite\nThe course website is designed by me so that you have access to all the course materials in a more organized and flexible way. All resources delivered from me to you will be available on the website. Any assignments turned in will be through Sakai.\nYou can navigate through different course resources and information using the left-side tabs or top navigation bar. Course materials, like lecture notes, homework, data examples, and recordings, can be found under each week’s page under the schedule tab. You can also find the individual resources under the “Course Materials” tab on the left. Links to turn in assignments through Sakai will be given on the website. Please explore the tabs and get a sense of the organization.\n\n\nSakai\nSakai is a learning management system for higher ed. This is the university sanctioned LMS where we will submit assignments.\nYou will turn in assignments through Sakai under the “Submissions” tab. Generally, there will be a link to each assignment on the course website. You can also view your grades under “Gradebook” and links to Webex under “Webex.”\n\n\n\n\n\nAssignments\n\n\n\n\n\n\n\n\n\nAssignment\nType of assessment\nBefore you submit/take it\nAfter it is graded\n\n\nHomework\nFormative\n\nWork out each problem on your own as much as you can\nTalk through problems with a peer\nGo to Office Hours for help\nWrite down work that shows your thought process\nSearch your issue on Stack Exchange/Stack Overflow\n\n\nReview the solutions\nReview your mistakes\nFor solutions that involve writing sentences, check with me or a TA if your answer fits the solution\nGo to Office Hours to ask about your solutions\n\n\n\nQuizzes\nSummative\n\nIdentify and achieve learning objectives in each lecture\nUnderstand why certain statistics tools are used for certain cases\nPractice testing yourself and others on concepts\nCome to Office Hours for help with specific problems or concepts\n\n\nReview the solutions\nReview your mistakes\nFor solutions that involve writing sentences, check with me or a TA if your answer fits the solution\nGo to Office Hours to ask about your solutions\nDo not ask for a regrade unless you have viewed the solutions\n\n\n\nProject Labs and Report\nFormative and Summtive\n\nStart the lab as early as possible\nWork on R coding and check with classmates on work\nCome to Office Hours for help with specific R work\nFor the report, compile your work from the labs, and decide what is important in the analysis.\n\n\nThis will be graded at the end of the semester, so you will not have a chance to interact with my feedback as much\nIf you have questions about your grade, you may email me\nKeep the project paper for future reference\nYou can add this project to your resume!\n\n\n\nClass Exit Tickets\nN/A\n\nBring appropriate electronic device to participate in polls\nComplete the survey during the last 5 minutes of class or after class within 7 days\n\n\nReview muddiest and clearest points from the week\n\n\n\n\nIf you would like any other course resources explained in this format, please request it through the Ongoing Course Feedback."
  },
  {
    "objectID": "syllabus.html#course-policies-and-resources",
    "href": "syllabus.html#course-policies-and-resources",
    "title": "BSTA 513/613 Syllabus",
    "section": "Course Policies and Resources",
    "text": "Course Policies and Resources\n\nLate Work Policy\nI encourage you to make your best effort to submit all assignments on time, but I understand circumstances arise that are beyond our control. Please see this Swansea University’s page on extenuating circumstances for some examples. Not all circumstances are covered here, so please reach out if you have questions. \n\nThe class will end on March 22, 2024. All coursework is expected to be completed by then. If you have extenuating circumstances, and need additional time to complete class assignments, please contact me. Together, we will come up with a plan for completion and to sort out registrar logistics.\nIf you have extenuating circumstances that may jeopardize your ability to do work for several weeks, please contact me. We will come up with a plan to keep you on track in the course and prevent any delay in your education.\nFor homework, there is a due date posted, but you may turn in the assignment any time before the class ends. I will give you the check regardless of when you submit the assignment. However, if you would like feedback on the homework, you must turn it in on time OR email me asking for feedback for your late homework.\nFor non-homework assignments, including labs, I ask you to email me directly. You can explain your circumstances and may ask me for an extension, but I won’t necessarily grant one.\nFor labs, you will have ONE no-questions-asked, 3-day extension. Please use this wisely! You just need to send me a quick email saying “I am using my no-questions-asked extension for Lab __.”\nIf you have a emergency involving your self, family, pet, friend, classmate, or anything/one deemed important to you, please do not worry about immediately contacting me. We can work something out after your emergency. If I contact you during an emergency, it is only because I am worried, and you do NOT need to respond until you are able. \n\n\n\nRegrade Policy\nIf you think a question was incorrectly graded, first compare your answer to the answer key. If you believe a re-grade would be appropriate, write an email to me containing the question and a short explanation as to why the question(s) was/were incorrectly graded. Deadline: One week after assignments were returned to class (late requests will not be considered).\n\n\nAttendance Policy\nYou are expected to attend class, participate in-class polls, and complete the exit ticket. For students who miss class or need a review, I will make video and audio recordings of lectures available. There are no guarantees against technical or other challenges for the recording availability or quality. For students who are unable to attend the class in-person and synchronously, viewing the recording within 7 days is acceptable. This is meant to keep you on track within the course and prevent a pile up of material. Make sure to complete the exit ticket to demonstrate attendance.\n\n\nPlagiarism and Attribution\nPlease note that this section has been motivated by Dr. Steven Bedrick’s Course Policies and Grading site for BMI 525. (Note that this is a good example of informal attribution of someone else’s work.)\nIn this class, it is easy to use ChatGPT or other AI tools to solve your homework for you. Many problems follow a basic structure that is especially easy for ChatGPT to solve. In this class, you may use ChatGPT to help with your homework. You may even ask for direct answers. However, there are a few things I do not want you to do:\n\nDo not copy ChatGPT’s answer directly into your homework. Your homework is graded for full credit if you turn it in, in any state, so turning in ChatGPT’s answers is unacceptable. I rather see half-written answers that show what you’re thinking than see a correct answer from ChatGPT.\nDo not stop once ChatGPT answered a question. If it gives an explanation, interact with it! Make sure you understand the thought process of ChatGPT. Try writing out the process to help cement it in your head. Check the answer with what we learn in class.\nDo not use ChatGPT on our quizzes! Hence, you need to really understand how to solve these problems even if you use ChatGPT on the homework.\n\nAt the end of the day, ChatGPT is a resource that will be available to you in a job and outside of school. Thus, we should use it as a tool in school as well! Let me know if ChatGPT helped you understand something! I would love to incorporate it into future classes!\n\n\n\n\n\n\nImportant\n\n\n\nYou can think of this class as assembling a toolbox. When a handyperson starts working for the first time, they need to buy their tools. For their first few jobs, they might need help finding their tools, or remembering which tool is best used for what action. Eventually, they get to know their tools well, and using them appropriately becomes second nature.\nFor now, ChatGPT can help us find and use our tools, but we need to work towards using them as second nature!"
  },
  {
    "objectID": "syllabus.html#course-expectations",
    "href": "syllabus.html#course-expectations",
    "title": "BSTA 513/613 Syllabus",
    "section": "Course Expectations",
    "text": "Course Expectations\n\nInstructor Expectations\nCommitment to your learning and your success\nI believe that everyone has the ability to be successful in this course and I have put a lot of effort into designing the course in a way that maximizes your learning to ensure your success. Please talk to me before or after class or stop by my office if there is anything you want to discuss or about which you are unclear. I want to be supportive of your learning and growth.\nInclusive & supportive learning community\nI believe that learning happens best when we all learn together, as a community. This means creating a space characterized by generous listening, civility, humility, patience, and hospitality. I will attempt to promote a safe climate where we examine content from multiple cultural perspectives, and I will strive to create and maintain a classroom atmosphere in which you feel free to both listen to others and express your views and ask questions to increase your learning.\nOpenness to feedback\nI appreciate straightforward feedback from you regarding how well the class is meeting your needs. Let me know if material is not clear or when its relevance to the student learning outcomes for the course is not apparent. In particular, let me know if you identify bias or stereotyping in my teaching materials as I will seek to continuously improve. Please also let me know if there’s an aspect of the class you find particularly interesting, helpful, or enjoyable!\nResponsiveness\nI will monitor email as well as the discussion board daily and try respond to all messages within 24 hours Monday-Friday.\nClear guidelines and prompt feedback on assignments\nI will provide clear instructions for all assignments, and a grading rubric when applicable. I will provide detailed feedback on your submissions and will update grades promptly in Sakai.\n\n\nStudent Expectations and Resources\nAttend class\nYou are expected to attend all scheduled class meetings synchronously or watch the recording within 7 days. Attendance is taken through exit tickets. If you have issues accessing the poll on a specific day, please let me know. \nParticipate\nI encourage you to participate actively in class and online discussions. I will expect all students, and all instructors, to be respectful of each other’s contributions, whether I agree with them or not. Professional interactions are expected.\nBuild rapport\nIf you find that you have any trouble keeping up with assignments or other aspects of the course, make sure you let me know as early as possible. As you will find, building rapport and effective relationships are key to becoming an effective professional. Make sure that you are proactive in informing me when difficulties arise during the quarter so that I can help you find a solution.\nComplete assignments\nAll assignments for this course will be submitted electronically through Sakai unless otherwise instructed.  I encourage you to make your best effort to submit all assignments on time, but I understand that sometimes circumstances arise that are beyond our control. If you need an extension, please contact me in congruence with the Late Policy.\nSeek help if you need it\nI believe it is important to support the physical and emotional well‐being of my students. If you are experiencing physical or mental health issues, I encourage you to use the resources on campus such as those listed below. If you have a health issue that is affecting your performance or participation in the course, and/or if you need help connecting with these resources, please contact me.\n\nStudent Health and Wellness Center (SHW), Website, 503-494-8665 (OHSU Students only)\nStudent Health and Counseling (SHAC), Website, 503-725-2800\n\nInform your instructor of any accommodations needed\nYou should speak with or email me before or during the first week of classes regarding any special needs. Students seeking academic accommodations should register with the appropriate service under the School policies below.\nSome religious holidays may occur on regularly scheduled class days. Because available class hours are so limited in number, we will have to hold class on all such days. Class video recordings will be available and you are encouraged to engage with the material outside of the regular class time. You are also encouraged to come to office hours with questions from the session.\nCommit to integrity\nAs a student in this course (and at PSU or OHSU) you are expected to maintain high degrees of professionalism, commitment to active learning and participation in this class and also integrity in your behavior in and out of the classroom.\nCheating and other forms of academic misconduct will not be tolerated in this course and will be dealt with firmly. Student academic misconduct refers to behavior that includes plagiarism, cheating on assignments, fabrication of data, falsification of records or official documents, intentional misuse of equipment or materials (including library materials), or aiding and abetting the perpetration of such acts. Preparation of exams, assigned on an individual basis, must represent each student’s own individual effort. When used, resource materials should be cited in conventional reference format."
  },
  {
    "objectID": "syllabus.html#course-communications",
    "href": "syllabus.html#course-communications",
    "title": "BSTA 513/613 Syllabus",
    "section": "Course Communications",
    "text": "Course Communications\nSakai/Slack announcements\nFor important/urgent matters, I will communicate with you using announcements via Sakai that will be delivered to your OHSU Email account as well as displayed in the Sakai course site Announcements section. I will copy these announcements in Slack if they do not involve changes to the schedule. Unfortunately, there are certain announcements that OHSU requires I initiate behind the firewall.\nGeneral course questions\nIt is normal to have many questions about things that relate to the course, such as clarification about assignments, course materials, or assessments. Please post these on our Slack Workspace. Please use the channels that I created for questions. You are encouraged to give answers and help each other. I will monitor these threads, so I will endorse or correct responses as needed. Please give me 24 hours to respond to questions within Monday-Friday. Work-life balance is important for me as well, so I will try to respond as quickly as I can within my healthy limits. \nE-mail\nE-mail should be used only for messages that are private in nature. Please send private messages to my OHSU email address (wakim@ohsu.edu). Messages sent through Sakai Inbox will not be answered. Do not send messages asking general information about the class; please post those on Slack instead."
  },
  {
    "objectID": "syllabus.html#further-student-resources",
    "href": "syllabus.html#further-student-resources",
    "title": "BSTA 513/613 Syllabus",
    "section": "Further Student Resources",
    "text": "Further Student Resources\n\nSPH Writing Lab\nThe School of Public Health Writing Support serves graduate students (master’s and PhD) in SPH, offering help on all professional writing tasks, including class papers, dissertations, job application documents, personal statements, and grant applications, to name a few. Leslie Bienen, MFA, DVM offers one-on-one writing support and other workshops. Appointments are virtual for the time being. You can make an appointment by contacting writingsupportsph@pdx.edu or making an appointment through Calendly.\n\n\nGrammarly Subscription\nThe School of Public Health students have access to a subscription version of Grammarly. While Grammarly cannot improve the argument and flow of your work, it can help with spelling, grammar, and sentence structure. If you are interested in this tool, please add your name to this email form and they will get you added to the subscription. Be sure to use your PSU login credentials to access the form.\n\n\nStudent Wellness\nI am committed to supporting the physical and emotional well-being of my students. Both PSU and OHSU have designated centers for student health. For OHSU, students can visit the Behavioral Health site, where you can find more information including the number to make an appointment. All student visits are free. OHSU students also have access to PSU’s Counseling Services through the school’s Student Health & Counseling. Information on additional student resources for OHSU students are available on the OHSU Health and Wellness Resource page. \n\n\nSupport for Food Insecurity\nStudents across the country experience food insecurity at alarming rates. OHSU and PSU both provide a list of resources to help combat food insecurity. Of note, the Committee to Improve Student Food Security (CISFS) at PSU provides a Free Food Market on the second Monday of each month. OHSU also provides SNAP Enrollment Assistance. The Supplemental Nutrition Assistance Program (SNAP) allocates money towards food for individuals below a certain income level. If you make less than $2,430 monthly, you may wish to enroll.\n\n\nSupport for Students with Children\nStudents who have children can use the PSU resource: Resource Center for Students with Children. Resources are mostly focused on students with younger children. There are several great resources available, including: family-friendly study spaces, new baby starter packs, free kids clothing, and further information on financial resources for childcare."
  },
  {
    "objectID": "syllabus.html#school-policies-and-resources",
    "href": "syllabus.html#school-policies-and-resources",
    "title": "BSTA 513/613 Syllabus",
    "section": "School Policies and Resources",
    "text": "School Policies and Resources\n\nSchool of Public Health Handbook\nAll students are responsible for following the policies and expectations outlined in the student handbook for their program of study. Students are responsible for their own academic work and are expected to have read and practice principles of academic honesty, as presented in the handbook.\n\n\nStudent Access & Accommodations\nThe School of Public Health values diversity and inclusion; we are committed to fostering mutual respect and full participation for all students. My goal is to create a learning environment that is equitable, usable, inclusive, and welcoming. If any aspects of instruction or course design result in barriers to your inclusion or learning, please notify me. \n\nIf you are already registered with disability services at either OHSU or PSU and you are taking a course at the opposite institution, you need to contact the office you’re registered with to transfer your accommodations.\nIf you are not already registered with a disability services office, and you have, or think you may have, a disability that may affect your work in this class, and feel you need accommodations, use the following table for guidance about which office to contact to initiate accommodations.\n\nResource Table\n\n\n\nEnrollment University and Standing\nWhere to Seek Accommodations\n\n\nUndergraduate School of Public Health major\nPSU’s Disability Resource Center\n\n503-725-4150\nSmith Memorial Student Union, Room 116\ndrc@pdx.edu\n\n\n\nAll PSU-registering Dual Degree (MSW/MPH and MURP/MPH) Graduate School of Public Health Majors and all PSU-registering PhD students admitted prior to fall 2016.\nPSU’s Disability Resource Center\n\n503-725-4150\nSmith Memorial Student Union, Room 116\ndrc@pdx.edu\nwww.pdx.edu/drc\n\n\n\nGraduate School of Public Health major (irrespective of institution at which you register)\nOHSU’s Office for Student Access\n(503) 494-0082\nStudentAccess@OHSU.edu\nOHSU Auditorium Building 330\n\n\nNon-SPH major, PSU-enrolled student\nPSU’s Disability Resource Center\n503-725-4150\nSmith Memorial Student Union, Room 116\ndrc@pdx.edu\nwww.pdx.edu/drc\n\n\nNon-SPH major, OHSU-enrolled student\nOHSU’s Office for Student Access\n(503) 494-0082\nStudentAccess@OHSU.edu\nOHSU Auditorium Building 330\n\n\n\n \nFor more information related accessibility and accommodations, please see the “Statement Regarding Students with Disabilities” within the Institutional Policies section of this syllabus.\n\n\nTitle IX\nThe School of Public Health is committed to providing an environment free of all forms of prohibited discrimination and discriminatory harassment. The School of Public Health students who have questions about an incident related to Title IX are welcome to contact either the OHSU or PSU’s Title IX Coordinator and they will direct you to the appropriate resource or office. Title IX pertains to any form of sex/gender discrimination, discriminatory harassment, sexual harassment or sexual violence.\n\nPSU’s Title IX Coordinator is Julie Caron, she may be reached at titleixccordinator@pdx.edu or 503-725-4410. Julie’s office is located at 1600 SW 4th Ave, In the Richard and Maureen Neuberger Center RMNC - Suite 830.\nThe OHSU Title IX Coordinator’s may be reachedat 503-494-0258 or titleix@ohsu.edu and is located at 2525 SW 3rd St.\n\nPlease note that faculty and the Title IX Coordinators will keep the information you disclose private but are not confidential. If you would like to speak with a confidential advocate, who will not disclose the information to a university official without your written consent, you may contact an advocate at PSU or OHSU.\n\nPSU’s confidential advocates are available in Women’s Resource Center (serving all genders) in Smith Student Memorial Union 479. You may schedule an appointment by (503-725-5672) or schedule on line at https://psuwrc.youcanbook.me. For more information about resources at PSU, please see PSU’s Response to Sexual Misconduct website.\nOHSU’s advocates are available through the Confidential Advocacy Program (CAP) at 833-495-CAPS (2277) or by email CAPsupport@ohsu.edu, but please note, email is not a secure form of communication. Also visit www.ohsu.edu/CAP.\n\nAt OHSU, if you encounter any harassment, or discrimination based on race, color, religion, age, national origin or ancestry, veteran or military status, sex, marital status, pregnancy or parenting status, sexual orientation, gender identity or expression, disability or any other protected status, please contact the Affirmative Action and Equal Opportunity (AAEO) Department at 503-494-5148 or aaeo@ohsu.edu.\nAt PSU, you may contact the Office of Equity and Compliance if you experience any form of discrimination or discriminatory harassment as listed above at equityandcompliance@pdx.edu or by calling 503-725-5919.\n\n\nTechnical Support\nThe OHSU ITG Help Desk is available to assist students with email account or network account access issues between 6 a.m. and 6 p.m., Monday through Friday at 503-494-2222. For technical support in using the Sakai Course Management System, please contact the Sakai Help Desk at 877-972-5249 or email us at sakai@ohsu.edu"
  },
  {
    "objectID": "syllabus.html#ohsu-competencies",
    "href": "syllabus.html#ohsu-competencies",
    "title": "BSTA 513/613 Syllabus",
    "section": "OHSU Competencies",
    "text": "OHSU Competencies\n\nList of OHSU Graduation Core Competencies\n\nProfessional Knowledge and Skills\nProfessionalism\nInformation Literacy\nCommunication\nTeamwork\nCommunity Engagement, Social Justice and Equity\nPatient Centered Care\n\nTo access a descriptive list of OHSU Graducation Core Competencies: OHSU Graduation Core Competencies"
  },
  {
    "objectID": "syllabus.html#institutional-policies-and-resources",
    "href": "syllabus.html#institutional-policies-and-resources",
    "title": "BSTA 513/613 Syllabus",
    "section": "Institutional Policies and Resources",
    "text": "Institutional Policies and Resources\n\nStatement Regarding Students with Disabilities\nOHSU is committed to inclusive and accessible learning environments in compliance with federal and state law. If you have a disability or think you may have a disability (mental health, attention-related, learning, vision, hearing, physical or health impacts) contact the Office for Student Access at (503) 494-0082 or OHSU Student Access to have a confidential conversation about academic accommodations. Information is also available at Student Access Website. Because accommodations may take time to implement and cannot be applied retroactively, it is important to have this discussion as soon as possible.\nPortland State students also have similar resources available via the PSU Disability Resource Center (website http://www.pdx.edu/drc ). Please contact the DRC at tel. (503) 725-4150 or email at drc@pdx.edu\n\n\nStudent Evaluation of Courses\nCourse evaluation results are extremely important and used to help improve courses and the learning experience of future students. Responses will always remain anonymous and will only be available to instructors after grades have been posted. The results of scaled questions and comments go to both the instructor and their unit head/supervisor. Refer to Student Evaluation of Courses and Instructional Effectiveness, *Policy No. 02-50-035.\n*To access the OHSU Student Evaluation of Courses and Instructional Effectiveness Policy, you must log into the OHSU O2 website.\n\n\nCopyright Information\nCopyright laws and fair use policies protect the rights of those who have produced the material. The copy in this course has been provided for private study, scholarship, or research. Other uses may require permission from the copyright holder. The user of this work is responsible for adhering to copyright law of the U.S. (Title 17, U.S. Code). To help you familiarize yourself with copyright and fair use policies, the University encourages you to visit its Copyright Web Page\nSakai course web sites contain material protected by copyrights held by the instructor, other individuals or institutions. Such material is used for educational purposes in accord with copyright law and/or with permission given by the owners of the original material. You may download one copy of the materials on any single computer for non-commercial, personal, or educational purposes only, provided that you (1) do not modify it, (2) use it only for the duration of this course, and (3) include both this notice and any copyright notice originally included with the material. Beyond this use, no material from the course web site may be copied, reproduced, re-published, uploaded, posted, transmitted, or distributed in any way without the permission of the original copyright holder. The instructor assumes no responsibility for individuals who improperly use copyrighted material placed on the web site.\n\n\nSyllabi Changes and Retention\nSyllabi are considered to be a learning agreement between students and the faculty of record. Information contained in syllabi, other than the minimum requirements, may be subject to change as deemed appropriate by the faculty of record in concurrence with the academic program and the Office of the Provost. Refer to the *Course Syllabi Policy, 02-50-050.\n*To access the OHSU Course Syllabus Policy, you must log into the OHSU O2 website.\n\n\nCommitment to Diversity & Inclusion\nOHSU is committed to creating and fostering a learning and working environment based on open communication and mutual respect. If you encounter sexual harassment, sexual misconduct, sexual assault, or discrimination based on race, color, religion, age, national origin, veteran’s status, ancestry, sex, marital status, pregnancy or parenting status, sexual orientation, gender identity, disability or any other protected status please contact the Affirmative Action and Equal Opportunity Department at 503-494-5148 or aaeo@ohsu.edu. Inquiries about Title IX compliance or sex/gender discrimination and harassment may be directed to the OHSU Title IX Coordinator at 503-494-0258 or titleix@ohsu.edu.\n\n\nModified Operations, Policy 01-40-010\nPortland Campus:  Marquam Hill and South Waterfront\nStudents should review O2 or call OHSU’s weather alert line at 503-494-9021 for the most up-to-date information on OHSU-wide modified operations which include but are not limited to delays or closures for inclement weather.\nIf your home institution is not on the Portland campus (Marquam Hill or South Waterfront, contact your home institution for more information.\n\n\nOHSU Resources Available to Students*:\nRemote Learning Resources\nThe Remote Learning webpage on O2 contains concise, practical resources, and strategies for students that need to quickly transition to a fully remote instructional format.\nRegistrar’s Office\nMackenzie Hall, Rm. 1120\n503-494-7800; Email the Registrar\nStudent Registration Information: \nTo Register for Classes\nOHSU ITG Help Desk\nRegular staff hours are 6 a.m. to 6 p.m., Monday through Friday, but phones are answered seven days a week, 24 hours a day. Call 503 494-2222.\nTeaching and Learning Center\nAcademic Support Counseling and Sakai Course Management System, please contact the TLC Help Desk at 877-972-5249 or email TLC Help Desk\nStudent Academic Support Services\nFor resources on improving student’s study strategies, time management, motivation, test-taking skills and more, Please access the Student Academic Support Services Sakai page. For one-on-one appointments or to arrange a workshop for students, please contact Emily Hillhouse.\nConfidential Advocacy Program\nSupport for OHSU employees, students, and volunteers who have experienced any form of sexual misconduct, including sexual harassment, sexual assault, intimate-partner violence, stalking, relationship/dating violence, and other forms — regardless of when or where it took place. Contact Us.\nConcourse Syllabus Management\nFor help with accessing your Concourse Syllabus:  Please contact the Sakai help Desk for all other Concourse inquiries please visit the Concourse Support - Sakai or please contact the Mark Rivera at rivermar@ohsu.edu or call 503-494-0934\nPublic Safety\nOHSU Public Safety-Portland Campus (Marquam Hill and South Waterfront)\n\nEmergency on Campus: 503-494-4444 (Portland)\nNon-emergency: 503-494-7744; Contact Public Safety\n\nStudent Health & Wellness Center \nBaird Hall, Rm. 18 (Primary Care) and Rm. 6 (Behavioral Health)\n503-494-8665; For urgent care after hours, 503-494-8311 and ask for the Nurse on call.\nWellness Center Information  \nWellness Center Website\nIf your home institution is not on the Portland campus, contact your home institution student support services for more information.\nOmbudsman Office\nGaines Hall, Rm. 117\n707 SW Gaines Street, Portland, OR 97239\n503-494-5397; Contact Ombudsman; Ombudsman Website\nLibrary: Biomedical Information Communication Center\nBICC Library Hours of Operation\n\n\nPrivacy While Learning\nStudents may be asked to take classes remotely through videoconferencing software like WebEx. Some of these remote classes will be recorded. Any recording will capture the presenter’s audio, video, and computer screen. Student video and audio will be recorded if and when you unmute your audio and share your video during the recorded sessions. These recordings will not be shared with or accessible to the public without prior written consent. \n\n\nStudent Central\nKey information for students across OHSU’s Schools of Dentistry, Medicine, Nursing, the OHSU-PSU School of Public Health and the College of Pharmacy. Student Central helps you find out more about student services, resources, policies and technology."
  },
  {
    "objectID": "extra_resources/Coefficient_interp.html",
    "href": "extra_resources/Coefficient_interp.html",
    "title": "Coefficient interpretations",
    "section": "",
    "text": "Keep in mind that words expected, average, and mean are interchangeable.\nThe following are required parts of the interpretation\n\nUnits of Y\nUnits of X\nDiscussing intercept: Mean or average or expected before Y\nDiscussing coefficient for continuous covariate: Mean or average or expected before difference, increase, or decrease\n\nOR: Mean or average or expected before Y\nOnly need before difference or Y!!\n\nConfidence interval\nIf other covariates in the model\n\nDiscussing intercept: Must state that variables are equal to 0\n\nor at their centered value if centered!\n\nDiscussing coefficient for covariate: Must state “adjusting for all other variables”, “Controlling for all other variables”, or “Holding all other variables constant”\n\nIf only one other variable in the model, then replace “all other variables” with the single variable name\n\n\n\nWhen the estimate of the population coefficient is…\n\nPositive: using the word “increase” in the place of “difference” helps with understanding the relationship\nNegative: using the word “decrease” in the place of “difference” helps with understanding the relationship\n\n\n\n\n\n\n\n\n\n\nPopulation Model\nVariable information\nCoefficient estimate interpretations\n\n\n\n\n\\(Y=\\beta_0+\\beta_1X_1+\\epsilon\\)\n\\(X_1\\): continuous covariate\n\n\\(\\widehat\\beta_0\\): Mean \\(Y\\) when \\(X_1\\) is 0\n\nExample: For someone who is 0 years old, the expected peak exercise heart rate is 214.233 beats per minute (95% CI: 204.918, 223.548)\n\n\\(\\widehat\\beta_1\\): Mean difference in \\(Y\\) per 1 unit increase in \\(X_1\\)\n\nExample: For every one year increase in age, the expected peak exercise heart rate decreases 0.834 bpm (95% CI: ….)\n\n\n\n\n\\(Y=\\beta_0+\\beta_1X^c_1+\\epsilon\\)\n\\(X^c_1\\): continuous covariate that is centered around its mean or median\n\n\\(\\widehat\\beta_0\\): Mean \\(Y\\) when \\(X^c_1\\) is at its mean or median\n\\(\\widehat\\beta_1\\): Mean difference in \\(Y\\) per 1 unit increase in \\(X^c_1\\)\n\n\n\n\\(Y=\\beta_0+\\beta_1X_1+\\beta_2X_2+\\epsilon\\)\n\\(X_1\\): continuous covariate\n\\(X_2\\): continuous covariate"
  },
  {
    "objectID": "homework/HW5.html",
    "href": "homework/HW5.html",
    "title": "Homework 5",
    "section": "",
    "text": "Important\n\n\n\nThis assignment is NO LONGER under construction !!! (3/1/2024)"
  },
  {
    "objectID": "homework/HW5.html#directions",
    "href": "homework/HW5.html#directions",
    "title": "Homework 5",
    "section": "Directions",
    "text": "Directions\n\nDownload the .qmd file here.\nYou will need to download the datasets. Use this link to download the homework datasets needed in this assignment. If you do not want to make changes to the paths set in this document, then make sure the files are stored in a folder named “data” that is housed in the same location as this homework .qmd file.\nPlease upload your homework to Sakai. Upload both your .qmd code file and the rendered .html file\n\nPlease rename you homework as Lastname_Firstinitial_HW5.qmd. This will help organize the homeworks when the TAs grade them.\nPlease also add the following line under subtitle: \"BSTA 512/612\": author: First-name Last-name with your first and last name so it is attached to the viewable document.\n\nFor each question, make sure to include all code and resulting output in the html file to support your answers.\nShow the work of your calculations using R code within a code chunk. Make sure that both your code and output are visible in the rendered html file. This is the default setting.\nIf you are computing something by hand, you may take a picture of your work and insert the image in this file. You may also use LaTeX to write it inline.\nWrite all answers in complete sentences as if communicating the results to a collaborator. This means including a sentence summarizing results in the context of the research study.\n\n\n\n\n\n\n\nTip\n\n\n\nIt is a good idea to try rendering your document from time to time as you go along! Note that rendering automatically saves your qmd file and rendering frequently helps you catch your errors more quickly."
  },
  {
    "objectID": "homework/HW3.html",
    "href": "homework/HW3.html",
    "title": "Homework 3",
    "section": "",
    "text": "Download the .qmd file here.\nYou will need to download the datasets. Use this link to download the homework datasets needed in this assignment. If you do not want to make changes to the paths set in this document, then make sure the files are stored in a folder named “data” that is housed in the same location as this homework .qmd file.\nPlease upload your homework to Sakai. Upload both your .qmd code file and the rendered .html file\n\nPlease rename you homework as Lastname_Firstinitial_HW0.qmd. This will help organize the homeworks when the TAs grade them.\nPlease also add the following line under subtitle: \"BSTA 512/612\": author: First-name Last-name with your first and last name so it is attached to the viewable document.\n\nFor each question, make sure to include all code and resulting output in the html file to support your answers.\nShow the work of your calculations using R code within a code chunk. Make sure that both your code and output are visible in the rendered html file. This is the default setting.\nIf you are computing something by hand, you may take a picture of your work and insert the image in this file. You may also use LaTeX to write it inline.\nWrite all answers in complete sentences as if communicating the results to a collaborator. This means including a sentence summarizing results in the context of the research study.\n\n\n\n\n\n\n\nTip\n\n\n\nIt is a good idea to try rendering your document from time to time as you go along! Note that rendering automatically saves your qmd file and rendering frequently helps you catch your errors more quickly."
  },
  {
    "objectID": "homework/HW3.html#directions",
    "href": "homework/HW3.html#directions",
    "title": "Homework 3",
    "section": "",
    "text": "Download the .qmd file here.\nYou will need to download the datasets. Use this link to download the homework datasets needed in this assignment. If you do not want to make changes to the paths set in this document, then make sure the files are stored in a folder named “data” that is housed in the same location as this homework .qmd file.\nPlease upload your homework to Sakai. Upload both your .qmd code file and the rendered .html file\n\nPlease rename you homework as Lastname_Firstinitial_HW0.qmd. This will help organize the homeworks when the TAs grade them.\nPlease also add the following line under subtitle: \"BSTA 512/612\": author: First-name Last-name with your first and last name so it is attached to the viewable document.\n\nFor each question, make sure to include all code and resulting output in the html file to support your answers.\nShow the work of your calculations using R code within a code chunk. Make sure that both your code and output are visible in the rendered html file. This is the default setting.\nIf you are computing something by hand, you may take a picture of your work and insert the image in this file. You may also use LaTeX to write it inline.\nWrite all answers in complete sentences as if communicating the results to a collaborator. This means including a sentence summarizing results in the context of the research study.\n\n\n\n\n\n\n\nTip\n\n\n\nIt is a good idea to try rendering your document from time to time as you go along! Note that rendering automatically saves your qmd file and rendering frequently helps you catch your errors more quickly."
  },
  {
    "objectID": "homework/HW3.html#questions",
    "href": "homework/HW3.html#questions",
    "title": "Homework 3",
    "section": "Questions",
    "text": "Questions\n\nQuestion 1\nThis question is taken from the Hosmer and Lemeshow textbook. The ICU study data set consists of a sample of 200 subjects who were part of a much larger study on survival of patients following admission to an adult intensive care unit (ICU). The dataset should be available within Course Materials. The major goal of this study was to develop a logistic regression model to predict the probability of survival to hospital discharge of these patients. In this question, the primary outcome variable is vital status at hospital discharge, STA. Clinicians associated with the study felt that a key determinant of survival was the patient’s age at admission, AGE. We will be building to a multivariable logistic regression model while adjusting for cancer part of the present problem (CAN), CPR prior to ICU admission (CPR), infection probable at ICU admission (INF), and level of consciousness at ICU admission (LOC).\nA code sheet for the variables to be considered is displayed in Table 1.5 below (from the Hosmer and Lemeshow textbook, pg. 23). We refer to this data set as the ICU data.\n\n\n\nPart a\nFrom the above list (AGE, CAN, CPR, INF, and LOC) of independent variables, identify if each is a continuous, binary, or multi-level (&gt;2) categorical variable.\n\n\nPart b\nFor the binary and multi-level categorical variables, please identify a reference group for each. Include justification for the reference group.\n\n\nPart c\nRefer back to Part c from Homework 2’s Question 4. Interpret the odds ratio for age in the simple logistic regression model. Please include the 95% confidence interval.\n\n\nPart d\nCompute the predicted probability of hospital discharge for a subject who is 63 years old. Compute the 95% confidence interval for the predicted probability and interpret the predicted probability.\n\n\nPart e\nFor the categorical variables (binary and multi-group), please mutate the variables within the ICU dataset to set your chosen reference groups.\n\n\nPart f\nWrite down the equation for the logistic regression model of STA on CPR.\n\n\nPart g\nUsing the glm() function, obtain the maximum likelihood estimates of the coefficient parameters of the logistic regression model in Part f. Using these estimates, write down fitted logistic regression model.\n\n\nPart h\nWrite a sentence interpreting the odds ratio for the coefficients in Part g’s model. Please include the 95% confidence interval.\n\n\nPart i\nWrite down the equation for the logistic regression model of STA on LOC.\n\n\nPart j\nUsing the glm() function, obtain the maximum likelihood estimates of the coefficient parameters of the logistic regression model in Part i. Present the coefficient estimates. No need to write out the fitted regression equation.\nPlease take note of the warnings that you receive from fitting the glm() model and any large coefficient estimate with large confidence intervals. In this case, we have a category within LOC that has very few observations. (We will discuss this more in Lesson 14: Numerical Problems)\nCheck the number of observations that have a deep stupor and death at discharge and the number of observations that have a deep stupor and live at discharge. You can do this using the table() function to create a contingency table.\n\n\nPart k\nWrite a sentence interpreting the odds ratio of death for the indicator of coma. Please include the 95% confidence interval."
  },
  {
    "objectID": "homework/HW1.html",
    "href": "homework/HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Caution\n\n\n\nI took out likelihood ratio tests in Question 5. We did not cover them!"
  },
  {
    "objectID": "homework/HW1.html#directions",
    "href": "homework/HW1.html#directions",
    "title": "Homework 1",
    "section": "Directions",
    "text": "Directions\n\nDownload the .qmd file here.\nYou will not need to download datasets for this homework.\nPlease upload your homework to Sakai. Upload both your .qmd code file and the rendered .html file\n\nPlease rename you homework as Lastname_Firstinitial_HW1.qmd. This will help organize the homeworks when the TAs grade them.\nPlease also add the following line under subtitle: “BSTA 513/613”: author: First-name Last-name with your first and last name so it is attached to the viewable document.\n\nFor each question, make sure to include all code and resulting output in the html file to support your answers\nShow the work of your calculations using R code within a code chunk. Make sure that both your code and output are visible in the rendered html file. This is the default setting.\nWrite all answers in complete sentences as if communicating the results to a collaborator.\n\n\n\n\n\n\n\nTip\n\n\n\nIt is a good idea to try rendering your document from time to time as you go along! Note that rendering automatically saves your .qmd file and rendering frequently helps you catch your errors more quickly."
  },
  {
    "objectID": "homework/HW1.html#questions",
    "href": "homework/HW1.html#questions",
    "title": "Homework 1",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "homework/HW2.html",
    "href": "homework/HW2.html",
    "title": "Homework 2",
    "section": "",
    "text": "This homework is designed to help you practice the following important skills and knowledge that we covered in Lessons 3-6:\n\nCalculate and interpret the estimated risk difference, relative risk, and odds ratios, and their confidence intervals\nExpand work on contingency tables to evaluate the agreement or reproducibility using Cohen’s Kappa\nUnderstand important differences between linear regression and logistic regression\nConstruct a simple logistic regression model\nTest a covariate for significance using the Wald test and LRT"
  },
  {
    "objectID": "homework/HW2.html#directions",
    "href": "homework/HW2.html#directions",
    "title": "Homework 2",
    "section": "Directions",
    "text": "Directions\n\nDownload the .qmd file here.\nYou will need to download the datasets. Use this link to download the homework datasets needed in this assignment. If you do not want to make changes to the paths set in this document, then make sure the files are stored in a folder named “data” that is housed in the same location as this homework .qmd file.\nPlease upload your homework to Sakai. Upload both your .qmd code file and the rendered .html file\n\nPlease rename you homework as Lastname_Firstinitial_HW1.qmd. This will help organize the homeworks when the TAs grade them.\nPlease also add the following line under subtitle: “BSTA 513/613”: author: First-name Last-name with your first and last name so it is attached to the viewable document.\n\nFor each question, make sure to include all code and resulting output in the html file to support your answers\nShow the work of your calculations using R code within a code chunk. Make sure that both your code and output are visible in the rendered html file. This is the default setting.\nWrite all answers in complete sentences as if communicating the results to a collaborator.\n\n\n\n\n\n\n\nTip\n\n\n\nIt is a good idea to try rendering your document from time to time as you go along! Note that rendering automatically saves your qmd file and rendering frequently helps you catch your errors more quickly."
  },
  {
    "objectID": "homework/HW4.html",
    "href": "homework/HW4.html",
    "title": "Homework 4",
    "section": "",
    "text": "Important\n\n\n\nThis assignment is no longer under construction!! (2/15/2024)"
  },
  {
    "objectID": "homework/HW4.html#directions",
    "href": "homework/HW4.html#directions",
    "title": "Homework 4",
    "section": "Directions",
    "text": "Directions\n\nDownload the .qmd file here.\nYou will need to download the datasets. Use this link to download the homework datasets needed in this assignment. If you do not want to make changes to the paths set in this document, then make sure the files are stored in a folder named “data” that is housed in the same location as this homework .qmd file.\nPlease upload your homework to Sakai. Upload both your .qmd code file and the rendered .html file\n\nPlease rename you homework as Lastname_Firstinitial_HW4.qmd. This will help organize the homeworks when the TAs grade them.\nPlease also add the following line under subtitle: \"BSTA 512/612\": author: First-name Last-name with your first and last name so it is attached to the viewable document.\n\nFor each question, make sure to include all code and resulting output in the html file to support your answers.\nShow the work of your calculations using R code within a code chunk. Make sure that both your code and output are visible in the rendered html file. This is the default setting.\nIf you are computing something by hand, you may take a picture of your work and insert the image in this file. You may also use LaTeX to write it inline.\nWrite all answers in complete sentences as if communicating the results to a collaborator. This means including a sentence summarizing results in the context of the research study.\n\n\n\n\n\n\n\nTip\n\n\n\nIt is a good idea to try rendering your document from time to time as you go along! Note that rendering automatically saves your qmd file and rendering frequently helps you catch your errors more quickly."
  },
  {
    "objectID": "homework/HW4.html#questions",
    "href": "homework/HW4.html#questions",
    "title": "Homework 4",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "extra_resources/Latex_qmd_formatting.html",
    "href": "extra_resources/Latex_qmd_formatting.html",
    "title": "LateX and R Markdown Formatting",
    "section": "",
    "text": "This style of coding has a bunch of different yet completely equivalent names. It is a form of coding within markdown files that helps us write equations in an easily readable format.\n\nLatex\nLateX\nLaTeX\nMay occasionally see it written with a K instead of an X\nPronounced as “lay-tek” or “lah-tek”"
  },
  {
    "objectID": "extra_resources/Latex_qmd_formatting.html#centered",
    "href": "extra_resources/Latex_qmd_formatting.html#centered",
    "title": "LateX and R Markdown Formatting",
    "section": "3.1 Centered",
    "text": "3.1 Centered\nIf you want your equation to be centered in your output, use the double dollar sign ($$) on either side of your equation: $$\\alpha = 0.05$$\n\\[ \\alpha = 0.05 \\]\nTip: If you put your $$   $$ out first, whatever you type in between them will render as you’re typing! Sometimes this is helpful to catch if you’ve made a typo or misspelled a Greek letter or command you meant to use (more on these later)."
  },
  {
    "objectID": "extra_resources/Latex_qmd_formatting.html#in-line",
    "href": "extra_resources/Latex_qmd_formatting.html#in-line",
    "title": "LateX and R Markdown Formatting",
    "section": "3.2 In-Line",
    "text": "3.2 In-Line\nIf you want your equation to be in-line with your markdown text, use the single dollar sign ($) on either side of your equation. Using this, you can write things like $\\alpha$ to output (\\(\\alpha\\) = 0.05)."
  },
  {
    "objectID": "extra_resources/Latex_qmd_formatting.html#subscript",
    "href": "extra_resources/Latex_qmd_formatting.html#subscript",
    "title": "LateX and R Markdown Formatting",
    "section": "5.1 Subscript",
    "text": "5.1 Subscript\nOnly the first value (letter or number) following the subscript command will be subscripted, by default. If you want to make a value subscripted, use the underscore (_) like this:\nH_0: \\(H_0\\)\nWhatever you type next will not be subscripted:\nH_12: \\(H_12\\)\nTo subscript more than one value, use curly brackets:\nH_{12}: \\(H_{12}\\)"
  },
  {
    "objectID": "extra_resources/Latex_qmd_formatting.html#superscript",
    "href": "extra_resources/Latex_qmd_formatting.html#superscript",
    "title": "LateX and R Markdown Formatting",
    "section": "5.2 Superscript",
    "text": "5.2 Superscript\nSometimes we want values to appear above others as a superscript, such as when we’re squaring or cubing them. As with the subscript, if you want more than one value following the carrot to be superscripted, use curly brackets:\nr^2: \\(r^2\\)\nr^12: \\(r^12\\)\nr^{12}: \\(r^{12}\\)"
  },
  {
    "objectID": "project.html#labs",
    "href": "project.html#labs",
    "title": "Project Central",
    "section": "Labs",
    "text": "Labs\n\n\n\nLab\nDue Date\nTopics\n\n\n\n\nLab 1\n4/18\nExploring the question and data\n\n\nLab 2\n5/2\nEDA continued + Simple logistic regression\n\n\nLab 3\n5/16\nBuilding a model\n\n\nLab 4\n5/30\nInterpreting the final model"
  },
  {
    "objectID": "project.html#report",
    "href": "project.html#report",
    "title": "Project Central",
    "section": "Report",
    "text": "Report\nReport Instructions\nDue 6/13/2024"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "ScheduleImportant timesCredit to\n\n\nLabs and homeworks may be switched around depending on the material learned in class.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApril\n\n\n\n\n\nMON\n\n\nTUE\n\n\nWED\n\n\nTHU\n\n\nFRI\n\n\n\n\n\n\n\n\n\n1\n\n\n\n\n\n\n2\n\n\n\n\n\n\n3\n\n\n\n\n\n\n4\n\n\n\n\n\n\n5\n\n\n\n\n\n\n\n\nWeek 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8\n\n\n\n\n\n\n9\n\n\n\n\n\n\n10\n\n\n\n\n\n\n11\n\n\n\n\n\n\n12\n\n\n\n\n\n\n\n\nWeek 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 1 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n15\n\n\n\n\n\n\n16\n\n\n\n\n\n\n17\n\n\n\n\n\n\n18\n\n\n\n\n\n\n19\n\n\n\n\n\n\n\n\nWeek 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 1 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n22\n\n\n\n\n\n\n23\n\n\n\n\n\n\n24\n\n\n\n\n\n\n25\n\n\n\n\n\n\n26\n\n\n\n\n\n\n\n\nWeek 4Quiz 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 2 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n29\n\n\n\n\n\n\n30\n\n\n\n\n\n\n1\n\n\n\n\n\n\n2\n\n\n\n\n\n\n3\n\n\n\n\n\n\n\n\nWeek 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 2 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMay\n\n\n\n\n\nMON\n\n\nTUE\n\n\nWED\n\n\nTHU\n\n\nFRI\n\n\n\n\n\n\n\n\n\n29\n\n\n\n\n\n\n30\n\n\n\n\n\n\n1\n\n\n\n\n\n\n2\n\n\n\n\n\n\n3\n\n\n\n\n\n\n\n\nWeek 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 2 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n6\n\n\n\n\n\n\n7\n\n\n\n\n\n\n8\n\n\n\n\n\n\n9\n\n\n\n\n\n\n10\n\n\n\n\n\n\n\n\nWeek 6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 3 dueMidterm feedback due\n\n\n\n\n\n\n\n\n\n\n\n\n\n13\n\n\n\n\n\n\n14\n\n\n\n\n\n\n15\n\n\n\n\n\n\n16\n\n\n\n\n\n\n17\n\n\n\n\n\n\n\n\nWeek 7Quiz 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 3 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n20\n\n\n\n\n\n\n21\n\n\n\n\n\n\n22\n\n\n\n\n\n\n23\n\n\n\n\n\n\n24\n\n\n\n\n\n\n\n\nWeek 8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 4 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n27\n\n\n\n\n\n\n28\n\n\n\n\n\n\n29\n\n\n\n\n\n\n30\n\n\n\n\n\n\n31\n\n\n\n\n\n\n\n\nNo Class: Mem Day\n\n\n\n\n\n\n\n\n\n\n\nWeek 9\n\n\n\n\n\n\nLab 4 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJune\n\n\n\n\n\nMON\n\n\nTUE\n\n\nWED\n\n\nTHU\n\n\nFRI\n\n\n\n\n\n\n\n\n\n3\n\n\n\n\n\n\n4\n\n\n\n\n\n\n5\n\n\n\n\n\n\n6\n\n\n\n\n\n\n7\n\n\n\n\n\n\n\n\nWeek 10Quiz 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 5 due\n\n\n\n\n\n\n\n\n\n\n\n\n\n10\n\n\n\n\n\n\n11\n\n\n\n\n\n\n12\n\n\n\n\n\n\n13\n\n\n\n\n\n\n14\n\n\n\n\n\n\n\n\nWeek 11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinal Project Due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere is a tentative list of important, recurring times:\n\nHomeworks are always due at 11pm on the specified day (usually Thursday)\nLabs are always due at 11pm on the specified day (usually Thursday)\nExit tickets are due at 11pm 7 days after class\n\nSo for Monday classes, they are due the following Monday at 11pm\nFor Wednesday classes, they are due the following Wednesday at 11pm\n\nOffice hours with Nicky: Link to Webex\n\nTBD\n\nClass meets on Mondays and Wednesdays at 1 - 2:50 pm\n\n\n\nSpecial thank you to Andrew Bray, who taught the Quarto workshop I attended. This schedule page was mostly taken from the Schedule on his STAT 20 course page. You can find the .qmd file for Andrew’s schedule page on his Github."
  },
  {
    "objectID": "homework/HW1.html#purpose",
    "href": "homework/HW1.html#purpose",
    "title": "Homework 1",
    "section": "Purpose",
    "text": "Purpose\nThis homework is designed to help you practice the following important skills and knowledge that we covered in Lessons 1-2:\n\nPracticing and outlining your decision process to analyze the relationship between two categorical variables\nInterpreting research aims into questions/tests that can be answered with statistics\nUsing R to calculate sample proportions\nUsing R to calculate test statistic values for inference tests\nInterpreting new phrasing of questions that were introduced in class"
  },
  {
    "objectID": "homework/HW1.html#question-1",
    "href": "homework/HW1.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1\nIf the probability that one white blood cell is a lymphocyte is 0.3, compute the probability of 2 lymphocytes out of 10 white blood cells. Also, compute the probability that at least 3 lymphocytes out of 10 white blood cells. You may calculate by hand, using a web app, or using R."
  },
  {
    "objectID": "homework/HW1.html#question-2",
    "href": "homework/HW1.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2\nConsider a 2 x 2 table from a prospective cohort study:\n\n\n\n\n \n  \n      \n    Favorable \n    Unfavorable \n  \n \n\n  \n    Treatment \n    30 \n    20 \n  \n  \n    Placebo \n    10 \n    60 \n  \n\n\n\n\n\n\nPart a\nEstimate the probability of having favorable results for subjects in the treatment group. Report with the 95% confidence interval.\n\n\nPart b\nRepeat part a for the placebo group.\n\n\nPart c\nConduct a statistical test to evaluate whether there is an association between group and outcome. What is the name of the test? Write down the null and alternative hypotheses. Compute the test statistic (by hand or by a software). What distribution does the test statistic follow under the null hypothesis? Give the p-value and interpret your result."
  },
  {
    "objectID": "homework/HW1.html#question-3",
    "href": "homework/HW1.html#question-3",
    "title": "Homework 1",
    "section": "Question 3",
    "text": "Question 3\nConsider a cohort study with results shown as in following table:\n\n\n\n\n \n  \n      \n    Favorable \n    Unfavorable \n  \n \n\n  \n    Treatment \n    6 \n    1 \n  \n  \n    Placebo \n    2 \n    5 \n  \n\n\n\n\n\nConduct a statistical test to evaluate whether there is an association between group and outcome. Write down the null and alternative hypotheses. Compute the expected cell counts under null hypothesis. What is the name of the test? Give the p-value and interpret your result."
  },
  {
    "objectID": "homework/HW1.html#question-4",
    "href": "homework/HW1.html#question-4",
    "title": "Homework 1",
    "section": "Question 4",
    "text": "Question 4\nTable 4 shows the information of a selected group of adolescents on whether they use smokeless tobacco and their perception of risk for using smokeless tobacco.\nTable 4:\n\n\n\n\n \n  \n      \n    YES \n    NO \n  \n \n\n  \n    Minimal \n    25 \n    60 \n  \n  \n    Moderate \n    35 \n    172 \n  \n  \n    Substantial \n    10 \n    200 \n  \n\n\n\n\n\n\nPart a\nConduct a statistical test to examine general association between adolescent smokeless tobacco users and risk perception. What is the name of the test? Write down the null and alternative hypotheses. Compute the test statistic (use software). What distribution does the test statistic follow under the null hypothesis? Give the p-value and interpret your result.\n\n\nPart b\nIs there a trend of increased risk perception for smokeless tobacco users? What test would you use? State the test, state any assumptions, conduct the inference test, and state your conclusions."
  },
  {
    "objectID": "homework/HW1.html#question-5",
    "href": "homework/HW1.html#question-5",
    "title": "Homework 1",
    "section": "Question 5",
    "text": "Question 5\nStart making a comprehensive table or outline for the inference tests that we have covered. Here is a list of the tests we have covered:\n\nSingle proportion\nChi-squared test for general association\nLikelihood ratio test for general association\nFisher’s Exact test for general association\nCochran-Armitage test for trend\nMantel-Haenszel test for linear trend\n\nAnd here is a list of attributes to include:\n\nNumber of variables testing\nTypes of variables\nCriteria (if any)\nHypothesis test\nTest statistic (if we went over it)\nR code for test\nSample size / Power calculation (optional, not discussed in class)\nSpecial notes (optional)\n\nFor example, I could make a table with different rows corresponding to different tests and different columns for each attribute."
  },
  {
    "objectID": "homework/HW1.html#question-6",
    "href": "homework/HW1.html#question-6",
    "title": "Homework 1",
    "section": "Question 6",
    "text": "Question 6\nI want you to gain experience exploring a package and function. This is an important skill in coding that can help you grow as an applied statistician.\nIn your previous course, the function lm() was introduced to perform linear regression. In this class, we will heavily use the function glm(). By typing “?glm” in the R console, we can open the Help page for glm(). The following questions ask about the glm() function. You can Google or use R documentation to answer the questions.\nFeel free to read more about the differences between lm() and glm().\n\nPart a\nWhat does the input “family” mean? If I wanted to perform regression using a Poisson distribution, what would I input into family?\n\n\nPart b\nWhat is the default action for the “na.action” input?\n\n\nPart c\nHow does the glm() function fit our model? (Hint: see “method”)\n\n\nPart d\nDo you think the output of summary() will be the same for lm() and glm()?"
  },
  {
    "objectID": "homework/HW1.html#question-7",
    "href": "homework/HW1.html#question-7",
    "title": "Homework 1",
    "section": "Question 7",
    "text": "Question 7\nOPTIONAL\nLet’s make a decision tree on the different tests we learned! I would like you to make a flow chart for the different tests we learned in Classes 1 and 2. You’ll need to include characteristics for:\n\nNumber of variables (1, 2, or 3 - we will go over 3 variables in Class 4)\nNumber of categories in each variable\nSample size is small\nOrdinal/nominal independent variable\nOrdinal/nominal response variable(s)\n\nFor example, if I make a decision tree that includes end nodes for different animals (cat, dog, snake, turtle, and hawk) using yes/no characteristics (has a shell, woof/meows, has fur, or flies), then my flow chart would look like: See my example under Sakai Resources. You are welcome to draw this chart. I used SmartArt under the Insert tab in Word to create mine."
  },
  {
    "objectID": "homework/HW2.html#questions",
    "href": "homework/HW2.html#questions",
    "title": "Homework 2",
    "section": "Questions",
    "text": "Questions\n\nQuestion 1\nA study looked at the effects of oral contraceptive (OC) use on heart disease in women 40 to 44 years of age. The researchers prospectively tracked whether or not the women developed a myocardial infarction (MI) over a 3-year period. The table below summarizes their results with columns indicating whether or not women developed MI and rows indicating their OC use.\n\n\n\n\n \n  \n      \n    Yes \n    No \n  \n \n\n  \n    OC users \n    13 \n    4987 \n  \n  \n    Non-OC users \n    7 \n    9993 \n  \n\n\n\n\n\n\nPart a\nCompute the estimated risk difference comparing OC users to non-OC users. Include a 95% CI for the estimate and interpretation of the estimated value.\n\n\nPart b\nCompute the estimated relative risk comparing OC users to non-OC users. Include a 95% CI for the estimate and interpretation of the estimated value.\n\n\nPart c\nCompute the estimated odds ratio comparing OC users to non-OC users. Include a 95% CI for the estimate and interpretation of the estimated value.\n\n\nPart d\nIs the OR a good approximation of the RR? Explain why or why not.\n\n\n\nQuestion 2\nOne important aspect of medical diagnosis is its reproducibility. Suppose that two different doctors examine 100 patients for dyspnea in a respiratory-disease clinic, and that doctor A diagnosed 15 patients as having dyspnea (while doctor B did not), doctor B diagnosed 10 patients as having dyspnea (while doctor A did not), and both doctor A and doctor B diagnosed 7 patients as having dyspnea.\n\nPart a\nConstruct a two-way contingency table to summarize the dyspnea diagnoses from doctor A and B.\n\n\nPart b\nCompute the Cohen’s kappa, 95% confidence interval, and interpret the results. What level of agreement does your kappa indicate?\n\n\n\nQuestion 3\nThis question is meant to emphasize the differences between linear regression and logistic regression. Each part will ask about different aspects of the two regression models. If the question has multiple choice answers, then you must write 1-2 sentences justifying your answer.\n\nPart a\nIn linear regression, what type of variable is our response/outcome variable?\n\nbinary\ncontinuous\ncount\nordinal\n\n\n\nPart b\nIn logistic regression, what type of variable is our response/outcome variable?\n\nbinary\ncontinuous\ncount\nnormal\n\n\n\nPart c\nWhat assumptions in linear regression? Please state the assumption name and characteristics of that assumption.\n\n\nPart d\nWhich assumptions of linear regression are violated if we try to fit a binary response using linear regression? You may choose more than one answer.\n\nIndependence\nLinearity\nNormality\nHomoscedasticity\n\n\n\nPart e\nPlease use our notes on generalized linear models (GLMs) to answer this question. What is the random component used in linear regression? What is the random component used in logistic regression? Name the specific variable type and distribution for it.\n\n\nPart f\nPlease use our notes on generalized linear models (GLMs) to answer this question. What link function do we use in linear regression? What link function do we use in logistic regression? Name the link and write out the function.\n\n\nPart g\nPlease use our notes on generalized linear models (GLMs) to answer this question. What is the systematic component used in simple linear regression? What is the systematic component used in simple logistic regression? Please write out the function for the systematic component for a single covariate.\n\n\nPart h\nHow do we determine our coefficient estimates (estimates of the parameter values) in linear regression? You may choose more than one answer.\n\nOrdinary least squares\nMaximum likelihood estimation\n\n\n\nPart i\nHow do we determine our coefficient estimates (estimates of the parameter values) in logistic regression? You may choose more than one answer.\n\nOrdinary least squares\nMaximum likelihood estimation\n\n\n\n\nQuestion 4\nThis question is taken from the Hosmer and Lemeshow textbook. The ICU study data set consists of a sample of 200 subjects who were part of a much larger study on survival of patients following admission to an adult intensive care unit (ICU). The dataset should be available within Course Materials. The major goal of this study was to develop a logistic regression model to predict the probability of survival to hospital discharge of these patients. In this question, the primary outcome variable is vital status at hospital discharge, STA. Clinicians associated with the study felt that a key determinant of survival was the patient’s age at admission, AGE.\nA code sheet for the variables to be considered is displayed in Table 1.5 below (from the Hosmer and Lemeshow textbook, pg. 23). We refer to this data set as the ICU data.\n\n\nPart a\nWrite down the equation for the logistic regression model of STA on AGE. What characteristic of the outcome variable, STA, leads us to consider the logistic regression model as opposed to the usual linear regression model to describe the relationship between STA and AGE?\n\n\nPart b\nWrite down an expression for the log-likelihood for the logistic regression model in Part a. This will me a mathematical expression. Please do not use generic expressions like \\(\\pi(X)\\), instead replace \\(X\\) with the specific variables in this question.\n\n\nPart c\nUsing the glm() function, obtain the maximum likelihood estimates of the coefficient parameters of the logistic regression model in Part a. Using these estimates, write down fitted logistic regression model.\n\n\nPart d\nUse the Wald test to test whether or not the intercept (\\(\\beta_0\\)) of the logistic regression model is significantly different from 0. Make sure to include your: hypothesis test, code/work leading to the computed test statistic, output including the test statistic and p-value, and conclusion. Please refer to the Additional Tips to guide you on what a complete/correct answer contains.\n\n\nPart e\nUse the Likelihood Ratio test to test whether or not the coefficient for age (\\(\\beta_1\\)) of the logistic regression model is significantly different from 0. Make sure to include your: hypothesis test, code/work leading to the computed test statistic, output including the test statistic and p-value, and conclusion. Please refer to the Additional Tips to guide you on what a complete/correct answer contains. You do not need to include an interpretation of the coefficient since we have not covered this."
  },
  {
    "objectID": "homework/HW2.html#question-1",
    "href": "homework/HW2.html#question-1",
    "title": "Homework 2",
    "section": "Question 1",
    "text": "Question 1\nA study looked at the effects of oral contraceptive (OC) use on heart disease in women 40 to 44 years of age. The researchers prospectively tracked whether or not the women developed a myocardial infarction (MI) over a 3-year period. The table below summarizes their results with columns indicating whether or not women developed MI and rows indicating their OC use.\n\n\nWarning: 'tidy.numeric' is deprecated.\nSee help(\"Deprecated\")\n\n\n# A tibble: 2 × 1\n  x[,\"Yes\"] [,\"No\"]\n      &lt;dbl&gt;   &lt;dbl&gt;\n1        13    4987\n2         7    9993\n\n\n\nPart a\nCompute the estimated risk difference comparing OC users to non-OC users. Include a 95% CI for the estimate and interpretation of the estimated value.\n\n\nPart b\nCompute the estimated relative risk comparing OC users to non-OC users. Include a 95% CI for the estimate and interpretation of the estimated value.\n\n\nPart c\nCompute the estimated odds ratio comparing OC users to non-OC users. Include a 95% CI for the estimate and interpretation of the estimated value.\n\n\nPart d\nIs the OR a good approximation of the RR? Explain why or why not."
  },
  {
    "objectID": "homework/HW2.html#question-2",
    "href": "homework/HW2.html#question-2",
    "title": "Homework 2",
    "section": "Question 2",
    "text": "Question 2\nI was intrigued by the results from Question 1, so I started researching the relationship between contraception and MI. In a journal review article, the authors present smoking status as a potential confounder for the relationship between OC use and MI. In Table 2 of their paper, they present various risk ratios for smoking and nonsmoking women. Use the below tables, that are recreated from one study’s data, to answer the following questions.\nNonsmokers:\n\n\nWarning: 'tidy.numeric' is deprecated.\nSee help(\"Deprecated\")\n\n\n# A tibble: 2 × 1\n  x[,\"Yes\"] [,\"No\"]\n      &lt;dbl&gt;   &lt;dbl&gt;\n1        36     317\n2        72     521\n\n\nSmokers:\n\n\nWarning: 'tidy.numeric' is deprecated.\nSee help(\"Deprecated\")\n\n\n# A tibble: 2 × 1\n  x[,\"Yes\"] [,\"No\"]\n      &lt;dbl&gt;   &lt;dbl&gt;\n1       210     416\n2       236     586\n\n\n\nPart a\nCompute the stratum-specific ORs for each smoking status. Present the estimates with 95% Confidence interval.\n\n\nPart b\nIs it appropriate to compute the smoking-adjusted Mantel-Haenszel odds ratio for OC vs. non-OC users? Explain your reasoning. You may choose to perform the Breslow-Day test only if you want to explore a new topic. Otherwise, use sentences to explain your general reasoning.\nIf you answered yes, then estimate the value with its 95% confidence interval.\n\n\nAside (not a homework problem)\nIf you are interested in a short review of the relationship between oral contraceptive pills (OCP) and MI, see this article abstract. I cannot find the full article online, so if you find it, please pass along. The abstract states:\n\nAlthough OCP doses were subsequently reduced, epidemiologic evidence continued to support a smaller, but significant association between OCPs and hypertension.\n\nThis single statement packs in some interesting aspects of the research process and influences from society. To start, the OCP doses were reduced from their initial approval. However, the early studies (1980s-90s) that link increased risk of hypertension and MI to OCs were still some of the first articles presented in my Google search. You may also find it interesting to think about how the perception of contraception has changed since the 1980s, and how societal views can impact research questions."
  },
  {
    "objectID": "homework/HW2.html#question-3",
    "href": "homework/HW2.html#question-3",
    "title": "Homework 2",
    "section": "Question 3",
    "text": "Question 3\nThe data presented below are from a case-control study of bladder cancer. Subjects with and without bladder cancer were recruited and then questioned about their occupation and cigarette consumption.\n\n\n\n\n\n\n  \n    \n    \n      High risk occupation\n      High cigarette consumption\n      Cases\n      Controls\n    \n  \n  \n    Yes\nNo\n48\n100\n    Yes\nYes\n180\n175\n    No\nNo\n30\n24\n    No\nYes\n120\n80\n  \n  \n  \n\n\n\n\n\nPart a\nPlease present the data using two 2x2 contingency table for High-risk occupation and Disease status, stratified by Cigarette consumption.\n\n\nPart b\nPlease present the data for High-risk occupation and Disease status using a 2x2 contingency table (you should combine the cigarette consumption).\n\n\nPart c\nIs it possible, in reference to the study design, to estimate the OR for bladder cancer and occupation from this study? If it is possible, calculate (using formulas) the crude odds ratio for bladder cancer comparing high-risk to other occupations, and estimate (using formulas) the associated 95% confidence intervals.\n\n\nPart d\nCompute the stratum-specific ORs at each of the two levels of cigarette consumption. Present the estimates with 95% Confidence interval.\n\n\nPart e\nIs it possible to estimate the RR for bladder cancer and occupation from this study? If it is possible, calculate the crude relative risk for bladder cancer comparing high-risk to other occupations, as well as the stratum-specific RRs at each of the two levels of cigarette consumption. Present the estimates with 95% Confidence interval. If it is not possible, give your reason.\n\n\nPart f\nWe will assume we found that odds ratios are relatively the same using the Breslow-Day test (which is true). Calculate the smoking-adjusted Mantel-Haenszel odds ratio for high-risk versus other occupations. Present the estimates with 95% Confidence interval.\n\n\nPart g\nAre the odds of bladder cancer different for high-risk versus other occupations after we adjusted for smoking status? (Hint: You should be running an inference test.)\n\n\nPart h\nDo you think the smoking-adjusted Mantel-Haenszel odds ratio for high-risk versus other occupations should be reported? Give your reason."
  },
  {
    "objectID": "homework/HW2.html#question-4",
    "href": "homework/HW2.html#question-4",
    "title": "Homework 2",
    "section": "Question 4",
    "text": "Question 4\nOne important aspect of medical diagnosis is its reproducibility. Suppose that two different doctors examine 100 patients for dyspnea in a respiratory-disease clinic, and that doctor A diagnosed 15 patients as having dyspnea (while doctor B did not), doctor B diagnosed 10 patients as having dyspnea (while doctor A did not), and both doctor A and doctor B diagnosed 7 patients as having dyspnea.\n\nPart a\nConstruct a two-way contingency table to summarize the dyspnea diagnoses from doctor A and B.\n\n\nPart b\nCompute the Cohen’s kappa (No need to compute the confidence interval.)\n\n\nPart c\nHow would you characterize the agreement between doctor A and B? Please refer to any guidelines used.\n\n\nPart d\nIs your computed kappa greater than 0? Run the appropriate test and interpret your results."
  },
  {
    "objectID": "homework/HW2.html#question-5",
    "href": "homework/HW2.html#question-5",
    "title": "Homework 2",
    "section": "Question 5",
    "text": "Question 5\nThis question is only graded for completion. Please fill out this Microsoft Form to help determine your project groups."
  },
  {
    "objectID": "readings.html",
    "href": "readings.html",
    "title": "613 Readings",
    "section": "",
    "text": "These reading assignments are for 613 students only. 613 students, you must complete all the readings by 6/6. I have included some recommended due dates that will keep you on track if you would like.\n\n\n\nReading\nRecommended Due Date\nLink to Sakai\nArticle\n\n\n\n\n1\n4/11 @ 11pm\n\n\n\n\n2\n4/25 @ 11pm\n\n\n\n\n3\n5/2 @ 11pm\n\n\n\n\n4\n5/16 @ 11pm\n\n\n\n\n5\n5/30 @ 11pm\n\n\n\n\n\n\nInstructions for each assignment\nFor each reading assignment, students will write a summary including:\n\nstudy background,\nwhy the author think the research important,\nstatistical methods used to address the research question,\nand a discussion/critique on whether you agree or disagree with the authors’  science and statistics.\n\nYou may write complete sentences under each bullet point. Please keep your summary to less than 1 page (margins are up to you). There are no requirements on formatting for references."
  },
  {
    "objectID": "weeks/week_01_sched.html",
    "href": "weeks/week_01_sched.html",
    "title": "Week 1",
    "section": "",
    "text": "```{css, echo=FALSE} .title{ font-size: 40px; color: #213c96; background-color: #fff; padding: 0px; }\n.description{ font-size: 20px; color: #fff; background-color: #213c96; padding: 10px; } ```"
  },
  {
    "objectID": "weeks/week_01_sched.html#resources",
    "href": "weeks/week_01_sched.html#resources",
    "title": "Week 1",
    "section": "Resources",
    "text": "Resources\nBelow is a table with links to resources. Icons in blue mean there is an available file link.\n\n\n\nLesson\nTopic\nSlides\nAnnotated Slides\nRecording(s)\n\n\n\n\n\nIntro to Course\n\n\n\n\n\n1\nFile Organization within R\n\n\n\n\n\n2\nIntroduction to Categorical Analysis\n\n\n\n\n\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser.\n\nFor example, in Chrome: I would click on the 3 vertical dots in the top right corner, then click Print, then change the Destination to “Save as PDF.”\nIt doesn’t seem to work well in Safari… Let me know if you’re having trouble.\n\n\nHere is the link to my Poll Everywhere!!"
  },
  {
    "objectID": "weeks/week_01_sched.html#announcements",
    "href": "weeks/week_01_sched.html#announcements",
    "title": "Week 1",
    "section": "Announcements",
    "text": "Announcements\n\nShared folder for students\n\nContains a few textbooks that you can use!\n\nWe will use Agresti and Hosmer & Lemeshaw mostly!\n\n\nMake sure you can get into the Echo360 page!!\nLast day to drop without penalty: 4/12/2024"
  },
  {
    "objectID": "weeks/week_01_sched.html#on-the-horizon",
    "href": "weeks/week_01_sched.html#on-the-horizon",
    "title": "Week 1",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_01_sched.html#class-exit-tickets",
    "href": "weeks/week_01_sched.html#class-exit-tickets",
    "title": "Week 1",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (4/1)\n Wednesday (4/3)"
  },
  {
    "objectID": "weeks/week_01_sched.html#additional-information",
    "href": "weeks/week_01_sched.html#additional-information",
    "title": "Week 1",
    "section": "Additional Information",
    "text": "Additional Information"
  },
  {
    "objectID": "weeks/week_01_sched.html#muddiest-points",
    "href": "weeks/week_01_sched.html#muddiest-points",
    "title": "Week 1",
    "section": "Muddiest Points",
    "text": "Muddiest Points\n\n1. Why does the test of trend treat ordinal variables as quantitative rather than qualitative?\nWhen we treat something as qualitative, we can only look at differences between groups. This means we cannot rank the groups and look at the change across groups. By treating the ordinal variables as quantitative, we can look at the change as we move from one group to another (and over all the ranked categories).\n\n\n2. Organizing the tests in a tree\nHere’s a organizational tree that I took from Meike and expanded:"
  },
  {
    "objectID": "lessons.html",
    "href": "lessons.html",
    "title": "Lessons",
    "section": "",
    "text": "Lesson\nTopic\nSlides\nAnnotated Slides\nRecording(s)\n\n\n\n\n1\nFile Organization within R\n\n\n\n\n\n2\nIntroduction to Categorical Analysis\n\n\n\n\n\n3\nMeasurement of Association for Contingency Tables\n\n\n\n\n\n4\nMeasurements of Association and Agreement\n\n\n\n\n\n\n5\nSimple Logistic Regression\n\n\n\n\n\n6\nTests for GLMs using Likelihood function\n\n\n\n\n\n7\nPredictions and Visualizations in Simple Logistic Regression\n\n\n\n\n\n8\nInterpretations and Visualizations of Odds Ratios\n\n\n\n\n\n9\nMissing Data\n\n\n\n\n\n9\nMultiple Logistic Regression\n\n\n\n\n\n10\nConfounders and Interactions\n\n\n\n\n\n11\nInterpretations and visualizations of ORs in Multiple Logistic Regression\n\n\n\n\n\n12\nModel Building Strategies\n\n\n\n\n\n13\nNumerical Problems\n\n\n\n\n\n14\nAssessing Model Fit\n\n\n\n\n\n15\nRevisit interpretations\n\n\n\n\n\n16\nPoisson Regression\n\n\n\n\n\n17\nLog-binomial regression"
  },
  {
    "objectID": "weeks/week_02_sched.html#resources",
    "href": "weeks/week_02_sched.html#resources",
    "title": "Week 2",
    "section": "Resources",
    "text": "Resources\n\n\n\nLesson\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n3\nMeasurement of Association for Contingency Tables\n\n\n\n\n\n4\nMeasurements of Association and Agreement\n\n\n\n\n\n\n\nIf you ever have trouble with the above links to the videos, this Echo360 link should take you to our class page.\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is from a computer internet browser:\n\nClick on the icon with three horizontal bars on the bottom left of the browser.\nClick on “Tools” with the gear icon at the top of the sidebar.\nClick on “PDF Export Mode.”\nFrom there, you can print or save the PDF as you would normally from your internet browser.\n\nNote: this process does not work very well on an iPad."
  },
  {
    "objectID": "weeks/week_02_sched.html#on-the-horizon",
    "href": "weeks/week_02_sched.html#on-the-horizon",
    "title": "Week 2",
    "section": "On the Horizon",
    "text": "On the Horizon\n\nHomework 1 due this Thursday!"
  },
  {
    "objectID": "weeks/week_02_sched.html#announcements",
    "href": "weeks/week_02_sched.html#announcements",
    "title": "Week 2",
    "section": "Announcements",
    "text": "Announcements\n\nMonday 4/8\n\nOffice hours!!\n\nTuesdays 5:30-7pm with Antara\nThursdays 3:30 - 5pm with Ariel\nFridays 2 - 3:30pm with Nicky\n\n\n\n\nWednesday 4/10\n\nEcho360: Let’s all double check that we can see the recordings\n\nLink to class site\n\nHomework question 5: no need to do LRT in the table\nLab 1 is up!!\nQuiz 1 decision\n\nOnline in Sakai\nWill open up on Monday at 2pm. You can chose to take it in the classroom or wait\nQuiz will close before class on Wednesday\nOpen book still\nPlease do not cheat\n\nIf I notice any unusual changes to quiz performance compared to last quarter then we will go back to the old way of giving quizzes\n\nMultiple choice with potentially some free response\n\nFor example: interpreting an OR would be divided into a multiple choice for the estimate, CI, and then writing a sentence to interpret the estimate"
  },
  {
    "objectID": "weeks/week_02_sched.html#class-exit-tickets",
    "href": "weeks/week_02_sched.html#class-exit-tickets",
    "title": "Week 2",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (4/8)\n Wednesday (4/10)"
  },
  {
    "objectID": "weeks/week_02_sched.html#muddiest-points",
    "href": "weeks/week_02_sched.html#muddiest-points",
    "title": "Week 2",
    "section": "Muddiest Points",
    "text": "Muddiest Points\n\n1. “times greater than” vs just “times” in interpretation\nI’ve seen it both ways. It comes down to more of an English language nuance, with what seems to be a long battle between viewpoints. Or maybe more accurately, I grammatically correct way to contruct the sentence, but with people understanding the meaning the “incorrect” way. I tend to be more lenient when it comes to grammar in this way, but maybe that’s because I have a general distaste when languages are rigid and don’t accommodate how people currently speak and write.\n\n\n2. For the relative risks poll everywhere question #2, how were they derived?\n\nFor #1 with Trt A’s risk as 0.01 (aka \\(risk_A=0.01\\)) and Trt B’s risk as 0.001 (aka \\(risk_B=0.01\\))\n\nThe risk ratio is: \\(\\widehat{RR} = \\dfrac{\\widehat{p}_1}{\\widehat{p}_2} = \\dfrac{risk_A}{risk_B} = \\dfrac{0.01}{0.001} = 10\\)\n\nFor #2 with Trt A’s risk as 0.41 (aka \\(risk_A=0.41\\)) and Trt B’s risk as 0.401 (aka \\(risk_B=0.401\\))\n\nThe risk ratio is: \\(\\widehat{RR} = \\dfrac{\\widehat{p}_1}{\\widehat{p}_2} = \\dfrac{risk_A}{risk_B} = \\dfrac{0.41}{0.401} = 1.02\\)\n\n\n\n\n3. Ranges that odds ratios can take (0, infinity) vs the ranges that risk ratios can take.\nYeah, so both can theoretically take on the range \\([0, \\infty)\\). Both are ratios, so we also have to think about the range of the denominator and numerator For relative risk, the numerator and denominator are probabilities that can only take values from 0 to 1. While for ORs, the denominator and numerator are odds that can be a range of values \\([0, \\infty)\\).\nThe main point I was trying to make was that once we observe one group’s proportion/probability, then RRs and ORs will differ in their potential range. Let’s say I observe the proportion fro group 1 and now know the numerator for RR and the odds in the numerator for OR. Because the RR has numerator and denominator that has ranges \\([0, 1]\\), if we know the proportion of group 1 (aka numerator value), then the ratio itself has a smaller range of values because the denominator can only be between 0 and 1. Because the OR has numerator and denominator that has ranges \\([0, \\infty)\\), if we know the proportion of group 1, then we do have a fixed numerator. However, the denominator can still be in \\([0, \\infty)\\).\n\n\n4. For the odds ratio equation that we reviewed today, is it different from ad/bc ? If they are different, when is it appropriate to use the equation we just reviewed over the other? p1/(1-p1) / p2/(1-p2)\nNope! These are the same! If you learned it that way, you can definitely use it when we are working with contingency tables. However, once we move into ORs from regression with multiple covariates, I think it’s better to understand the ORs and odds in terms of the probability/proportion.\n\n\n5. Not directly related to this class, but did we cover LRTs already? They’re mentioned in HW1 but aren’t in my notes.\nOops! Fixed it in the HW. No need to do anything with LRTs!\n\n\n6. In Epi, we were very strictly told that Odds Ratios were only to be used in one type of study. (I.e. we CAN NOT use them in cross-sectional and cohort studies) only case-control. So what is the application of attempting to utilize them, if each respective type of study already has a “pre-assigned” statistical method that suits it best?\nOdds ratios CAN be used in cross-sectional AND cohort studies. It is often an over-estimate of the relative risk in those situations, so it is important to interpret it ONLY as the odds ratio.\nEach respective study does not have a pre-assigned method. The only restriction is that relative risk cannot be used in case-control studies."
  },
  {
    "objectID": "instructors.html",
    "href": "instructors.html",
    "title": "Instructors",
    "section": "",
    "text": "Email: wakim@ohsu.edu\nOffice: VPT 622A\n\nPronouns: she/her/hers\nYou are welcome to address me as Nicky (pronounced “nik-EE”), Dr. Wakim (pronounced “wah-KEEM”), Dr. W, Dr. Nicky, Professor, Professor Wakim, or any combination of the prior.\nBest method to contact: Office hours or Slack for general course questions or E-mail/Calendly appointments for private communication.\n\n\n\n\n\n\n\n\n\n\nBrief professor statement: As a professor, my main goal is to instill a growth mindset into my students. Growth mindset means we are NOT stuck in our abilities or knowledge, and that we all can and will grow! This course aims to be as transparent as possible. I want you to understand my motivation for assessments, questions, and lessons. I also want those assessments to be clear, so please ask for clarification whenever needed.\n\n\nLink to Webex!!\n\nFridays 2 - 3:30pm"
  },
  {
    "objectID": "instructors.html#instructor-nicole-nicky-wakim-phd",
    "href": "instructors.html#instructor-nicole-nicky-wakim-phd",
    "title": "Instructors",
    "section": "",
    "text": "Email: wakim@ohsu.edu\nOffice: VPT 622A\n\nPronouns: she/her/hers\nYou are welcome to address me as Nicky (pronounced “nik-EE”), Dr. Wakim (pronounced “wah-KEEM”), Dr. W, Dr. Nicky, Professor, Professor Wakim, or any combination of the prior.\nBest method to contact: Office hours or Slack for general course questions or E-mail/Calendly appointments for private communication.\n\n\n\n\n\n\n\n\n\n\nBrief professor statement: As a professor, my main goal is to instill a growth mindset into my students. Growth mindset means we are NOT stuck in our abilities or knowledge, and that we all can and will grow! This course aims to be as transparent as possible. I want you to understand my motivation for assessments, questions, and lessons. I also want those assessments to be clear, so please ask for clarification whenever needed.\n\n\nLink to Webex!!\n\nFridays 2 - 3:30pm"
  },
  {
    "objectID": "instructors.html#teaching-assistants",
    "href": "instructors.html#teaching-assistants",
    "title": "Instructors",
    "section": "Teaching Assistants",
    "text": "Teaching Assistants\nAntara and Ariel were great students in my BSTA 513 class last year! They will have the following office hours and will help answer questions on Slack.\n\nAntara Vidyarthi\nLink to Zoom!!\n\nTuesdays 5:30 - 7pm\n\n\n\nAriel Weingarten\nLink to Webex!!\n\nThursdays 3:30 - 5pm"
  },
  {
    "objectID": "instructors.html#statistics-tutor-for-epidemiology-students",
    "href": "instructors.html#statistics-tutor-for-epidemiology-students",
    "title": "Instructors",
    "section": "Statistics Tutor for Epidemiology Students",
    "text": "Statistics Tutor for Epidemiology Students\n\nBecky Lanford\n\nEmail: lanford@ohsu.edu\nLink to Becky’s Calendly\n\nBecky can help with:\n\nStatistical coding support\nSupport with stats concepts you are learning in class\nData management and analysis plan scheming during your PE\n\nIntroduction from Becky:\n\nHello fellow MPH classmates! My name is Becky Lanford. I’m looking forward to helping support you in your coursework this quarter. A little about my background: I am currently in my final year in the MPH Epidemiology track and have completed most of my coursework including the biostatistics and epidemiology series (mostly working in R). I enrolled at the SPH as someone re-entering the workforce and quite new to statistical programming. Though I had previously completed a graduate degree (as a Physician Assistant/Associate), re-acclimating to graduate work and learning programming skills made for a steep learning curve my first academic year. I credit the collaborative learning environment at SPH - support of TA’s and classmates and availability of instructors - for helping me be successful. I hope I can help answer course-content questions, problem solve with you and find answers if I don’t have them myself. I know there are many challenges to being a graduate student and I am excited to help our public health student community grow stronger and more knowledgeable together."
  },
  {
    "objectID": "lectures/01_Data_Management/01_Data_Management.html#folder-organization",
    "href": "lectures/01_Data_Management/01_Data_Management.html#folder-organization",
    "title": "Lesson 1: Data Management",
    "section": "",
    "text": "For a project, I usually have the following folders\n\nBackground\nCode\nData_Raw\nData_Processed\nDissemination\nReports\nMeetings\n\n\n\n\nFor our class, I suggest making one folder for the course with the following folders in it:\n\nData\nHomework\nNotes\nProject\nQuizzes\nAnd other folders if you want"
  },
  {
    "objectID": "lectures/01_Data_Management/01_Data_Management.html#creating-project",
    "href": "lectures/01_Data_Management/01_Data_Management.html#creating-project",
    "title": "Lesson 1: Data Management",
    "section": "Creating project",
    "text": "Creating project\n\nGo into RStudio\nCreate new project"
  },
  {
    "objectID": "lectures/01_Data_Management/01_Data_Management.html#here-package",
    "href": "lectures/01_Data_Management/01_Data_Management.html#here-package",
    "title": "Lesson 1: Data Management",
    "section": "Here package",
    "text": "Here package\n::: columns ::: column - Good source for the here package\n-   Just substitute `.Rmd` with `.qmd`\n:::"
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#still-me",
    "href": "lectures/00_Intro/00_Intro.html#still-me",
    "title": "Lesson 0: Introduction",
    "section": "Still me!",
    "text": "Still me!"
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#some-important-tasks",
    "href": "lectures/00_Intro/00_Intro.html#some-important-tasks",
    "title": "Lesson 0: Introduction",
    "section": "Some important tasks",
    "text": "Some important tasks\n\nJoin the Slack page!\nStar the class website: https://nwakim.github.io/S2024_BSTA_513/\nComplete the WhenIsGood for office hours\n\nIf your calendar feels set, take 5 mintues to fill this out now!\nComplete by Thursday at 11pm!!!\n\nHighly suggest that you make an appointment with a learning specialist through Student Academic Support Services!\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#syllabus",
    "href": "lectures/00_Intro/00_Intro.html#syllabus",
    "title": "Lesson 0: Introduction",
    "section": "Syllabus",
    "text": "Syllabus\n\nNot many changes from last quarter’s syllabus\nAssessment breakdown is the same\n\n\n\n\n\n\n\n\n\n\n\nCourse activity\nType of Assessment\nDue Date\nPercentage of final grade (BSTA 513)\nPercentage of final grade (BSTA 613)\n\n\nHomework\nFormative\nEvery 1-2 weeks\n33%\n28%\n\n\nQuizzes\nSummative\n4/22, 5/13, 6/3\n25%\n25%\n\n\nProject Labs\nFormative\nEvery 2-3 weeks\n25%\n25%\n\n\nProject Report\nSummative\n6/13\n10%\n10%\n\n\nExit tickets (Attendance)\nN/A\nTwice Weekly\n5%\n5%\n\n\nMid-Quarter Feedback\nN/A\n5/2\n2%\n2%\n\n\n613 Readings\nFormative\nApprox. every other week\n0%\n5%"
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#homework-grading",
    "href": "lectures/00_Intro/00_Intro.html#homework-grading",
    "title": "Lesson 0: Introduction",
    "section": "Homework grading",
    "text": "Homework grading\n\nSlightly new grading\nNow, need to turn in 50% of the homework completed to get check mark\nNoticed that demonstrating understanding in the project was correlated with completing the homework*\n\nNo formal analysis was done on this\nAnd there may be confounders like time available to commit to this class in general\n\nEither way, I think practice is the most important tool for learning\n\nSo I want to us to practice the work, but I’m trying to balance this with added stress"
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#how-to-print-slides",
    "href": "lectures/00_Intro/00_Intro.html#how-to-print-slides",
    "title": "Lesson 0: Introduction",
    "section": "How to print slides",
    "text": "How to print slides\n\nAnyone have issues with this?\n\nI can show how to do it in Chrome and Safari\n\nInstructions on Quarto page"
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#lets-take-10-minutes",
    "href": "lectures/00_Intro/00_Intro.html#lets-take-10-minutes",
    "title": "Lesson 0: Introduction",
    "section": "Let’s take 10 minutes",
    "text": "Let’s take 10 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLesson 0: Introduction"
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#lets-take-10-minutes-for-student-survey",
    "href": "lectures/00_Intro/00_Intro.html#lets-take-10-minutes-for-student-survey",
    "title": "Lesson 0: Introduction",
    "section": "Let’s take 10 minutes for Student Survey",
    "text": "Let’s take 10 minutes for Student Survey\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n−+\n11:00"
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#homework-grading-in-syllabus",
    "href": "lectures/00_Intro/00_Intro.html#homework-grading-in-syllabus",
    "title": "Lesson 0: Introduction",
    "section": "Homework grading in syllabus",
    "text": "Homework grading in syllabus"
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#quizzes",
    "href": "lectures/00_Intro/00_Intro.html#quizzes",
    "title": "Lesson 0: Introduction",
    "section": "Quizzes",
    "text": "Quizzes\n\nMight be delivered slightly differently\nWe will still have the 50 minutes at the end of class to take the quiz\n\nAnd the quiz should only take 30 minutes\n\nHowever, RPV does not have private rooms for those who need it\nI am work-shopping ideas on how to deliver the quiz, including:\n\nTake home and turn in on Wednesday\nOnline vs. on paper\nWays to mitigate cheating"
  },
  {
    "objectID": "lectures/01_Data_Management/01_Data_Management.html",
    "href": "lectures/01_Data_Management/01_Data_Management.html",
    "title": "Lesson 1: Data Management",
    "section": "",
    "text": "For a project, I usually have the following folders\n\nBackground\nCode\nData_Raw\nData_Processed\nDissemination\nReports\nMeetings\n\n\n\n\nFor our class, I suggest making one folder for the course with the following folders in it:\n\nData\nHomework\nNotes\nProject\nQuizzes\nAnd other folders if you want"
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#course-learning-objectives",
    "href": "lectures/00_Intro/00_Intro.html#course-learning-objectives",
    "title": "Lesson 0: Introduction",
    "section": "Course Learning Objectives",
    "text": "Course Learning Objectives\nAt the end of this course, students should be able to…\n\nApply and interpret some hypothesis-testing procedures for two-way and three-way contingency tables\nCompute and interpret measures of association for binary and ordinal data.\nCalculate and correctly interpret odds ratios using logistic regression, make comparison across groups and examine relationship between binary outcome and predictor variables.\nApply appropriate model-building strategies for logistic regression. Effectively use statistical computing packages for contingency table and logistic regression procedures.\nPerform Poisson regression analysis using count data and interpret model estimates, make comparison across groups and examine relationship between outcome and predictor variables.\nCoherently summarize methods and results of data analyses, and discuss in context of original health-related research questions to audiences with varied statistical background."
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#new-way-to-recordview-lectures",
    "href": "lectures/00_Intro/00_Intro.html#new-way-to-recordview-lectures",
    "title": "Lesson 0: Introduction",
    "section": "New way to record/view lectures",
    "text": "New way to record/view lectures\n\nI will be using Echo360 to automatically record time from 1-3pm in this room!\nIt will be LIVE\n\nSo you can watch in real time, but won’t be able to interact with us\nMight have a 10 second lag\nNo need to tell me if you cannot make class\n\nHere is the link to our site! I’ll keep posting it on the weekly pages\n\nCurrently a public link, but working on getting everyone an account so we can make it private\n\nI don’t have to post anything after class, so no issues with me forgetting to post it"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html#folder-organization",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html#folder-organization",
    "title": "Lesson 1: File Organization within R",
    "section": "Folder organization",
    "text": "Folder organization\n\nMake these folders in your computer\n\nOnly make them in OneDrive if you have a desktop connection\n\n\n\n\n\nFor a project, I usually have the following folders\n\nBackground\nCode\nData_Raw\nData_Processed\nDissemination\nReports\nMeetings\n\n\n\n\nFor our class, I suggest making one folder for the course with the following folders in it:\n\nData\nHomework\nNotes\nProject\nQuizzes\nAnd other folders if you want\n\n\n\n\n\nTake a few minutes to create these folders\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html#creating-project",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html#creating-project",
    "title": "Lesson 1: File Organization within R",
    "section": "Creating project",
    "text": "Creating project\n\nGo into RStudio\nCreate new project"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html#here-package",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html#here-package",
    "title": "Lesson 1: File Organization within R",
    "section": "Here package",
    "text": "Here package\n\n\n\nGood source for the here package\nJust substitute .Rmd with .qmd\nBasically, a .qmd file and .R file work differently\n\nWe haven’t worked much with .R files\n\nFor .qmd files, the automatic directory is the folder it is in\n\nBut we want it to be the main project folder\n\nhere can help with that"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html#creating-a-new-qmd-file",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html#creating-a-new-qmd-file",
    "title": "Lesson 1: File Organization within R",
    "section": "Creating a new qmd file",
    "text": "Creating a new qmd file\n\nBasic steps\n\nCreate new .qmd (under File or top left corner)\nDecide on document types/options\n\nLet me show you my process\nCreate a .qmd in your Sample_folder under any folder (maybe Notes is good)\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html#creating-project-in-rstudio",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html#creating-project-in-rstudio",
    "title": "Lesson 1: File Organization within R",
    "section": "Creating project in RStudio",
    "text": "Creating project in RStudio\n\nWay to designate a working directory: basically your home base when working in R\n\nWe have to tell R exactly where we are in our folders and where to find other things\nA project makes it easier to tell R where we are\n\nBasic steps to create a project\n\nGo into RStudio\nCreate new project for this class (under File or top right corner)\n\nOnce we have projects, we can open one are R will automatically know that its location is the start of our working directory\nLet me show you my process\n\nI will create one in my Sample_folder\nI will show you how I switch between classes\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R_notes.html#folder-organization",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R_notes.html#folder-organization",
    "title": "Lesson 1: File Organization within R",
    "section": "Folder organization",
    "text": "Folder organization\n\n\n\nFor a project, I usually have the following folders\n\nBackground\nCode\nData_Raw\nData_Processed\nDissemination\nReports\nMeetings\n\n\n\n\nFor our class, I suggest making one folder for the course with the following folders in it:\n\nData\nHomework\nNotes\nProject\nQuizzes\nAnd other folders if you want\n\n\n\n\n\nLet’s take a couple minutes to do this!"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R_notes.html#creating-project-in-rstudio",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R_notes.html#creating-project-in-rstudio",
    "title": "Lesson 1: File Organization within R",
    "section": "Creating project in RStudio",
    "text": "Creating project in RStudio\n\nBasic steps\n\nGo into RStudio\nCreate new project for this class (under File or top right corner)\n\nLet me show you my process\nLet’s take a couple minutes to do this!"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R_notes.html#creating-a-new-qmd-file",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R_notes.html#creating-a-new-qmd-file",
    "title": "Lesson 1: File Organization within R",
    "section": "Creating a new qmd file",
    "text": "Creating a new qmd file"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R_notes.html#here-package",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R_notes.html#here-package",
    "title": "Lesson 1: File Organization within R",
    "section": "Here package",
    "text": "Here package\n::: columns ::: column - Good source for the here package\n-   Just substitute `.Rmd` with `.qmd`\n:::\n\n\n\n\n\n\n\n\n\nLesson 1: File Organization within R"
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#now-we-take-a-10-minute-break",
    "href": "lectures/00_Intro/00_Intro.html#now-we-take-a-10-minute-break",
    "title": "Lesson 0: Introduction",
    "section": "Now we take a 10 minute break!",
    "text": "Now we take a 10 minute break!\n\n\n\n−+\n10:00\n\n\n\n\n\nLesson 0: Introduction"
  },
  {
    "objectID": "lectures/00_Intro/00_Intro.html#new-exit-ticket-style",
    "href": "lectures/00_Intro/00_Intro.html#new-exit-ticket-style",
    "title": "Lesson 0: Introduction",
    "section": "New Exit ticket style",
    "text": "New Exit ticket style\n\nAll the questions are optional\nBut still open the link and submit!\n5 of the exit tickets are dropped!"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html#looking-at-source-vs.-visual",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html#looking-at-source-vs.-visual",
    "title": "Lesson 1: File Organization within R",
    "section": "Looking at Source vs. Visual",
    "text": "Looking at Source vs. Visual"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html#using-onedrive",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html#using-onedrive",
    "title": "Lesson 1: File Organization within R",
    "section": "Using OneDrive",
    "text": "Using OneDrive\n\nWe all have free access to OneDrive to store files\nLet’s login into our online accounts\nYou can also download OneDrive for your desktop\n\nAllows you to access the OneDrive from your computer’s interface instead of the browser\nCreates a link between your computer and the cloud!\n\nLet me show you mine\n\nI can access all the files through RStudio as well!\n\nLet’s take a couple minutes to log into OneDrive\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html#now-download-some-data-from-my-the-onedrive",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html#now-download-some-data-from-my-the-onedrive",
    "title": "Lesson 1: File Organization within R",
    "section": "Now download some data from my the OneDrive",
    "text": "Now download some data from my the OneDrive\n\nGo into the Student files folder\nDownload the dataset in Sample_folder, under Data\nCreate your own Sample_folder under Notes\n\nSave the dataset there\n\nAlternatively, you can download all of Sample_folder and then put that under Notes"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html#here-package-1n",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html#here-package-1n",
    "title": "Lesson 1: File Organization within R",
    "section": "Here package (1/n)",
    "text": "Here package (1/n)\n\n\n\nGood source for the here package\nJust substitute .Rmd with .qmd\nBasically, a .qmd file and .R file work differently\n\nWe haven’t worked much with .R files\n\nFor .qmd files, the automatic directory is the folder it is in\n\nBut we want it to be the main project folder\n\nhere can help with that"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html#here-package-2n",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html#here-package-2n",
    "title": "Lesson 1: File Organization within R",
    "section": "Here package (2/n)",
    "text": "Here package (2/n)\n\nInstall here package: you can do this in your console (not inside .qmd file)\n\n\ninstall.packages(\"here\")\n\n\nWithin your .qmd file\n\n\n\nLesson 1: File Organization within R"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html#install-here-package",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html#install-here-package",
    "title": "Lesson 1: File Organization within R",
    "section": "Install here package",
    "text": "Install here package\n\nInstall here package: you can do this in your console (not inside .qmd file)\n\n\ninstall.packages(\"here\")\n\n\nWithin your console, type here() and enter\n\nTry this with getwd() as well"
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html#using-here-to-load-data",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html#using-here-to-load-data",
    "title": "Lesson 1: File Organization within R",
    "section": "Using here() to load data",
    "text": "Using here() to load data\n\nThere here() function will start at the working directory (where your .Rproj file is) and let you write out a file path for anything\nTo load the dataset in our .qmd file, we will use:\n\n\ndata = read_excel(here(\"./Data/CH05Q01.xls\"))\ndata = read_excel(here(\"Data\", \"CH05Q01.xls\"))\n\n\n\nWatch out when using lubridate package simultaneously\n\n\nUse here::here() if you have lubridate loaded within same .qmd. This will tell R to use the function here() within the here package instead of lubridate’s here() function. To call lubridate’s function, we’d use lubridate::here()\n\n\n\n\n\n−+\n05:00\n\n\n\n\n\nLesson 1: File Organization within R"
  },
  {
    "objectID": "homework/HW1.html#questons-part-1",
    "href": "homework/HW1.html#questons-part-1",
    "title": "Homework 1",
    "section": "Questons Part 1",
    "text": "Questons Part 1\nThe following questions are intended to give you practice in understanding concepts and completing calculations.\n\nQuestion 1\nIf the probability that one white blood cell is a lymphocyte is 0.3, compute the probability of 2 lymphocytes out of 10 white blood cells. Also, compute the probability that at least 3 lymphocytes out of 10 white blood cells. You may calculate by hand, using a web app, or using R.\n\n\nQuestion 2\nConsider a 2 x 2 table from a prospective cohort study:\n\n\n\n\n \n  \n      \n    Favorable \n    Unfavorable \n  \n \n\n  \n    Treatment \n    30 \n    20 \n  \n  \n    Placebo \n    10 \n    60 \n  \n\n\n\n\n\n\nPart a\nEstimate the probability of having favorable results for subjects in the treatment group. Include an interpretation and report with the 95% confidence interval.\n\n\nPart b\nRepeat part a for the placebo group.\n\n\nPart c\nConduct a statistical test to evaluate whether there is an association between group and outcome. What is the name of the test? Make sure to follow the entire test process demonstrated in the slides.\n\n\n\nQuestion 3\nConsider a cohort study with results shown as in following table:\n\n\n\n\n \n  \n      \n    Favorable \n    Unfavorable \n  \n \n\n  \n    Treatment \n    6 \n    1 \n  \n  \n    Placebo \n    2 \n    5 \n  \n\n\n\n\n\nConduct a statistical test to evaluate whether there is an association between group and outcome. What is the name of the test? Make sure to follow the entire test process demonstrated in the slides.\n\n\nQuestion 4\nTable 4 shows the information of a selected group of adolescents on whether they use smokeless tobacco and their perception of risk for using smokeless tobacco.\nTable 4:\n\n\n\n\n \n  \n      \n    YES \n    NO \n  \n \n\n  \n    Minimal \n    25 \n    60 \n  \n  \n    Moderate \n    35 \n    172 \n  \n  \n    Substantial \n    10 \n    200 \n  \n\n\n\n\n\n\nPart a\nConduct a statistical test to examine general association between adolescent smokeless tobacco users and risk perception. What is the name of the test? Make sure to follow the entire test process demonstrated in the slides.\n\n\nPart b\nIs there a trend of increased risk perception for smokeless tobacco users? What test would you use? Make sure to follow the entire test process demonstrated in the slides."
  },
  {
    "objectID": "homework/HW1.html#questions-part-2",
    "href": "homework/HW1.html#questions-part-2",
    "title": "Homework 1",
    "section": "Questions Part 2",
    "text": "Questions Part 2\nThe following questions are intended to give you practice in connecting concepts that will help you make decisions in real world applications.\n\nQuestion 5\nStart making a comprehensive table or outline for the inference tests that we have covered. Here is a list of the tests we have covered:\n\nSingle proportion\nChi-squared test for general association\nFisher’s Exact test for general association\nCochran-Armitage test for trend\nMantel-Haenszel test for linear trend\n\nAnd here is a list of attributes to include:\n\nNumber of variables testing\nTypes of variables\nCriteria (if any)\nHypothesis test\nTest statistic (if we went over it)\nR code for test\nSample size / Power calculation (optional, not discussed in class)\nSpecial notes (optional)\n\nFor example, I could make a table with different rows corresponding to different tests and different columns for each attribute.\n\n\nQuestion 6\nI want you to gain experience exploring a package and function. This is an important skill in coding that can help you grow as an applied statistician.\nIn your previous course, the function lm() was introduced to perform linear regression. In this class, we will heavily use the function glm(). By typing “?glm” in the R console, we can open the Help page for glm(). The following questions ask about the glm() function. You can Google or use R documentation to answer the questions.\nFeel free to read more about the differences between lm() and glm().\n\nPart a\nWhat does the input “family” mean? If I wanted to perform regression using a Poisson distribution, what would I input into family?\n\n\nPart b\nWhat is the default action for the “na.action” input?\n\n\nPart c\nHow does the glm() function fit our model? (Hint: see “method”)\n\n\nPart d\nDo you think the output of summary() will be the same for lm() and glm()?\n\n\n\nQuestion 7\nOPTIONAL\nLet’s make a decision tree on the different tests we learned! I would like you to make a flow chart for the different tests we learned in Classes 1 and 2. You’ll need to include characteristics for:\n\nNumber of variables (1, 2, or 3 - we will go over 3 variables in Class 4)\nNumber of categories in each variable\nSample size is small\nOrdinal/nominal independent variable\nOrdinal/nominal response variable(s)\n\nFor example, if I make a decision tree that includes end nodes for different animals (cat, dog, snake, turtle, and hawk) using yes/no characteristics (has a shell, woof/meows, has fur, or flies), then my flow chart would look like: See my example under Sakai Resources. You are welcome to draw this chart. I used SmartArt under the Insert tab in Word to create mine."
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#what-is-categorical-data-analysis",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#what-is-categorical-data-analysis",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "What is Categorical Data Analysis?",
    "text": "What is Categorical Data Analysis?\n\nIn BSTA 512/612 (linear regression), we focused on continuous responses/outcomes\n\nWe included categorical variables only as covariates (aka predictors, independent variables, explanatory variables)\nExamples from 512/612: life expectancy (in years), IAT score (ranging from -2 to 2)\n\n\n   \n\nCategorical data analysis focuses on the statistical methods for categorical responses/outcomes\n\nExplanatory (or ‘independent’) variable can be of any type (continuous or categorical)"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#types-of-variables",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#types-of-variables",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Types of Variables",
    "text": "Types of Variables"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#types-of-variables-1",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#types-of-variables-1",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Types of Variables",
    "text": "Types of Variables\n\n\n\nLesson 2: Introduction to Categorical Data Analysis"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#types-of-variables-outcomes-we-will-cover-in-this-course",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#types-of-variables-outcomes-we-will-cover-in-this-course",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Types of Variables: Outcomes we will cover in this course",
    "text": "Types of Variables: Outcomes we will cover in this course"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#what-does-this-course-cover",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#what-does-this-course-cover",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "What does this course cover?",
    "text": "What does this course cover?\n\nStrategies for assessing association between categorical response variable and a one explanatory variable\n\nHypothesis testing\nMeasure of association\nSimple logistic regression\n\n\n   \n\nStatistical modeling strategies for assessing association between the categorical response variable and a set of explanatory variables\n\nLogistic regression\n\nFor binary, ordinal, and multinomial outcomes\n\nPoisson regression\n\nFor counts outcomes"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#section",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#section",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "",
    "text": "Smoking status example\n\n\nA cross-sectional study of 8681 patients was conducted to evaluate the nature of smoking status among people. Of the 8681 people, 4840 were nonsmokers and 3841 were smokers.\n\n\nNeeded steps:\n\nEstimate proportion \\(\\widehat{p}\\)\nCheck that \\(n\\widehat{p}&gt;10\\) and \\(n(1-\\widehat{p})&gt;10\\) in order to make normal approximation\nConstruct 95% confidence interval\nWrite interpretation"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#what-does-this-course-cover-1",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#what-does-this-course-cover-1",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "What does this course cover?",
    "text": "What does this course cover?\n\n\nStrategies for assessing association between categorical response variable and a one explanatory variable\n\nHypothesis testing\n\n\n\n\n\nMeasure of association\nSimple logistic regression\n\n\n   \n\nStatistical modeling strategies for assessing association between the categorical response variable and a set of explanatory variables\n\nLogistic regression\n\nFor binary, ordinal, and multinomial outcomes\n\nPoisson regression\n\nFor counts outcomes"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#more-resources",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#more-resources",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "More resources",
    "text": "More resources\n\nFor a refresher or review of one proportion and differences in proportions\n\nAnd their power calculations\nFrom Meike’s BSTA 511 course (see Day 12!)\n\nFor a refresher or review of Chi-squared test or Fisher’s Exact test\n\nFrom Meike’s BSTA 511 course (see Day 13!)\n\n\n\n\nLesson 2: Introduction to Categorical Data Analysis"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#poll-everywhere-question-1",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#poll-everywhere-question-1",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Poll everywhere question 1",
    "text": "Poll everywhere question 1"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#binomial-distribution",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#binomial-distribution",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nConsider a sample of \\(n\\) independent trials, each of which can have only two possible outcomes (“success” and “failure”)\nFor each trial: \\[\\begin{align} P( \\text{success}) & = p \\\\\n                  P( \\text{failure}) & = 1- p = q \\end{align}\\]\nBinomial distribution: distribution of the number of successes in n independent trials\nThe probability mass function for the binomial distribution is: \\[P(X=k) = {n \\choose k} p^k q^{n-k}, \\text{ for } k = 0, 1, ..., n\\]\n\n\\(E(X) = np\\)\n\\(Var(X) = npq = np(1-p)\\)"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#binomial-distribution-1",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#binomial-distribution-1",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nConsider a sample of \\(n\\) independent trials, each of which can have only two possible outcomes (“success” and “failure”)\nFor each trial: \\[\\begin{align} P( \\text{success}) & = p \\\\\n                  P( \\text{failure}) & = 1- p = q \\end{align}\\]\nBinomial distribution: distribution of the number of successes in n independent trials\nThe probability mass function for the binomial distribution is: \\[P(X=k) = {n \\choose k} p^k q^{n-k}, \\text{ for } k = 0, 1, ..., n\\]\n\n\\(E(X) = np\\)\n\\(Var(X) = npq = np(1-p)\\)"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#binomial-distribution-r-commands",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#binomial-distribution-r-commands",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Binomial Distribution: R commands",
    "text": "Binomial Distribution: R commands\nR commands with their input and output:\n\n\n\n\n\n\n\nR code\nWhat does it return?\n\n\n\n\nrbinom()\nreturns sample of random variables with specified binomial distribution\n\n\ndbinom()\nreturns probability of getting certain number of successes\n\n\npbinom()\nreturns cumulative probability of getting certain number or less successes\n\n\nqbinom()\nreturns number of successes corresponding to desired quantile"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#binomial-distribution-example",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#binomial-distribution-example",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Binomial Distribution Example",
    "text": "Binomial Distribution Example\n\n\nExample\n\n\nIf the probability that one white blood cell is a lymphocyte is 0.2, compute the probability of 2 lymphocytes out of 10 white blood cells\n\n\n\\[P(X=2) = {10 \\choose 2} 0.2^2 (1-0.2)^{10-2}  = 0.3020\\]\n\ndbinom(2, 10, 0.2) %&gt;% round(4)\n\n[1] 0.302"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#normal-approximation-of-the-binomial-distribution",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#normal-approximation-of-the-binomial-distribution",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Normal Approximation of the Binomial Distribution",
    "text": "Normal Approximation of the Binomial Distribution\n\nAlso known as: Sampling distribution of \\(\\widehat{p}\\)\nIF \\(X\\sim \\text{Binomial}(n,p)\\) and \\(np&gt;10\\) and \\(nq = n(1-p) &gt; 10\\)\n\nEnsures sample size (\\(n\\)) is moderately large and the \\(p\\) is not too close to 0 or 1\nOther resources use other criteria (like \\(npq&gt;5\\) or \\(np&gt;5\\))\nWhen looking at a sample, we use \\(\\widehat{p}\\) instead of \\(p\\) to check this!!\n\n\n \n\nTHEN approximately \\(𝑋\\sim \\text{Normal}\\big(\\mu_X = np, \\sigma_X = \\sqrt{np(1-p)} \\big)\\)\n\nOr we often write this as the sampling distribution of \\(\\widehat{p}\\): \\[\\widehat{p} \\sim \\text{Normal}\\bigg(\\mu_{\\widehat{p}} = p, \\sigma_{\\widehat{p}} = \\sqrt{\\dfrac{p(1-p)}{n}}\\bigg)\\]\n\nPretty good video behind the intuition of this (Watch 00:00 - 05:40)"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#estimate-of-single-proportion",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#estimate-of-single-proportion",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Estimate of Single Proportion",
    "text": "Estimate of Single Proportion\n\nEstimate of proportion:\n\n\\[\n\\widehat{p} = \\dfrac{\\# \\text{successes}}{\\# \\text{successes} + \\# \\text{failures}}\n\\]\n\nUse the sampling distribution of \\(\\widehat{p}\\) to contruct the confidence interval:\n\n\\((1-\\alpha)\\%\\) confidence interval for estimate proportion:\n\n\n\\[\\begin{align} \\widehat{p} &\\pm z^*_{(1-\\alpha/2)} \\cdot SE_{\\hat{p}} \\\\ \\widehat{p} &\\pm z^*_{(1-\\alpha/2)} \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\end{align}\\]\n\nUsing \\(SE_{\\hat{p}} = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) - instead of \\(\\sigma_{p} = \\sqrt{\\frac{p(1-p)}{n}}\\) - because we don’t know exactly what \\(p\\) is"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#example-smoking-status",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#example-smoking-status",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Example: Smoking Status",
    "text": "Example: Smoking Status\nA cross-sectional study of 8681 patients was conducted to evaluate the nature of smoking status among people. Of the 8681 people, 4840 were nonsmokers and 3841 were smokers.\n\nEstimate proportion \\(\\widehat{p}\\)\nCheck that \\(np&gt;10\\) in order to make normal approximation\nConstruct 95% confidence interval\nWrite interpretation"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#estimate-for-difference-in-proportions",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#estimate-for-difference-in-proportions",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Estimate for Difference in Proportions",
    "text": "Estimate for Difference in Proportions\nWhat to use for SE in CI formula?\n\\[\\hat{p}_1 - \\hat{p}_2 \\pm z^* \\cdot SE_{\\hat{p}_1 - \\hat{p}_2}\\]\nSE in sampling distribution of \\(\\hat{p}_1 - \\hat{p}_2\\)\n\\[\\sigma_{\\hat{p}_1 - \\hat{p}_2} =\n\\sqrt{\n\\frac{p_1\\cdot(1-p_1)}{n_1} + \\frac{p_2\\cdot(1-p_2)}{n_2}} \\]\nProblem: We don’t know what \\(p\\) is - it’s what we’re estimating with the CI.\nSolution: approximate \\(p_1\\), \\(p_2\\) with \\(\\hat{p}_1\\), \\(\\hat{p}_2\\):\n\\[SE_{\\hat{p}_1 - \\hat{p}_2} = \\sqrt{\n\\frac{\\hat{p}_1\\cdot(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2\\cdot(1-\\hat{p}_2)}{n_2}}\\]"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#example-heart-attack-study",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#example-heart-attack-study",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Example: Heart Attack Study",
    "text": "Example: Heart Attack Study"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#mcnemars-test",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#mcnemars-test",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "McNemar’s Test",
    "text": "McNemar’s Test\n\nMcNemar’s test should be used if data is from a matched pairs study\n\n \n\nWhat is a matched-pairs study?\n\nParticipants are paired based on key characteristics\nEach participant within a pair will be assigned to different treatment groups\n\nCategorical test that is parallel to the “paired t-test”\n\n \n\nR packages and functions\n\nNormal approximation: mcnemar.test() in built-in stats package\nExact test: mcnemar.exact() in exact2x2 package\n\n\n \n\nIf you would like more information of McNemar’s test, please see Rosner TB: 10.4 and 10.5: Paired Samples"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#contingency-tables",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#contingency-tables",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Contingency Tables",
    "text": "Contingency Tables"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of General Association",
    "text": "Test of General Association\n\nGeneral research question: Are two variables (both categorical, nominal) associated with each other?\n\n \n\nTranslated to a hypothesis test:\n\n\\(H_0\\) : There is no association between the two variables / The variables are independent\n\\(H_1\\) : There is an association between the two variables / The variables are not independent\n\n\n   \n\nWe have two options for testing general association:\n\nChi-squared test\nFisher’s Exact test"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-chi-squared",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-chi-squared",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of General Association: Chi-squared",
    "text": "Test of General Association: Chi-squared\n\nTest to see how likely is it that we observe our data given the null hypothesis (no association)\nWe use the null to calculate the expected cell counts and compare them to the observed cell counts\nRequirements to conduct Chi-squared test\n\nFor 2 x 2 contingency table:\n\nNo expected cell counts should be less than 10\n\nFor contingency table with 3x2, 3x3, 4x4, etc.:\n\nNo more than 20% of expected cell counts are less than 5\nNo expected cell counts are less than 1"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-likelihood-ratio-test-lrt",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-likelihood-ratio-test-lrt",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of General Association: Likelihood Ratio Test (LRT)",
    "text": "Test of General Association: Likelihood Ratio Test (LRT)"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-fishers-exact-test",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-fishers-exact-test",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of General Association: Fisher’s Exact Test",
    "text": "Test of General Association: Fisher’s Exact Test\n\nOnly necessary when expected counts in one or more cells is less than 5\nGiven row and column totals fixed, computes exact probability that we observe our data or more extreme data\nConsider a general 2 x 2 table:\n\n\n\nThe exact probability of observing a table with cells (a, b, c, d) can be computed based on the hypergeometric distribution\n\n\\[P(a, b, c, d) = \\dfrac{(a+b)!\\cdot(c+d)!\\cdot(a+c)!\\cdot(b+d)!}{n!\\cdot a!\\cdot b!\\cdot c!\\cdot d!}\\]\n\nNumerator is fixed and denominator changes"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#example-heart-attack-study-1",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#example-heart-attack-study-1",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Example: Heart Attack Study",
    "text": "Example: Heart Attack Study"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of Trend",
    "text": "Test of Trend\n\nIf one or both variables are ordinal, a test of trend may be of interest\n\nTreats ordinal variables as quantitative rather than qualitative (nominal scale)\nTest of trend has greater power than the test of general association\nYou can use a test of general association for non-ordinal variables\n\n\n \n\nTwo tests of trend that we we learn:\n\nCochran-Armitage test\n\nTests association between a binary response and an ordinal explanatory variable\n\nMantel-Haenszel test\n\nTest association between an ordinal response and an ordinal explanatory variable"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-cochran-armitage-test",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-cochran-armitage-test",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of Trend: Cochran-Armitage test",
    "text": "Test of Trend: Cochran-Armitage test\n\nCochran-Armitage test for trend will determine if there is association between a binary response variable and an ordinal variable with 3 or more categories\nIt will test the trend of the proportions over the ordinal variable\n\nAnswers the question: Does the proportion of people with a “successful” outcome increase as the ordinal explanatory variable increases?\n\nCochran-Armitage test for trend is only suitable for 2 x C contingency tables"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-mantel-haenszel-test",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-mantel-haenszel-test",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of Trend: Mantel-Haenszel test",
    "text": "Test of Trend: Mantel-Haenszel test\n\nWhen both variables are ordinal, we can conduct Mantel-Haenszel test of trend for linear association\nMantel-Haenszel test for linear trend is suitable for any R x C contingency tables with two ordinal variables\nHypothesis test:\n\n\n\n\n\nNull Hypothesis (\\(H_0\\))\n\n\nThere is no correlation between the two variables \\[ \\rho = 0\\]\n\n\n\n\n\nAlternative Hypothesis (\\(H_1\\))\n\n\nThere is correlation between the two variables\n\\[ \\rho \\neq 0\\]"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#section-1",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#section-1",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "",
    "text": "Smoking status example\n\n\nA cross-sectional study of 8681 patients was conducted to evaluate the nature of smoking status among people. Of the 8681 people, 4840 were nonsmokers and 3841 were smokers.\n\n\n\n\n\nEstimate proportion \\(\\widehat{p}\\) \\[ \\widehat{p} = \\dfrac{3841}{3841 + 4840} = \\dfrac{3841}{8681} = 0.44246\\]\nCheck that \\(n\\widehat{p}&gt;10\\) and \\(n(1-\\widehat{p})&gt;10\\) in order to make normal approximation \\[ n\\widehat{p} = 8681\\cdot0.4425 = 3841 &gt; 10\\] \\[ n(1-\\widehat{p}) = 8681\\cdot(1-0.4425) = 4840 &gt; 10\\]\n\n\n\nConstruct 95% confidence interval\n\n\\[ \\widehat{p} \\pm z^*_{0.975} \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\]\n\nprop.test(x = 3841, n = 8681, correct = T)\n\n\n    1-sample proportions test with continuity correction\n\ndata:  3841 out of 8681, null probability 0.5\nX-squared = 114.73, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.4319827 0.4529896\nsample estimates:\n        p \n0.4424605 \n\n\n\nWrite interpretation of estimate\n\nThe estimated proportion of smokers is 0.442 (95% CI: 0.432, 0.453).\nAdditional interpretation of CI: We are 95% confident that the (population) proportion of smokers is between 0.432 and 0.453."
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#poll-everywhere-question-2",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#poll-everywhere-question-2",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Poll everywhere question 2",
    "text": "Poll everywhere question 2"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#summary-so-far",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#summary-so-far",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Summary so far",
    "text": "Summary so far\n\nIntroduced categorical data as the response in analysis\nReviewed an important distribution (Binomial distribution) for categorical data analysis\nEstimated a single proportion from a sample with its confidence interval\nEstimated a difference in proportions from a sample with its confidence interval\n\n   \n\nCan we expand this to ask a more general question about association between a response and explanatory variable?\n\nWhat if there is more than 2 categories for either variable?"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#basic-analytical-procedures",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#basic-analytical-procedures",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Basic Analytical Procedures",
    "text": "Basic Analytical Procedures\nGeneral procedure:\n \n\nPresent observed data\n\n \n\nDescriptive analysis\n\n \n\nInferential tests"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#estimate-and-confidence-interval-of-single-proportion",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#estimate-and-confidence-interval-of-single-proportion",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Estimate and Confidence Interval of Single Proportion",
    "text": "Estimate and Confidence Interval of Single Proportion\n\nEstimate of proportion:\n\n\\[\n\\widehat{p} = \\dfrac{\\# \\text{successes}}{\\# \\text{successes} + \\# \\text{failures}}\n\\]\n\nUse the sampling distribution of \\(\\widehat{p}\\) to construct the confidence interval:\n\n\\((1-\\alpha)\\%\\) confidence interval for estimate proportion:\n\n\n\\[\\begin{align} \\widehat{p} &\\pm z^*_{(1-\\alpha/2)} \\cdot SE_{\\hat{p}} \\\\ \\widehat{p} &\\pm z^*_{(1-\\alpha/2)} \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\end{align}\\]\n\nUsing \\(SE_{\\hat{p}} = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) - instead of \\(\\sigma_{p} = \\sqrt{\\frac{p(1-p)}{n}}\\) - because we don’t know exactly what \\(p\\) is"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#estimate-and-confidence-interval-for-difference-in-proportions",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#estimate-and-confidence-interval-for-difference-in-proportions",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Estimate and Confidence Interval for Difference in Proportions",
    "text": "Estimate and Confidence Interval for Difference in Proportions\n\nUse the sampling distribution of \\(\\widehat{p}_1\\) and \\(\\widehat{p}_2\\) to construct the confidence interval:\n\n\\((1-\\alpha)\\%\\) confidence interval for estimate difference in proportions:\n\n\n\\[\\begin{align} \\widehat{p}_1 - \\widehat{p}_2 &\\pm z^*_{(1-\\alpha/2)} \\cdot SE_{\\hat{p}_1 - \\hat{p}_2} \\\\ \\widehat{p}_1 - \\widehat{p}_2 &\\pm z^*_{(1-\\alpha/2)} \\cdot \\sqrt{\n\\frac{\\hat{p}_1\\cdot(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2\\cdot(1-\\hat{p}_2)}{n_2}} \\end{align}\\]\n\nUsing \\(SE_{\\hat{p}_1 - \\hat{p}_2} = \\sqrt{\\frac{\\hat{p}_1\\cdot(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2\\cdot(1-\\hat{p}_2)}{n_2}}\\) because we don’t know exactly what \\(p_1\\) and \\(p_2\\) are"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#poll-everywhere-question-3",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#poll-everywhere-question-3",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Poll Everywhere Question 3",
    "text": "Poll Everywhere Question 3"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#step-1-present-observed-data",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#step-1-present-observed-data",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Step 1: Present Observed Data",
    "text": "Step 1: Present Observed Data\nCategorical data are often presented in tabular form, known as contingency table, which displays counts of outcomes in the cell • Smoking Example: 2 X 2 contingency table for smoking status by sex assigned at birth (sex AAB) • For ordinal variables: make sure level of rows and columns are sorted correctly"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#step-2-descriptive-analysis",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#step-2-descriptive-analysis",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Step 2: Descriptive Analysis",
    "text": "Step 2: Descriptive Analysis\nIncludes estimation of the proportions • Computed proportions should almost always be reported with 95% estimated confidence interval • If proportions are confusing as written, can use graphic representation (i.e. bar chart) • Smoking Example: 49.6% (95% CI: (48.1%, 51.0%)) of people assigned male at birth are nonsmokers and 62.5% (95% CI: (61.0%, 63.9%)) of people assigned female at birth are nonsmokers"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#step-3-inferential-tests",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#step-3-inferential-tests",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Step 3: Inferential Tests",
    "text": "Step 3: Inferential Tests\nTo evaluate the association between the categorical response variable and a categorical independent variable • If only two categories in both variables (Class 1 notes) • Use difference in proportions • If matched-pair, use McNemar’s test • If two variables with 2 or more categories (Today’s Notes) • For nominal categories: Chi-square test, Likelihood Ratio test, or Fisher’s exact test • For one nominal/one ordinal variable: Cochran-Armitage test • For ordinal categories: Mantel-Haenszel test"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#contingency-tables-r-x-c",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#contingency-tables-r-x-c",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Contingency Tables (R x C)",
    "text": "Contingency Tables (R x C)\n\nR X C contingency tables\n\nContains information for two discrete variables: one has R categories and the other has C categories.\nRefers to the number of rows (R) and number of columns (C) in the table\n\n\n \n\nFor two proportions: focused on 2 X 2 contingency tables\n\nR = 2, C = 2\n\n\n \n\nExpand our contingency tables to variables with 2 or more categories\n\nCategories can be ordinal or nominal"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#contigency-table-example",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#contigency-table-example",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Contigency Table: Example",
    "text": "Contigency Table: Example\nLet’s say we are interested in learning the association between the development of breast cancer and age at first birth. Our first step in our basic analytical procedure is to display the data with a contingency table:\n{fig-align=“center”; width=“400”}\n\nThis is a 2 x 5 contingency table"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-associationtrend-of-r-x-c-contingency-table",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-associationtrend-of-r-x-c-contingency-table",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test Association/Trend of R X C Contingency Table",
    "text": "Test Association/Trend of R X C Contingency Table\n \n\n\nIf both variables are nominal, a test of general association will be sufficient\n\nTest of general association is the same regardless of R and C\nTest used for 2x2 contingency table same as 5x3 contingency table\nWe will cover:\n\nChi-squared test\nFisher Exact test\n\n\n\n\n\nIf one or both variables are ordinal, a test of trend may be of interest\n\nTreats ordinal variables as quantitative rather than qualitative (nominal scale)\nTest of trend has greater power than the test of general association\nWe will cover:\n\nCochran-Armitage test\nMantel-Haenszel test"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#poll-everywhere-question-5",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#poll-everywhere-question-5",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Poll Everywhere Question 5",
    "text": "Poll Everywhere Question 5"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#example-strong-heart-study",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#example-strong-heart-study",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Example: Strong Heart Study",
    "text": "Example: Strong Heart Study\n\n\nThe Strong Heart Study is an ongoing study of American Indians residing in 13 tribal communities in three geographic areas (AZ, OK, and SD/ND) to study prevalence and incidence of cardiovascular disease and to identify risk factors. We will be examining the 4-year cumulative incidence of diabetes with one risk factor, glucose tolerance.\n \n\nImpaired glucose: normal or impaired glucose tolerance at baseline visit (between 1988 and 1991)\n \nDiabetes: Indicator of diabetes at follow-up visit (roughly four years after baseline) according to two-hour oral glucose tolerance test"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#example-strong-heart-study-12",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#example-strong-heart-study-12",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Example: Strong Heart Study (1/2)",
    "text": "Example: Strong Heart Study (1/2)\n\n\nThe Strong Heart Study is an ongoing study of American Indians residing in 13 tribal communities in three geographic areas (AZ, OK, and SD/ND) to study prevalence and incidence of cardiovascular disease and to identify risk factors. We will be examining the 4-year cumulative incidence of diabetes with one risk factor, glucose tolerance.\n \n\nImpaired glucose: normal or impaired glucose tolerance at baseline visit (between 1988 and 1991)\n \nDiabetes: Indicator of diabetes at follow-up visit (roughly four years after baseline) according to two-hour oral glucose tolerance test"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#example-strong-heart-study-22",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#example-strong-heart-study-22",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Example: Strong Heart Study (2/2)",
    "text": "Example: Strong Heart Study (2/2)\nThere is a total of 1664 American Indians in the dataset, with the following distribution of folks with diabetes and glucose tolerance:\n \n\n\n\n#shs_data = read.csv(file = here(\"./data/SHS_data.csv\"))\n\n\nSHS = tibble(Diabetes = c(rep(\"Not diabetic\", \n                   1338), \n                   rep(\"Diabetic\", 326)),\n              Glucose = c(rep(\"Normal\", \n                  1004),#Not diabetic\n          rep(\"Impaired\", 334),\n          rep(\"Normal\", \n              128), #Diabetic\n          rep(\"Impaired\", 198)))\n\n\n\n\nDisplaying the contingency table in R\nSHS %&gt;% tabyl(Glucose, Diabetes) %&gt;% \n  adorn_totals(where = c(\"row\", \"col\")) %&gt;% \n  gt() %&gt;% \n  tab_stubhead(label = \"Glucose Impairment\") %&gt;%\n  tab_spanner(label = \"Diabetes\", \n              columns = c(\"Not diabetic\", \"Diabetic\")) %&gt;%\n  tab_options(table.font.size = 45)\n\n\n\n\n\n\n  \n    \n    \n      Glucose\n      \n        Diabetes\n      \n      Total\n    \n    \n      Not diabetic\n      Diabetic\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#section-2",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#section-2",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "",
    "text": "Strong Heart Study\n\n\nWhat is the difference in proportions for American Indians that have diabetes comparing individuals with normal vs. impaired glucose?\n\n\nNeeded steps:\n\nEstimate the difference in proportions\nCheck that each cell has at least 10 individuals\nConstruct 95% confidence interval\nWrite interpretation of estimate"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#section-3",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#section-3",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "",
    "text": "Strong Heart Study\n\n\nWhat is the difference in proportions for American Indians that have diabetes comparing individuals with normal vs. impaired glucose?\n\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose\n      \n        Diabetes\n      \n      Total\n    \n    \n      Not diabetic\n      Diabetic\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\nEstimate the difference in proportions \\[ \\widehat{p}_1 -\\widehat{p}_2 = \\dfrac{198}{532} - \\dfrac{128}{1132} = 0.2591\\]\nCheck that each cell has at least 10 individuals\n\n\n\nConstruct 95% confidence interval\n\n\nprop.test(x = table(SHS$Glucose, SHS$Diabetes), \n          correct = T)\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  table(SHS$Glucose, SHS$Diabetes)\nX-squared = 152.6, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n95 percent confidence interval:\n 0.2126963 0.3055162\nsample estimates:\n   prop 1    prop 2 \n0.3721805 0.1130742 \n\n\n\nWrite interpretation of estimate\n\nThe estimated difference in proportion of diabetic American Indians comparing is 0.259 (95% CI: 0.213, 0.306).\nAdditional interpretation of CI: We are 95% confident that the difference in (population) proportions of American Indians who have normal glucose tolerance and impaired glucose tolerance that developed diabetes is between 0.213 and 0.306."
  },
  {
    "objectID": "lectures/01_File_Organization_R/01_File_Organization_R.html",
    "href": "lectures/01_File_Organization_R/01_File_Organization_R.html",
    "title": "Lesson 1: File Organization within R",
    "section": "",
    "text": "We all have free access to OneDrive to store files\nLet’s login into our online accounts\nYou can also download OneDrive for your desktop\n\nAllows you to access the OneDrive from your computer’s interface instead of the browser\nCreates a link between your computer and the cloud!\n\nLet me show you mine\n\nI can access all the files through RStudio as well!\n\nLet’s take a couple minutes to log into OneDrive\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#basic-analytic-procedures",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#basic-analytic-procedures",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Basic Analytic Procedures",
    "text": "Basic Analytic Procedures\nGeneral procedure:\n \n\nPresent observed data\n\n \n\nDescriptive analysis\n\n \n\nInferential tests"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-shs-example-12",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-shs-example-12",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of General Association: SHS Example (1/2)",
    "text": "Test of General Association: SHS Example (1/2)\n\nMain question: Do American Indians with impaired glucose tolerance have a different incidence of diabetes?\n\nIs glucose tolerance associated with diabetes incidence among American Indians?\n\nWe have two variables, and both variables have two nominal categories\n\nDiabetes outcome: Not diabetic and Diabetic\nGlucose tolerance: Normal or Impaired\n\nAnswer research question with a test of general association\nHypothesis:\n\n\\(H_0\\) : no association between glucose tolerance and diabetes\n\\(H_1\\) : association exists between glucose tolerance and diabetes"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-shs-example-22",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-shs-example-22",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of General Association: SHS Example (2/2)",
    "text": "Test of General Association: SHS Example (2/2)\n\nMain question: Do American Indians with impaired glucose tolerance have a different incidence of diabetes?\n\nIs glucose tolerance associated with diabetes incidence among American Indians?\n\nStart with the 2x2 contingency table\nWe have two variables, and both variables have two nominal categories\n\nDiabetes outcome: Not diabetic and Diabetic\nGlucose tolerance: Normal or Impaired\n\nAnswer research question with a test of general association"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-shs-example",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-shs-example",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of General Association: SHS Example",
    "text": "Test of General Association: SHS Example\n\nMain question: Do American Indians with impaired glucose tolerance have a different incidence of diabetes?\n\nIs glucose tolerance associated with diabetes incidence among American Indians?\n\nWe have two variables, and both variables have two nominal categories\n\nDiabetes outcome: Not diabetic and Diabetic\nGlucose tolerance: Normal or Impaired\n\n\n \n\nAnswer research question with a test of general association\nHypothesis:\n\n\\(H_0\\) : There is no association between glucose tolerance and diabetes / Glucose tolerance and diabetes are independent\n\\(H_1\\) : There is an association between glucose tolerance and diabetes / Glucose tolerance and diabetes are not independent"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-1",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-1",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of General Association",
    "text": "Test of General Association\n\nWe have three options for testing general association:\n\nChi-squared test\nLikelihood Ratio test (LRT)\nFisher’s Exact test"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#expected-cell-counts",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#expected-cell-counts",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Expected Cell Counts",
    "text": "Expected Cell Counts\n\nIs the sample size big enough for the chi-square test to be adequate? Expected cell counts?\nIf you want an explanation of how to calculate by hand, please see Vu and Harringtion TB (section 8.3.1, page 405)\nToo time consuming for this class, but R does it quickly using the"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-cochran-armitage-test-hypothesis-test",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-cochran-armitage-test-hypothesis-test",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of Trend: Cochran-Armitage test: Hypothesis Test",
    "text": "Test of Trend: Cochran-Armitage test: Hypothesis Test\n\n\n\n\nNull Hypothesis (\\(H_0\\))\n\n\nThe proportions of successes are the same across all C ordinal values of the explanatory variable. \\[p_1 = p_2 = ... = p_C\\]\n\n\n\n\n\nAlternative Hypothesis (\\(H_1\\))\n\n\nThe proportions of successes tend to increase as ordinal value of the explanatory variable increases\n\\[p_1 \\leq p_2 \\leq ... \\leq p_C\\]\nOR\nThe proportions of successes tend to decrease as ordinal value of the explanatory variable increases\n\\[p_1 \\geq p_2 \\geq ... \\geq p_C\\]"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-cochran-armitage-test-process",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-cochran-armitage-test-process",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of Trend: Cochran-Armitage test: Process",
    "text": "Test of Trend: Cochran-Armitage test: Process\n\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the test statistic and p-value for Cochran-Armitage test in R\n\nWe will not discuss the test statistic’s equation\nJust know it follows a Normal distribution\n\nWrite a conclusion to the hypothesis test\n\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-cochran-armitage-test-example",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-cochran-armitage-test-example",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of Trend: Cochran-Armitage test: Example",
    "text": "Test of Trend: Cochran-Armitage test: Example\nWe are interested in learning the association between the development of breast cancer and age at first birth among people who have given birth"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-cochran-armitage-test-example-1",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-cochran-armitage-test-example-1",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of Trend: Cochran-Armitage test: Example",
    "text": "Test of Trend: Cochran-Armitage test: Example\n\nBefore we go into the hypothesis test procedure, we need to construct the contingency table in R\n\n\nCancer = c(320, 1206, 1011, 463, 220)\nNo_Cancer = c(1422, 4432, 2893, 1092, 406)\nbscancer = matrix (c(Cancer, No_Cancer), nrow = 2, byrow = T)\nrownames(bscancer) = c(\"Cancer\",\"No Cancer\")\ncolnames(bscancer) = c(\"&lt;20\",\"20-24\",\"25-29\",\"30-34\",\"&gt;=35\")\nbscancer\n\n           &lt;20 20-24 25-29 30-34 &gt;=35\nCancer     320  1206  1011   463  220\nNo Cancer 1422  4432  2893  1092  406\n\n\n\nIt does not need to be pretty to use in function"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-cochran-armitage-test-example-2",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-cochran-armitage-test-example-2",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of Trend: Cochran-Armitage test: Example",
    "text": "Test of Trend: Cochran-Armitage test: Example\n\n\n\n\\(\\alpha = 0.05\\)\nHypothesis test:\n\n\\(H_0\\): The proportions of breast cancer are the same for all age levels of first birth. \\[p_1 = p_2 = ... = p_5\\]\n\\(H_1\\): The proportions of breast cancer tends to increase as level of age of first birth increases\n\n\n\\[p_1 \\leq p_2 \\leq ... \\leq p_5\\]\n\n\nCalculate the test statistic and p-value for Cochran-Armitage test in R\n\n\nlibrary(DescTools)\nCochranArmitageTest(bscancer)\n\n\n    Cochran-Armitage test for trend\n\ndata:  bscancer\nZ = 11.358, dim = 5, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\nConclusion to the hypothesis test\n\nWe reject the null hypothesis that proportions of breast cancer are the same for all age levels of first birth (\\(p&lt;2.2\\cdot10^{-16}\\)). There is sufficient evidence that the proportion of of breast cancer increase as the the age at first birth increases."
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-mantel-haenszel-test-process",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-mantel-haenszel-test-process",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of Trend: Mantel-Haenszel test: Process",
    "text": "Test of Trend: Mantel-Haenszel test: Process\n\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the test statistic and p-value for Mantel-Haenszel test in R\n\nWe will not discuss the test statistic’s equation\n\nWrite a conclusion to the hypothesis test\n\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-mantel-haenszel-test-example",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-mantel-haenszel-test-example",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of Trend: Mantel-Haenszel test: Example",
    "text": "Test of Trend: Mantel-Haenszel test: Example\nA water treatment company is studying water additives and investigating how they affect clothes washing. The treatments studies where no treatment (plain water), the standard treatment, and a double dose of the standard treatment, called super. Washability was measured as low, medium and high. Are levels of washability associated with treatment?"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-mantel-haenszel-test-example-1",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-mantel-haenszel-test-example-1",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of Trend: Mantel-Haenszel test: Example",
    "text": "Test of Trend: Mantel-Haenszel test: Example\n\nBefore we go into the hypothesis test procedure, we need to construct the contingency table in R\n\n\nwater = matrix (c(27, 14, 5, 10, 17, 26, 5, 12, 50), nrow = 3, byrow = T)\nrownames(water) = c(\"plain\",\"standard\",\"super\")\ncolnames(water) = c(\"low\",\"medium\",\"high\")\nwater\n\n         low medium high\nplain     27     14    5\nstandard  10     17   26\nsuper      5     12   50\n\n\n\nIt does not need to be pretty to use in function"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-mantel-haenszel-test-example-2",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-trend-mantel-haenszel-test-example-2",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of Trend: Mantel-Haenszel test: Example",
    "text": "Test of Trend: Mantel-Haenszel test: Example\n\n\n\n\\(\\alpha = 0.05\\)\nHypothesis test:\n\n\\(H_0\\): Water treatment and washability are not correlated. \\[ \\rho = 0\\]\n\\(H_1\\): Water treatment and washability are correlated.\n\n\n\\[ \\rho \\neq 0\\]\n\n\nCalculate the test statistic and p-value for Mantel-Haenszel test in R\n\n\nlibrary(DescTools)\nMHChisqTest(water)\n\n\n    Mantel-Haenszel Chi-Square\n\ndata:  water\nX-squared = 50.602, df = 1, p-value = 1.132e-12\n\n\n\nConclusion to the hypothesis test\n\nWe reject the null hypothesis that there is no correlation between washability and water treatment (\\(p = 1.13 \\cdot 10^{-12} &lt; 0.05\\)). There is sufficient evidence that level of water treatment is associated with washability."
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#what-have-we-learned-today",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#what-have-we-learned-today",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "What have we learned today?",
    "text": "What have we learned today?"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-chi-squared-test",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-chi-squared-test",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of General Association: Chi-squared test",
    "text": "Test of General Association: Chi-squared test\n\nTest to see how likely is it that we observe our data given the null hypothesis (no association)\n\n \n\nWe use the null to calculate the expected cell counts and compare them to the observed cell counts\n\n \n\nRequirements to conduct Chi-squared test\n\nFor 2 x 2 contingency table:\n\nNo expected cell counts should be less than 10\n\nFor contingency table with 3x2, 3x3, 4x4, etc.:\n\nNo more than 20% of expected cell counts are less than 5\nNo expected cell counts are less than 1"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#chi-squared-test-expected-cell-counts",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#chi-squared-test-expected-cell-counts",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Chi-squared test: Expected Cell Counts",
    "text": "Chi-squared test: Expected Cell Counts\n\nIs the sample size big enough for the chi-square test to be adequate? What are the expected cell counts?\n\n \n\nIf you want an explanation of how to calculate by hand, please see Vu and Harringtion TB (section 8.3.1, page 405)\n\n \n\nToo time consuming for this class, but R does it quickly using the expected() function in the epitools package"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#chi-squared-test-expected-cell-counts-1",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#chi-squared-test-expected-cell-counts-1",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Chi-squared test: Expected Cell Counts",
    "text": "Chi-squared test: Expected Cell Counts\n\nIn the Strong Heart Study…\n\n\nSHS_table = table(SHS$Glucose, SHS$Diabetes)\nSHS_table\n\n          \n           Diabetic Not diabetic\n  Impaired      198          334\n  Normal        128         1004\n\nlibrary(epitools)\nexpected(SHS_table)\n\n          \n           Diabetic Not diabetic\n  Impaired  104.226      427.774\n  Normal    221.774      910.226\n\n\n \n\n\n\n\n\nAll expected counts &gt; 5"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-chi-squared-test-process",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-chi-squared-test-process",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of General Association: Chi-squared test: Process",
    "text": "Test of General Association: Chi-squared test: Process\n\nCheck that the expected cell counts threshold is met\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the test statistic and p-value for Chi-squared test in R\n\nWe will not discuss the test statistic’s equation\n\nWrite a conclusion to the hypothesis test\n\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#chi-squared-test-shs-example",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#chi-squared-test-shs-example",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Chi-squared test: SHS Example",
    "text": "Chi-squared test: SHS Example\n\n\n\nCheck expected cell counts threshold\n\n\nexpected(SHS_table)\n\n          \n           Diabetic Not diabetic\n  Impaired  104.226      427.774\n  Normal    221.774      910.226\n\n\nAll expected cells are greater than 5.\n\n\\(\\alpha = 0.05\\)\nHypothesis test:\n\n\\(H_0\\) : There is no association between glucose tolerance and diabetes\n\\(H_1\\) : There is an association between glucose tolerance and diabetes\n\n\n\n\nCalculate the test statistic and p-value for Chi-squared test in R\n\n\nchisq.test(x = SHS_table, correct = T)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  SHS_table\nX-squared = 152.6, df = 1, p-value &lt; 2.2e-16\n\n\n\nConclusion to the hypothesis test\n\nWe reject the null hypothesis that glucose tolerance and diabetes are not associated (\\(p&lt;2.2\\cdot10^{-16}\\)). There is sufficient evidence that glucose tolerance and diabetes incidence are associated among American Indians."
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-fisher-exact-test-process",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#test-of-general-association-fisher-exact-test-process",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Test of General Association: Fisher Exact test: Process",
    "text": "Test of General Association: Fisher Exact test: Process\n\nCheck the expected cell counts\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the test statistic and p-value for Fisher Exact test in R\n\nWe will not discuss the test statistic’s equation\n\nWrite a conclusion to the hypothesis test\n\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#fisher-exact-test-shs-example-not-appropriate-use-of-fisher-exact-test",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#fisher-exact-test-shs-example-not-appropriate-use-of-fisher-exact-test",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Fisher Exact test: SHS Example (not appropriate use of Fisher Exact test)",
    "text": "Fisher Exact test: SHS Example (not appropriate use of Fisher Exact test)\n\n\n\nCheck expected cell counts threshold\n\n\nexpected(SHS_table)\n\n          \n           Diabetic Not diabetic\n  Impaired  104.226      427.774\n  Normal    221.774      910.226\n\n\nAll expected cells are greater than 5.\n\n\\(\\alpha = 0.05\\)\nHypothesis test:\n\n\\(H_0\\) : There is no association between glucose tolerance and diabetes\n\\(H_1\\) : There is an association between glucose tolerance and diabetes\n\n\n\n\nCalculate the test statistic and p-value for Chi-squared test in R\n\n\nfisher.test(x = SHS_table)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  SHS_table\np-value &lt; 2.2e-16\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 3.576595 6.048639\nsample estimates:\nodds ratio \n  4.644825 \n\n\n\nConclusion to the hypothesis test\n\nWe reject the null hypothesis that glucose tolerance and diabetes are not associated (\\(p&lt;2.2\\cdot10^{-16}\\)). There is sufficient evidence that glucose tolerance and diabetes incidence are associated among American Indians."
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#contingency-table-example",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#contingency-table-example",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Contingency Table: Example",
    "text": "Contingency Table: Example\nLet’s say we are interested in learning the association between the development of breast cancer and age at first birth. Our first step is typically to present the observed data:\n\n\nThis is a 2 x 5 contingency table"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#poll-everywhere-question-4",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#poll-everywhere-question-4",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Poll Everywhere Question 4",
    "text": "Poll Everywhere Question 4"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#chi-squared-test",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#chi-squared-test",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Chi-squared test",
    "text": "Chi-squared test\n\nTest to see how likely is it that we observe our data given the null hypothesis (no association)\n\n \n\nWe use the null to calculate the expected cell counts and compare them to the observed cell counts\n\n \n\nRequirements to conduct Chi-squared test (expected cell counts)\n\nFor 2 x 2 contingency table:\n\nNo expected cell counts should be less than 10\n\nFor contingency table with 3x2, 3x3, 4x4, etc.:\n\nNo more than 20% of expected cell counts are less than 5\nNo expected cell counts are less than 1"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#chi-squared-test-process",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#chi-squared-test-process",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Chi-squared test: Process",
    "text": "Chi-squared test: Process\n\nCheck that the expected cell counts threshold is met\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the test statistic and p-value for Chi-squared test in R\n\nWe will not discuss the test statistic’s equation\n\nWrite a conclusion to the hypothesis test\n\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#fishers-exact-test",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#fishers-exact-test",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Fisher’s Exact Test",
    "text": "Fisher’s Exact Test\n\nOnly necessary when expected counts in one or more cells is less than 5\nGiven row and column totals fixed, computes exact probability that we observe our data or more extreme data\nConsider a general 2 x 2 table:\n\n\n\nThe exact probability of observing a table with cells (a, b, c, d) can be computed based on the hypergeometric distribution\n\n\\[P(a, b, c, d) = \\dfrac{(a+b)!\\cdot(c+d)!\\cdot(a+c)!\\cdot(b+d)!}{n!\\cdot a!\\cdot b!\\cdot c!\\cdot d!}\\]\n\nNumerator is fixed and denominator changes"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#fisher-exact-test-process",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#fisher-exact-test-process",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Fisher Exact test: Process",
    "text": "Fisher Exact test: Process\n\nCheck the expected cell counts\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the test statistic and p-value for Fisher Exact test in R\n\nWe will not discuss the test statistic’s equation\n\nWrite a conclusion to the hypothesis test\n\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#fishers-exact-test-process",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#fishers-exact-test-process",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Fisher’s Exact test: Process",
    "text": "Fisher’s Exact test: Process\n\nCheck the expected cell counts\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the test statistic and p-value for Fisher Exact test in R\n\nWe will not discuss the test statistic’s equation\n\nWrite a conclusion to the hypothesis test\n\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#fishers-exact-test-shs-example-not-appropriate-use-of-fishers-exact",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#fishers-exact-test-shs-example-not-appropriate-use-of-fishers-exact",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Fisher’s Exact test: SHS Example (not appropriate use of Fisher’s Exact)",
    "text": "Fisher’s Exact test: SHS Example (not appropriate use of Fisher’s Exact)\n\n\n\nCheck expected cell counts threshold\n\n\nexpected(SHS_table)\n\n          \n           Diabetic Not diabetic\n  Impaired  104.226      427.774\n  Normal    221.774      910.226\n\n\nWe’re going to pretend they are less than 5.\n\n\\(\\alpha = 0.05\\)\nHypothesis test:\n\n\\(H_0\\) : There is no association between glucose tolerance and diabetes\n\\(H_1\\) : There is an association between glucose tolerance and diabetes\n\n\n\n\nCalculate the test statistic and p-value for Chi-squared test in R\n\n\nfisher.test(x = SHS_table)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  SHS_table\np-value &lt; 2.2e-16\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 3.576595 6.048639\nsample estimates:\nodds ratio \n  4.644825 \n\n\n\nConclusion to the hypothesis test\n\nWe reject the null hypothesis that glucose tolerance and diabetes are not associated (\\(p&lt;2.2\\cdot10^{-16}\\)). There is sufficient evidence that glucose tolerance and diabetes incidence are associated among American Indians."
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#cochran-armitage-test",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#cochran-armitage-test",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Cochran-Armitage test",
    "text": "Cochran-Armitage test\n\nCochran-Armitage test for trend will determine if there is association between a binary response variable and an ordinal variable with 3 or more categories\n\n \n\nIt will test the trend of the proportions over the ordinal variable\n\nAnswers the question: Does the proportion of people with a “successful” outcome increase as the ordinal explanatory variable increases?\n\n\n \n\nCochran-Armitage test for trend is only suitable for 2 x C contingency tables"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#cochran-armitage-test-hypothesis-test",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#cochran-armitage-test-hypothesis-test",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Cochran-Armitage test: Hypothesis Test",
    "text": "Cochran-Armitage test: Hypothesis Test\n\n\n\n\nNull Hypothesis (\\(H_0\\))\n\n\nThe proportions of successes are the same across all C ordinal values of the explanatory variable. \\[p_1 = p_2 = ... = p_C\\]\n\n\n\n\n\nAlternative Hypothesis (\\(H_1\\))\n\n\nThe proportions of successes tend to increase as ordinal value of the explanatory variable increases\n\\[p_1 \\leq p_2 \\leq ... \\leq p_C\\]\nOR\nThe proportions of successes tend to decrease as ordinal value of the explanatory variable increases\n\\[p_1 \\geq p_2 \\geq ... \\geq p_C\\]"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#cochran-armitage-test-example-13",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#cochran-armitage-test-example-13",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Cochran-Armitage test: Example (1/3)",
    "text": "Cochran-Armitage test: Example (1/3)\nWe are interested in learning the association between the development of breast cancer and age at first birth among people who have given birth"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#cochran-armitage-test-example-23",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#cochran-armitage-test-example-23",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Cochran-Armitage test: Example (2/3)",
    "text": "Cochran-Armitage test: Example (2/3)\n\nBefore we go into the hypothesis test procedure, we need to construct the contingency table in R\n\n\nCancer = c(320, 1206, 1011, 463, 220)\nNo_Cancer = c(1422, 4432, 2893, 1092, 406)\nbscancer = matrix (c(Cancer, No_Cancer), nrow = 2, byrow = T)\nrownames(bscancer) = c(\"Cancer\",\"No Cancer\")\ncolnames(bscancer) = c(\"&lt;20\",\"20-24\",\"25-29\",\"30-34\",\"&gt;=35\")\nbscancer\n\n           &lt;20 20-24 25-29 30-34 &gt;=35\nCancer     320  1206  1011   463  220\nNo Cancer 1422  4432  2893  1092  406\n\n\n\nIt does not need to be pretty to use in function"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#cochran-armitage-test-example-33",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#cochran-armitage-test-example-33",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Cochran-Armitage test: Example (3/3)",
    "text": "Cochran-Armitage test: Example (3/3)\n\n\n\n\\(\\alpha = 0.05\\)\nHypothesis test:\n\n\\(H_0\\): The proportions of breast cancer are the same for all age levels of first birth. \\[p_1 = p_2 = ... = p_5\\]\n\\(H_1\\): The proportions of breast cancer tends to increase as level of age of first birth increases\n\n\n\\[p_1 \\leq p_2 \\leq ... \\leq p_5\\]\n\n\nCalculate the test statistic and p-value for Cochran-Armitage test in R\n\n\nlibrary(DescTools)\nCochranArmitageTest(bscancer)\n\n\n    Cochran-Armitage test for trend\n\ndata:  bscancer\nZ = 11.358, dim = 5, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\nConclusion to the hypothesis test\n\nWe reject the null hypothesis that proportions of breast cancer are the same for all age levels of first birth (\\(p&lt;2.2\\cdot10^{-16}\\)). There is sufficient evidence that the proportion of of breast cancer increase as the the age at first birth increases."
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#cochran-armitage-test-process",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#cochran-armitage-test-process",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Cochran-Armitage test: Process",
    "text": "Cochran-Armitage test: Process\n\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the test statistic and p-value for Cochran-Armitage test in R\n\nWe will not discuss the test statistic’s equation\nJust know it follows a Normal distribution\n\nWrite a conclusion to the hypothesis test\n\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Mantel-Haenszel test",
    "text": "Mantel-Haenszel test\n\nWhen both variables are ordinal, we can conduct Mantel-Haenszel test of trend for linear association\nMantel-Haenszel test for linear trend is suitable for any R x C contingency tables with two ordinal variables\nHypothesis test:\n\n\n\n\n\nNull Hypothesis (\\(H_0\\))\n\n\nThere is no correlation between the two variables \\[ \\rho = 0\\]\n\n\n\n\n\nAlternative Hypothesis (\\(H_1\\))\n\n\nThere is correlation between the two variables\n\\[ \\rho \\neq 0\\]"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-process",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-process",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Mantel-Haenszel test: Process",
    "text": "Mantel-Haenszel test: Process\n\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the test statistic and p-value for Mantel-Haenszel test in R\n\nWe will not discuss the test statistic’s equation\n\nWrite a conclusion to the hypothesis test\n\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-example",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-example",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Mantel-Haenszel test: Example",
    "text": "Mantel-Haenszel test: Example\nA water treatment company is studying water additives and investigating how they affect clothes washing. The treatments studies where no treatment (plain water), the standard treatment, and a double dose of the standard treatment, called super. Washability was measured as low, medium and high. Are levels of washability associated with treatment?"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-example-1",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-example-1",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Mantel-Haenszel test: Example",
    "text": "Mantel-Haenszel test: Example\n\nBefore we go into the hypothesis test procedure, we need to construct the contingency table in R\n\n\nwater = matrix (c(27, 14, 5, 10, 17, 26, 5, 12, 50), nrow = 3, byrow = T)\nrownames(water) = c(\"plain\",\"standard\",\"super\")\ncolnames(water) = c(\"low\",\"medium\",\"high\")\nwater\n\n         low medium high\nplain     27     14    5\nstandard  10     17   26\nsuper      5     12   50\n\n\n\nIt does not need to be pretty to use in function"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-example-2",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-example-2",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Mantel-Haenszel test: Example",
    "text": "Mantel-Haenszel test: Example\n\n\n\n\\(\\alpha = 0.05\\)\nHypothesis test:\n\n\\(H_0\\): Water treatment and washability are not correlated. \\[ \\rho = 0\\]\n\\(H_1\\): Water treatment and washability are correlated.\n\n\n\\[ \\rho \\neq 0\\]\n\n\nCalculate the test statistic and p-value for Mantel-Haenszel test in R\n\n\nlibrary(DescTools)\nMHChisqTest(water)\n\n\n    Mantel-Haenszel Chi-Square\n\ndata:  water\nX-squared = 50.602, df = 1, p-value = 1.132e-12\n\n\n\nConclusion to the hypothesis test\n\nWe reject the null hypothesis that there is no correlation between washability and water treatment (\\(p = 1.13 \\cdot 10^{-12} &lt; 0.05\\)). There is sufficient evidence that level of water treatment is associated with washability."
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-example-13",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-example-13",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Mantel-Haenszel test: Example (1/3)",
    "text": "Mantel-Haenszel test: Example (1/3)\nA water treatment company is studying water additives and investigating how they affect clothes washing (through measurements of abrasions, wearing, and color loss).\nThe treatments studies where no treatment (plain water), the standard treatment, and a double dose of the standard treatment, called super. Washability was measured as low, medium and high.\nAre levels of washability associated with treatment?"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-example-23",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-example-23",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Mantel-Haenszel test: Example (2/3)",
    "text": "Mantel-Haenszel test: Example (2/3)\n\nBefore we go into the hypothesis test procedure, we need to construct the contingency table in R\n\n\nwater = matrix (c(27, 14, 5, 10, 17, 26, 5, 12, 50), nrow = 3, byrow = T)\nrownames(water) = c(\"plain\",\"standard\",\"super\")\ncolnames(water) = c(\"low\",\"medium\",\"high\")\nwater\n\n         low medium high\nplain     27     14    5\nstandard  10     17   26\nsuper      5     12   50\n\n\n\nIt does not need to be pretty to use in function"
  },
  {
    "objectID": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-example-33",
    "href": "lectures/02_Intro_CDA/02_Intro_CDA.html#mantel-haenszel-test-example-33",
    "title": "Lesson 2: Introduction to Categorical Data Analysis",
    "section": "Mantel-Haenszel test: Example (3/3)",
    "text": "Mantel-Haenszel test: Example (3/3)\n\n\n\n\\(\\alpha = 0.05\\)\nHypothesis test:\n\n\\(H_0\\): Water treatment and washability are not correlated. \\[ \\rho = 0\\]\n\\(H_1\\): Water treatment and washability are correlated.\n\n\n\\[ \\rho \\neq 0\\]\n\n\nCalculate the test statistic and p-value for Mantel-Haenszel test in R\n\n\nlibrary(DescTools)\nMHChisqTest(water)\n\n\n    Mantel-Haenszel Chi-Square\n\ndata:  water\nX-squared = 50.602, df = 1, p-value = 1.132e-12\n\n\n\nConclusion to the hypothesis test\n\nWe reject the null hypothesis that there is no correlation between washability and water treatment (\\(p = 1.13 \\cdot 10^{-12} &lt; 0.05\\)). There is sufficient evidence that level of water treatment is associated with washability."
  },
  {
    "objectID": "weeks.html",
    "href": "weeks.html",
    "title": "Weekly Pages",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\n4/1/24\n\n\nWeek 1\n\n\nIntroduction; File Organization\n\n\n\n\n4/8/24\n\n\nWeek 2\n\n\nMeasurements of Association and Agreement\n\n\n\n\n4/15/24\n\n\nWeek 3\n\n\nIntroduction to Logistic Regression\n\n\n\n\n4/22/24\n\n\nWeek 4\n\n\nPrediction, Visualization, and Interpretations\n\n\n\n\n4/29/24\n\n\nWeek 5\n\n\nMissing Data\n\n\n\n\n5/6/24\n\n\nWeek 6\n\n\nConfounders and Interactions\n\n\n\n\n5/13/24\n\n\nWeek 7\n\n\nModel Building Strategies\n\n\n\n\n5/20/24\n\n\nWeek 8\n\n\nAssessing Model Fit and Numeric Problems\n\n\n\n\n5/27/24\n\n\nWeek 9\n\n\nModel Diagnostics\n\n\n\n\n6/3/24\n\n\nWeek 10\n\n\nOther generalized linear regressions\n\n\n\n\n6/10/24\n\n\nWeek 11\n\n\nSpill-Over Week\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "weeks/week_03_sched.html#resources",
    "href": "weeks/week_03_sched.html#resources",
    "title": "Week 3",
    "section": "Resources",
    "text": "Resources\n\n\n\nLesson\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n5\nSimple Logistic Regression\n\n\n\n\n\n6\nTests for GLMs using Likelihood function\n\n\n\n\n\n\nIf you ever have trouble with the above links to the videos, this Echo360 link should take you to our class page."
  },
  {
    "objectID": "weeks/week_03_sched.html#on-the-horizon",
    "href": "weeks/week_03_sched.html#on-the-horizon",
    "title": "Week 3",
    "section": "On the Horizon",
    "text": "On the Horizon\n\nLab 1 due this Thursday (4/18)\nQuiz 1 opens on Monday, 4/22, at 2pm and will close on Wednesday, 4/24, at 1pm"
  },
  {
    "objectID": "weeks/week_03_sched.html#class-exit-tickets",
    "href": "weeks/week_03_sched.html#class-exit-tickets",
    "title": "Week 3",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (4/15)\n Wednesday (4/17)"
  },
  {
    "objectID": "weeks/week_03_sched.html#announcements",
    "href": "weeks/week_03_sched.html#announcements",
    "title": "Week 3",
    "section": "Announcements",
    "text": "Announcements\n\nMonday 4/15\n\nI am trying to stay on track of the Exit tickets this quarter\n\nThat may mean you have a 0 in your gradebook\nAs long as you complete the exit ticket within the 7 days, I will change the 0 to a 1\nI plan to have a scheduled block on Fridays to check them\n\n\n\n\nWednesday 4/17\n\nQuiz 1 info"
  },
  {
    "objectID": "weeks/week_03_sched.html#muddiest-points",
    "href": "weeks/week_03_sched.html#muddiest-points",
    "title": "Week 3",
    "section": "Muddiest Points",
    "text": "Muddiest Points\n\n1. Not entirely sure I understand what IRLS is about\nFair enough. It’s a little confusing. IWLS is an iterative solving technique that let’s us solve the coefficient estimates ( \\(\\beta_0\\) , \\(\\beta_1\\)) without solving the equations theoretically.\nWe start with an educated guess of the estimates, put them into the likelihood, and calculate the likelihood. Then we update the estimates using some complicated math, put them into the likelihood, and calculate the likelihood again. We compare the two likelihoods, and if the likelihood increases, then we keep going. We stop when the increase in likelihood between iterations is small. This means we are at or very close to the maximum likelihood.\n\n\n2. Link functions\nYes! Link functions are the important transformations we need to make to our outcome in order to connect them to our perdictors/covariates. Specifically, it’s the transformation we make to our mean/expected value.\nThe same link function can be used different types of outcomes. And here’s a few examples:\n\nContinuous data: identity\nBinary: logit, log\nCount/Poisson: log\n\nOur goal with link functions is to put our outcome on a flexible range so that any range of covariates can be mapped to it with coefficients. So think about trying to map age onto a 0 or 1… We can’t come up with an equation like \\(\\beta_0 + \\beta_1 Age\\) that perfectly maps to only 0’s and 1’s.\n\n\n3. Is GLM the umbrella over the other functions? The 4 functions all use different distributions, yes?\nGLM is the umbrella term for different types of regression! Not all types of regression have different outcome distributions. For example, a binary outcome can be used in logistic regression with the logit link or log-binomial regression with the log link.\n\n\n4. What would you need to change in your model to reduce a high IRLS number? As I understand it from the lecture, a high number suggests convergence but it appeared like something unfavorable even though a model that converges might be closer to maximum likelihood or maybe the distance to maximum likelihood\nA high number suggests that the model did NOT converge! Thus, we did not land on an estimate close to our maximum likelihood. You can think of the IRLS number as the number of iterations it is taking to find the maximum likelihood estimate (MLE). If it takes too many iterations, then it just stops without finding the MLE.\n\n\n5. We’re using linear vs logistic, but which are we focusing on? Regarding linear, how does linear used in categorical differ from continuous?\nWe are focusing on logistic! We cannot use linear regression on our binary outcomes anymore. When I say “linear” mapping I mean the mapping between our covariates and the transformed mean outcome using the link function.\n\n\n6. By the end of class (Lesson 6) my understanding is that the saturated model likelihood is the same between the two models being compared, right?\nYep!!\n\n\n7. The differences between each test and when to use them.\nIn terms of what each test is measuring:\n\nThe Wald test measures the distance between two potential values of \\(\\beta\\). One under the null and one under the alternative. The further they are from each other, the more evidence we have that they are different.\n\nThe Wald test approximates the differences in the likelihood function, but we do not actually compare the likelihoods under the null vs. alternative. We are only comparing the difference in the \\(\\beta\\) value, that is a reasonable approximation of the difference in the likelihood.\n\nThe Score test measures how close the tangent line of the likelihood function is to 0 (under the null). If it is close to 0 under the null, this indicates that our MLE of \\(\\beta\\) is not far from 0. Again, this is no a direct comparison of the likelihoods, but only an approximation of the difference.\nThe likelihood ratio test measures the difference in the log-likelihoods. This is a direct comparison of likelihoods, and is not an approximation!\n\nThus, we compare the likelihoods (horizontally, as someone asked) because we are making direct comparisons between the likelihood under the null and under the alternative."
  },
  {
    "objectID": "weeks/week_04_sched.html#resources",
    "href": "weeks/week_04_sched.html#resources",
    "title": "Week 4",
    "section": "Resources",
    "text": "Resources\n\n\n\nLesson\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n7\nPredictions and Visualizations in Simple Logistic Regression\n\n\n\n\n\n8\nInterpretations and Visualizations of Odds Ratios"
  },
  {
    "objectID": "weeks/week_04_sched.html#on-the-horizon",
    "href": "weeks/week_04_sched.html#on-the-horizon",
    "title": "Week 4",
    "section": "On the Horizon",
    "text": "On the Horizon\n\nHomework 2 due this Thursday"
  },
  {
    "objectID": "weeks/week_04_sched.html#class-exit-tickets",
    "href": "weeks/week_04_sched.html#class-exit-tickets",
    "title": "Week 4",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (4/22)\n\nMonday Exit ticket will not be graded bc of quiz\n\n Wednesday (4/24)"
  },
  {
    "objectID": "weeks/week_04_sched.html#announcements",
    "href": "weeks/week_04_sched.html#announcements",
    "title": "Week 4",
    "section": "Announcements",
    "text": "Announcements\nWednesday 4/24\n\nHave you all seen this??? Page on Basic Needs for students\n\nSPH Emergency funds\nCARE program\nCommittee for Improving Student Food Security\n\nLab 2 is up!\n\nFrom Lab 1:\n\nDO NOT USE ANY_HARDSHIP or MULT_HARDSHIP as your main variable\n\nThese are constructed from food insecurity variable\nSee the User Guide in the downloaded ICPSR folder\n\n\n\nQuiz 1 should be in!\nLab 1 feedback still in progress\nReview last quarter’s project\n\nOn Monday we will take 15 minutes to discuss changes to the project report instructions\nI will bring the learning objectives that I want to assess\nWe can rework or scrap parts of the report that do not assess these learning objectives\nAs part of the exit ticket, I will ask about your preferences as well"
  },
  {
    "objectID": "weeks/week_04_sched.html#muddiest-points",
    "href": "weeks/week_04_sched.html#muddiest-points",
    "title": "Week 4",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nNone?? Wowza!"
  },
  {
    "objectID": "weeks/week_05_sched.html",
    "href": "weeks/week_05_sched.html",
    "title": "Week 5",
    "section": "",
    "text": "MONDAY CLASS CANCELLED\n\n\n\nMonday’s class is cancelled! We will be back on Wednesday for a fun, random lecture on missing data!!"
  },
  {
    "objectID": "weeks/week_05_sched.html#resources",
    "href": "weeks/week_05_sched.html#resources",
    "title": "Week 5",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nLesson\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n9\nMissing Data"
  },
  {
    "objectID": "weeks/week_05_sched.html#on-the-horizon",
    "href": "weeks/week_05_sched.html#on-the-horizon",
    "title": "Week 5",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_05_sched.html#class-exit-tickets",
    "href": "weeks/week_05_sched.html#class-exit-tickets",
    "title": "Week 5",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Wednesday (5/1)"
  },
  {
    "objectID": "weeks/week_05_sched.html#announcements",
    "href": "weeks/week_05_sched.html#announcements",
    "title": "Week 5",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "weeks/week_05_sched.html#muddiest-points",
    "href": "weeks/week_05_sched.html#muddiest-points",
    "title": "Week 5",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nI couldn’t resist making a gif of me reacting to the fire alarm when I was editing the Echo360 recording."
  },
  {
    "objectID": "weeks/week_06_sched.html#resources",
    "href": "weeks/week_06_sched.html#resources",
    "title": "Week 6",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nLesson\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n10\n\n\n\n\n\n\n11"
  },
  {
    "objectID": "weeks/week_06_sched.html#on-the-horizon",
    "href": "weeks/week_06_sched.html#on-the-horizon",
    "title": "Week 6",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_06_sched.html#class-exit-tickets",
    "href": "weeks/week_06_sched.html#class-exit-tickets",
    "title": "Week 6",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (5/6)\n Wednesday (5/8)"
  },
  {
    "objectID": "weeks/week_06_sched.html#announcements",
    "href": "weeks/week_06_sched.html#announcements",
    "title": "Week 6",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "weeks/week_06_sched.html#muddiest-points",
    "href": "weeks/week_06_sched.html#muddiest-points",
    "title": "Week 6",
    "section": "Muddiest Points",
    "text": "Muddiest Points"
  },
  {
    "objectID": "weeks/week_11_sched.html#announcements",
    "href": "weeks/week_11_sched.html#announcements",
    "title": "Week 11",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "weeks/week_10_sched.html#resources",
    "href": "weeks/week_10_sched.html#resources",
    "title": "Week 10",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nChapter\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n\n\n\n\n\n\n\n13\n\n\n\n\n\n\n14"
  },
  {
    "objectID": "weeks/week_10_sched.html#on-the-horizon",
    "href": "weeks/week_10_sched.html#on-the-horizon",
    "title": "Week 10",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_10_sched.html#announcements",
    "href": "weeks/week_10_sched.html#announcements",
    "title": "Week 10",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "weeks/week_10_sched.html#class-exit-tickets",
    "href": "weeks/week_10_sched.html#class-exit-tickets",
    "title": "Week 10",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (6/3)\n Wednesday (6/5)"
  },
  {
    "objectID": "weeks/week_10_sched.html#muddiest-points",
    "href": "weeks/week_10_sched.html#muddiest-points",
    "title": "Week 10",
    "section": "Muddiest Points",
    "text": "Muddiest Points"
  },
  {
    "objectID": "weeks/week_07_sched.html#resources",
    "href": "weeks/week_07_sched.html#resources",
    "title": "Week 7",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nLesson\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n11"
  },
  {
    "objectID": "weeks/week_07_sched.html#on-the-horizon",
    "href": "weeks/week_07_sched.html#on-the-horizon",
    "title": "Week 7",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_07_sched.html#class-exit-tickets",
    "href": "weeks/week_07_sched.html#class-exit-tickets",
    "title": "Week 7",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (5/13)\n Wednesday (5/15)"
  },
  {
    "objectID": "weeks/week_07_sched.html#announcements",
    "href": "weeks/week_07_sched.html#announcements",
    "title": "Week 7",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "weeks/week_07_sched.html#muddiest-points",
    "href": "weeks/week_07_sched.html#muddiest-points",
    "title": "Week 7",
    "section": "Muddiest Points",
    "text": "Muddiest Points"
  },
  {
    "objectID": "weeks/week_08_sched.html#resources",
    "href": "weeks/week_08_sched.html#resources",
    "title": "Week 8",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nLesson\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n11\n\n\n\n\n\n\n11"
  },
  {
    "objectID": "weeks/week_08_sched.html#on-the-horizon",
    "href": "weeks/week_08_sched.html#on-the-horizon",
    "title": "Week 8",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_08_sched.html#announcements",
    "href": "weeks/week_08_sched.html#announcements",
    "title": "Week 8",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "weeks/week_08_sched.html#class-exit-tickets",
    "href": "weeks/week_08_sched.html#class-exit-tickets",
    "title": "Week 8",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Monday (5/20)\n Wednesday (5/22)"
  },
  {
    "objectID": "weeks/week_08_sched.html#muddiest-points",
    "href": "weeks/week_08_sched.html#muddiest-points",
    "title": "Week 8",
    "section": "Muddiest Points",
    "text": "Muddiest Points"
  },
  {
    "objectID": "weeks/week_09_sched.html#resources",
    "href": "weeks/week_09_sched.html#resources",
    "title": "Week 9",
    "section": "Resources",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\nLesson\nTopic\nSlides\nAnnotated Slides\nRecording\n\n\n\n\n\n\n\n\n\n\n\n12\n\n\n\n\n\n\n13"
  },
  {
    "objectID": "weeks/week_09_sched.html#on-the-horizon",
    "href": "weeks/week_09_sched.html#on-the-horizon",
    "title": "Week 9",
    "section": "On the Horizon",
    "text": "On the Horizon"
  },
  {
    "objectID": "weeks/week_09_sched.html#announcements",
    "href": "weeks/week_09_sched.html#announcements",
    "title": "Week 9",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "weeks/week_09_sched.html#class-exit-tickets",
    "href": "weeks/week_09_sched.html#class-exit-tickets",
    "title": "Week 9",
    "section": "Class Exit Tickets",
    "text": "Class Exit Tickets\n Wednesday (5/29)"
  },
  {
    "objectID": "weeks/week_09_sched.html#muddiest-points",
    "href": "weeks/week_09_sched.html#muddiest-points",
    "title": "Week 9",
    "section": "Muddiest Points",
    "text": "Muddiest Points\nThis will be filled in with your Exit Ticket responses."
  },
  {
    "objectID": "weeks/week_10_sched.html",
    "href": "weeks/week_10_sched.html",
    "title": "Week 10",
    "section": "",
    "text": "Room Locations for the week\n\n\n\nOn Monday, 6/3, we will be in RPV Room A (1217)"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Poll Everywhere Question 1",
    "text": "Poll Everywhere Question 1\nMake sure to remember your answer!! We’ll use this on Wednesday!"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#review-of-test-of-association",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#review-of-test-of-association",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Review of Test of Association",
    "text": "Review of Test of Association\n\nLast week: learned some tests of association for contingency tables\n\n \n\nFor studies with two independent samples\n\nGeneral association\n\nChi-squared test\nFisher’s Exact test\n\nTest of trends\n\nCochran-Armitage test\nMantel-Haenszel test\n\n\n\n \n\nTest of association does not provide an effective measure of association"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#test-of-association-does-not-measure-association",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#test-of-association-does-not-measure-association",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Test of association does not measure association",
    "text": "Test of association does not measure association\n\nTest of association does not provide an effective measure of association. The p-value alone is not enough\n\n\\(\\text{p-value} &lt; 0.05\\) suggests there is a statistically significant association between the group and outcome\n\\(\\text{p-value} = 0.00001\\) vs. \\(\\text{p-value} = 0.01\\) does not mean the magnistude of association is different\n\n\n \n\nBut it does not tell how different the risks are between the two groups\n\n \n\nWe want to find out one or more measurements for quantifying the risks across the groups."
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measures-of-association",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measures-of-association",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Measures of Association",
    "text": "Measures of Association\n\nWhen we have a 2x2 contingency table and independent samples, we have an option of three measures of association:\n \n\nRisk difference (RD)\n\n \n\nRelative risk (RR)\n\n \n\nOdds ratio (OR)\n\n\n \nEach measures association by comparing the proportion of successes/failures from each categorical group of our explanatory variable."
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#before-we-discuss-each-further",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#before-we-discuss-each-further",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Before we discuss each further…",
    "text": "Before we discuss each further…\n \nLet’s define the cells within a 2x2 contingency table:\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThen we can define risk: the proportion of “successes”\n\nWith \\(\\text{Risk}_1 = \\dfrac{n_{11}}{n_1}\\)"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#risk-difference",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#risk-difference",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Risk Difference",
    "text": "Risk Difference\n\nRisk difference computes the absolute difference in risk for the two groups (from the explanatory variable)\nPoint estimate: \\[\\widehat{RD} = \\widehat{p}_1 - \\widehat{p}_1\\]\n\nWith range of point estimate from \\([-1, 1]\\)\n\nApproximate standard error:\n\n\\[ SE_{\\widehat{RD}} = \\sqrt{\\frac{\\hat{p}_1\\cdot(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2\\cdot(1-\\hat{p}_2)}{n_2}}\\]\n\n95% Wald confidence interval for \\(\\widehat{RD}\\):\n\n\\[\\widehat{RD} \\pm 1.96 \\cdot SE_{\\widehat{RD}}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#risk-difference-example",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#risk-difference-example",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Risk Difference Example",
    "text": "Risk Difference Example"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#when-is-the-risk-difference-misleading",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#when-is-the-risk-difference-misleading",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "When is the risk difference misleading?",
    "text": "When is the risk difference misleading?\n\nThe same risk differences can have very different clinical meanings depending on the risk for each group\n\n \n \n\nExample: for two treatments A and B, we know the risk difference (RD) is 0.009. Is it a meaningful difference?\n\nIf the risk is 0.01 for Trt A and 0.001 for Trt B?\nIf the risk is 0.41 for Trt A and 0.401 for Trt B?\n\n\n \n\nUsing the RD alone to summarize the difference in risks for comparing the two groups can be misleading\n\nThe ratio of risk can provide an informative descriptive measure of the “relative risk”"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relative-risk-rr",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relative-risk-rr",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Relative Risk (RR)",
    "text": "Relative Risk (RR)\n\nRelative risk computes the ratio of each group’s proportions of “success”\n\nAlso called risk ratio    \n\nPoint estimate: \\[\\widehat{RR}=\\dfrac{\\hat{p}_1}{\\hat{p}_2} = \\dfrac{n_{11}/n_1}{n_{21}/n_2}\\]\n\nRange: \\([0, \\infty]\\)"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-2",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-2",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Poll Everywhere Question 2",
    "text": "Poll Everywhere Question 2"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#log-transformation-of-rr",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#log-transformation-of-rr",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Log-transformation of RR",
    "text": "Log-transformation of RR\n\nSampling distribution of the relative risk is highly skewed unless sample sizes are quite large\n\nLog transformation results in approximately normal distribution\nThus, compute confidence interval using normally distributed, log-transformed RR\nThen we convert back to the RR\n\nWe take the log (natural log) of RR: \\(\\ln(\\widehat{RR})\\) or \\(log(\\widehat{RR})\\)\n\nWhenever I say “log” I mean natural log (very common in statistics)\n\n\n\n\n\nThen we need to find approximate standard error for \\(\\ln(\\widehat{RR})\\) \\[SE_{\\ln(\\widehat{RR})}=\\sqrt{\\frac{1}{n_{11}}\\ -\\frac{1}{n_1}+\\frac{1}{n_{21}}-\\frac{1}{n_2}}\\]\n95% confidence interval for \\(\\ln(\\widehat{RR})\\): \\[\\ln(\\widehat{RR}) \\pm 1.96 \\times SE_{\\ln(\\widehat{RR})}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#how-do-we-get-back-to-the-rr-scale",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#how-do-we-get-back-to-the-rr-scale",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "How do we get back to the RR scale?",
    "text": "How do we get back to the RR scale?\n\nWe computed confidence interval using normally distributed, log-transformed RR (\\(\\ln(\\widehat{RR})\\)):\n\n\\[ \\bigg(\\ln(\\widehat{RR}) - 1.96 \\times SE_{\\ln(\\widehat{RR})}, \\ \\ln(\\widehat{RR}) + 1.96 \\times SE_{\\ln(\\widehat{RR})}\\bigg)\\]\n\nNow we need to exponentiate the CI to get back to interpretable values\n\nTake exponential of lower and upper bounds\n\n95% confidence interval for RR: two ways to display equation\n\n\\[ \\bigg(e^{\\ln(\\widehat{RR}) - 1.96 \\times SE_{\\ln(\\widehat{RR})}}, \\ e^{\\ln(\\widehat{RR}) + 1.96 \\times SE_{\\ln(\\widehat{RR})}}\\bigg)\\] \\[ \\bigg(\\exp\\big(\\ln(\\widehat{RR}) - 1.96 \\times SE_{\\ln(\\widehat{RR})}\\big), \\ \\exp\\big(\\ln(\\widehat{RR}) + 1.96 \\times SE_{\\ln(\\widehat{RR})}\\big)\\bigg)\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relative-risk-rr-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relative-risk-rr-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Relative Risk (RR)",
    "text": "Relative Risk (RR)\n\nCan you compute the estimated RRs for the previous example?\n\nIf the risk for Trt A is 0.01 and Trt B is 0.001? \\(\\widehat{RR}= 10\\)\nIf the risk for Trt A is 0.41 and Trt B is 0.401? \\(\\widehat{RR}= 1.02\\)\n\nWhen \\(\\widehat{RR}= 1\\) …\n\nRisk is the same for the two groups\nIn other words, the group and the outcome are independent\n\nWhen computing \\(\\widehat{RR}\\) it is important to identify which variable is the response variable and which is explanatory variable\n\nWe may say “risk for Trt A” but this translates to the risk (or probability) of outcome success for those receiving Trt A"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relative-risk-rr-example",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relative-risk-rr-example",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Relative Risk (RR) Example",
    "text": "Relative Risk (RR) Example\n\nlibrary(pubh)\ncontingency(case ~ glucimp, data = SHS)\n\n          Outcome\nPredictor     1    0\n  Normal    128 1004\n  Impaired  198  334\n\n             Outcome +    Outcome -      Total                 Inc risk *\nExposed +          128         1004       1132      11.31 (9.52 to 13.30)\nExposed -          198          334        532     37.22 (33.10 to 41.48)\nTotal              326         1338       1664     19.59 (17.71 to 21.58)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nInc risk ratio                                 0.30 (0.25, 0.37)\nInc odds ratio                                 0.22 (0.17, 0.28)\nAttrib risk in the exposed *                   -25.91 (-30.41, -21.41)\nAttrib fraction in the exposed (%)            -229.15 (-300.81, -170.30)\nAttrib risk in the population *                -17.63 (-22.16, -13.10)\nAttrib fraction in the population (%)         -89.97 (-106.38, -74.87)\n-------------------------------------------------------------------\nUncorrected chi2 test that OR = 1: chi2(1) = 154.239 Pr&gt;chi2 = &lt;0.001\nFisher exact test that OR = 1: Pr&gt;chi2 = &lt;0.001\n Wald confidence limits\n CI: confidence interval\n * Outcomes per 100 population units \n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  dat\nX-squared = 152.6, df = 1, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#odds-building-up-to-odds-ratio",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#odds-building-up-to-odds-ratio",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Odds (building up to Odds Ratio)",
    "text": "Odds (building up to Odds Ratio)\n\nFor a probability of success \\(p\\) (or sometimes referred to as \\(\\pi\\)), the odds of success is: \\[\\text{odds}=\\frac{p}{1-p}=\\frac{\\pi}{1-\\pi}\\]\n\nExample: if \\(\\pi=0.75\\), then odds of success \\(= \\dfrac{0.75}{0.25}=3\\)\n\nIf odds &gt; 1, it implies a success is more likely than a failure\n\nExample: for \\(odds = 3\\), we expect to observe three times as many successes as failures\n\nIf odds is known, the probability of success can be computed \\[\\pi = \\dfrac{\\text{odds}}{\\text{odds}+1}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#odds-ratio-or",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#odds-ratio-or",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Odds Ratio (OR)",
    "text": "Odds Ratio (OR)\n\nOdds ratio is the ratio of two odds:\\[\\widehat{OR}=\\frac{odds_1}{odds_2}=\\frac{{\\hat{p}}_1/(1-{\\hat{p}}_1)}{{\\hat{p}}_2/(1-{\\hat{p}}_2)}\\]\n\nRange: \\([0, \\infty]\\)\nInterpretation: The odds of success for “group 1” is “\\(\\widehat{OR}\\)” times the odds of success for “group 2”\n\n\n \n\nWhat do values of odds ratios mean?\n\n\n\n\n\n\n\nOdds Ratio\nClinical Meaning\n\n\n\n\n\\(\\widehat{OR} &lt; 1\\)\nOdds of success is smaller in group 1 than in group 2\n\n\n\\(\\widehat{OR} = 1\\)\nExplanatory and response variables are independent\n\n\n\\(\\widehat{OR} &gt; 1\\)\nOdds of success is greater in group 1 than in group 2"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-3",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-3",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Poll Everywhere Question 3",
    "text": "Poll Everywhere Question 3"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#odds-ratio-or-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#odds-ratio-or-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Odds Ratio (OR)",
    "text": "Odds Ratio (OR)\n\nValues of OR farther from 1.0 in a given direction represent stronger association\n\nAn OR = 4 is farther from independence than an OR = 2\nAn OR = 0.25 is farther from independence than an OR = 0.5\nFor OR = 4 and OR = 0.25, they are equally away from independence (because ¼ = 0.25)\n\n\n \n\nWe take the inverse of the OR for success of group 1 compared to group 2 to get…\n\nOR for failure of group 1 compared to group 2\nOR for success of group 2 compared to group 1"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#log-transformation-of-or",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#log-transformation-of-or",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Log-transformation of OR",
    "text": "Log-transformation of OR\n\nLike RR, sampling distribution of the odds ratio is highly skewed\n\nLog transformation results in approximately normal distribution\nThus, compute confidence interval using normally distributed, log-transformed OR\n\n\n\n\n\nApproximate standard error for \\(\\ln (\\widehat{OR})\\): \\[SE_{\\ln(\\widehat{OR})}=\\sqrt{\\frac{1}{n_{11}}\\ +\\frac{1}{n_{12}}+\\frac{1}{n_{21}}+\\frac{1}{n_{22}}}\\]\n95% confidence interval for \\(\\ln(\\widehat{OR})\\): \\[\\ln(\\widehat{OR}) \\pm 1.96 \\times SE_{\\ln(\\widehat{OR})}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#how-do-we-get-back-to-the-or-scale",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#how-do-we-get-back-to-the-or-scale",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "How do we get back to the OR scale?",
    "text": "How do we get back to the OR scale?\n\nWe computed confidence interval using normally distributed, log-transformed RR (\\(\\ln(\\widehat{OR})\\)):\n\n\\[ \\bigg(\\ln(\\widehat{OR}) - 1.96 \\times SE_{\\ln(\\widehat{OR})}, \\ \\ln(\\widehat{OR}) + 1.96 \\times SE_{\\ln(\\widehat{OR})}\\bigg)\\]\n\nNow we need to exponentiate the CI to get back to interpretable values\n\nTake exponential of lower and upper bounds\n\n95% confidence interval for RR: two ways to display equation\n\n\\[ \\bigg(e^{\\ln(\\widehat{OR}) - 1.96 \\times SE_{\\ln(\\widehat{OR})}}, \\ e^{\\ln(\\widehat{OR}) + 1.96 \\times SE_{\\ln(\\widehat{OR})}}\\bigg)\\] \\[ \\bigg(\\exp\\big(\\ln(\\widehat{OR}) - 1.96 \\times SE_{\\ln(\\widehat{OR})}\\big), \\ \\exp\\big(\\ln(\\widehat{OR}) + 1.96 \\times SE_{\\ln(\\widehat{OR})}\\big)\\bigg)\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#odds-ratio-or-example",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#odds-ratio-or-example",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Odds Ratio (OR) Example",
    "text": "Odds Ratio (OR) Example"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-4",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-4",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Poll Everywhere Question 4",
    "text": "Poll Everywhere Question 4"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relationship-between-rr-and-or",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relationship-between-rr-and-or",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Relationship Between RR and OR",
    "text": "Relationship Between RR and OR\n\nNotice that odds ratio is not equivalent to relative risk (or risk ratio)\nHowever, when the probability of “success” is small (e.g., rare disease), \\(\\widehat{OR}\\) is a nice approximation of \\(\\widehat{RR}\\) \\[\\widehat{OR}=\\frac{{\\hat{p}}_1/(1-{\\hat{p}}_1)}{{\\hat{p}}_2/(1-{\\hat{p}}_2)}=\\widehat{RR}\\cdot \\frac{1-\\widehat{p_2}}{1-\\widehat{p_1}}\\]\n\nThe fraction in the last term of the above expression approximately equals to 1.0 if \\(\\widehat{p}_1\\) and \\(\\widehat{p}_2\\) BOTH quite small (&lt; 0.1)\n\nThe \\(\\widehat{OR}\\) and \\(\\widehat{RR}\\) are not very close to each other in SHS: diabetes not a rare disease\n\n\\(\\widehat{OR} = 4.65\\)\n\\(\\widehat{RR} = 3.29\\)"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#notes-for-odds-ratios",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#notes-for-odds-ratios",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Notes for Odds Ratios",
    "text": "Notes for Odds Ratios\n\nThe OR is valid for\n\nCase-control studies (where the RR is not appropriate)\nProspective cohort studies\nCross-sectional studies\n\nIt can be interpreted either as…\n\nOdds of event for exposed vs. unexposed individuals, or\nOdds of exposure for individuals with vs. without the event of interest\n\nPay attention to the numerator and denominator for the OR"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#rr-in-retrospective-case-control-study",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#rr-in-retrospective-case-control-study",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "RR in retrospective case-control study",
    "text": "RR in retrospective case-control study\n\nIn retrospective, case-control studies, we often identify cases (patients with the outcome), then select a number of controls (patients without the outcome)\n\nCase-control study to require much smaller sample size than do equivalent cohort studies\n\nHowever, the proportion of cases in the sample does not represent the proportion of cases in the population\n\nRR compares probability of the outcome (case) for exposed and unexposed groups\nNumber of outcomes has been artificially inflated for retrospective study"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#or-in-retrospective-case-control-study",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#or-in-retrospective-case-control-study",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "OR in retrospective case-control study",
    "text": "OR in retrospective case-control study\n\nWhile we cannot estimate RR from a case-control study, we can still estimate OR for case-control study\n\nOR does not require us to distinguish between the outcome variable and explanatory variable in the contingency table\n\nAKA: Odds ratio of disease comparing exposed to not exposed is same as odds ratio of being exposed comparing diseased and not diseased\n\n\nFor case-control study where the probability of having outcome is small, the \\(\\widehat{OR}\\) is a nice approximation to \\(\\widehat{RR}\\)\n\nFor the 1:2 case-control table: \\(\\widehat{OR}=\\frac{40\\cdot160}{40\\cdot60} = 2.667\\)"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#which-measurement-should-one-use",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#which-measurement-should-one-use",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Which measurement should one use?",
    "text": "Which measurement should one use?\n\n\n\n\n\n\n\nMeasurement\nPros and Cons\n\n\n\n\nRisk difference\n\nCan provide additional information, but can be misleading on its own\nNot the preferred measurement\n\n\n\nRisk ratio\n\nEasy to interpret because is a ratio of probabilities\nCannot use in retrospective, case-control studies\n\n\n\nOdds ratio\n\nAdequate for all studies\nGood estimate of RR for rare diseases\nMost preferred by statisticians because integrated into logistic regression"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-5",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-5",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Poll Everywhere Question 5",
    "text": "Poll Everywhere Question 5"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measuring-agreement",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measuring-agreement",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Measuring Agreement",
    "text": "Measuring Agreement\n\nStill within the realm of contingency tables\nWhat if we are NOT looking at the association between two variables?\nWhat if we want to look at the agreement between two things?\n\nAnswers of same subjects for same survey taken at different times\nTwo different radiologists’ assessment of the same X-ray\n\nCohen’s Kappa statistics: widely used as a measure of agreement\n\nExample: Reliability studies, interobserver agreement"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-beef-consumption-in-survey",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-beef-consumption-in-survey",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Example: Beef Consumption in Survey",
    "text": "Example: Beef Consumption in Survey\nA diet questionnaire was mailed to 537 female American nurses on two separate occasions several months apart. The questions asked included the quantities eaten of more than 100 separate food items. The data from the two surveys for the amount of beef consumption are presented in the below table. How can reproducibility of response for the beef-consumption data be quantified?"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measuring-agreement-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measuring-agreement-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Measuring Agreement",
    "text": "Measuring Agreement\n\nIf perfect agreement among the two raters/surveys, we would expect nonzero entries only in the diagonal cells of the table\n\n \n\n\\(p_o\\) is the observed proportion of complete agreement (concordance)\n\\(p_E\\) is the expected proportion of complete agreement if the agreement is just due to chance\nIf the \\(p_o\\) is much greater than \\(p_E\\), then the agreement level is high. Otherwise, the agreement level is low\n\n \n\nCohen’s Kappa is based on the difference between \\(p_o\\) and \\(p_E\\): \\[\\hat{\\kappa}=\\frac{p_o-p_E}{1-p_E}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-beef-consumption-in-survey-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-beef-consumption-in-survey-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Example: Beef Consumption in Survey",
    "text": "Example: Beef Consumption in Survey"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-6",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-6",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Poll Everywhere Question 6",
    "text": "Poll Everywhere Question 6"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measuring-agreement-between-two-raters",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measuring-agreement-between-two-raters",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Measuring Agreement Between Two Raters",
    "text": "Measuring Agreement Between Two Raters"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#testing-measuring-agreement",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#testing-measuring-agreement",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Testing Measuring Agreement",
    "text": "Testing Measuring Agreement"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-beef-consumption",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-beef-consumption",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Example: Beef Consumption",
    "text": "Example: Beef Consumption"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measurement-of-association-so-far",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measurement-of-association-so-far",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Measurement of Association So Far",
    "text": "Measurement of Association So Far\n\nUsed contingency tables to test and measure association between two variables\n\nCategorical outcome variable (Y)\nOne categorical explanatory variable (X)\n\nSuch an association is called crude association\n\nNo adjustment for possible confounding factors\nAlso called marginal association\n\nBut we cannot expand analysis based on contingency tables past 3 variables\n\nWe can get into stratified contingency tables to bring in a 3rd variable\nBut I don’t think it’s worth it because regression can bring in (adjust for) many variables"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#confounding",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#confounding",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Confounding",
    "text": "Confounding"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measurement-of-association-for-three-way-tables",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measurement-of-association-for-three-way-tables",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Measurement of Association for Three-way Tables",
    "text": "Measurement of Association for Three-way Tables"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-lung-cancer-and-drinking-status",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-lung-cancer-and-drinking-status",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Example: Lung cancer and drinking status",
    "text": "Example: Lung cancer and drinking status"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#types-of-confounders",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#types-of-confounders",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Types of confounders",
    "text": "Types of confounders"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-7",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-7",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Poll Everywhere Question 7",
    "text": "Poll Everywhere Question 7"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-scottish-health-heart-study",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-scottish-health-heart-study",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Example: Scottish Health Heart Study",
    "text": "Example: Scottish Health Heart Study"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#confounding-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#confounding-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Confounding",
    "text": "Confounding"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#adjusted-or-mantel-haenszel-method",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#adjusted-or-mantel-haenszel-method",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Adjusted OR: Mantel-Haenszel Method",
    "text": "Adjusted OR: Mantel-Haenszel Method"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#stratified-tables",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#stratified-tables",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Stratified tables",
    "text": "Stratified tables"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#adjusted-or-mantel-haenszel-method-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#adjusted-or-mantel-haenszel-method-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Adjusted OR: Mantel-Haenszel Method",
    "text": "Adjusted OR: Mantel-Haenszel Method"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-scottish-health-heart-study-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-scottish-health-heart-study-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Example: Scottish Health Heart Study",
    "text": "Example: Scottish Health Heart Study"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-7-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#poll-everywhere-question-7-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Poll Everywhere Question 7",
    "text": "Poll Everywhere Question 7"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#cochran-mantel-haenszel-cmh-test",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#cochran-mantel-haenszel-cmh-test",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Cochran-Mantel-Haenszel (CMH) Test",
    "text": "Cochran-Mantel-Haenszel (CMH) Test"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-scottish-health-heart-study-2",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#example-scottish-health-heart-study-2",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Example: Scottish Health Heart Study",
    "text": "Example: Scottish Health Heart Study"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#tests-from-last-class",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#tests-from-last-class",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Tests from last class",
    "text": "Tests from last class"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#section",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#section",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "1",
    "text": "1\n\nlibrary(pubh)\nct = mtcars |&gt;\n  contingency(as.factor(vs) ~ as.factor(am))\n\n         Outcome\nPredictor  1  0\n        1  7  6\n        0  7 12\n\n             Outcome +    Outcome -      Total                 Inc risk *\nExposed +            7            6         13     53.85 (25.13 to 80.78)\nExposed -            7           12         19     36.84 (16.29 to 61.64)\nTotal               14           18         32     43.75 (26.36 to 62.34)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nInc risk ratio                                 1.46 (0.67, 3.17)\nInc odds ratio                                 2.00 (0.48, 8.40)\nAttrib risk in the exposed *                   17.00 (-17.71, 51.71)\nAttrib fraction in the exposed (%)            31.58 (-48.44, 68.46)\nAttrib risk in the population *                6.91 (-20.77, 34.58)\nAttrib fraction in the population (%)         15.79 (-24.73, 43.15)\n-------------------------------------------------------------------\nUncorrected chi2 test that OR = 1: chi2(1) = 0.907 Pr&gt;chi2 = 0.341\nFisher exact test that OR = 1: Pr&gt;chi2 = 0.473\n Wald confidence limits\n CI: confidence interval\n * Outcomes per 100 population units \n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  dat\nX-squared = 0.34754, df = 1, p-value = 0.5555\n\nct$observed\n\n         Outcome\nPredictor  1  0\n        1  7  6\n        0  7 12"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#section-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#section-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "2",
    "text": "2\n\nmtcars\n\n\n\n\nmpgcyldisphpdratwtqsecvsamgearcarb\n\n21  6160  1103.9 2.6216.50144\n\n21  6160  1103.9 2.8817  0144\n\n22.84108  933.852.3218.61141\n\n21.46258  1103.083.2119.41031\n\n18.78360  1753.153.4417  0032\n\n18.16225  1052.763.4620.21031\n\n14.38360  2453.213.5715.80034\n\n24.44147  623.693.1920  1042\n\n22.84141  953.923.1522.91042\n\n19.26168  1233.923.4418.31044\n\n17.86168  1233.923.4418.91044\n\n16.48276  1803.074.0717.40033\n\n17.38276  1803.073.7317.60033\n\n15.28276  1803.073.7818  0033\n\n10.48472  2052.935.2518  0034\n\n10.48460  2153   5.4217.80034\n\n14.78440  2303.235.3417.40034\n\n32.4478.7664.082.2 19.51141\n\n30.4475.7524.931.6118.51142\n\n33.9471.1654.221.8319.91141\n\n21.54120  973.7 2.4620  1031\n\n15.58318  1502.763.5216.90032\n\n15.28304  1503.153.4417.30032\n\n13.38350  2453.733.8415.40034\n\n19.28400  1753.083.8517.10032\n\n27.3479  664.081.9418.91141\n\n26  4120  914.432.1416.70152\n\n30.4495.11133.771.5116.91152\n\n15.88351  2644.223.1714.50154\n\n19.76145  1753.622.7715.50156\n\n15  8301  3353.543.5714.60158\n\n21.44121  1094.112.7818.61142"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#recall-the-strong-heart-study",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#recall-the-strong-heart-study",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Recall the Strong Heart Study",
    "text": "Recall the Strong Heart Study\n\n\nThe Strong Heart Study is an ongoing study of American Indians residing in 13 tribal communities in three geographic areas (AZ, OK, and SD/ND). We will look at data from this study examining the incidence of diabetes at a follow-up visit and impaired glucose tolerance (ITG) at baseline (4 years apart).\n \n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference",
    "text": "SHS Example: Risk Difference\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\nNeeded steps:\n\nCompute the risk difference\nCompute 95% confidence interval\nInterpret the estimate"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#risk-difference-rd",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#risk-difference-rd",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Risk Difference (RD)",
    "text": "Risk Difference (RD)\n\nRisk difference computes the absolute difference in risk for the two groups (from the explanatory variable)\nPoint estimate: \\[\\widehat{RD} = \\widehat{p}_1 - \\widehat{p}_1 = \\dfrac{n_{11}}{n_1} - \\dfrac{n_{21}}{n_2}\\]\n\nWith range of point estimate from \\([-1, 1]\\)\n\nApproximate standard error:\n\n\\[ SE_{\\widehat{RD}} = \\sqrt{\\frac{\\hat{p}_1\\cdot(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2\\cdot(1-\\hat{p}_2)}{n_2}}\\]\n\n95% Wald confidence interval for \\(\\widehat{RD}\\):\n\n\\[\\widehat{RD} \\pm 1.96 \\cdot SE_{\\widehat{RD}}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference",
    "text": "SHS Example: Risk Difference\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nCompute 95% confidence interval\n\n\\[\\begin{aligned} &\\widehat{RD}\\pm z_{\\left(1-\\frac{\\alpha}{2}\\right)}^\\ast \\times SE_{\\widehat{RD}} \\\\\n= &\\widehat{RD}\\pm z_{\\left(1-\\frac{\\alpha}{2}\\right)}^\\ast \\times \\sqrt{\\frac{{\\hat{p}}_1\\ (1-{\\hat{p}}_1)}{n_1}+\\frac{{\\hat{p}}_2(1-{\\hat{p}}_2)}{n_2}\\ }\\\\\n=  & -0.025 \\pm 1.96\\times \\sqrt{\\frac{0.056(1-0.056)}{733}+\\frac{0.081(1-0.081)}{742}\\ }\\\\\n=  & (-0.0506,\\ 0.0008)\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-13",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-13",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (1/3)",
    "text": "SHS Example: Risk Difference (1/3)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nCompute the risk difference \\[\\widehat{RD}={\\hat{p}}_1 - {\\hat{p}}_2=\\frac{n_{11}}{n_1}-\\frac{n_{21}}{n_2}=\\ \\frac{198}{532}\\ - \\frac{128}{1132}=0.3722−0.1131=0.2591\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-33",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-33",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (3/3)",
    "text": "SHS Example: Risk Difference (3/3)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n1/2. Compute risk difference and 95% confidence interval\n\nfmsb::riskdifference(198, 128, 532, 1132)\n\n                 Cases People at risk         Risk\nExposed    198.0000000    532.0000000    0.3721805\nUnexposed  128.0000000   1132.0000000    0.1130742\nTotal      326.0000000   1664.0000000    0.1959135\n\n\n\n    Risk difference and its significance probability (H0: The difference\n    equals to zero)\n\ndata:  198 128 532 1132\np-value &lt; 2.2e-16\n95 percent confidence interval:\n 0.2140779 0.3041346\nsample estimates:\n[1] 0.2591062"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-2",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-2",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (2/)",
    "text": "SHS Example: Risk Difference (2/)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nCompute 95% confidence interval\n\n\\[\\begin{aligned} &\\widehat{RD}\\pm z_{\\left(1-\\frac{\\alpha}{2}\\right)}^\\ast \\times SE_{\\widehat{RD}} \\\\\n= &\\widehat{RD}\\pm z_{\\left(1-\\frac{\\alpha}{2}\\right)}^\\ast \\times \\sqrt{\\frac{{\\hat{p}}_1\\ (1-{\\hat{p}}_1)}{n_1}+\\frac{{\\hat{p}}_2(1-{\\hat{p}}_2)}{n_2}\\ }\\\\\n=  & 0.2591 \\pm 1.96\\times \\sqrt{\\frac{0.3722(1-0.3722)}{532}+\\frac{0.1131(1-0.1131)}{1132}\\ }\\\\\n=  & (0.2141,\\ 0.3041 )\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-33-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-33-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (3/3)",
    "text": "SHS Example: Risk Difference (3/3)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nInterpret the estimate\n\nThe diabetes diagnosis risk difference between impaired and normal glucose tolerance is 0.2591 (95% CI: 0.2141, 0.3041). Since the 95% confidence interval contains 0, we do not have sufficient evidence that the risk of diabetes diagnosis between impaired and normal glucose tolerance is different."
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-14",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-14",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (1/4)",
    "text": "SHS Example: Risk Difference (1/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nCompute the risk difference \\[\\widehat{RD}={\\hat{p}}_1 - {\\hat{p}}_2=\\frac{n_{11}}{n_1}-\\frac{n_{21}}{n_2}=\\ \\frac{198}{532}\\ - \\frac{128}{1132}=0.3722−0.1131=0.2591\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-24",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-24",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (2/4)",
    "text": "SHS Example: Risk Difference (2/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nCompute 95% confidence interval\n\n\\[\\begin{aligned} &\\widehat{RD}\\pm z_{\\left(1-\\frac{\\alpha}{2}\\right)}^\\ast \\times SE_{\\widehat{RD}} \\\\\n= &\\widehat{RD}\\pm z_{\\left(1-\\frac{\\alpha}{2}\\right)}^\\ast \\times \\sqrt{\\frac{{\\hat{p}}_1\\ (1-{\\hat{p}}_1)}{n_1}+\\frac{{\\hat{p}}_2(1-{\\hat{p}}_2)}{n_2}\\ }\\\\\n=  & 0.2591 \\pm 1.96\\times \\sqrt{\\frac{0.3722(1-0.3722)}{532}+\\frac{0.1131(1-0.1131)}{1132}\\ }\\\\\n=  & (0.2141,\\ 0.3041 )\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-34",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-34",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (3/4)",
    "text": "SHS Example: Risk Difference (3/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n1/2. Compute risk difference and 95% confidence interval\n\nfmsb::riskdifference(198, 128, 532, 1132)\n\n                 Cases People at risk         Risk\nExposed    198.0000000    532.0000000    0.3721805\nUnexposed  128.0000000   1132.0000000    0.1130742\nTotal      326.0000000   1664.0000000    0.1959135\n\n\n\n    Risk difference and its significance probability (H0: The difference\n    equals to zero)\n\ndata:  198 128 532 1132\np-value &lt; 2.2e-16\n95 percent confidence interval:\n 0.2140779 0.3041346\nsample estimates:\n[1] 0.2591062"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-44",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-44",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (4/4)",
    "text": "SHS Example: Risk Difference (4/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nInterpret the estimate\n\nThe diabetes diagnosis risk difference between impaired and normal glucose tolerance is 0.2591 (95% CI: 0.2141, 0.3041). Since the 95% confidence interval contains 0, we do not have sufficient evidence that the risk of diabetes diagnosis between impaired and normal glucose tolerance is different."
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Relative Risk",
    "text": "SHS Example: Relative Risk\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\nNeeded steps:\n\nCompute the relative risk\nFind confidence interval of log RR\nConvert back to RR\nInterpret the estimate"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-14-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-14-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (1/4)",
    "text": "SHS Example: Risk Difference (1/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nCompute the relative risk \\[\\widehat{RR}=\\dfrac{{\\hat{p}}_1}{{\\hat{p}}_2}=\\dfrac{n_{11}/{n_1}}{n_{21}/{n_2}}=\\ \\frac{ 198/532}{128/1132}=\\dfrac{0.3722}{0.1131}=3.2915\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-24-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-24-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (2/4)",
    "text": "SHS Example: Risk Difference (2/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nFind confidence interval of log RR then convert back to RR\n\n\\[\\begin{aligned} & ln(\\widehat{RR}) \\pm 1.96 \\times SE_{\\ln(\\widehat{RR})} \\\\\n= &ln(\\widehat{RR}) \\pm z_{\\left(1-\\frac{\\alpha}{2}\\right)}^\\ast \\times \\sqrt{\\frac{1}{n_{11}}\\ -\\frac{1}{n_1}+\\frac{1}{n_{21}}-\\frac{1}{n_2}}\\\\\n=  & 1.1913 \\pm 1.96\\times \\sqrt{\\frac{1}{198}\\ -\\frac{1}{532}+\\frac{1}{128}-\\frac{1}{1132}}\\\\\n=  & (0.2,\\ 0.3 )\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-34-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-34-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (3/4)",
    "text": "SHS Example: Risk Difference (3/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n1/2. Compute risk difference and 95% confidence interval\n\nlibrary(epitools)\nSHS_ct = table(SHS$glucimp, SHS$case)\nriskratio(x = SHS_ct, rev = \"rows\")$measure\n\n          risk ratio with 95% C.I.\n           estimate    lower    upper\n  Normal   1.000000       NA       NA\n  Impaired 3.291471 2.702998 4.008061"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-44-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-44-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (4/4)",
    "text": "SHS Example: Risk Difference (4/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nInterpret the estimate\n\nThe diabetes diagnosis risk difference between impaired and normal glucose tolerance is 0.2591 (95% CI: 0.2141, 0.3041). Since the 95% confidence interval contains 0, we do not have sufficient evidence that the risk of diabetes diagnosis between impaired and normal glucose tolerance is different."
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-24-2",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-difference-24-2",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Difference (2/4)",
    "text": "SHS Example: Risk Difference (2/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nFind confidence interval of log RR then convert back to RR\n\n\\[\\begin{aligned} & ln(\\widehat{RR}) \\pm 1.96 \\times SE_{\\ln(\\widehat{RR})} \\\\\n= &ln(\\widehat{RR}) \\pm z_{\\left(1-\\frac{\\alpha}{2}\\right)}^\\ast \\times \\sqrt{\\frac{1}{n_{11}}\\ -\\frac{1}{n_1}+\\frac{1}{n_{21}}-\\frac{1}{n_2}}\\\\\n=  & 1.1913 \\pm 1.96\\times \\sqrt{\\frac{1}{198}\\ -\\frac{1}{532}+\\frac{1}{128}-\\frac{1}{1132}}\\\\\n=  & (0.2141,\\ 0.3041 )\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#pause-other-option",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#pause-other-option",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Pause: other option",
    "text": "Pause: other option\n\nlibrary(pubh)\nSHS = SHS %&gt;% mutate(glucimp = as.factor(glucimp) %&gt;% relevel(ref = \"Normal\"))\ncontingency(case ~ glucimp, data = SHS)\n\n          Outcome\nPredictor     1    0\n  Impaired  198  334\n  Normal    128 1004\n\n             Outcome +    Outcome -      Total                 Inc risk *\nExposed +          198          334        532     37.22 (33.10 to 41.48)\nExposed -          128         1004       1132      11.31 (9.52 to 13.30)\nTotal              326         1338       1664     19.59 (17.71 to 21.58)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nInc risk ratio                                 3.29 (2.70, 4.01)\nInc odds ratio                                 4.65 (3.61, 6.00)\nAttrib risk in the exposed *                   25.91 (21.41, 30.41)\nAttrib fraction in the exposed (%)            69.62 (63.00, 75.05)\nAttrib risk in the population *                8.28 (5.63, 10.94)\nAttrib fraction in the population (%)         42.28 (34.71, 48.98)\n-------------------------------------------------------------------\nUncorrected chi2 test that OR = 1: chi2(1) = 154.239 Pr&gt;chi2 = &lt;0.001\nFisher exact test that OR = 1: Pr&gt;chi2 = &lt;0.001\n Wald confidence limits\n CI: confidence interval\n * Outcomes per 100 population units \n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  dat\nX-squared = 152.6, df = 1, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-ratio-14",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-ratio-14",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Ratio (1/4)",
    "text": "SHS Example: Risk Ratio (1/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nCompute the relative risk \\[\\widehat{RR}=\\dfrac{{\\hat{p}}_1}{{\\hat{p}}_2}=\\dfrac{n_{11}/{n_1}}{n_{21}/{n_2}}=\\ \\frac{ 198/532}{128/1132}=\\dfrac{0.3722}{0.1131}=3.2915\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-ratio-24",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-ratio-24",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Ratio (2/4)",
    "text": "SHS Example: Risk Ratio (2/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nFind confidence interval of log RR\n\n\\[\\begin{aligned} & ln(\\widehat{RR}) \\pm 1.96 \\times SE_{\\ln(\\widehat{RR})} \\\\\n= &ln(\\widehat{RR}) \\pm z_{\\left(1-\\frac{\\alpha}{2}\\right)}^\\ast \\times \\sqrt{\\frac{1}{n_{11}}\\ -\\frac{1}{n_1}+\\frac{1}{n_{21}}-\\frac{1}{n_2}}\\\\\n=  & 1.1913 \\pm 1.96\\times \\sqrt{\\frac{1}{198}\\ -\\frac{1}{532}+\\frac{1}{128}-\\frac{1}{1132}}\\\\\n=  & (0.9944,\\ 1.3883 )\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-ratio-34",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-ratio-34",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Ratio (3/4)",
    "text": "SHS Example: Risk Ratio (3/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n1/2/3. Compute risk ratio and 95% confidence interval\n\nlibrary(epitools)\nSHS_ct = table(SHS$glucimp, SHS$case)\nriskratio(x = SHS_ct, rev = \"rows\")$measure\n\n          risk ratio with 95% C.I.\n           estimate    lower    upper\n  Normal   1.000000       NA       NA\n  Impaired 3.291471 2.702998 4.008061"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#pause-other-option-in-pubh-package",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#pause-other-option-in-pubh-package",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Pause: other option in pubh package",
    "text": "Pause: other option in pubh package\n\nSHS = SHS %&gt;% mutate(glucimp = as.factor(glucimp) %&gt;% relevel(ref = \"Normal\"))\ncontingency(case ~ glucimp, data = SHS)\n\n          Outcome\nPredictor     1    0\n  Impaired  198  334\n  Normal    128 1004\n\n             Outcome +    Outcome -      Total                 Inc risk *\nExposed +          198          334        532     37.22 (33.10 to 41.48)\nExposed -          128         1004       1132      11.31 (9.52 to 13.30)\nTotal              326         1338       1664     19.59 (17.71 to 21.58)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nInc risk ratio                                 3.29 (2.70, 4.01)\nInc odds ratio                                 4.65 (3.61, 6.00)\nAttrib risk in the exposed *                   25.91 (21.41, 30.41)\nAttrib fraction in the exposed (%)            69.62 (63.00, 75.05)\nAttrib risk in the population *                8.28 (5.63, 10.94)\nAttrib fraction in the population (%)         42.28 (34.71, 48.98)\n-------------------------------------------------------------------\nUncorrected chi2 test that OR = 1: chi2(1) = 154.239 Pr&gt;chi2 = &lt;0.001\nFisher exact test that OR = 1: Pr&gt;chi2 = &lt;0.001\n Wald confidence limits\n CI: confidence interval\n * Outcomes per 100 population units \n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  dat\nX-squared = 152.6, df = 1, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-ratio-24-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-ratio-24-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Ratio (2/4)",
    "text": "SHS Example: Risk Ratio (2/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nConvert back to RR\n\n\\[\\begin{aligned} & (\\exp(0.9944),\\ \\exp(1.3883 )) \\\\\n= & (2.703,\\ 4.0081 )\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-ratio-44",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-risk-ratio-44",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Risk Ratio (4/4)",
    "text": "SHS Example: Risk Ratio (4/4)\n\n\n\n\nRisk difference\n\n\nCompute the point estimate and 95% confidence interval for the diabetes risk difference between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nInterpret the estimate\n\nThe estimated risk of diabetes is 3.29 times greater for American Indians who had impaired glucose tolerance at baseline compared to those who had normal glucose tolerance (95% CI: 2.70, 4.01).\n \nAdditional interpretation of 95% CI (not needed): We are 95% confident that the (population) relative risk is between 2.70 and 4.01.\n \nSince the 95% confidence interval does not include 1, there is sufficient evidence that the risk of diabetes differs significantly between impaired and normal glucose tolerance at baseline."
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk-16",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk-16",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Relative Risk (1/6)",
    "text": "SHS Example: Relative Risk (1/6)\n\n\n\n\nRelative risk\n\n\nCompute the point estimate and 95% confidence interval for the diabetes Relative risk between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\nNeeded steps:\n\nCompute the relative risk\nFind confidence interval of log RR\nConvert back to RR\nInterpret the estimate"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk-26",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk-26",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Relative Risk (2/6)",
    "text": "SHS Example: Relative Risk (2/6)\n\n\n\n\nRelative risk\n\n\nCompute the point estimate and 95% confidence interval for the diabetes Relative risk between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nCompute the relative risk \\[\\widehat{RR}=\\dfrac{{\\hat{p}}_1}{{\\hat{p}}_2}=\\dfrac{n_{11}/{n_1}}{n_{21}/{n_2}}=\\ \\frac{ 198/532}{128/1132}=\\dfrac{0.3722}{0.1131}=3.2915\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk-36",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk-36",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Relative Risk (3/6)",
    "text": "SHS Example: Relative Risk (3/6)\n\n\n\n\nRelative risk\n\n\nCompute the point estimate and 95% confidence interval for the diabetes Relative risk between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nFind confidence interval of log RR\n\n\\[\\begin{aligned} & \\ln(\\widehat{RR}) \\pm 1.96 \\times SE_{\\ln(\\widehat{RR})} \\\\\n= &\\ln(\\widehat{RR}) \\pm z_{\\left(1-\\frac{\\alpha}{2}\\right)}^\\ast \\times \\sqrt{\\frac{1}{n_{11}}\\ -\\frac{1}{n_1}+\\frac{1}{n_{21}}-\\frac{1}{n_2}}\\\\\n=  & 1.1913 \\pm 1.96\\times \\sqrt{\\frac{1}{198}\\ -\\frac{1}{532}+\\frac{1}{128}-\\frac{1}{1132}}\\\\\n=  & (0.9944,\\ 1.3883 )\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk-46",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk-46",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Relative Risk (4/6)",
    "text": "SHS Example: Relative Risk (4/6)\n\n\n\n\nRelative risk\n\n\nCompute the point estimate and 95% confidence interval for the diabetes Relative risk between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nConvert back to RR\n\n\\[\\begin{aligned} & (\\exp(0.9944),\\ \\exp(1.3883 )) \\\\\n= & (2.703,\\ 4.0081 )\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk-56",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk-56",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Relative Risk (5/6)",
    "text": "SHS Example: Relative Risk (5/6)\n\n\n\n\nRelative risk\n\n\nCompute the point estimate and 95% confidence interval for the diabetes Relative risk between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n1/2/3. Compute risk ratio and 95% confidence interval\n\nlibrary(epitools)\nSHS_ct = table(SHS$glucimp, SHS$case)\nriskratio(x = SHS_ct, rev = \"rows\")$measure\n\n          risk ratio with 95% C.I.\n           estimate    lower    upper\n  Normal   1.000000       NA       NA\n  Impaired 3.291471 2.702998 4.008061"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk-66",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-relative-risk-66",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Relative Risk (6/6)",
    "text": "SHS Example: Relative Risk (6/6)\n\n\n\n\nRelative risk\n\n\nCompute the point estimate and 95% confidence interval for the diabetes Relative risk between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nInterpret the estimate\n\nThe estimated risk of diabetes is 3.29 times greater for American Indians who had impaired glucose tolerance at baseline compared to those who had normal glucose tolerance (95% CI: 2.70, 4.01).\n \nAdditional interpretation of 95% CI (not needed): We are 95% confident that the (population) relative risk is between 2.70 and 4.01.\n \nSince the 95% confidence interval does not include 1, there is sufficient evidence that the risk of diabetes differs significantly between impaired and normal glucose tolerance at baseline."
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-odds-ratio-16",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-odds-ratio-16",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Odds Ratio (1/6)",
    "text": "SHS Example: Odds Ratio (1/6)\n\n\n\n\nOdds ratio\n\n\nCompute the point estimate and 95% confidence interval for the diabetes odds ratio between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\nNeeded steps:\n\nCompute the odds ratio\nFind confidence interval of log OR\nConvert back to OR\nInterpret the estimate"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-odds-ratio-26",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-odds-ratio-26",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Odds Ratio (2/6)",
    "text": "SHS Example: Odds Ratio (2/6)\n\n\n\n\nOdds ratio\n\n\nCompute the point estimate and 95% confidence interval for the diabetes Odds ratio between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nCompute the odds ratio\n\n\\(\\widehat{p}_1 = 198/532 = 0.3722\\), \\(\\widehat{p}_2 = 128/1132 = 0.1131\\) \\[\\widehat{OR}=\\frac{\\widehat{p_1}/(1-\\widehat{p_1})}{\\widehat{p_2}/(1-\\widehat{p_2})}= \\dfrac{0.3722/(1-0.3722)}{0.1131/(1-0.1131)}= 4.6499\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-odds-ratio-36",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-odds-ratio-36",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Odds Ratio (3/6)",
    "text": "SHS Example: Odds Ratio (3/6)\n\n\n\n\nOdds ratio\n\n\nCompute the point estimate and 95% confidence interval for the diabetes Odds ratio between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nFind confidence interval of log OR\n\n\\[\\begin{aligned} & \\ln(\\widehat{OR}) \\pm 1.96 \\times SE_{\\ln(\\widehat{OR})} \\\\\n= &\\ln(\\widehat{OR}) \\pm z_{\\left(1-\\frac{\\alpha}{2}\\right)}^\\ast \\times \\sqrt{\\frac{1}{n_{11}}\\ +\\frac{1}{n_{12}}+\\frac{1}{n_{21}}+\\frac{1}{n_{22}}}\\\\\n=  & 1.5368 \\pm 1.96\\times \\sqrt{\\frac{1}{198}\\ +\\frac{1}{334}+\\frac{1}{128}+\\frac{1}{1004}}\\\\\n=  & (1.2824,\\ 1.7913 )\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-odds-ratio-46",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-odds-ratio-46",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Odds Ratio (4/6)",
    "text": "SHS Example: Odds Ratio (4/6)\n\n\n\n\nOdds ratio\n\n\nCompute the point estimate and 95% confidence interval for the diabetes Odds ratio between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nConvert back to OR\n\n\\[\\begin{aligned} & (\\exp(1.2824),\\ \\exp(1.7913 )) \\\\\n= & (3.6053,\\ 5.9971 )\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-odds-ratio-56",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-odds-ratio-56",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Odds Ratio (5/6)",
    "text": "SHS Example: Odds Ratio (5/6)\n\n\n\n\nOdds ratio\n\n\nCompute the point estimate and 95% confidence interval for the diabetes Odds ratio between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n1/2/3. Compute OR and 95% confidence interval\n\nlibrary(epitools)\nSHS_ct = table(SHS$glucimp, SHS$case)\n# no `rev` needed below bc we set the reference level in slide 32\noddsratio(x = SHS_ct, method = \"wald\")$measure \n\n          odds ratio with 95% C.I.\n           estimate    lower    upper\n  Normal   1.000000       NA       NA\n  Impaired 4.649888 3.605289 5.997148"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#pause-other-option-in-pubh-package-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#pause-other-option-in-pubh-package-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Pause: other option in pubh package",
    "text": "Pause: other option in pubh package\n\ncontingency(case ~ glucimp, data = SHS, digits = 3)\n\n          Outcome\nPredictor     1    0\n  Impaired  198  334\n  Normal    128 1004\n\n             Outcome +    Outcome -      Total                 Inc risk *\nExposed +          198          334        532  37.218 (33.097 to 41.482)\nExposed -          128         1004       1132   11.307 (9.521 to 13.298)\nTotal              326         1338       1664  19.591 (17.709 to 21.581)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nInc risk ratio                                 3.291 (2.703, 4.008)\nInc odds ratio                                 4.650 (3.605, 5.997)\nAttrib risk in the exposed *                   25.911 (21.408, 30.413)\nAttrib fraction in the exposed (%)            69.618 (63.004, 75.050)\nAttrib risk in the population *                8.284 (5.631, 10.937)\nAttrib fraction in the population (%)         42.284 (34.713, 48.976)\n-------------------------------------------------------------------\nUncorrected chi2 test that OR = 1: chi2(1) = 154.239 Pr&gt;chi2 = &lt;0.001\nFisher exact test that OR = 1: Pr&gt;chi2 = &lt;0.001\n Wald confidence limits\n CI: confidence interval\n * Outcomes per 100 population units \n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  dat\nX-squared = 152.6, df = 1, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-odds-ratio-66",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-odds-ratio-66",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Odds Ratio (6/6)",
    "text": "SHS Example: Odds Ratio (6/6)\n\n\n\n\nOdds ratio\n\n\nCompute the point estimate and 95% confidence interval for the diabetes Odds ratio between impaired and normal glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\n\nInterpret the estimate\n\nThe estimated odds of diabetes for American Indians with impaired glucose tolerance at baseline is 4.65 times the odds for American Indians with normal glucose tolerance at baseline.\n \nAdditional interpretation of 95% CI (not needed): We are 95% confident that the odds ratio is between 3.61 and 6.00.\n \nSince the 95% confidence interval does not include 1, there is sufficient evidence that the odds of diabetes differs significantly between impaired and normal glucose tolerance at baseline."
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#inversing-an-odds-ratio",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#inversing-an-odds-ratio",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Inversing an Odds Ratio",
    "text": "Inversing an Odds Ratio\n\nSome clinicians may prefer interpretations of OR &gt; 1 instead of an OR &lt; 1\nThe transformation can easily be done by inverse\n\nRemember we discussed that OR = 4 is an equivalent a strong association as OR = 0.25 (1/4)\n\nOR comparing group 1 to group 2 = inverse of OR comparing group 2 to group 1\n\n\\[ OR_{1v2}=\\frac{{\\hat{p}}_1/(1-{\\hat{p}}_1)}{{\\hat{p}}_2/(1-{\\hat{p}}_2)}=\\frac{1}{\\frac{{\\hat{p}}_2/(1-{\\hat{p}}_2)}{{\\hat{p}}_1/(1-{\\hat{p}}_1)}}=\\frac{1}{OR_{2v1}}\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-inversing-odds-ratio",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-inversing-odds-ratio",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Inversing Odds Ratio",
    "text": "SHS Example: Inversing Odds Ratio\n\n\n\n\nInversing odds ratio\n\n\nCompute the point estimate and 95% confidence interval for the diabetes odds ratio between normal and impaired glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\nNeeded steps:\n\nInverse point estimate and confidence interval\n\n\\[\\widehat{OR}=\\frac{1}{4.6499}=0.2151\\] The 95% Confidence interval is then\n\\[ \\left(\\frac{1}{5.9971}, \\frac{1}{3.6053}\\right)\\ =\\ (0.1667, 0.2774)\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-inversing-odds-ratio-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-inversing-odds-ratio-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Inversing Odds Ratio",
    "text": "SHS Example: Inversing Odds Ratio\n\n\n\n\nInversing odds ratio\n\n\nCompute the point estimate and 95% confidence interval for the diabetes odds ratio between normal and impaired glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\nNeeded steps:\n\nInverse point estimate and confidence interval\n\n\nlibrary(epitools)\noddsratio(x = SHS_ct, method = \"wald\", rev = \"rows\")$measure \n\n          odds ratio with 95% C.I.\n           estimate     lower     upper\n  Impaired 1.000000        NA        NA\n  Normal   0.215059 0.1667459 0.2773702"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:janitor':\n\n    make_clean_names\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nhere() starts at /Users/wakim/Library/CloudStorage/OneDrive-OregonHealth&ScienceUniversity/Teaching/Classes/S2024_BSTA_513_613/S2024_BSTA_513"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relationship-between-rr-and-or-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relationship-between-rr-and-or-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Relationship Between RR and OR",
    "text": "Relationship Between RR and OR\n\nAn example where a disease rare over the whole sample (~1%), but …\n\n\\(\\widehat{OR}\\) is not a good estimate of \\(\\widehat{RR}\\) in “rare” disease\n\n\n\n\n\\(\\widhat{p}_1\\) is 0.5: thus \\(\\widehat{OR}\\) and \\(\\widehat{RR}\\) are very different\n\n\\[\\widehat{RR}=\\frac{0.5}{0.00102}=490 \\text{ and } \\widehat{OR} = \\frac{0.5(1-0.5)}{0.00102(1-0.00102)}=981\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relationship-between-rr-and-or-12",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relationship-between-rr-and-or-12",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Relationship Between RR and OR (1/2)",
    "text": "Relationship Between RR and OR (1/2)\n\nNotice that odds ratio is not equivalent to relative risk (or risk ratio)\nHowever, when the probability of “success” is small (e.g., rare disease), \\(\\widehat{OR}\\) is a nice approximation of \\(\\widehat{RR}\\) \\[\\widehat{OR}=\\frac{{\\hat{p}}_1/(1-{\\hat{p}}_1)}{{\\hat{p}}_2/(1-{\\hat{p}}_2)}=\\widehat{RR}\\cdot \\frac{1-\\widehat{p_2}}{1-\\widehat{p_1}}\\]\n\nThe fraction in the last term of the above expression approximately equals to 1.0 if \\(\\widehat{p}_1\\) and \\(\\widehat{p}_2\\) BOTH quite small (&lt; 0.1)\n\nThe \\(\\widehat{OR}\\) and \\(\\widehat{RR}\\) are not very close to each other in SHS: diabetes not a rare disease\n\n\\(\\widehat{OR} = 4.65\\)\n\\(\\widehat{RR} = 3.29\\)"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relationship-between-rr-and-or-22",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#relationship-between-rr-and-or-22",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Relationship Between RR and OR (2/2)",
    "text": "Relationship Between RR and OR (2/2)\n\nAn example where a disease rare over the whole sample (~1%), but …\n\n\\(\\widehat{OR}\\) is not a good estimate of \\(\\widehat{RR}\\) in “rare” disease\n\n\n\n\n\\(\\widehat{p}_1\\) is 0.5: thus \\(\\widehat{OR}\\) and \\(\\widehat{RR}\\) are very different\n\n\\[\\widehat{RR}=\\frac{0.5}{0.00102}=490 \\text{ and } \\widehat{OR} = \\frac{0.5(1-0.5)}{0.00102(1-0.00102)}=981\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#which-measurement-should-one-use-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#which-measurement-should-one-use-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Which measurement should one use?",
    "text": "Which measurement should one use?\n\n\n\n\n\n\n\nMeasurement\nPros and Cons\n\n\n\n\nRisk difference\n\nCan provide additional information, but can be misleading on its own\nNot the preferred measurement\n\n\n\nRisk ratio\n\nEasy to interpret because is a ratio of probabilities\nCannot use in retrospective, case-control studies\n\n\n\nOdds ratio\n\nAdequate for all studies\nGood estimate of RR for rare diseases\nMost preferred by statisticians because integrated into logistic regression"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#rr-in-retrospective-case-control-study-1",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#rr-in-retrospective-case-control-study-1",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "RR in retrospective case-control study",
    "text": "RR in retrospective case-control study\n\nAssume a 1:2 case-control study summarized in below table:\n\n\n\nAssume we compute the RR as if it is from a cohort study:\n\n\\[\\widehat{RR}=\\frac{\\widehat{p_1}}{\\widehat{p_2}}=\\frac{n_{11}/n_{1+}}{n_{21}/n_{2+}}=\\frac{40/80}{60/220}=1.8333\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#rr-in-retrospective-case-control-study-2",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#rr-in-retrospective-case-control-study-2",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "RR in retrospective case-control study",
    "text": "RR in retrospective case-control study\n\nIn real world, the proportion of controls (not diseased) is typically much higher. Assume the table below shows the proportion in the population in a cohort study\n\n\n\nThe estimated RR for the patient population is:\n\n\\[\\widehat{RR}=\\frac{\\widehat{p_1}}{\\widehat{p_2}}=\\frac{400/4400}{600/16600}=2.5152\\]"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measuring-agreement-2",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#measuring-agreement-2",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Measuring Agreement",
    "text": "Measuring Agreement\nCohen’s Kappa: \\[\\hat{\\kappa}=\\frac{p_o-p_E}{1-p_E}\\]\n\n\\(p_o=\\ \\frac{\\sum_{i}\\ n_{ii}}{n}\\) (sum of diagonals divided by total)\n\\(p_E=\\sum_{i}{a_ib_i}\\)\n\n \n\nWhat’s \\(\\sum_{i}{a_ib_i}\\)?\n\nFor \\(i\\) responses (row/columns), \\(a_i\\) is proportion of \\(i\\) response category in first survey and \\(b_i\\) is proportion of \\(i\\) response category in second survey (we’ll show this in the example)"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#to-give-a-taste-of-regression-for-a-categorical-outcome-we-will-come-back-to-this",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#to-give-a-taste-of-regression-for-a-categorical-outcome-we-will-come-back-to-this",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "To give a taste of regression for a categorical outcome (we will come back to this!!)",
    "text": "To give a taste of regression for a categorical outcome (we will come back to this!!)\n\nlogreg = glm(case ~ glucimp, data = SHS, family = binomial)\n\n\n\n\nsummary(logreg)\n\n\nCall:\nglm(formula = case ~ glucimp, family = binomial, data = SHS)\n\nCoefficients:\n                Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -2.05972    0.09385  -21.95   &lt;2e-16 ***\nglucimpImpaired  1.53684    0.12982   11.84   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1646.3  on 1663  degrees of freedom\nResidual deviance: 1501.3  on 1662  degrees of freedom\nAIC: 1505.3\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nlibrary(epiDisplay)\nlogistic.display(logreg)\n\n\nLogistic regression predicting case \n \n                            OR(95%CI)      P(Wald's test) P(LR-test)\nglucimp: Impaired vs Normal 4.65 (3.61,6)  &lt; 0.001        &lt; 0.001   \n                                                                    \nLog-likelihood = -750.6533\nNo. of observations = 1664\nAIC value = 1505.3066\n\n\n\nlibrary(oddsratio)\nor_glm(data = SHS, model = logreg)"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#a-taste-of-regression-for-a-binary-outcome-we-will-come-back-to-this",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#a-taste-of-regression-for-a-binary-outcome-we-will-come-back-to-this",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "A taste of regression for a binary outcome (we will come back to this!!)",
    "text": "A taste of regression for a binary outcome (we will come back to this!!)\n\nlogreg = glm(case ~ glucimp, data = SHS, family = binomial)\n\n\n\n\nsummary(logreg)\n\n\nCall:\nglm(formula = case ~ glucimp, family = binomial, data = SHS)\n\nCoefficients:\n                Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -2.05972    0.09385  -21.95   &lt;2e-16 ***\nglucimpImpaired  1.53684    0.12982   11.84   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1646.3  on 1663  degrees of freedom\nResidual deviance: 1501.3  on 1662  degrees of freedom\nAIC: 1505.3\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nlibrary(epiDisplay)\nlogistic.display(logreg)\n\n\nLogistic regression predicting case \n \n                            OR(95%CI)      P(Wald's test) P(LR-test)\nglucimp: Impaired vs Normal 4.65 (3.61,6)  &lt; 0.001        &lt; 0.001   \n                                                                    \nLog-likelihood = -750.6533\nNo. of observations = 1664\nAIC value = 1505.3066"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-inversing-odds-ratio-2",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#shs-example-inversing-odds-ratio-2",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "SHS Example: Inversing Odds Ratio",
    "text": "SHS Example: Inversing Odds Ratio\n\n\n\n\nInversing odds ratio\n\n\nCompute the point estimate and 95% confidence interval for the diabetes odds ratio between normal and impaired glucose tolerance.\n\n\n\n\n\n\n\n\n\n  \n    \n    \n      Glucose tolerance\n      \n        Diabetes\n      \n      Total\n    \n    \n      No\n      Yes\n    \n  \n  \n    Impaired\n334\n198\n532\n    Normal\n1004\n128\n1132\n    Total\n1338\n326\n1664\n  \n  \n  \n\n\n\n\n\n\nNeeded steps:\n\nInterpret the estimate\n\nThe estimated odds of diabetes for American Indians with normal glucose tolerance at baseline is 0.22 times the odds for American Indians with impaired glucose tolerance at baseline.\n \nAdditional interpretation of 95% CI (not needed): We are 95% confident that the odds ratio is between 0.17 and 0.28.\n \nSince the 95% confidence interval does not include 1, there is sufficient evidence that the odds of diabetes differs significantly between impaired and normal glucose tolerance at baseline."
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#pubh-vs.-epitools",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#pubh-vs.-epitools",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "pubh vs. epitools",
    "text": "pubh vs. epitools\n\nIn pubh with contingency()\n\nGet all the info at once\nReally nice to double check how the code is interpreting your input\n\nIn epitools with riskratio() or oddsratio()\n\nMuch easier to grab the numbers!\nIn Quarto you can take R code and directly put it in your text\n\ng = oddsratio(x = SHS_ct, method = \"wald\", rev = \"rows\")\ng$measure[2,1]\n\n[1] 0.215059\n\n\n\nI can write {r eval=\"false\" echo=\"true\"} round(g$measure[2,1], 3) to print the number 0.215\n\n\n\n\n\nLesson 3: Measurement of Association for Contingency Tables"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#review-of-test-of-association-12",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#review-of-test-of-association-12",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Review of Test of Association (1/2)",
    "text": "Review of Test of Association (1/2)\n\nLast week: learned some tests of association for contingency tables\n\n \n\nFor studies with two independent samples\n\nGeneral association\n\nChi-squared test\nFisher’s Exact test\n\nTest of trends\n\nCochran-Armitage test\nMantel-Haenszel test"
  },
  {
    "objectID": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#review-of-test-of-association-22",
    "href": "lectures/03_Meas_Assoc_CT/03_Meas_Assoc_CT.html#review-of-test-of-association-22",
    "title": "Lesson 3: Measurement of Association for Contingency Tables",
    "section": "Review of Test of Association (2/2)",
    "text": "Review of Test of Association (2/2)"
  },
  {
    "objectID": "project/Lab_01_instructions.html",
    "href": "project/Lab_01_instructions.html",
    "title": "Lab 1 Instructions",
    "section": "",
    "text": "Caution\n\n\n\nThis project includes analysis on food insecurity."
  },
  {
    "objectID": "project/Lab_01_instructions.html#directions",
    "href": "project/Lab_01_instructions.html#directions",
    "title": "Lab 1 Instructions",
    "section": "1 Directions",
    "text": "1 Directions\nYou can download the .qmd file for this lab here.\nThe above link will take you to your editing file. Please do not remove anything from this editing file!! You will only add your code and work to this file.\n\n1.1 Grading\nThis lab is graded out of 12 points. The TAs will go through and grade your lab. They will make sure each section is complete and will follow the rubric below. I have instructed them that completion and clear effort is all that is needed to receive 100%. Nicky will go through the labs to give you feedback.\n\n1.1.1 Rubric\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\n\n\nFormatting\nLab submitted on Sakai with .html file. Answers are written in complete sentences with no major grammatical nor spelling errors. With little editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with grammatical or spelling errors. With editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with major grammatical or spelling errors. With major editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are bulletted or do not use complete sentences.\nLab not submitted on Sakai with .html file.\n\n\nCode/Work\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMost tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nSome tasks are directly followed or answered.This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMore than a quarter of the tasks are not completed properly.\n\n\nReasoning*\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful and can be easily integrated into the final report.\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful, but lack the clarity needed to easily integrate into the final report.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers are fairly thoughtful, but lack connection to the research.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers seem rushed and with minimal thought.\nAnswers lack understanding of research context and investigation of the data. Answers seem rushed and without thought.\n\n\n\n*Applies to questions with reasoning"
  },
  {
    "objectID": "project/Lab_01_instructions.html#lab-activities",
    "href": "project/Lab_01_instructions.html#lab-activities",
    "title": "Lab 1 Instructions",
    "section": "2 Lab activities",
    "text": "2 Lab activities\n\n\n\n\n\n\nNote\n\n\n\nI have left it up to you to load the needed packages for this lab.\n\n\n\n2.1 Reading and listening activities\nI will not check that you have read or listened to any of these, but it is a good starting point for understanding the context of our data: food insecurity in the United States. I haven’t fully read them all yet, but I will be reading and sharing throughout the quarter.\nHere are some articles:\n\nNPR: Millions of American families struggle to get food on the table, report finds\n\nWith option to listen to article\n\nIdentification of factors related to food insecurity and the implications for social determinants of health screenings\nNIMHD’s page on Food Accessibility, Insecurity and Health Outcomes\nFood Insecurity among American Indians and Alaska Natives: A National Profile using the Current Population Survey–Food Security Supplement\nA Framework for Evaluating Social Determinants of Health Screening and Referrals for Assistance\n\n\n\n2.2 Familiarize yourself with the Well-Being and Basic Needs Survey\nPlease read the Urban Institute’s page on the Well-Being and Basic Needs Survey (WBNS) and more of their published information of the survey (at least the first 4 pages). You can also read about the overarching From Safety Net to Solid Ground Initiative that started the survey. Answer the following questions:\n\nWhat is the motivation for this study?\nHow could an analysis that looks at associations with food insecurity help facilitate change in policy?\nWhy is it important to study food insecurity?\n\n\n\n\n\n\n\nTask\n\n\n\nAnswer the following questions using information on WBNS:\n\nWhat is the motivation for this study?\nHow could an analysis that looks at associations with food insecurity help facilitate change in policy?\nWhy is it important to study food insecurity?\n\n\n\n\n\n2.3 File organization\nBefore downloading the data, go back to Lesson 2 and follow the file setup for our project. This includes making an .Rproj file within the main folder. Make sure you are working with the project by using the here() function to display your working directory.\n\n\n\n\n\n\nTask\n\n\n\nDisplay your working directory using the here package and here() function.\n\n\n\n\n2.4 Access and download the data\n\nGo to the Health and Medical Care Archive page for the Well-Being and Basic Needs Survey\nGo to the Data & Documentation tab \nDownload the R version of the Public use data \nRead and agree to the Terms of Use. After this, you will be redirected to a new page.\nLog into ICPSR by clicking “Access through your institution”. You should be taken to a new page where you need to select “Oregon Health & Science University” \nLogin using standard OHSU login. Then the download should begin!\nMake sure to move this into your project folder under the Data folder.\nTake a look at the folders/files you just downloaded. Make sure to locate and understand the difference between the Codebook, Questionnaire, and User Guide. (Note that the website also contains the codebook if you go to the variable tab. I think the online one has an easier user interface than the pdf.)\n\n\n\n\n\n\n\nTask\n\n\n\nNo task to report back on. Just make sure you have the data!\n\n\n\n\n2.5 Decide on list of variables to focus on\nFrom the codebook, I want you to explore the variables and create a list of 10 predictors that you would like to focus on. Our outcome is FOOD_INSEC so we cannot use this as a predictor. Feel free to take a look at the Urban Institute’s list of publications to get ideas of variables and relationships.\nThere are a few requirements for your predictors:\n\n1 variable must be a numeric (i.e. PPAGE)\n1 variable must be binary\n1 variable must be multi-level categorical (categorical with more than 2 groups)\nYou must choose at least 10 predictors (does not include the outcome)\n\nThere is a good online version of the codebook with information about the variables. I have linked you to the ID varaible, but you can take a look at all the other variables using the left hand side navigator:\n\nYou can look under survey questions to get a better sense of how questions were asked, but please stick to variables under Demographic Variables, Family Income, Insurance Status, and Material Hardship. Do not choose variables from the Administrative levels, Survey Questions, nor School Enrollment or Child Care variables. May leave in the ID variable for easier tracking on individuals, but it does not count towards the 10 predictors.\n\n\n\n\n\n\nTask\n\n\n\nList the 10 predictors that you plan to use in your analysis. Note which variables are numeric, binary, or multi-level categorical.\n\n\n\n\n2.6 Get a sense of how you would like to analyze the data\nFor our project, we will examine the association between the food insecurity and one other variable (our main explanatory variable). From the above readings, survey information, and your list of predictors in Section 2.5, which association are you most interested in analyzing?\nPlease write this in the form of a research question statement. Feel free to copy this sentence and insert your chosen predictor: We will investigate the association between food insecurity and ____.\n\n\n\n\n\n\nTask\n\n\n\nComplete the following statement to identify your research question:\nWe will investigate the association between food insecurity and ____.\n\n\n\n\n2.7 Save data for processing with .Rda\nWithin this document, or in a separate document, use R to save a copy of the dataset so that you can process it without changing the raw data. Recall the file organization that we discussed to set up proper folders. Include a screenshot showing the new .Rda file within your Data folder.\n\n\n\n\n\n\nTask\n\n\n\nInclude a screenshot showing the new .Rda file within your Data folder.\n\n\n\n\n2.8 Getting data in working format\nYou can start by selecting only the variables you will use in your analysis. Again, you can keep ID in addition to your outcome and predictors for easy tracking.\nUse the following code (with your dataset’s name) to remove the parentheses with values that are in front of the category names. Make sure to change old_df and new_df.\n\nnew_df = data.frame(lapply(old_df, function(x) {gsub(\".*) \", \"\", x)}))\n\n\n\n\n\n\n\nTask\n\n\n\n\nSelect the variables that will be used in your analysis and make a new dataset. Include the code that you used.\nRemove the parentheses with values that are in front of the category names.\n\n\n\n\n\n2.9 Explore the outcome and predictors\nThe codebook online gives some nice plots of each variable. Please take a look at the codebook online to see the spread of each variable. Make note of any categorical variables that have less than 100 observations in a group. This may cause issues in our analysis later.\n\n\n\n\n\n\nTask\n\n\n\n\nTo check that you have looked that the variables, please report the percent of respondents that were food insecure in the past 12 months.\nList any categorical variables that have less than 100 observations in a group\n\n\n\n\n\n2.10 Compile above work into an introduction\nPlease check out this source for what a research article introduction includes and how to organize it. The only thing I would add is mentioning the Well-Being and Basic Needs Survey.\n\n\n\n\n\n\nTask\n\n\n\nWrite an introduction to the analysis."
  },
  {
    "objectID": "project.html#information-and-resources-on-food-insecurity",
    "href": "project.html#information-and-resources-on-food-insecurity",
    "title": "Project Central",
    "section": "Information and Resources on Food Insecurity",
    "text": "Information and Resources on Food Insecurity\nThis project will discuss food insecurity and unmet basic needs. If you have experienced or are experiencing food insecurity, and this project impacts your mental health or ability to work, please let me know. We can work on an alternative analysis with a different dataset.\nIf you are currently experiencing food insecurity or not meeting your basic needs, here are some resources for Oregon residents:\n\nOregon One elegibility page\n\nYou can apply for benefits including medical, food, cash, or child care assistance\nThis is one way to apply to multiple benefits\n\nOregon Health Plan\nThe Oregon Food Bank has a food finder\n\nIn addition to these statewide resources, as students, there are other resources available to you:\n\nFood Assistance and Basic Needs for OHSU students\n\nIncludes information on SNAP program\nIncludes information on free groceries available to students at the Food Resource Center\n\nYou can even order it online and pick it up!\n\n\nYou can email basicneeds@ohsu.edu for help getting assistance or connecting you to the following services:\n\nManage your finances\nAccess emergency funds\nFind legal services\nApply for SNAP\nFind child care\nFind housing"
  },
  {
    "objectID": "project.html#reading-and-listening-sources",
    "href": "project.html#reading-and-listening-sources",
    "title": "Project Central",
    "section": "Reading and listening sources",
    "text": "Reading and listening sources"
  },
  {
    "objectID": "lectures/Project_prez/Project_intro.html#original-motivation",
    "href": "lectures/Project_prez/Project_intro.html#original-motivation",
    "title": "Project Introduction",
    "section": "Original motivation",
    "text": "Original motivation\n\nMixed-Status Immigrant Families Disproportionately Experienced Material Hardships in 2021\n\n\n\nProject Introduction"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#relationship-between-rr-and-or-12",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#relationship-between-rr-and-or-12",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Relationship Between RR and OR (1/2)",
    "text": "Relationship Between RR and OR (1/2)\n\nNotice that odds ratio is not equivalent to relative risk (or risk ratio)\n\n \n\nHowever, when the probability of “success” is small (e.g., rare disease), \\(\\widehat{OR}\\) is a nice approximation of \\(\\widehat{RR}\\) \\[\\widehat{OR}=\\frac{{\\hat{p}}_1/(1-{\\hat{p}}_1)}{{\\hat{p}}_2/(1-{\\hat{p}}_2)}=\\widehat{RR}\\cdot \\frac{1-\\widehat{p_2}}{1-\\widehat{p_1}}\\]\n\nThe fraction in the last term of the above expression approximately equals to 1.0 if \\(\\widehat{p}_1\\) and \\(\\widehat{p}_2\\) BOTH quite small (&lt; 0.1)\n\n\n \n\nThe \\(\\widehat{OR}\\) and \\(\\widehat{RR}\\) are not very close to each other in SHS: diabetes not a rare disease\n\n\\(\\widehat{OR} = 4.65\\)\n\\(\\widehat{RR} = 3.29\\)"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#relationship-between-rr-and-or-22",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#relationship-between-rr-and-or-22",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Relationship Between RR and OR (2/2)",
    "text": "Relationship Between RR and OR (2/2)\n\nAn example where a disease rare over the whole sample (~1%), but …\n\n\\(\\widehat{OR}\\) is not a good estimate of \\(\\widehat{RR}\\) in “rare” disease\n\n\n\n\n\n\n\n\n\\(\\widehat{p}_1\\) is 0.5: thus \\(\\widehat{OR}\\) and \\(\\widehat{RR}\\) are very different\n\n\\[\\widehat{RR}=\\frac{0.5}{0.00102}=490 \\text{ and } \\widehat{OR} = \\frac{0.5(1-0.5)}{0.00102(1-0.00102)}=981\\]"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#notes-for-odds-ratios",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#notes-for-odds-ratios",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Notes for Odds Ratios",
    "text": "Notes for Odds Ratios\n\nThe OR is valid for\n\nCase-control studies (where the RR is not appropriate)\nProspective cohort studies\nCross-sectional studies\n\n\n \n\nIt can be interpreted either as…\n\nOdds of event for exposed vs. unexposed individuals, or\nOdds of exposure for individuals with vs. without the event of interest\n\n\n \n\nPay attention to the numerator and denominator for the OR"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#which-measurement-should-one-use",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#which-measurement-should-one-use",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Which measurement should one use?",
    "text": "Which measurement should one use?"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#rr-in-retrospective-case-control-study",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#rr-in-retrospective-case-control-study",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "RR in retrospective case-control study",
    "text": "RR in retrospective case-control study\n\nIn retrospective, case-control studies, we identify cases (patients with the outcome), then select a number of controls (patients without the outcome)\n\nCase-control study to require much smaller sample size than equivalent cohort studies\nSo we pick out the cases and controls first, then see if there is exposure\nBecause the odds can be interpreted as \\(OR\\) of exposure and \\(OR\\) of case, we can use the \\(OR\\) to assess the case\n\\(RR\\) relative risk does not have this property\n\nHowever, the proportion of cases in the sample does not represent the proportion of cases in the population\n\nRR compares probability of the outcome (case) for exposed and unexposed groups\nNumber of outcomes has been artificially inflated for retrospective study"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#rr-in-retrospective-case-control-study-1",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#rr-in-retrospective-case-control-study-1",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "RR in retrospective case-control study",
    "text": "RR in retrospective case-control study\n\nAssume a 1:2 case-control study summarized in below table:\n\n\n\nAssume we compute the RR as if it is from a cohort study:\n\n\\[\\widehat{RR}=\\frac{\\widehat{p_1}}{\\widehat{p_2}}=\\frac{n_{11}/n_{1+}}{n_{21}/n_{2+}}=\\frac{40/80}{60/220}=1.8333\\]"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#rr-in-retrospective-case-control-study-2",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#rr-in-retrospective-case-control-study-2",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "RR in retrospective case-control study",
    "text": "RR in retrospective case-control study\n\nIn real world, the proportion of controls (not diseased) is typically much higher. Assume the table below shows the proportion in the population in a cohort study\n\n\n\nThe estimated RR for the patient population is:\n\n\\[\\widehat{RR}=\\frac{\\widehat{p_1}}{\\widehat{p_2}}=\\frac{400/4400}{600/16600}=2.5152\\]"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#or-in-retrospective-case-control-study",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#or-in-retrospective-case-control-study",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "OR in retrospective case-control study",
    "text": "OR in retrospective case-control study\n\nWhile we cannot estimate RR from a case-control study, we can still estimate OR for case-control study\n\nOR does not require us to distinguish between the outcome variable and explanatory variable in the contingency table\n\nAKA: Odds ratio of disease comparing exposed to not exposed is same as odds ratio of being exposed comparing diseased and not diseased\n\n\n\n \n\n\n\nFor case-control study where the probability of having outcome is small, the \\(\\widehat{OR}\\) is a nice approximation to \\(\\widehat{RR}\\)\n\nFor the 1:2 case-control table: \\(\\widehat{OR}=\\frac{40\\cdot160}{40\\cdot60} = 2.667\\)\nPopulation cohort study: \\(\\widehat{RR}=2.5152\\)"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#poll-everywhere-question-5",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#poll-everywhere-question-5",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Poll Everywhere Question 5",
    "text": "Poll Everywhere Question 5"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measuring-agreement",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measuring-agreement",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Measuring Agreement",
    "text": "Measuring Agreement\n\nStill within the realm of contingency tables\nWhat if we are NOT looking at the association between two variables?\n\n \n\nWhat if we want to look at the agreement between two things?\n\nAnswers of same subjects for same survey taken at different times\nTwo different radiologists’ assessment of the same X-ray\n\n\n \n\nCohen’s Kappa statistics: widely used as a measure of agreement\n\nExample: Reliability studies, interobserver agreement"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption-in-survey",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption-in-survey",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Beef Consumption in Survey",
    "text": "Example: Beef Consumption in Survey\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between beef consumption surveys. Similar to question: Are results reproducible for the beef-consumption in the survey?\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n\nCompute the kappa statistic\nFind confidence interval of kappa\nInterpret the estimate"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measuring-agreement-1",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measuring-agreement-1",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Measuring Agreement",
    "text": "Measuring Agreement\n\nIf perfect agreement among the two raters/surveys:\n\nWe would expect nonzero entries only in the diagonal cells of the table\n\n\n \n\n\\(p_o\\) is the observed proportion of complete agreement (concordance)\n\\(p_E\\) is the expected proportion of complete agreement if the agreement is just due to chance\nIf the \\(p_o\\) is much greater than \\(p_E\\), then the agreement level is high.\n\nOtherwise, the agreement level is low\n\n\n \n\n\n\nCohen’s Kappa is based on the difference between \\(p_o\\) and \\(p_E\\): \\[\\hat{\\kappa}=\\frac{p_o-p_E}{1-p_E}\\]\n\n\n\n\n\n\\(\\hat{\\kappa} = 0\\): No agreement between surveys/raters other than what would be expected by chance\n\\(\\hat{\\kappa} = 1\\): Complete agreement"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measuring-agreement-2",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measuring-agreement-2",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Measuring Agreement",
    "text": "Measuring Agreement\nCohen’s Kappa: \\[\\hat{\\kappa}=\\frac{p_o-p_E}{1-p_E}\\]\n\n\\(p_o=\\ \\frac{\\sum_{i}\\ n_{ii}}{n}\\) (sum of diagonals divided by total)\n\\(p_E=\\sum_{i}{a_ib_i}\\)\n\n \n\nWhat’s \\(\\sum_{i}{a_ib_i}\\)?\n\nFor \\(i\\) responses (row/columns), \\(a_i\\) is proportion of \\(i\\) response category in first survey and \\(b_i\\) is proportion of \\(i\\) response category in second survey (we’ll show this in the example)"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption-in-survey-1",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption-in-survey-1",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Beef Consumption in Survey",
    "text": "Example: Beef Consumption in Survey\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between beef consumption surveys. Similar to question: Are results reproducible for the beef-consumption in the survey?\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n1/2. Compute the kappa statistic and find confidence interval of kappa\n\nlibrary(epiR)\nbeef = matrix(c(136, 92, 69, 240), nrow = 2, byrow = T)\nepi.kappa(beef, method = \"cohen\")$kappa \n\n        est         se     lower     upper\n1 0.3781906 0.04100635 0.2978196 0.4585616"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#poll-everywhere-question-6",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#poll-everywhere-question-6",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Poll Everywhere Question 6",
    "text": "Poll Everywhere Question 6"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measuring-agreement-between-two-raters",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measuring-agreement-between-two-raters",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Measuring Agreement Between Two Raters",
    "text": "Measuring Agreement Between Two Raters"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#testing-measuring-agreement",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#testing-measuring-agreement",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Testing Measuring Agreement",
    "text": "Testing Measuring Agreement"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Beef Consumption",
    "text": "Example: Beef Consumption"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measurement-of-association-so-far",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measurement-of-association-so-far",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Measurement of Association So Far",
    "text": "Measurement of Association So Far\n\nUsed contingency tables to test and measure association between two variables\n\nCategorical outcome variable (Y)\nOne categorical explanatory variable (X)\n\nWe looked at risk difference, risk ratio, and odds ratio to measure association\nSuch an association is called crude association\n\nNo adjustment for possible confounding factors\nAlso called marginal association\n\nBut we cannot expand analysis based on contingency tables past 3 variables\n\nWe can get into stratified contingency tables to bring in a 3rd variable\nBut I don’t think it’s worth it because regression can bring in (adjust for) many variables"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#a-taste-of-regression-for-a-binary-outcome-we-will-come-back-to-this",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#a-taste-of-regression-for-a-binary-outcome-we-will-come-back-to-this",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "A taste of regression for a binary outcome (we will come back to this!!)",
    "text": "A taste of regression for a binary outcome (we will come back to this!!)\n\nlogreg = glm(case ~ glucimp, data = SHS, family = binomial)\n\n\n\n\nsummary(logreg)\n\n\nCall:\nglm(formula = case ~ glucimp, family = binomial, data = SHS)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   -0.52287    0.08969   -5.83 5.55e-09 ***\nglucimpNormal -1.53684    0.12982  -11.84  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1646.3  on 1663  degrees of freedom\nResidual deviance: 1501.3  on 1662  degrees of freedom\nAIC: 1505.3\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nlibrary(epiDisplay)\n\nLoading required package: foreign\n\n\nLoading required package: survival\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:gtsummary':\n\n    select\n\n\nThe following object is masked from 'package:rstatix':\n\n    select\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\nLoading required package: nnet\n\n\n\nAttaching package: 'epiDisplay'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    alpha\n\nlogistic.display(logreg)\n\n\nLogistic regression predicting case \n \n                     OR(95%CI)         P(Wald's test) P(LR-test)\nglucimp (cont. var.) 0.22 (0.17,0.28)  &lt; 0.001        &lt; 0.001   \n                                                                \nLog-likelihood = -750.6533\nNo. of observations = 1664\nAIC value = 1505.3066"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#our-example",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#our-example",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Our example!",
    "text": "Our example!"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#poll-everywhere-question-1",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#poll-everywhere-question-1",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Poll Everywhere Question 1",
    "text": "Poll Everywhere Question 1"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#poll-everywhere-question-2",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#poll-everywhere-question-2",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Poll Everywhere Question 2",
    "text": "Poll Everywhere Question 2"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#lets-get-this-data-down",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#lets-get-this-data-down",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Let’s get this data down!",
    "text": "Let’s get this data down!"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#just-in-case-our-data-doesnt-work-out-beef-consumption-in-survey",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#just-in-case-our-data-doesnt-work-out-beef-consumption-in-survey",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Just in case our data doesn’t work out: Beef Consumption in Survey",
    "text": "Just in case our data doesn’t work out: Beef Consumption in Survey\nA diet questionnaire was mailed to 537 female American nurses on two separate occasions several months apart. The questions asked included the quantities eaten of more than 100 separate food items. The data from the two surveys for the amount of beef consumption are presented in the below table. How can reproducibility of response for the beef-consumption data be quantified?"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#lets-get-our-mood-data-down",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#lets-get-our-mood-data-down",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Let’s get our mood data down!",
    "text": "Let’s get our mood data down!"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Our moods",
    "text": "Example: Our moods\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between our Monday and Wednesday moods.\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n\nCompute the kappa statistic\nFind confidence interval of kappa\nInterpret the estimate"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measuring-agreement-oberved-kappas",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measuring-agreement-oberved-kappas",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Measuring Agreement: Oberved Kappas",
    "text": "Measuring Agreement: Oberved Kappas\n\nGuidelines for evaluating Kappa (Rosner TB)\n \n\nExcellent agreement if \\(\\hat\\kappa \\geq 0.75\\)\n\n \n\nFair to good agreement if \\(0.4 &lt; \\hat\\kappa &lt; 0.75\\)\n\n \n\nPoor agreement if \\(\\hat\\kappa \\leq 0.4\\)\n\n\n \nIf \\(\\hat\\kappa&lt;0\\), suggest agreement less than by chance"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measuring-agreement-cohens-kappa",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#measuring-agreement-cohens-kappa",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Measuring Agreement: Cohen’s Kappa",
    "text": "Measuring Agreement: Cohen’s Kappa\n\n\n\nPoint estimate: \\[\\hat{\\kappa}=\\frac{p_o-p_E}{1-p_E}\\]\n\nWith \\(p_o=\\ \\frac{\\sum_{i}\\ n_{ii}}{n}\\) (sum of diagonals divided by total)\nWith \\(p_E=\\sum_{i}{a_ib_i}\\)\nWith range of point estimate from \\([-1, 1]\\)\n\n\n\n\n\n\n\nWhat’s \\(\\sum_{i}{a_ib_i}\\)?\n\n\nFor \\(i\\) responses (row/columns), \\(a_i\\) is proportion of \\(i\\) response category in first survey and \\(b_i\\) is proportion of \\(i\\) response category in second survey (we’ll show this in the example)\n\n\n\n\n\nApproximate standard error:\n\n\\[ SE_{\\widehat{\\kappa}} = \\sqrt{\\frac{1}{{n\\left(1-p_e\\right)}^2}\\left\\{p_e^2+p_e-\\sum_{i}\\left[a_ib_i\\left(a_i+b_i\\right)\\right]\\right\\}}\\]\n\n95% Wald confidence interval for \\(\\widehat{\\kappa}\\):\n\n\\[\\widehat{\\kappa} \\pm 1.96 \\cdot SE_{\\widehat{\\kappa}}\\]"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-1",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-1",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Our moods",
    "text": "Example: Our moods\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between our Monday and Wednesday moods.\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n1/2. Compute the kappa statistic and find confidence interval of kappa\n\nlibrary(epiR)\nmoods = matrix(c(13, 9, 6, 24), nrow = 2, byrow = T)\nepi.kappa(moods, method = \"cohen\")$kappa \n\n        est       se     lower     upper\n1 0.3981481 0.131082 0.1412321 0.6550642"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#last-class",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#last-class",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Last class",
    "text": "Last class\n\nUsed contingency tables to test and measure association between two variables\n\nCategorical outcome variable (Y)\nOne categorical explanatory variable (X)\n\nWe looked at risk difference, risk ratio, and odds ratio to measure association\n\n\n\n\n\n\n\n\nMeasure\nEstimate\n\n\n\n\nRisk difference\n\\[\\widehat{RD} = \\widehat{p}_1 - \\widehat{p}_1 = \\dfrac{n_{11}}{n_1} - \\dfrac{n_{21}}{n_2}\\]\n\n\nRelative risk / risk ratio\n\\[\\widehat{RR}=\\dfrac{\\hat{p}_1}{\\hat{p}_2} = \\dfrac{n_{11}/n_1}{n_{21}/n_2}\\]\n\n\nOdds ratio\n\\[\\widehat{OR}=\\frac{odds_1}{odds_2}=\\frac{{\\hat{p}}_1/(1-{\\hat{p}}_1)}{{\\hat{p}}_2/(1-{\\hat{p}}_2)}\\]\n\n\n\n\nDiscussed how OR will be an important measurement in logistic regression"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-2",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-2",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Our moods",
    "text": "Example: Our moods\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between our Monday and Wednesday moods.\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n\nInterpret the estimate\n\nThe kappa statistic is ____ (95% CI: _____, _____), indicating ______ agreement.\nSince the 95% confidence interval does/does not contain 0, we have/do not have sufficient evidence that there is _________ agreement between our mood on Monday and our mood on Wednesday."
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-3",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-3",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Our moods",
    "text": "Example: Our moods\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between our Monday and Wednesday moods.\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n1/2. Compute the kappa statistic and find confidence interval of kappa\n\nlibrary(epiR)\nbeef = matrix(c(136, 92, 69, 240), nrow = 2, byrow = T)\nepi.kappa(beef, method = \"cohen\")$kappa \n\n        est         se     lower     upper\n1 0.3781906 0.04100635 0.2978196 0.4585616\n\n\n\n\n        est         se     lower     upper\n1 0.3781906 0.04100635 0.2978196 0.4585616"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-4",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-4",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Our moods",
    "text": "Example: Our moods\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between our Monday and Wednesday moods.\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n\nInterpret the estimate\n\nThe kappa statistic is 0.378 (95% CI: 0.298, 0.459), indicating fair agreement.\nSince the 95% confidence interval does not contain 0, we have sufficient evidence that there is fair agreement between the surveys for beef consumption. I would say this survey is not reliably reproducible since we did not achieve excellent agreement.\n\n\nLesson 4: Measurements of Association and Agreement"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption-in-survey-2",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption-in-survey-2",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Beef Consumption in Survey",
    "text": "Example: Beef Consumption in Survey\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between beef consumption surveys. Similar to question: Are results reproducible for the beef-consumption in the survey?\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n\nInterpret the estimate\n\nThe kappa statistic is 0.378 (95% CI: 0.298, 0.459), indicating fair agreement.\nSince the 95% confidence interval does not contain 0, we have sufficient evidence that there is fair agreement between the surveys for beef consumption. The survey is not reliably reproducible since we did not achieve excellent agreement.\n\n\nLesson 4: Measurements of Association and Agreement"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-13",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-13",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Our moods (1/3)",
    "text": "Example: Our moods (1/3)\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between our Monday and Wednesday moods.\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n\nCompute the kappa statistic\nFind confidence interval of kappa\nInterpret the estimate"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-23",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-23",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Our moods (2/3)",
    "text": "Example: Our moods (2/3)\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between our Monday and Wednesday moods.\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n1/2. Compute the kappa statistic and find confidence interval of kappa\n\nlibrary(epiR)\n\nPackage epiR 2.0.63 is loaded\n\n\nType help(epi.about) for summary information\n\n\nType browseVignettes(package = 'epiR') to learn how to use epiR for applied epidemiological analyses\n\n\n\n\nmoods = matrix(c(100, 40, 10, 30), nrow = 2, byrow = T)\nmoods\n\n     [,1] [,2]\n[1,]  100   40\n[2,]   10   30\n\nepi.kappa(moods, method = \"cohen\")$kappa \n\n        est         se     lower     upper\n1 0.3661972 0.07617362 0.2168996 0.5154947"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-33",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-our-moods-33",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Our moods (3/3)",
    "text": "Example: Our moods (3/3)\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between our Monday and Wednesday moods.\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n\nInterpret the estimate\n\nThe kappa statistic is ____ (95% CI: _____, _____), indicating ______ agreement.\nSince the 95% confidence interval does/does not contain 0, we have/do not have sufficient evidence that there is _________ agreement between our mood on Monday and our mood on Wednesday."
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption-in-survey-13",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption-in-survey-13",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Beef Consumption in Survey (1/3)",
    "text": "Example: Beef Consumption in Survey (1/3)\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between beef consumption surveys. Similar to question: Are results reproducible for the beef-consumption in the survey?\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n\nCompute the kappa statistic\nFind confidence interval of kappa\nInterpret the estimate"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption-in-survey-23",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption-in-survey-23",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Beef Consumption in Survey (2/3)",
    "text": "Example: Beef Consumption in Survey (2/3)\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between beef consumption surveys. Similar to question: Are results reproducible for the beef-consumption in the survey?\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n1/2. Compute the kappa statistic and find confidence interval of kappa\n\nlibrary(epiR)\nbeef = matrix(c(136, 92, 69, 240), nrow = 2, byrow = T)\nepi.kappa(beef, method = \"cohen\")$kappa \n\n        est         se     lower     upper\n1 0.3781906 0.04100635 0.2978196 0.4585616"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption-in-survey-33",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#example-beef-consumption-in-survey-33",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Example: Beef Consumption in Survey (3/3)",
    "text": "Example: Beef Consumption in Survey (3/3)\n\n\n\n\nAgreement of surveys\n\n\nCompute the point estimate and 95% confidence interval for the agreement between beef consumption surveys. Similar to question: Are results reproducible for the beef-consumption in the survey?\n\n\n\n\n\n\n\n\n\n\nNeeded steps:\n\nInterpret the estimate\n\nThe kappa statistic is 0.378 (95% CI: 0.298, 0.459), indicating fair agreement.\nSince the 95% confidence interval does not contain 0, we have sufficient evidence that there is fair agreement between the surveys for beef consumption. The survey is not reliably reproducible since we did not achieve excellent agreement."
  },
  {
    "objectID": "project/LastName_FirstInit_Lab_01.html",
    "href": "project/LastName_FirstInit_Lab_01.html",
    "title": "Lab 1",
    "section": "",
    "text": "This lab is graded out of 12 points. The TAs will go through and grade your lab. They will make sure each section is complete and will follow the rubric below. I have instructed them that completion and clear effort is all that is needed to receive 100%. Nicky will go through the labs to give you feedback.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\n\n\nFormatting\nLab submitted on Sakai with .html file. Answers are written in complete sentences with no major grammatical nor spelling errors. With little editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with grammatical or spelling errors. With editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with major grammatical or spelling errors. With major editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are bulletted or do not use complete sentences.\nLab not submitted on Sakai with .html file.\n\n\nCode/Work\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMost tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nSome tasks are directly followed or answered.This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMore than a quarter of the tasks are not completed properly.\n\n\nReasoning*\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful and can be easily integrated into the final report.\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful, but lack the clarity needed to easily integrate into the final report.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers are fairly thoughtful, but lack connection to the research.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers seem rushed and with minimal thought.\nAnswers lack understanding of research context and investigation of the data. Answers seem rushed and without thought.\n\n\n\n*Applies to questions with reasoning"
  },
  {
    "objectID": "project/LastName_FirstInit_Lab_01.html#lab-activities",
    "href": "project/LastName_FirstInit_Lab_01.html#lab-activities",
    "title": "Lab 1",
    "section": "2 Lab activities",
    "text": "2 Lab activities\n\n2.1 Reading and listening activities\n\n\n2.2 Familiarize yourself with the Well-Being and Basic Needs Survey\n\n\n\n\n\n\nTask\n\n\n\nAnswer the following questions using information on WBNS:\n\nWhat is the motivation for this study?\nHow could an analysis that looks at associations with food insecurity help facilitate change in policy?\nWhy is it important to study food insecurity?\n\n\n\n\n\n2.3 File organization\n\n\n\n\n\n\nTask\n\n\n\nDisplay your working directory using the here package and here() function.\n\n\n\n\n2.4 Access and download the data\n\n\n\n\n\n\nTask\n\n\n\nNo task to report back on. Just make sure you have the data!\n\n\n\n\n2.5 Decide on list of variables to focus on\n\n\n\n\n\n\nTask\n\n\n\nList the 10 predictors that you plan to use in your analysis. Note which variables are numeric, binary, or multi-level categorical.\n\n\n\n\n2.6 Get a sense of how you would like to analyze the data\n\n\n\n\n\n\nTask\n\n\n\nComplete the following statement to identify your research question:\nWe will investigate the association between food insecurity and ____.\n\n\n\n\n2.7 Save data for processing with .Rda\n\n\n\n\n\n\nTask\n\n\n\nInclude a screenshot showing the new .Rda file within your Data folder.\n\n\n\n\n2.8 Getting data in working format\n\n\n\n\n\n\nTask\n\n\n\n\nSelect the variables that will be used in your analysis and make a new dataset. Include the code that you used.\nRemove the parentheses with values that are in front of the category names.\n\n\n\n\n\n2.9 Explore the outcome and predictors\n\n\n\n\n\n\nTask\n\n\n\n\nTo check that you have looked that the variables, please report the percent of respondents that were food insecure in the past 12 months.\nList any categorical variables that have less than 100 observations in a group\n\n\n\n\n\n2.10 Compile above work into an introduction\n\n\n\n\n\n\nTask\n\n\n\nWrite an introduction to the analysis."
  },
  {
    "objectID": "project/LastName_FirstInit_Lab_01.html#directions",
    "href": "project/LastName_FirstInit_Lab_01.html#directions",
    "title": "Lab 1",
    "section": "",
    "text": "This lab is graded out of 12 points. The TAs will go through and grade your lab. They will make sure each section is complete and will follow the rubric below. I have instructed them that completion and clear effort is all that is needed to receive 100%. Nicky will go through the labs to give you feedback.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\n\n\nFormatting\nLab submitted on Sakai with .html file. Answers are written in complete sentences with no major grammatical nor spelling errors. With little editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with grammatical or spelling errors. With editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with major grammatical or spelling errors. With major editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are bulletted or do not use complete sentences.\nLab not submitted on Sakai with .html file.\n\n\nCode/Work\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMost tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nSome tasks are directly followed or answered.This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMore than a quarter of the tasks are not completed properly.\n\n\nReasoning*\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful and can be easily integrated into the final report.\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful, but lack the clarity needed to easily integrate into the final report.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers are fairly thoughtful, but lack connection to the research.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers seem rushed and with minimal thought.\nAnswers lack understanding of research context and investigation of the data. Answers seem rushed and without thought.\n\n\n\n*Applies to questions with reasoning"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#poll-everywhere-question-3",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#poll-everywhere-question-3",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Poll Everywhere Question 3",
    "text": "Poll Everywhere Question 3"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#poll-everywhere-question-4",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#poll-everywhere-question-4",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "Poll Everywhere Question 4",
    "text": "Poll Everywhere Question 4"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#rr-in-retrospective-case-control-study-13",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#rr-in-retrospective-case-control-study-13",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "RR in retrospective case-control study (1/3)",
    "text": "RR in retrospective case-control study (1/3)\n\nIn retrospective case-control studies: we identify cases (patients with the outcome), then select a number of controls (patients without the outcome)\n\nCase-control study to require much smaller sample size than equivalent cohort studies\nSo we pick out the cases and controls first, then see if there is exposure\n\n\n \n\nHowever, the proportion of cases in the sample does not represent the proportion of cases in the population\n\nRR compares probability of the outcome (case) for exposed and unexposed groups\nNumber of outcomes has been artificially inflated for case-control study"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#rr-in-retrospective-case-control-study-23",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#rr-in-retrospective-case-control-study-23",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "RR in retrospective case-control study (2/3)",
    "text": "RR in retrospective case-control study (2/3)\n\nAssume a 1:2 case-control study summarized in below table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssume we compute the RR as if it is from a cohort study:\n\n\\[\\widehat{RR}=\\frac{\\widehat{p_1}}{\\widehat{p_2}}=\\frac{n_{11}/n_{1+}}{n_{21}/n_{2+}}=\\frac{40/80}{60/220}=1.8333\\]"
  },
  {
    "objectID": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#rr-in-retrospective-case-control-study-33",
    "href": "lectures/04_Meas_Assoc_Agree/04_Meas_Assoc_Agree.html#rr-in-retrospective-case-control-study-33",
    "title": "Lesson 4: Measurements of Association and Agreement",
    "section": "RR in retrospective case-control study (3/3)",
    "text": "RR in retrospective case-control study (3/3)\n\nIn real world, the proportion of controls (not diseased) is typically much higher. Assume the table below shows the proportion in the population in a cohort study\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe estimated RR for the patient population is:\n\n\\[\\widehat{RR}=\\frac{\\widehat{p_1}}{\\widehat{p_2}}=\\frac{400/4400}{600/16600}=2.5152\\]"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#health-disparities-in-breast-cancer-diagnosis-working-example",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#health-disparities-in-breast-cancer-diagnosis-working-example",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Health disparities in breast cancer diagnosis: working example",
    "text": "Health disparities in breast cancer diagnosis: working example\n\nQuestion: Is race/ethnicity and/or age associated with an individual’s diagnosed stage of breast cancer?\n\nFor now, consider each covariate separately\n\n\n \n\nPopulation: individuals who are assigned female at birth who have been diagnosed with breast cancer in the United States\n\n \n\nData from the Surveillance, Epidemiology, and End Results (SEER) Program (2014-2018)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#please-note-that-this-question-has-been-answered",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#please-note-that-this-question-has-been-answered",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Please note that this question has been answered",
    "text": "Please note that this question has been answered\n\nYou can take a look at the Breast Cancer Research Foundation’s page: Understanding Breast Cancer Racial Disparities\nBig contributors to racial disparities include:\n\nUnderrepresentation in clinical trials\nAccess to healthcare\nMore aggressive cancers more likely in people of Native American, African, Hispanic, and Latin American descent\n\nOur analysis will not be new, but this kind of work has shed light on the importance of focused research on people of color to better serve people of color who develop breast cancer\n\nDr. Davis focuses research on genomics and tumor microenvironment in African and African American patients\nDr. Ambrosone focuses research on how immune cells differ between patients. Specifically on the DARC gene, which is an evolved gene that helps fight malaria, that is found at a higher rate in people with African descent."
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-health-disparities-in-breast-cancer-diagnosis-12",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-health-disparities-in-breast-cancer-diagnosis-12",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Example: Health disparities in breast cancer diagnosis (1/2)",
    "text": "Example: Health disparities in breast cancer diagnosis (1/2)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-health-disparities-in-breast-cancer-diagnosis-22",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-health-disparities-in-breast-cancer-diagnosis-22",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Example: Health disparities in breast cancer diagnosis (2/2)",
    "text": "Example: Health disparities in breast cancer diagnosis (2/2)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#poll-everywhere-question-1",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#poll-everywhere-question-1",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Poll Everywhere Question 1",
    "text": "Poll Everywhere Question 1"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-determine-differences-in-diagnosis-i",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-determine-differences-in-diagnosis-i",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do we determine differences in diagnosis? (I)",
    "text": "How do we determine differences in diagnosis? (I)\n\n\nLesson 5: Simple Logistic Regression"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-determine-differences-in-diagnosis-12",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-determine-differences-in-diagnosis-12",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do we determine differences in diagnosis? (1/2)",
    "text": "How do we determine differences in diagnosis? (1/2)\n\nBreast cancer diagnosis study: two variables that are categorical\nWe could use a contingency table (or two-way table)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-determine-differences-in-diagnosis-22",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-determine-differences-in-diagnosis-22",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do we determine differences in diagnosis? (2/2)",
    "text": "How do we determine differences in diagnosis? (2/2)\n\n\n\nContingency table does not work for…\n\nContinuous covariates\nMultiple covariates\n\n\n \n\nLogistic regression models can handle multiple covariates that are continuous or categorical"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-determine-differences-in-diagnosis-22-1",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-determine-differences-in-diagnosis-22-1",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do we determine differences in diagnosis? (2/2)",
    "text": "How do we determine differences in diagnosis? (2/2)\n\n\n\nContingency table does not work for…\n\nContinuous covariates\nMultiple covariates\n\n\n \n\nLogistic regression models can handle multiple covariates that are continuous or categorical"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#reference-for-individual-overview",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#reference-for-individual-overview",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Reference for individual overview",
    "text": "Reference for individual overview"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#building-towards-simple-logistic-regression",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#building-towards-simple-logistic-regression",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Building towards simple logistic regression",
    "text": "Building towards simple logistic regression\n\nGoal: model the probability of our outcome (\\(\\pi(X)\\)) with the covariate (\\(X_1\\))\nIn simple linear regression, we use the model in its various forms: \\[\\begin{aligned} Y&=\\beta_0+\\beta_1X_1+\\epsilon \\\\ E[Y|X] &= \\beta_0 + \\beta_1X_1 \\\\ \\widehat{Y} &= \\beta_0 + \\beta_1X_1 \\end{aligned}\\]\nPotential problem? Probabilities can only take values from 0 to 1"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#simple-logistic-regression-model-components",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#simple-logistic-regression-model-components",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Simple Logistic Regression Model: Components",
    "text": "Simple Logistic Regression Model: Components\n\n\n\nOutcome: \\(Y\\) - binary (two-level) categorical variable\n\n\\(Y=1\\)\n\\(Y=0\\)\n\n\n\n\nCovariate: \\(X_1\\)\n\nFor today: simple logistic regression with one covariate\n\\(X_1\\) can be continuous or categorical\n\n\n\n\n\nProbability of outcome for individual with observed covariates\n\n\\(P\\left(Y=1|X\\right)=\\pi\\left(X\\right)\\)\n\\(P\\left(Y=0|X\\right)=1-\\pi(X)\\)\n\nBecause the expected value is a weighted average, we can say: \\[\\begin{aligned} E(Y|X) & = P(Y=1|X) \\cdot 1 + P(Y=1|X) \\cdot 0 \\\\ & = P(Y=1|X) \\cdot 1 \\\\ & = P(Y=1|X) \\\\ & = \\pi(X) \\end{aligned}\\]\n\nFor categorical outcomes, \\(\\pi(X)\\) (or \\(\\pi\\) for shorthand), is more widely used than \\(E(Y|X)\\)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#can-we-apply-olr-to-our-binary-outcome",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#can-we-apply-olr-to-our-binary-outcome",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Can we apply OLR to our binary outcome?",
    "text": "Can we apply OLR to our binary outcome?"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#review-of-ordinary-linear-regression-olr-i",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#review-of-ordinary-linear-regression-olr-i",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Review of Ordinary Linear Regression (OLR) (I)",
    "text": "Review of Ordinary Linear Regression (OLR) (I)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#violated-linearity",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#violated-linearity",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Violated: Linearity",
    "text": "Violated: Linearity\n\n\n\nThe relationship between the variables is linear (a straight line):\n\n\\(E[Y|X]\\) or \\(\\pi(X)\\), is a straight-line function of \\(X\\)\n\nThe independent variable \\(X\\) can take any value, while \\(\\pi(X)\\) is a probability that should be bounded by [0,1]\n\nWe cannot use linear mapping to translate \\(X\\) to \\(\\pi(X)\\)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#violated-normality",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#violated-normality",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Violated: Normality",
    "text": "Violated: Normality\n\n\n\nIn linear regression, \\(\\epsilon\\) is distributed normally\n\n \n\nRecall that \\(Y\\) can take only one of the two values: 0 or 1\nAnd the fitted \\(Y\\), \\(\\widehat{Y}\\) can also only take values 0 or 1\nThus, \\(\\epsilon = Y - \\widehat{Y}\\) can only take values -1, 0, or 1\n\n \n\nThen \\(\\epsilon\\) cannot follow a normal distribution, which would require \\(\\epsilon\\) to have a continuum of values and no upper or lower bound"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#violated-homoscedasticity",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#violated-homoscedasticity",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Violated: Homoscedasticity",
    "text": "Violated: Homoscedasticity\n\nIn linear regression, \\(\\text{var}(\\epsilon) = \\sigma^2\\)\n\nVariance does not depend on \\(X\\)\n\n\n \n\nWhen Y is a binary outcome \\[\\begin{aligned} \\text{var}\\left(Y\\right) & =\\pi\\left(1-\\pi\\right)\\\\ & = \\left(\\beta_0+\\beta_1X\\right)\\left(1-\\beta_0-\\beta_1X\\right) \\end{aligned}\\]\n\nVariance depends on \\(X\\)\n\n\n \n\nBecause variance depends on \\(X\\): no homoscedasticity\n\nVariance will not be equal across X-values"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#what-happens-if-we-use-olr-for-categorical-responses",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#what-happens-if-we-use-olr-for-categorical-responses",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "What happens if we use OLR for categorical responses?",
    "text": "What happens if we use OLR for categorical responses?"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#simple-logistic-regression-model-components-1",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#simple-logistic-regression-model-components-1",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Simple Logistic Regression Model: Components",
    "text": "Simple Logistic Regression Model: Components"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#poll-everywhere-question-2",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#poll-everywhere-question-2",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Poll Everywhere Question 2",
    "text": "Poll Everywhere Question 2"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-fix-these-violations",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-fix-these-violations",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do we fix these violations?",
    "text": "How do we fix these violations?\n\nQuestion: How do we manipulate our response variable so that we fix these violations?\n\n \n\nAnswer: We need to transform the outcome so we can map differences in covariates to the two levels\n\nWill discuss in a few slides: called link function"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-transform-our-outcome",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-transform-our-outcome",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do we transform our outcome?",
    "text": "How do we transform our outcome?"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#simple-logistic-regression-model",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#simple-logistic-regression-model",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Simple Logistic Regression Model",
    "text": "Simple Logistic Regression Model\nThe (population) regression model is denoted by:\n \n\n\n\n\n\n\\[ \\text{logit} (\\pi) =  \\beta_0 + \\beta_1X\\]\n\n\n\n\n\n \nComponents\n\n\n\n\\(\\pi\\)\nprobability that the outcome occurs (\\(Y=1\\)) given \\(X\\)\n\n\n\\(\\beta_0\\)\nintercept\n\n\n\\(\\beta_1\\)\nslope\n\n\n\\(X\\)\npredictor, covariate, independent variable"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#generalized-linear-models-glm-i",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#generalized-linear-models-glm-i",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Generalized Linear Models (GLM) (I)",
    "text": "Generalized Linear Models (GLM) (I)\n\n\n\nGeneralized Linear Models are a class of models that includes regression models for continuous and categorical responses\n\nResponses follow exponential family distribution\n\n\n \n\nHere we will focus on the GLMs for categorical/count data\n\nLogistic regression is just a one type of GLM\nPoisson regression – for counts\nLog-binomial can be used to focus on risk ratio"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#poll-everywhere-question-3",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#poll-everywhere-question-3",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Poll Everywhere Question 3",
    "text": "Poll Everywhere Question 3"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#glm-random-component",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#glm-random-component",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "GLM: Random Component",
    "text": "GLM: Random Component\n\nThe random component specifies the response variable \\(Y\\) and selects a probability distribution for it\n\n \n \n\nBasically, we are just identifying the distribution for our outcome\n\nIf Y is binary: assumes a binomial distribution of Y\nIf Y is count: assumes Poisson or negative binomial distribution of Y\nIf Y is continuous: assumea Normal distribution of Y"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#glm-systematic-component",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#glm-systematic-component",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "GLM: Systematic Component",
    "text": "GLM: Systematic Component\n\nThe systematic component specifies the explanatory variables, which enter linearly as predictors \\[\\beta_0+\\beta_1X_1+\\ldots+\\beta_kX_k\\]\n\n \n\nAbove equation includes:\n\nCentered variables\nInteractions\nTransformations of variables (like squares)\n\n\n \n\nSystematic component is the same as what we learned in Linear Models"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#glm-link-function",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#glm-link-function",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "GLM: Link Function",
    "text": "GLM: Link Function\n\nIf \\(\\mu = E(Y)\\), then the link function specifies a function \\(g(.)\\) that relates \\(\\mu\\) to the linear predictor as: \\[g\\left(\\mu\\right)=\\beta_0+\\beta_1X_1+\\ldots+\\beta_kX_k\\]\n\n\\(g\\left(\\mu\\right)\\) is the transformation we make to \\(E(Y)\\) (aka \\(\\mu\\)) so that the linear predictors (right side of equation) can be linked to the outcome\n\nThe link function connects the random component with the systematic component\nCan also think of this as: \\[\\mu=g^{-1}\\left(\\beta_0+\\beta_1X_1+\\ldots+\\beta_kX_k\\right)\\]"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#simple-logistic-regression-model-1",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#simple-logistic-regression-model-1",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Simple Logistic Regression Model",
    "text": "Simple Logistic Regression Model"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#estimation-for-logistic-regression-model",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#estimation-for-logistic-regression-model",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Estimation for Logistic Regression Model",
    "text": "Estimation for Logistic Regression Model\n\nSame as linear regression model: we need to estimate the values of \\(\\beta_0\\) and \\(\\beta_1\\)\n\n \n\nMaximum likelihood: yields values for the unknown parameters that maximize the probability of obtaining observed set of data\n\nIn linear regression, this leads to least squares estimation\nMaximum likelihood estimators (MLE): values of parameters that maximize likelihood\n\n\n \n\nLikelihood function: expresses the probability of the observed data as a function of the unknown parameters"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#poll-everywhere-question-5",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#poll-everywhere-question-5",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Poll Everywhere Question 5",
    "text": "Poll Everywhere Question 5"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-to-find-maximum-likelihood-estimator-mle",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-to-find-maximum-likelihood-estimator-mle",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How to find Maximum Likelihood Estimator (MLE)?",
    "text": "How to find Maximum Likelihood Estimator (MLE)?\n\nConstruct a likelihood function for an individual\n\n \n\nConstruct the likelihood function across the sample\n\n \n\nConvert to log-likelihood\n\n \n\nFind parameter values that maximize log-likelihood (MLEs)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#construct-a-likelihood-function-for-an-individual",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#construct-a-likelihood-function-for-an-individual",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "1. Construct a likelihood function for an individual",
    "text": "1. Construct a likelihood function for an individual\n\n\n\nWithin a dataset with n subjects, for the \\(i\\)th subject:\n\nif \\(Y_i=1\\), the contribution to the likelihood function is \\(\\pi\\left(X_i\\right)\\)\nif \\(Y_i=0\\), the contribution to the likelihood function is \\(1-\\pi\\left(X_i\\right)\\)\n\n\n \n\nThe contribution from the \\(i\\)th subject to the likelihood function can be expressed as: \\[\\pi\\left(X_i\\right)^{Y_i}\\left[1-\\pi\\left(X_i\\right)\\right]^{1-Y_i}\\]\n\n\n\n\nRecall\n\n\n\n\\(Y_i\\): Response variable of the \\(i\\)th subject\n\\(X_i\\): Independent variable for the \\(i\\)th subject\n\\(\\pi\\left(X_i\\right)=\\Pr{\\left(Y_i=1\\middle|\\ X_i\\right)}\\)\n\\(1-\\pi\\left(X_i\\right)=\\Pr(Y_i=0|X_i)\\)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#construct-the-likelihood-function-across-the-sample",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#construct-the-likelihood-function-across-the-sample",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "2. Construct the likelihood function across the sample",
    "text": "2. Construct the likelihood function across the sample\n\n\n\nSince there are \\(n\\) subjects in the data, and each subject is considered independent of each other, the likelihood function for the whole data can be expressed as:\n\n\\[l(\\beta_0, \\beta_1) = \\prod_{i=1}^{n}{\\pi(X_i)^{Y_i} (1-\\pi(X_i)) ^ {1-Y_i}}\\]\n\n\n\nRecall\n\n\n\n\\(Y_i\\): Response variable of the \\(i\\)th subject\n\\(X_i\\): Independent variable for the \\(i\\)th subject\n\\(\\pi\\left(X_i\\right)=\\Pr{\\left(Y_i=1\\middle|\\ X_i\\right)}\\)\n\\(1-\\pi\\left(X_i\\right)=\\Pr(Y_i=0|X_i)\\)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#convert-to-log-likelihood",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#convert-to-log-likelihood",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "3. Convert to log-likelihood",
    "text": "3. Convert to log-likelihood\n\n\n\nMathematically, it is easier to work with the log likelihood function for maximization\nThe log likelihood function is: \\[\\begin{aligned}L\\left(\\beta_0,\\beta_1\\right) &=\\ln{\\left(l\\left(\\beta_0,\\beta_1\\right)\\right)} \\\\ & =\n\\sum_{i=1}^{n}\\bigg[Y_i\\cdot\\text{ln}[\\pi(X_i)] + (1-Y_i)\\cdot\\text{ln}[1-\\pi(X_i)] \\bigg]\n\\end{aligned}\\]\n\n\n\n\nRecall\n\n\n\n\\(Y_i\\): Response variable of the \\(i\\)th subject\n\\(X_i\\): Independent variable for the \\(i\\)th subject\n\\(\\pi\\left(X_i\\right)=\\Pr{\\left(Y_i=1\\middle|\\ X_i\\right)}\\)\n\\(1-\\pi\\left(X_i\\right)=\\Pr(Y_i=0|X_i)\\)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#find-mles-that-maximize-log-likelihood",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#find-mles-that-maximize-log-likelihood",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "4. Find MLEs that maximize log-likelihood",
    "text": "4. Find MLEs that maximize log-likelihood\n\nTo find \\(\\beta_0\\) and \\(\\beta_1\\) that maximizes \\(L\\left(\\beta_0,\\beta_1\\right)\\):\n\nWe differentiate \\(L\\left(\\beta_0,\\beta_1\\right)\\) with respect to \\(\\beta_0\\) and \\(\\beta_1\\)…\nAnd set the resulting expression to zero\n\n \nSuch equations are called likelihood equations.\n\n\\(\\sum\\left[Y_i-\\pi\\left(X_i\\right)\\right]=0\\)\n\\(\\sum\\ X_i\\left[Y_i-\\pi\\left(X_i\\right)\\right]=0\\)\n\n \nIn logistic regression, there is no “closed form” solution to the above equations\nNeed to use iterative algorithm, such as iteratively reweighted least squares (IRLS) algorithm, should be used to find the MLEs for logistic regression"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-do-this-in-r",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-do-this-in-r",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do we do this in R?",
    "text": "How do we do this in R?\n\nglm() function automatically does MLE for you\nYou can explore other algorithms (other than IWLS) to maximize the likelihood\n\nPretty good Cross Validated post on algorithms in glm()"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#can-we-apply-ols-to-our-binary-outcome",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#can-we-apply-ols-to-our-binary-outcome",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Can we apply OLS to our binary outcome?",
    "text": "Can we apply OLS to our binary outcome?\n\nLet’s see if we can apply OLS/linear regression to our binary outcome\nWhat assumptions do our data need to meet in order to use OLR?\nLet’s review OLR assumptions!"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#review-of-simple-linear-regression-i",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#review-of-simple-linear-regression-i",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Review of simple linear regression (I)",
    "text": "Review of simple linear regression (I)\nThe (population) regression model is denoted by:\n \n\n\\[Y =  \\beta_0 + \\beta_1X + \\epsilon\\]\n\n \nComponents\n\n\n\n\\(Y\\)\nresponse, outcome, dependent variable\n\n\n\\(\\beta_0\\)\nintercept\n\n\n\\(\\beta_1\\)\nslope\n\n\n\\(X\\)\npredictor, covariate, independent variable\n\n\n\\(\\epsilon\\)\nresiduals, error term"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#review-of-simple-linear-regression-12",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#review-of-simple-linear-regression-12",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Review of simple linear regression (1/2)",
    "text": "Review of simple linear regression (1/2)\nThe (population) regression model is denoted by:\n \n\n\\[Y =  \\beta_0 + \\beta_1X + \\epsilon\\]\n\n \nComponents\n\n\n\n\\(Y\\)\nresponse, outcome, dependent variable\n\n\n\\(\\beta_0\\)\nintercept\n\n\n\\(\\beta_1\\)\nslope\n\n\n\\(X\\)\npredictor, covariate, independent variable\n\n\n\\(\\epsilon\\)\nresiduals, error term"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#review-of-simple-linear-regression-22",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#review-of-simple-linear-regression-22",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Review of simple linear regression (2/2)",
    "text": "Review of simple linear regression (2/2)\n\nAssumptions of the linear regression model:\n\nIndependence: observations are independent\nLinearity: linear relationship between \\(E[Y|X]\\) and \\(X\\) \\[E[Y|X] = \\beta_0 + \\beta_1 \\cdot X\\]\nNormality and homoscedasticity assumption for residuals (\\(\\epsilon\\)):\n\nNormality: residuals are normally distributed\nHomoscedasticity (equal variance): Variance of \\(Y\\) given \\(X\\) (\\(\\sigma_{Y|X}^2\\)), is the same for any \\(X\\)\n\n\n\n \n\nWhich assumptions are violated if dependent variable is categorical?\n\nThink in terms of binary dependent variable"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#review-of-simple-linear-regression12",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#review-of-simple-linear-regression12",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Review of simple linear regression(1/2)",
    "text": "Review of simple linear regression(1/2)\nThe (population) regression model is denoted by:\n \n\n\n\n\n\n\\[Y =  \\beta_0 + \\beta_1X + \\epsilon\\]\n\n\n\n\n\n \nComponents\n\n\n\n\\(Y\\)\nresponse, outcome, dependent variable\n\n\n\\(\\beta_0\\)\nintercept\n\n\n\\(\\beta_1\\)\nslope\n\n\n\\(X\\)\npredictor, covariate, independent variable\n\n\n\\(\\epsilon\\)\nresiduals, error term"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#generalized-linear-models-glms-12",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#generalized-linear-models-glms-12",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Generalized Linear Models (GLMs) (1/2)",
    "text": "Generalized Linear Models (GLMs) (1/2)\n\n\n\nGeneralized Linear Models are a class of models that includes regression models for continuous and categorical responses\n\nResponses follow exponential family distribution\nHelps us set up other types of regressions using each outcome’s needed transformations\n\n\n \n\nHere we will focus on the GLMs for categorical/count data\n\nLogistic regression is just a one type of GLM\nPoisson regression – for counts\nLog-binomial can be used to focus on risk ratio"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#generalized-linear-models-glms-22",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#generalized-linear-models-glms-22",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Generalized Linear Models (GLMs) (2/2)",
    "text": "Generalized Linear Models (GLMs) (2/2)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#glm-link-function-1",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#glm-link-function-1",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "GLM: Link Function",
    "text": "GLM: Link Function"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#poll-everywhere-question-4",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#poll-everywhere-question-4",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Poll Everywhere Question 4",
    "text": "Poll Everywhere Question 4"
  },
  {
    "objectID": "homework/HW2.html#purpose",
    "href": "homework/HW2.html#purpose",
    "title": "Homework 2",
    "section": "",
    "text": "This homework is designed to help you practice the following important skills and knowledge that we covered in Lessons 3-6:\n\nCalculate and interpret the estimated risk difference, relative risk, and odds ratios, and their confidence intervals\nExpand work on contingency tables to evaluate the agreement or reproducibility using Cohen’s Kappa\nUnderstand important differences between linear regression and logistic regression\nConstruct a simple logistic regression model\nTest a covariate for significance using the Wald test and LRT"
  },
  {
    "objectID": "weeks/week_08_sched.html",
    "href": "weeks/week_08_sched.html",
    "title": "Week 8",
    "section": "",
    "text": "Room Locations for the week\n\n\n\nOn Wednesday, 5/22, we will be in RPV Room A (1217)"
  },
  {
    "objectID": "weeks/week_11_sched.html",
    "href": "weeks/week_11_sched.html",
    "title": "Week 11",
    "section": "",
    "text": "Room Locations for the week\n\n\n\nIf we meet this week, we will be in RPV Room A (1217)"
  },
  {
    "objectID": "homework/HW3.html#question-2",
    "href": "homework/HW3.html#question-2",
    "title": "Homework 3",
    "section": "Question 2",
    "text": "Question 2\nThis question is adapted from the Hosmer and Lemeshow textbook, page 47. (Note that the parts are sited differently in the textbook.)\nUse the Myopia Study data described in Section 1.6.6 and use MYOPIC as the outcome and as possible variables for a model: AGE, GENDER, family history of myopia (MOMMY and DADMY), number of hours playing sports (SPORTHR) and number of hours watching television (TVHR).\n\nPart a\nWrite down the equation for the logistic regression model of MYOPIC on AGE, GENDER, MOMMY, DADMY, SPORTHR, and TVHR. How many parameters does this model contain?\n\n\nPart b\nUsing glm(), obtain the maximum likelihood estimates of the parameters of the logistic regression model. Using these estimates write down the equation for the fitted values (i.e., the estimated logistic probabilities).\n\n\nPart c\nAssess the significance of the coefficient corresponding to number of hours playing sports. You may use the Wald test or the likelihood ratio test. Please interpret the odds ratio for the coefficient (in this part, you do not need to calculate the confidence interval.)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-transform-our-outcome-12",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-transform-our-outcome-12",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do we transform our outcome? (1/2)",
    "text": "How do we transform our outcome? (1/2)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-transform-our-outcome-22",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-transform-our-outcome-22",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do we transform our outcome? (2/2)",
    "text": "How do we transform our outcome? (2/2)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#translate-the-results-back-to-an-equation",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#translate-the-results-back-to-an-equation",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Translate the results back to an equation!",
    "text": "Translate the results back to an equation!\n\nJust going to pull the coefficients so I have a reference as I create the fitted regression model:\n\n\nsummary(bc_reg)$coefficients\n\n              Estimate Std. Error   z value     Pr(&gt;|z|)\n(Intercept) -0.9894225  0.0232055 -42.63742 0.000000e+00\nAge_c        0.0569645  0.0032039  17.77974 1.014557e-70\n\n\n\nFitted logistic regression model: \\[\\text{logit}(\\pi(Age)) = -0.989 + 0.057 \\cdot Age\\]"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-do-this-in-r-12",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-do-this-in-r-12",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do we do this in R? (1/2)",
    "text": "How do we do this in R? (1/2)\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nsummary(bc_reg)\n\n\nCall:\nglm(formula = Late_stage_diag ~ Age_c, family = binomial, data = bc)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.989422   0.023205  -42.64   &lt;2e-16 ***\nAge_c        0.056965   0.003204   17.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 11861  on 9999  degrees of freedom\nResidual deviance: 11510  on 9998  degrees of freedom\nAIC: 11514\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-do-this-in-r-12-1",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-we-do-this-in-r-12-1",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do we do this in R? (1/2)",
    "text": "How do we do this in R? (1/2)\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nsummary(bc_reg)\n\n\nCall:\nglm(formula = Late_stage_diag ~ Age_c, family = binomial, data = bc)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.989422   0.023205  -42.64   &lt;2e-16 ***\nAge_c        0.056965   0.003204   17.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 11861  on 9999  degrees of freedom\nResidual deviance: 11510  on 9998  degrees of freedom\nAIC: 11514\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#reminder-simple-logistic-regression-model",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#reminder-simple-logistic-regression-model",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Reminder: Simple Logistic Regression Model",
    "text": "Reminder: Simple Logistic Regression Model\nThe (population) regression model is denoted by:\n \n\n\n\n\n\n\\[ \\text{logit} (\\pi) =  \\beta_0 + \\beta_1X\\]\n\n\n\n\n\n \nComponents\n\n\n\n\\(\\pi\\)\nprobability that the outcome occurs (\\(Y=1\\)) given \\(X\\)\n\n\n\\(\\beta_0\\)\nintercept\n\n\n\\(\\beta_1\\)\nslope\n\n\n\\(X\\)\npredictor, covariate, independent variable"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-perform-mle-in-r",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#how-do-perform-mle-in-r",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do perform MLE in R?",
    "text": "How do perform MLE in R?\n\nglm() function automatically does MLE for you\n\nFor logistic regression with a binary outcome, we need to set the family within glm() to “binomial” which will automatically set the logit link\n\nYou can explore other algorithms (other than IRLS) to maximize the likelihood\n\nPretty good Cross Validated post on algorithms in glm()"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-breast-cancer-diagnosis-12",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-breast-cancer-diagnosis-12",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Example: Breast cancer diagnosis (1/2)",
    "text": "Example: Breast cancer diagnosis (1/2)\n\nLet’s start with simple logistic regression with late stage breast cancer diagnosis as the outcome and age as our independent variable\nWe want to fit: \\[\\text{logit}(\\pi(Age)) = \\beta_0 + \\beta_1 \\cdot Age\\]\n\nDon’t forget: \\(\\pi(Age) = P(Y=1 | Age) = P(\\text{Late stage BC diagnosis}| Age)\\)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-breast-cancer-diagnosis-13",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-breast-cancer-diagnosis-13",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Example: Breast cancer diagnosis (1/3)",
    "text": "Example: Breast cancer diagnosis (1/3)\n\nLet’s start with simple logistic regression with late stage breast cancer diagnosis as the outcome and age as our independent variable\n\n \n\nWe want to fit: \\[\\text{logit}(\\pi(Age)) = \\beta_0 + \\beta_1 \\cdot Age\\]\n\nDon’t forget: \\(\\pi(Age) = P(Y=1 | Age) = P(\\text{Late stage BC diagnosis}| Age)\\)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-breast-cancer-diagnosis-23",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-breast-cancer-diagnosis-23",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Example: Breast cancer diagnosis (2/3)",
    "text": "Example: Breast cancer diagnosis (2/3)\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nsummary(bc_reg)\n\n\nCall:\nglm(formula = Late_stage_diag ~ Age_c, family = binomial, data = bc)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.989422   0.023205  -42.64   &lt;2e-16 ***\nAge_c        0.056965   0.003204   17.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 11861  on 9999  degrees of freedom\nResidual deviance: 11510  on 9998  degrees of freedom\nAIC: 11514\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-breast-cancer-diagnosis-33",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-breast-cancer-diagnosis-33",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Example: Breast cancer diagnosis (3/3)",
    "text": "Example: Breast cancer diagnosis (3/3)\n\nTranslate the results back to an equation!\nJust going to pull the coefficients so I have a reference as I create the fitted regression model:\n\n\n\n\nsummary(bc_reg)$coefficients\n\n              Estimate Std. Error   z value     Pr(&gt;|z|)\n(Intercept) -0.9894225  0.0232055 -42.63742 0.000000e+00\nAge_c        0.0569645  0.0032039  17.77974 1.014557e-70\n\n\n\nFitted logistic regression model: \\[\\text{logit}(\\widehat{\\pi}(Age)) = -0.989 + 0.057 \\cdot Age\\]\n\nWe will need to reverse the transformation process in slide 24-25 to find the odds ratios"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#slide-transform",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#slide-transform",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "How do we transform our outcome? (1/2)",
    "text": "How do we transform our outcome? (1/2)"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-breast-cancer-diagnosis-33-1",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#example-breast-cancer-diagnosis-33-1",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Example: Breast cancer diagnosis (3/3)",
    "text": "Example: Breast cancer diagnosis (3/3)\n\nTranslate the results back to an equation!\nJust going to pull the coefficients so I have a reference as I create the fitted regression model:\n\n\n\n\nsummary(bc_reg)$coefficients\n\n              Estimate Std. Error   z value     Pr(&gt;|z|)\n(Intercept) -0.9894225  0.0232055 -42.63742 0.000000e+00\nAge_c        0.0569645  0.0032039  17.77974 1.014557e-70\n\n\n\nFitted logistic regression model: \\[\\text{logit}(\\widehat{\\pi}(Age)) = -0.989 + 0.057 \\cdot Age\\]\n\nWe will need to reverse the transformation process in slide 24-25 to find the odds ratios\n\nWill do in next week’s lessons\n\n\n\nThis is the fitted line:"
  },
  {
    "objectID": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#reference-individual-components",
    "href": "lectures/05_Simple_logistic_reg/05_Simple_logistic_reg.html#reference-individual-components",
    "title": "Lesson 5: Simple Logistic Regression",
    "section": "Reference: individual components",
    "text": "Reference: individual components"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/Tests_GLMs.html#connection-between-tests-in-linear-models-and-glms",
    "href": "lectures/06_Tests_GLMs/Tests_GLMs.html#connection-between-tests-in-linear-models-and-glms",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Connection between tests in linear models and GLMs",
    "text": "Connection between tests in linear models and GLMs\n\nBecause we used OLS to find the estimate in our linear model class, we could use the following tests:\n\nt-test for single coefficients\nF-test for single coefficients or groups of coefficients\n\nThese tests hinge on the Mean Squared Error (MSE) which we minimized in OLS\n\nThink back to our ANOVA table and how we compared the MSE of one model to another to determine if a covariate explains enough variation of our outcome\n\nIn GLMs, when we use maximum likelihood estimation (MLE), we cannot use t-tests or F-tests\n\nBecause we are now using likelihood to find our estimates (not OLS)\n\nBut we have parallel tests!!\n\nt-test –&gt; Wald test\n\nThese are asymptotically equivalent (as our sample goes to infinity)\n\nF-test –&gt; Likelihood ratio test"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/Tests_GLMs.html#reference-hypothesis-testing-using-confidence-intervals",
    "href": "lectures/06_Tests_GLMs/Tests_GLMs.html#reference-hypothesis-testing-using-confidence-intervals",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Reference: hypothesis testing using confidence intervals",
    "text": "Reference: hypothesis testing using confidence intervals"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/Tests_GLMs.html#tests-and-what-theyre-used-for",
    "href": "lectures/06_Tests_GLMs/Tests_GLMs.html#tests-and-what-theyre-used-for",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Tests and what they’re used for",
    "text": "Tests and what they’re used for\n\n\n\n\n\n\n\n\n\n\nWald test\nScore test\nLRT\n\n\n\n\nUsed for single coefficient\n\n\n\n\n\nCan be used to report confidence interval for a single coefficient\n\n\n\n\n\nConfidence interval reported by R for a single coefficient (and most commonly used)\n\n\n\n\n\nUse for multi-level categorical covariate\n\n\n\n\n\nUsed for comparing two models with different (but nested) covariates\n\n\n\n\n\n\n\n\nLesson 6: Tests for Generalized Linear Models"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/Tests_GLMs.html#series-of-poll-everywhere-questions-to-make-the-following-table",
    "href": "lectures/06_Tests_GLMs/Tests_GLMs.html#series-of-poll-everywhere-questions-to-make-the-following-table",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Series of Poll Everywhere questions to make the following table",
    "text": "Series of Poll Everywhere questions to make the following table"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/Tests_GLMs.html#introduction-to-three-tests-in-glm",
    "href": "lectures/06_Tests_GLMs/Tests_GLMs.html#introduction-to-three-tests-in-glm",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Introduction to three tests in GLM",
    "text": "Introduction to three tests in GLM\n\nTo introduce these three tests, we will work on the hypothesis test for a single coefficient\n\nTo be clear: the Likelihood ratio test can be extended to more coefficients\n\nLet’s say we fit a GLM using MLE\n\nWe will continue to use logistic regression as our working example\n\nNow we want to test the significant of a coefficient:\nHypothesis test for an individual coefficient \\(j\\):\n\n\\(H_0: \\beta_j = 0\\)\n\\(H_1: \\beta_j \\neq 0\\)\n\nThree potential tests to use:\n\nWald test\nScore test\nLikelihood ratio test (LRT)"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#connection-between-tests-in-linear-models-and-glms",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#connection-between-tests-in-linear-models-and-glms",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Connection between tests in linear models and GLMs",
    "text": "Connection between tests in linear models and GLMs\n\nIn linear regression, we used ordinary least squares (OLS) to find the best fit model, so we could use the following tests:\n\nt-test for single coefficients\nF-test for single coefficients or groups of coefficients\n\nThese tests hinge on the Mean Squared Error (MSE) which we minimized in OLS and the LINE assumptions\n\n \n\nIn GLMs, when we use maximum likelihood estimation (MLE), we cannot use t-tests or F-tests\n\nBecause we are now using likelihood to find our estimates (not OLS)\n\nBut we have parallel tests in MLE!!\n\nt-test ⟶ Wald test\nF-test ⟶ Likelihood ratio test"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#introduction-to-three-tests-in-glm",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#introduction-to-three-tests-in-glm",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Introduction to three tests in GLM",
    "text": "Introduction to three tests in GLM\n\nTo introduce these three tests, we will work on a single coefficient\n\nTo be clear: the Likelihood ratio test can be extended to more coefficients\n\nLet’s say we fit a GLM using MLE\n\nWe will continue to use logistic regression as our working example\n\n\n \n\nNow we want to run a hypothesis test for an individual coefficient \\(j\\):\n\n\\(H_0: \\beta_j = 0\\)\n\\(H_1: \\beta_j \\neq 0\\)\n\nThree potential tests that we use with a Likelihood function are:\n\nWald test\nScore test\nLikelihood ratio test (LRT)"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#glm-random-component",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#glm-random-component",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "GLM: Random Component",
    "text": "GLM: Random Component"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#reference-hypothesis-testing-using-confidence-intervals",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#reference-hypothesis-testing-using-confidence-intervals",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Reference: hypothesis testing using confidence intervals",
    "text": "Reference: hypothesis testing using confidence intervals\n\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the test statistic and p-value\nWrite a conclusion to the hypothesis test\n\nWhat is the estimate and its confidence interval?\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#series-of-poll-everywhere-questions-to-make-the-following-table",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#series-of-poll-everywhere-questions-to-make-the-following-table",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Series of Poll Everywhere questions to make the following table",
    "text": "Series of Poll Everywhere questions to make the following table"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#tests-and-what-theyre-used-for",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#tests-and-what-theyre-used-for",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Tests and what they’re used for",
    "text": "Tests and what they’re used for\n\n\n\n\n\n\n\n\n\n\nWald test\nScore test\nLRT\n\n\n\n\nUsed to test significance of single coefficient\n\n\n\n\n\nCan be used to report confidence interval for a single coefficient\n\n\n\n\n\nConfidence interval reported by R for a single coefficient (and most commonly used)\n\n\n\n\n\nUse to test significance/contribution to outcome prediction of multi-level categorical covariate\n\n\n\n\n\nUsed for comparing two models with different (but nested) covariates"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Wald test",
    "text": "Wald test\n\nVery similar to a t-test!\n\nBut slightly different because it based in our likelihood function\n\nAssumes test statistic W follows a standard normal distribution under the null hypothesis\nTest statistic: \\[W=\\frac{{\\hat{\\beta}}_1}{se({\\hat{\\beta}}_1)}\\sim N(0,1)\\]\n\nwhere \\(\\widehat{\\beta}_1\\) is a MLE\n\nThe Wald test is a routine output in R (summary() of glm() output)"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#score-test",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#score-test",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Score test",
    "text": "Score test\n\nScore test does not require the computation of MLE for \\(\\beta_1\\), while both likelihood test and Wald test does\n\nOnly need to know \\(\\beta_1\\) under the null\n\nScore test is based on the first and second derivatives of the log-likelihood under the null hypothesis: \\[S=\\frac{\\sum_{i=1}^{n}{x_i(y_i-\\bar{y})}}{\\sqrt{\\bar{y}(1-\\bar{y})\\sum_{i=1}^{n}\\left(x_i-\\bar{x}\\right)^2}} \\sim N(0,1)\\]"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Likelihood ratio test",
    "text": "Likelihood ratio test"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#revisit-the-likelihood-function",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#revisit-the-likelihood-function",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Revisit the likelihood function",
    "text": "Revisit the likelihood function\n\n\n\nLikelihood function: expresses the probability of the observed data as a function of the unknown parameters\n\nFunction that enumerates the likelihood (similar to probability) that we observe the data across the range of potential values of our coefficients\n\nWe often compare likelihoods to see what estimates are more likely given our data\nPlot to right is a simplistic view of likelihood\n\nI have flattened the likelihood that would be a function of \\(\\beta_0\\) and \\(\\beta_1\\) into a 2D plot (instead of 3D: \\(\\beta_0\\) vs. \\(\\beta_1\\) vs. \\(L(\\beta_0, \\beta_1)\\))\n\nI use \\(L\\) to represent the log-likelihood and \\(l\\) to represent the likelihood"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#lets-say-we-want-to-look-at-our-previous-model-with-age-and-late-stage-bc-diagnosis",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#lets-say-we-want-to-look-at-our-previous-model-with-age-and-late-stage-bc-diagnosis",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Let’s say we want to look at our previous model with age and late stage BC diagnosis",
    "text": "Let’s say we want to look at our previous model with age and late stage BC diagnosis\n\nLet’s start with simple logistic regression with late stage breast cancer diagnosis as the outcome and age as our independent variable\nWe want to fit: \\[\\text{logit}(\\pi(Age)) = \\beta_0 + \\beta_1 \\cdot Age\\]\n\nDon’t forget: \\(\\pi(Age) = P(Y=1 | Age) = P(\\text{Late stage BC diagnosis}| Age)\\)\n\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nsummary(bc_reg)\n\n\nCall:\nglm(formula = Late_stage_diag ~ Age_c, family = binomial, data = bc)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.989422   0.023205  -42.64   &lt;2e-16 ***\nAge_c        0.056965   0.003204   17.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 11861  on 9999  degrees of freedom\nResidual deviance: 11510  on 9998  degrees of freedom\nAIC: 11514\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-1",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-1",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Wald test",
    "text": "Wald test"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-2",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-2",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Wald test",
    "text": "Wald test"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-1",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-1",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Poll Everywhere Question 1",
    "text": "Poll Everywhere Question 1"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-in-r",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-in-r",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Wald test in R",
    "text": "Wald test in R\n\nlibrary(epiDisplay)\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nsummary(bc_reg)\n\n\nCall:\nglm(formula = Late_stage_diag ~ Age_c, family = binomial, data = bc)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.989422   0.023205  -42.64   &lt;2e-16 ***\nAge_c        0.056965   0.003204   17.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 11861  on 9999  degrees of freedom\nResidual deviance: 11510  on 9998  degrees of freedom\nAIC: 11514\n\nNumber of Fisher Scoring iterations: 4\n\ntidy(bc_reg, conf.int=T) %&gt;% gt() %&gt;% tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n−0.989\n0.023\n−42.637\n0.000\n−1.035\n−0.944\n    Age_c\n0.057\n0.003\n17.780\n0.000\n0.051\n0.063"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#score-test-1",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#score-test-1",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Score test",
    "text": "Score test"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-1",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-1",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Likelihood ratio test",
    "text": "Likelihood ratio test\n\nTo assess the significance of the covariate’s coefficient in the simple logistic regression, we compare the deviance (D) with and without the covariate \\[G=D\\left(\\text{model without } x\\right)-D\\left(\\text{model with } x\\right)\\]\nFor a continuous or binary variable, this is equivalent to test: \\(H_0: \\beta_j = 0\\) vs. \\(H_1: \\beta_j \\neq 0\\)\nTest statistic for LRT: \\[G=-2ln\\left[\\frac{\\text{likelihood without } x}{\\text{likelihood with } x}\\right]=2ln\\left[\\frac{l\\left({\\hat{\\beta}}_0,{\\hat{\\beta}}_1\\right)}{l({\\hat{\\beta}}_0)}\\right]\\]"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-2",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-2",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Likelihood ratio test",
    "text": "Likelihood ratio test\n\nTo assess the significance of the covariate’s coefficient in the simple logistic regression, we compare the deviance (D) with and without the covariate \\[G=D\\left(\\text{model without } x\\right)-D\\left(\\text{model with } x\\right)\\]\nFor a continuous or binary variable, this is equivalent to test: \\(H_0: \\beta_j = 0\\) vs. \\(H_1: \\beta_j \\neq 0\\)\nTest statistic for LRT: \\[G=-2ln\\left[\\frac{\\text{likelihood without } x}{\\text{likelihood with } x}\\right]=2ln\\left[\\frac{l\\left({\\hat{\\beta}}_0,{\\hat{\\beta}}_1\\right)}{l({\\hat{\\beta}}_0)}\\right]\\]"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-3",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-3",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Likelihood ratio test",
    "text": "Likelihood ratio test"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-4",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-4",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Likelihood ratio test",
    "text": "Likelihood ratio test"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-5",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-5",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Likelihood ratio test",
    "text": "Likelihood ratio test"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#lrt-what-is-deviance",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#lrt-what-is-deviance",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "LRT: what is Deviance?",
    "text": "LRT: what is Deviance?\n\nDeviance: quantifies the difference in likelihoods between a fitted and saturated model\n\nFitted model:\n\nYour proposed fitted model\n\nSaturated model:\n\nA model that contains as many parameters as there are data points = perfect fit\n\nBasically every individual has their own covariate\n\nPerfect fit = maximum possible likelihood\n\n\n\n \n\nAll fitted models will have likelihood less than saturated model"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#lrt-what-is-deviance-1",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#lrt-what-is-deviance-1",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "LRT: what is Deviance?",
    "text": "LRT: what is Deviance?\n\nThe deviance is mathematically defined as: \\[D=-2[L_{\\text{fitted}}-L_{\\text{saturated}}]\\]\nAn alternative way to write it is: \\[D=-2ln\\left[\\frac{\\text{likelihood of the fitted model}}{\\text{likelihood of the saturated model}}\\right]\\]\nUsing ‘-2’ is to make the deviance follow a chi-square distribution"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#deviance-to-likelihood-ratio-test",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#deviance-to-likelihood-ratio-test",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Deviance to Likelihood Ratio Test",
    "text": "Deviance to Likelihood Ratio Test\n\nIn the LRT, we are NOT comparing the likelihood of saturated model to the fitted model\n\n \n\nWe ARE comparing the Deviance of the model with x and the model without x\n\nWe just use the saturated model to calculate Deviance\nBoth are considered fitted models with their own respective Deviance\n\n\n \n\nSo our LRT is: \\[G=D\\left(\\text{model without } x\\right)-D\\left(\\text{model with } x\\right)\\]"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#for-reference",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#for-reference",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "For reference",
    "text": "For reference\n\\[ \\begin{aligned}\nG&=D\\left(\\text{model without } x\\right)-D\\left(\\text{model with }x\\right) \\\\\nG&=-2ln\\left[\\frac{\\text{likelihood of model without } x}{\\text{likelihood of saturated model}}\\right]-\\left(-2ln\\left[\\frac{\\text{likelihood of model with } x}{\\text{likelihood of saturated model}}\\right]\\right) \\\\\nG&=-2ln\\left[\\frac{\\text{likelihood of model without } x}{\\text{likelihood of saturated model}}\\times\\frac{\\text{likelihood of saturated model}}{\\text{likelihood of model with } x}\\right] \\\\\nG&=-2ln\\left[\\frac{\\text{likelihood of model without } x}{\\text{likelihood of model with }}\\right] \\\\\nG&=2ln\\left[\\frac{l\\left({\\hat{\\beta}}_0,{\\hat{\\beta}}_1\\right)}{l({\\hat{\\beta}}_0)}\\right]\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-4",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-4",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Poll Everywhere Question 4",
    "text": "Poll Everywhere Question 4"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#lrt-in-r",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#lrt-in-r",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "LRT in R",
    "text": "LRT in R\n\nlibrary(lmtest)\nbc_age = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nbc_int = glm(Late_stage_diag ~ 1, data = bc, family = binomial)\nlmtest::lrtest(bc_age, bc_int)\n\nLikelihood ratio test\n\nModel 1: Late_stage_diag ~ Age_c\nModel 2: Late_stage_diag ~ 1\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   2 -5754.8                         \n2   1 -5930.5 -1 351.27  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#all-three-tests-together",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#all-three-tests-together",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "All three tests together",
    "text": "All three tests together\n\nUCLA FAQ on Tests"
  },
  {
    "objectID": "quizzes.html",
    "href": "quizzes.html",
    "title": "Quizzes",
    "section": "",
    "text": "Quiz\nAnswer key\n\n\n\n\n1\n\n\n\n2\n\n\n\n3\n\n\n\n\n\nQuiz Instructions\n\nI have written a “30 minute” quiz, but there is no time limit. You will have from Monday at 2pm to Wednesday at 1pm to finish the quiz. The quiz will be administered through Sakai under “Tests & Quizzes.”\nThe quiz is open book and open notes. You may use books other than the class textbook, you may use anything on our course webpage, and you may use reference websites (like Wikipedia, Googling expected value of specific distribution, etc.).\nNo cheating will be tolerated. Cheating includes:\n\nUsing ChatGPT\nUsing question and answer threads typically seen on sites like StackExchange, WikiHow, Quora, Reddit, StackOverflow, Chegg, etc.\nAsking other students in the room or looking at other students’ quiz work.\n\nEach multiple choice question is worth 3 points. The free response questions are labelled with their point value.\nIf taking the quiz in class, you may use headphones.\n\n\n\nQuiz 1 Information\n\nWill cover the learning objectives in Lesson 1-4, with more emphasis on the new material presented in Lessons 3-4\n\nFrom Lesson 2 there will be a question about the Normal approximation of the binomial distribution and a question about which test to use for a set of variables"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#which-test-to-use",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#which-test-to-use",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Which test to use?",
    "text": "Which test to use?\n\nAll three tests are asymptotically equivalent\n\nAs sample approaches infinity\n\nFor testing significance of single covariate coefficient:\n\nLRT\n\nWald and score are only approximations of LRT\nFor smaller samples, LRT better\n\nWald test is very convenient\n\nAutomatically performed in R\nDoes not need to estimate two models (LRT does)\nGood for constructing confidence intervals of coefficients and odds ratios\n\nScore test\n\nDoes not need to estimate two models (LRT does)\nI don’t really see people use this…"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#revisit-our-previous-model-with-late-stage-bc-diagnosis-and-age",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#revisit-our-previous-model-with-late-stage-bc-diagnosis-and-age",
    "title": "Lesson 6: Tests for Generalized Linear Models",
    "section": "Revisit our previous model with late stage BC diagnosis and age",
    "text": "Revisit our previous model with late stage BC diagnosis and age\n\nSimple logistic regression with late stage breast cancer diagnosis as outcome and age as independent variable\n\n\n\n\\[\\text{logit}(\\pi(Age)) = \\beta_0 + \\beta_1 \\cdot Age\\]\n\nDon’t forget: \\(\\pi(Age) = P(Y=1 | Age)\\)\n\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nsummary(bc_reg)\n\n\nCall:\nglm(formula = Late_stage_diag ~ Age_c, family = binomial, data = bc)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.989422   0.023205  -42.64   &lt;2e-16 ***\nAge_c        0.056965   0.003204   17.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 11861  on 9999  degrees of freedom\nResidual deviance: 11510  on 9998  degrees of freedom\nAIC: 11514\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#revisit-previous-model-with-late-stage-bc-diagnosis-and-age",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#revisit-previous-model-with-late-stage-bc-diagnosis-and-age",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Revisit previous model with late stage BC diagnosis and age",
    "text": "Revisit previous model with late stage BC diagnosis and age\n\n\n\nSimple logistic regression model: \\[\\text{logit}(\\pi(Age)) = \\beta_0 + \\beta_1 \\cdot Age\\]\n\n\n \nDon’t forget: \\(\\pi(Age) = P(Y=1 | Age)\\)\n\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nsummary(bc_reg)\n\n\nCall:\nglm(formula = Late_stage_diag ~ Age_c, family = binomial, data = bc)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.989422   0.023205  -42.64   &lt;2e-16 ***\nAge_c        0.056965   0.003204   17.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 11861  on 9999  degrees of freedom\nResidual deviance: 11510  on 9998  degrees of freedom\nAIC: 11514\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-13",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-13",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Wald test (1/3)",
    "text": "Wald test (1/3)\n\nVery similar to a t-test!\n\nBut slightly different because it based in our likelihood function\n\nAssumes test statistic W follows a standard normal distribution under the null hypothesis\nTest statistic: \\[W=\\frac{{\\hat{\\beta}}_j}{se({\\hat{\\beta}}_j)}\\sim N(0,1)\\]\n\nwhere \\(\\widehat{\\beta}_j\\) is a MLE of coefficient \\(j\\)\n\n95% Wald confidence interval: \\[{\\hat{\\beta}}_1\\pm1.96 \\cdot SE_{{\\hat{\\beta}}_j}\\]\nThe Wald test is a routine output in R (summary() of glm() output)\n\nIncludes \\(SE_{{\\hat{\\beta}}_j}\\) and can easily find confidence interval with tidy()"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-23",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-23",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Wald test (2/3)",
    "text": "Wald test (2/3)"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-33",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-33",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Wald test (3/3)",
    "text": "Wald test (3/3)"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-procedure-with-confidence-intervals",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#wald-test-procedure-with-confidence-intervals",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Wald test procedure with confidence intervals",
    "text": "Wald test procedure with confidence intervals\n\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the confidence interval and determine if it overlaps with null\n\nOverlap with null (usually 0 for coefficient) = fail to reject null\nNo overlap with null (usually 0 for coefficient) = reject null\n\nWrite a conclusion to the hypothesis test\n\nWhat is the estimate and its confidence interval?\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#ive-never-explicitly-said-this",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#ive-never-explicitly-said-this",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "I’ve never explicitly said this…",
    "text": "I’ve never explicitly said this…\n\nBecause we are in a public health class, we are often analyzing data with sensitive outcomes\n\n \n\nIf you ever need a moment in class because of our topic, feel free to just step out or leave and privately view the lecture\n\n \n\nIf you need extra time on your assignments because you have an emotional response to lectures/homework/lab, just let me know! Extenuating circumstance!"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nWald test for age coefficient\n\n\nInterpret the coefficient for age in our model of late stage breast cancer diagnosis.\n\n\n\n\nNeeded steps:\n\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\nCalculate the confidence interval and determine if it overlaps with null\nWrite a conclusion to the hypothesis test\n\n\n\n\nNote\n\n\nI don’t want us to get fixated on this interpretation. This is more to introduce the process, BUT it’s MUCH better to interpret the coefficient in terms of OR (next class)."
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-1",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-1",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nWald test for age coefficient\n\n\nInterpret the coefficient for age in our model of late stage breast cancer diagnosis.\n\n\n\nSet the level of significance \\(\\alpha\\) \\[\\alpha=0.05\\]\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\n\\[\\begin{aligned}\nH_0 &: \\beta_{Age} = 0 \\\\\nH_1 &: \\beta_{Age} \\neq 0 \\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-2",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-2",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nWald test for age coefficient\n\n\nInterpret the coefficient for age in our model of late stage breast cancer diagnosis.\n\n\n\nCalculate the confidence interval and determine if it overlaps with null\n\n\nlibrary(epiDisplay)\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\ntidy(bc_reg, conf.int=T) %&gt;% gt() %&gt;% tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n−0.989\n0.023\n−42.637\n0.000\n−1.035\n−0.944\n    Age_c\n0.057\n0.003\n17.780\n0.000\n0.051\n0.063"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-3",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-3",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nWald test for age coefficient\n\n\nInterpret the coefficient for age in our model of late stage breast cancer diagnosis.\n\n\n\n\n\nWrite a conclusion to the hypothesis test\n\nFor every one year increase in age, the log-odds of late stage breast cancer diagnosis increases 0.057 (95% CI: 0.051, 0.063).\nThere is sufficient evidence that age an breast cancer diagnosis are associated.\n\n\n\nNote\n\n\nI don’t want us to get fixated on this interpretation. This is more to introduce the process, BUT it’s MUCH better to interpret the coefficient in terms of OR (next class)."
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-4",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-4",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nLRT\n\n\nDetermine if the model including age is more likely than model without age. Aka: Is age associated with late stage breast cancer diagnosis?\n\n\nNeeded steps:\n\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\nCalculate the test statistic and p-value\nWrite a conclusion to the hypothesis test"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-13",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-13",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Likelihood ratio test (1/3)",
    "text": "Likelihood ratio test (1/3)\n\nLikelihood ratio test answers the question:\n\nFor a specific covariate, which model tell us more about the outcome variable: the model including the covariate or the model omitting the covariate?\nAka: Which model is more likely given our data: model including the covariate or the model omitting the covariate?\n\n\n \n\nTest a single coefficient by comparing different models\n\nVery similar to the F-test\n\n\n \n\nImportant: LRT can be used conduct hypothesis tests for multiple coefficients\n\nJust like F-test, we can test a single coefficient, continuous/binary covariate, multi-level covariate, or multiple covariates"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-23",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-23",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Likelihood ratio test (2/3)",
    "text": "Likelihood ratio test (2/3)\n\nTo assess the significance of a continuous/binary covariate’s coefficient in the simple logistic regression, we compare the deviance (D) with and without the covariate \\[G=D\\left(\\text{model without } x\\right)-D\\left(\\text{model with } x\\right)\\]\n\n \n\nFor a continuous or binary variable, this is equivalent to test: \\(H_0: \\beta_j = 0\\) vs. \\(H_1: \\beta_j \\neq 0\\)\nTest statistic for LRT: \\[G=-2ln\\left[\\frac{\\text{likelihood without } x}{\\text{likelihood with } x}\\right]=2ln\\left[\\frac{l\\left({\\hat{\\beta}}_0,{\\hat{\\beta}}_1\\right)}{l({\\hat{\\beta}}_0)}\\right]\\]"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-23-1",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-23-1",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Likelihood ratio test (2/3)",
    "text": "Likelihood ratio test (2/3)\n\nTo assess the significance of a continuous/binary covariate’s coefficient in the simple logistic regression, we compare the deviance (D) with and without the covariate \\[G=D\\left(\\text{model without } x\\right)-D\\left(\\text{model with } x\\right)\\]\n\n \n\nFor a continuous or binary variable, this is equivalent to test: \\(H_0: \\beta_j = 0\\) vs. \\(H_1: \\beta_j \\neq 0\\)\nTest statistic for LRT: \\[G=-2ln\\left[\\frac{\\text{likelihood without } x}{\\text{likelihood with } x}\\right]=2ln\\left[\\frac{l\\left({\\hat{\\beta}}_0,{\\hat{\\beta}}_1\\right)}{l({\\hat{\\beta}}_0)}\\right]\\]"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-23-2",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-23-2",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Likelihood ratio test (2/3)",
    "text": "Likelihood ratio test (2/3)\n\nTo assess the significance of a continuous/binary covariate’s coefficient in the simple logistic regression, we compare the deviance (D) with and without the covariate \\[G=D\\left(\\text{model without } x\\right)-D\\left(\\text{model with } x\\right)\\]\n\n \n\nFor a continuous or binary variable, this is equivalent to test: \\(H_0: \\beta_j = 0\\) vs. \\(H_1: \\beta_j \\neq 0\\)\nTest statistic for LRT: \\[G=-2ln\\left[\\frac{\\text{likelihood without } x}{\\text{likelihood with } x}\\right]=2ln\\left[\\frac{l\\left({\\hat{\\beta}}_0,{\\hat{\\beta}}_1\\right)}{l({\\hat{\\beta}}_0)}\\right]\\]"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-33",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#likelihood-ratio-test-33",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Likelihood ratio test (3/3)",
    "text": "Likelihood ratio test (3/3)\n\nUnder the null hypothesis, with adequate sample size, LRT statistic follows a chi-square distribution: \\[G \\sim \\chi^2(df)\\]\n\n\\(df = (\\# \\text{coefficients in larger model}) − (\\# \\text{coefficients in smaller model})\\)\n\n\n \n\nIf we are testing a single coefficient, like age, then \\(df=1\\)"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#lrt-procedure",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#lrt-procedure",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "LRT procedure",
    "text": "LRT procedure\n\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the test statistic and p-value\nWrite a conclusion to the hypothesis test\n\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-5",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-5",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nLRT\n\n\nDetermine if the model including age is more likely than model without age. Aka: Is age associated with late stage breast cancer diagnosis?\n\n\n\nSet the level of significance \\(\\alpha\\) \\[\\alpha=0.05\\]\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\n\\[\\begin{aligned}\nH_0 &: \\beta_{Age} = 0 \\\\\nH_1 &: \\beta_{Age} \\neq 0 \\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-6",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-6",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nLRT\n\n\nDetermine if the model including age is more likely than model without age. Aka: Is age associated with late stage breast cancer diagnosis?\n\n\n\nCalculate the test statistic and p-value\n\n\nlibrary(lmtest)\nbc_age = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nbc_int = glm(Late_stage_diag ~ 1, data = bc, family = binomial)\nlmtest::lrtest(bc_age, bc_int)\n\nLikelihood ratio test\n\nModel 1: Late_stage_diag ~ Age_c\nModel 2: Late_stage_diag ~ 1\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   2 -5754.8                         \n2   1 -5930.5 -1 351.27  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-7",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#example-bc-diagnosis-and-age-7",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nLRT\n\n\nDetermine if the model including age is more likely than model without age. Aka: Is age associated with late stage breast cancer diagnosis?\n\n\n\nWrite a conclusion to the hypothesis test\n\nWe reject the null hypothesis that the coefficient corresponding to age is 0 (\\(p-value &lt;&lt; 0.05\\)). There is sufficient evidence that there is an association between age and late stage breast cancer diagnosis."
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#so-how-would-the-wald-test-and-lrt-show-up-in-research",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#so-how-would-the-wald-test-and-lrt-show-up-in-research",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "So how would the Wald test and LRT show up in research?",
    "text": "So how would the Wald test and LRT show up in research?\n\nWald test\n\nOften used when reporting estimates\nGenerally presented using a forest plot or table of ORs or RRs\n\nThen we highlight the specific variable of interest in text\nWill include the OR/RR estimate (not the coefficient like we saw today) with the 95% CI and proper interpretation of result\n\n\n\n \n\nLRT\n\nOften when performing model selection and comparing two models\n\nReporting model selection Cross Validated post\n\nOften does not show up explicitly in our reports, but is essential to get to our final model!!\n\n\n\n\nLesson 6: Tests for GLMs using Likelihood function"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-2",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-2",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Poll Everywhere Question 2",
    "text": "Poll Everywhere Question 2"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-3",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-3",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Poll Everywhere Question 3",
    "text": "Poll Everywhere Question 3"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-5",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-5",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Poll Everywhere Question 5",
    "text": "Poll Everywhere Question 5"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-6",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-6",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Poll Everywhere Question 6",
    "text": "Poll Everywhere Question 6"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-7",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-7",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Poll Everywhere Question 7",
    "text": "Poll Everywhere Question 7"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-8",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#poll-everywhere-question-8",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Poll Everywhere Question 8",
    "text": "Poll Everywhere Question 8"
  },
  {
    "objectID": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#tests-and-what-theyre-used-for-filled",
    "href": "lectures/06_Tests_GLMs/06_Tests_GLMs.html#tests-and-what-theyre-used-for-filled",
    "title": "Lesson 6: Tests for GLMs using Likelihood function",
    "section": "Tests and what they’re used for (filled)",
    "text": "Tests and what they’re used for (filled)\n\n\n\n\n\n\n\n\n\n\nWald test\nScore test\nLRT\n\n\n\n\nUsed to test significance of single coefficient\n\n\n\n\n\nCan be used to report confidence interval for a single coefficient\n\n\n\n\n\nConfidence interval reported by R for a single coefficient (and most commonly used)\n\n\n\n\n\nUse to test significance/contribution to outcome prediction of multi-level categorical covariate\n\n\n\n\n\nUsed for comparing two models with different (but nested) covariates"
  },
  {
    "objectID": "project/LastName_FirstInit_Lab_02.html",
    "href": "project/LastName_FirstInit_Lab_02.html",
    "title": "Lab 2",
    "section": "",
    "text": "This is your editing file. Please do not remove anything from this editing file!! You will only add your code and work to this file.\n\n\nThe purpose of this lab is to explore our data further, set up the unadjusted odds ratio, and create code to later help us present our final model.\n\n\n\nThis lab is graded out of 12 points. The TAs will go through and grade your lab. They will make sure each section is complete and will follow the rubric below. I have instructed them that completion and clear effort is all that is needed to receive 100%. Nicky will go through the labs to give you feedback."
  },
  {
    "objectID": "project/LastName_FirstInit_Lab_02.html#directions",
    "href": "project/LastName_FirstInit_Lab_02.html#directions",
    "title": "Lab 2",
    "section": "",
    "text": "This is your editing file. Please do not remove anything from this editing file!! You will only add your code and work to this file.\n\n\nThe purpose of this lab is to explore our data further, set up the unadjusted odds ratio, and create code to later help us present our final model.\n\n\n\nThis lab is graded out of 12 points. The TAs will go through and grade your lab. They will make sure each section is complete and will follow the rubric below. I have instructed them that completion and clear effort is all that is needed to receive 100%. Nicky will go through the labs to give you feedback."
  },
  {
    "objectID": "project/LastName_FirstInit_Lab_02.html#lab-activities",
    "href": "project/LastName_FirstInit_Lab_02.html#lab-activities",
    "title": "Lab 2",
    "section": "2 Lab activities",
    "text": "2 Lab activities\n\n\n\n\n\n\nNote\n\n\n\nI have left it up to you to load the needed packages for this lab.\n\n\n\n2.1 Restate research question\n\n\n\n\n\n\nTask\n\n\n\nPlease restate your research question below using the provided format (1 sentence). You can change the wording if you’d like, but please make sure it is still clear. It’s repetitive, but it helps me contextualize my feedback as I look through your lab.\n\n\nIn this study, we will investigate the association between food insecurity and ________.\n\n\n2.2 Make sure variables are coded correctly\n\n\n\n\n\n\nTask\n\n\n\n\nUse class() to determine the class of each of the 11 variables you selected from Lab 1 (including the outcome).\nChange the variable type to the appropriate type.\n\n\n\n\n\n2.3 Consider potential confounders and effect modifiers\n\n\n\n\n\n\nTask\n\n\n\nFill in the below table (or any other way you wish to present the same information).\n\n\n\n\n\n\n\n\n\n\nVariable name\nConfounder, Effect modifier, or nothing?\nReasoning (1-2 sentences)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4 Create contingency tables for categorical predictors\n\n\n\n\n\n\nTask\n\n\n\n\nCreate contingency tables for all categorical covariates with food insecurity.\nTake note of any cell counts that are less than 10\n\n\n\n\n\n2.5 Bivariate exploratory data analysis\n\n\n\n\n\n\nTask\n\n\n\n\nUse ggpairs() (introduced in BSTA 512 Lesson 13) to quickly look at the relationship between variables.\nList predictors with which there is a clear trend with food insecurity.\n\n\n\n\n\n2.6 Fit simple logistic regression\n\n\n\n\n\n\nTask\n\n\n\n\nUsing glm(), run a logistic regression with food insecurity and your main variable of interest.\nDisplay the unadjusted odds ratio of the regression. You can use logistic.display()\nInterpret the unadjusted odds ratio (with 95% confidence interval). If you’re main variable is multi-level, then you will need to interpret multiple odds ratios.\n\n\n\n\n\n2.7 Plot the predicted probability\n\n\n\n\n\n\nTask\n\n\n\nPlot or make a table of your predicted probabilities."
  },
  {
    "objectID": "project/Project_report_instructions.html",
    "href": "project/Project_report_instructions.html",
    "title": "Project Report Instructions",
    "section": "",
    "text": "Project template\n\n\n\nYou may use this project template to get started on the report. It is your responsibility to meet the formatting guidelines below!!\nDO NOT USE SITE PAGE (“Project Report Instructions”, current page) as your template!!\n\n\n\n\nProject reports serve as a great way to communicate the knowledge learned in a statistics class and connect it to context within research. It is important that we can take a step back from the numbers and analysis to see what questions linear regression can help us answer.\n\n\n\n\nThe report will be written in Quarto. Turn in both the qmd and html files\n\nNo code should appear in the html document\n\nThis means all R code chunks should have #| echo: false\nThis also means warnings and messages should be turned off\n\n\nThe report should be 10 - 14 paragraphs long\nTables and figures should NOT have variable names as they appear in the data frame\n\nVariable names should be understood by a reader\nVariable names should be written in full words\nInclude a title or caption for all figures\nFigure and tables appear on same page or close to same page where they are first referenced\nTables and figures are an appropriate size in the html - Nicky is able to read all words in figures and tables\n\nWriting, spelling, and grammar should be admissable\n\nThis means I can generally follow your thought/what you are trying to communicate\nSome spelling and grammar mistakes are allowed\n\nI will not take off points if there are a few sprinkled in\nIf every or close to every sentence has mistakes, then I will take off\n\n\nSectioning of the report\n\nMain sections that were required: Introduction, Statistical Methods, Results, Discussion, Conclusion, and References\nOther sections that might help group specific methods or results\n\nTitle information at the top of the html\n\nThis includes the title itself, your name, and the date\n\n\n\n\n\n\n\n\nThe project report is a separate file from the labs\n\n\n\nYou can save tables and figures from labs or separate files, then load them in the report\n\nSave R objects in analyses file:\n\nSuppose you named the Table 1 as table1\nsave(table1, file = \"table1.Rdata\")\n\nLoad R objects in report file: load(file = \"table1.Rdata\")\n\n\n\n\n\n\nThe following are examples of reports from BSTA 513 with the feedback that I gave them.\nPlease note that 513 uses a different type of outcome than our class. These examples are meant to help guide you with the formatting and some appropriate content.\nAlso note that these were converted to PDFs so I could write in feedback. Some of the tables and figure sizes were distorted. They need to be legible in the html.\n\nReport 1 with my feedback\nReport 2 with my feedback\n\nThe above reports have code showing in their html. Remember that I am asking you to hide all code, warnings, and messages.\n\n\n\nThe project report is out of 36 points. Note that the Statistical Methods and Results sections are graded on an 8-point scale, while all other components are graded on a 4-point scale.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\n\n\nFormatting\nLab submitted on Sakai (or by email if late) with .html file. Report is written in complete sentences with very few grammatical or spelling errors. With little editing, the report can be distributed.\nLab submitted on Sakai (or by email if late) with .html file. Report is written in complete sentences with some (around 2 per section) grammatical or spelling errors. With some editing, the report can be distributed.\nLab submitted on Sakai (or by email if late) with .html file. Report is written in complete sentences, but have many grammatical or spelling errors. With major editing, the report can be distributed.\nLab submitted on Sakai (or by email if late) with .html file. Report is written in complete sentences, but are very hard to follow due to grammar mistakes.\nLab not submitted on Sakai (or by email if late) with .html file. Report is not written with complete sentences. With major editing, the report can be distributed.\n\n\nFigures and work\nAll requested output is displayed, including 2 required figures and tables, and at least one additional figure. Figures and tables look professional, are easily interpreted by the reader, and easily convey the intended message.\nAll requested output is displayed, including 2 required figures and tables, and at least one additional figure. For the most part, figures and tables look professional, are easily interpreted by the reader, and easily convey the intended message. A few mistakes in the figures are made.\nAll requested output is displayed, including 2 required figures and tables, and at least one additional figure. Figures and tables look semi-professional, are not so easily interpreted by the reader, and convey the intended message but after some work by the reader. Some mistakes in the figures are made.\nAll requested output is displayed, including 2 required figures and tables, and at least one additional figure. Figures and tables do not look professional, are not easily interpreted by the reader, and/or do not convey the intended message. Many mistakes in the figures are made.\nRequested output is not displayed, Missing one or more figures.\n\n\nIntroduction\nProvides a good background for the research question, includes motivation for the question, and references previous research that justifies this analysis.\nProvides a decent background for the research question and includes motivation for the question. Previous research is mentioned, but feels disconnected to the current analysis.\nProvides a decent background for the research question and includes motivation for the question. Previous research is mentioned, but feels disconnected to the current analysis.\nDoes not provide a background that connects to the research question. Motivation and previous research are not mentioned.\nNo introduction included.\n\n\nMethods (8 points)\nDescribes statistical methods concisely and highlights pertinent information to the reader (listed Sections below). Demonstrates proper analyses were performed.\nDescribes statistical methods and highlights pertinent information to the reader (listed Sections below). Details were omitted or added that were not needed to explain the overarching methods. Demonstrates proper analyses were performed.\nDescribes statistical methods and highlights pertinent information to the reader (listed Sections below). Details were omitted or added that were not needed to explain the overarching methods. Some incorrect analyses included in the description.\nDescribes statistical methods, but lacks clarity. Demonstrates a lack of understanding about the overall process of regression analysis. Incorrect analyses included in the description.\nNo methods included.\n\n\nResults (8 points)\nCorrectly interprets coefficients for the explanatory variable and identifies any other interesting trends. Highlights pertinent results to the reader (listed Sections below).\nCorrectly interprets coefficients, but does correctly incorporate the interaction (if in the model). Highlights pertinent results to the reader (listed Sections below).\nIncorrectly interprets coefficients. Highlights pertinent results to the reader (listed Sections below).\nIncorrectly interprets coefficients.Omits pertinent results to the reader (listed Sections below).\nNo results included.\n\n\nDiscussion\nThoroughly and concisely discusses limitations and considerations of the results, and their consequences.\nDiscusses limitations and considerations of the results and their consequences, but misses some big considerations.\nDiscusses limitations and considerations of the results, but does not discuss the consequences.\nDiscusses limitations and considerations of the results, but misses many considerations and does not discuss consequences.\nNo discussion included.\n\n\nConclusion and References\nFor the conclusion, main research question is answered and statistical caveats described to non-technical person. References are mostly cited consistently within the report, and in the Reference section. This includes the data source!\nFor the conclusion, main research question is answered and statistical caveats described to non-technical person. References are sometimes cited consistently within the report, and in the Reference section. This includes the data source!\nFor the conclusion, main research question is somewhat answered (but focus is not on the research question) and statistical caveats described to non-technical person. References are sometimes cited consistently within the report, and in the Reference section. This includes the data source!\nFor the conclusion, main research question is somewhat answered (but not the focus at all) and statistical caveats are not described. References are not cited consistently within the report, and in the Reference section. This includes the data source!\nFor the conclusion, main research question is not answered. Or references are not included at all.\n\n\n\n\nIn formatting, an example of a report with little editing needed is one that has zero to some grammar or spelling mistakes, no code chunks showing, and no output warnings nor messages showing.\nProfessional figures mean\n\nI can read the words and numbers in the html\n\nVariable names are converted from the data frame version to readable text\nFor example: iam_001 does not show up on axes, instead something like: Response to \"Currently, I am...\"\n\nColors are only used if conveying information\nIntended message of the figure is easily understood\n\nIf you are trying to show a trend of mean IAT vs. an ordered categorical variable, then the variable is ordered on the x-axis\n\n\nFor the references\n\nI will not be overly critical about the formatting\nBy consistency, I mean that you if you are citing things like (Last Name, Year) it doesn’t suddenly change to number citations.\nIf you would like to use Quarto’s citation tool, you can! I actually pair it with Zotero and it works beautifully! (But I would not embark on this if you haven’t used Zotero before)"
  },
  {
    "objectID": "project/Project_report_instructions.html#directions",
    "href": "project/Project_report_instructions.html#directions",
    "title": "Project Report Instructions",
    "section": "",
    "text": "Project template\n\n\n\nYou may use this project template to get started on the report. It is your responsibility to meet the formatting guidelines below!!\nDO NOT USE SITE PAGE (“Project Report Instructions”, current page) as your template!!\n\n\n\n\nProject reports serve as a great way to communicate the knowledge learned in a statistics class and connect it to context within research. It is important that we can take a step back from the numbers and analysis to see what questions linear regression can help us answer.\n\n\n\n\nThe report will be written in Quarto. Turn in both the qmd and html files\n\nNo code should appear in the html document\n\nThis means all R code chunks should have #| echo: false\nThis also means warnings and messages should be turned off\n\n\nThe report should be 10 - 14 paragraphs long\nTables and figures should NOT have variable names as they appear in the data frame\n\nVariable names should be understood by a reader\nVariable names should be written in full words\nInclude a title or caption for all figures\nFigure and tables appear on same page or close to same page where they are first referenced\nTables and figures are an appropriate size in the html - Nicky is able to read all words in figures and tables\n\nWriting, spelling, and grammar should be admissable\n\nThis means I can generally follow your thought/what you are trying to communicate\nSome spelling and grammar mistakes are allowed\n\nI will not take off points if there are a few sprinkled in\nIf every or close to every sentence has mistakes, then I will take off\n\n\nSectioning of the report\n\nMain sections that were required: Introduction, Statistical Methods, Results, Discussion, Conclusion, and References\nOther sections that might help group specific methods or results\n\nTitle information at the top of the html\n\nThis includes the title itself, your name, and the date\n\n\n\n\n\n\n\n\nThe project report is a separate file from the labs\n\n\n\nYou can save tables and figures from labs or separate files, then load them in the report\n\nSave R objects in analyses file:\n\nSuppose you named the Table 1 as table1\nsave(table1, file = \"table1.Rdata\")\n\nLoad R objects in report file: load(file = \"table1.Rdata\")\n\n\n\n\n\n\nThe following are examples of reports from BSTA 513 with the feedback that I gave them.\nPlease note that 513 uses a different type of outcome than our class. These examples are meant to help guide you with the formatting and some appropriate content.\nAlso note that these were converted to PDFs so I could write in feedback. Some of the tables and figure sizes were distorted. They need to be legible in the html.\n\nReport 1 with my feedback\nReport 2 with my feedback\n\nThe above reports have code showing in their html. Remember that I am asking you to hide all code, warnings, and messages.\n\n\n\nThe project report is out of 36 points. Note that the Statistical Methods and Results sections are graded on an 8-point scale, while all other components are graded on a 4-point scale.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\n\n\nFormatting\nLab submitted on Sakai (or by email if late) with .html file. Report is written in complete sentences with very few grammatical or spelling errors. With little editing, the report can be distributed.\nLab submitted on Sakai (or by email if late) with .html file. Report is written in complete sentences with some (around 2 per section) grammatical or spelling errors. With some editing, the report can be distributed.\nLab submitted on Sakai (or by email if late) with .html file. Report is written in complete sentences, but have many grammatical or spelling errors. With major editing, the report can be distributed.\nLab submitted on Sakai (or by email if late) with .html file. Report is written in complete sentences, but are very hard to follow due to grammar mistakes.\nLab not submitted on Sakai (or by email if late) with .html file. Report is not written with complete sentences. With major editing, the report can be distributed.\n\n\nFigures and work\nAll requested output is displayed, including 2 required figures and tables, and at least one additional figure. Figures and tables look professional, are easily interpreted by the reader, and easily convey the intended message.\nAll requested output is displayed, including 2 required figures and tables, and at least one additional figure. For the most part, figures and tables look professional, are easily interpreted by the reader, and easily convey the intended message. A few mistakes in the figures are made.\nAll requested output is displayed, including 2 required figures and tables, and at least one additional figure. Figures and tables look semi-professional, are not so easily interpreted by the reader, and convey the intended message but after some work by the reader. Some mistakes in the figures are made.\nAll requested output is displayed, including 2 required figures and tables, and at least one additional figure. Figures and tables do not look professional, are not easily interpreted by the reader, and/or do not convey the intended message. Many mistakes in the figures are made.\nRequested output is not displayed, Missing one or more figures.\n\n\nIntroduction\nProvides a good background for the research question, includes motivation for the question, and references previous research that justifies this analysis.\nProvides a decent background for the research question and includes motivation for the question. Previous research is mentioned, but feels disconnected to the current analysis.\nProvides a decent background for the research question and includes motivation for the question. Previous research is mentioned, but feels disconnected to the current analysis.\nDoes not provide a background that connects to the research question. Motivation and previous research are not mentioned.\nNo introduction included.\n\n\nMethods (8 points)\nDescribes statistical methods concisely and highlights pertinent information to the reader (listed Sections below). Demonstrates proper analyses were performed.\nDescribes statistical methods and highlights pertinent information to the reader (listed Sections below). Details were omitted or added that were not needed to explain the overarching methods. Demonstrates proper analyses were performed.\nDescribes statistical methods and highlights pertinent information to the reader (listed Sections below). Details were omitted or added that were not needed to explain the overarching methods. Some incorrect analyses included in the description.\nDescribes statistical methods, but lacks clarity. Demonstrates a lack of understanding about the overall process of regression analysis. Incorrect analyses included in the description.\nNo methods included.\n\n\nResults (8 points)\nCorrectly interprets coefficients for the explanatory variable and identifies any other interesting trends. Highlights pertinent results to the reader (listed Sections below).\nCorrectly interprets coefficients, but does correctly incorporate the interaction (if in the model). Highlights pertinent results to the reader (listed Sections below).\nIncorrectly interprets coefficients. Highlights pertinent results to the reader (listed Sections below).\nIncorrectly interprets coefficients.Omits pertinent results to the reader (listed Sections below).\nNo results included.\n\n\nDiscussion\nThoroughly and concisely discusses limitations and considerations of the results, and their consequences.\nDiscusses limitations and considerations of the results and their consequences, but misses some big considerations.\nDiscusses limitations and considerations of the results, but does not discuss the consequences.\nDiscusses limitations and considerations of the results, but misses many considerations and does not discuss consequences.\nNo discussion included.\n\n\nConclusion and References\nFor the conclusion, main research question is answered and statistical caveats described to non-technical person. References are mostly cited consistently within the report, and in the Reference section. This includes the data source!\nFor the conclusion, main research question is answered and statistical caveats described to non-technical person. References are sometimes cited consistently within the report, and in the Reference section. This includes the data source!\nFor the conclusion, main research question is somewhat answered (but focus is not on the research question) and statistical caveats described to non-technical person. References are sometimes cited consistently within the report, and in the Reference section. This includes the data source!\nFor the conclusion, main research question is somewhat answered (but not the focus at all) and statistical caveats are not described. References are not cited consistently within the report, and in the Reference section. This includes the data source!\nFor the conclusion, main research question is not answered. Or references are not included at all.\n\n\n\n\nIn formatting, an example of a report with little editing needed is one that has zero to some grammar or spelling mistakes, no code chunks showing, and no output warnings nor messages showing.\nProfessional figures mean\n\nI can read the words and numbers in the html\n\nVariable names are converted from the data frame version to readable text\nFor example: iam_001 does not show up on axes, instead something like: Response to \"Currently, I am...\"\n\nColors are only used if conveying information\nIntended message of the figure is easily understood\n\nIf you are trying to show a trend of mean IAT vs. an ordered categorical variable, then the variable is ordered on the x-axis\n\n\nFor the references\n\nI will not be overly critical about the formatting\nBy consistency, I mean that you if you are citing things like (Last Name, Year) it doesn’t suddenly change to number citations.\nIf you would like to use Quarto’s citation tool, you can! I actually pair it with Zotero and it works beautifully! (But I would not embark on this if you haven’t used Zotero before)"
  },
  {
    "objectID": "project/Project_report_instructions.html#sections",
    "href": "project/Project_report_instructions.html#sections",
    "title": "Project Report Instructions",
    "section": "2 Sections",
    "text": "2 Sections\n\n2.1 Title\n\nPurpose: Create an identifiable name for your research project that includes the main research question’s variables and gives some context to the analysis or results\n\n\n\n2.2 Introduction\n\nLength: 1-2 paragraphs\nPurpose: Introduce the project motivation, data, and research question. It also includes any background information relevant for understanding the analysis and relevant previous work.\nThis section is non-technical.\n\nBy reading just the introduction, someone without a technical background should have an idea of what they study was about, and why it is important\n\nYou may start with the introduction written in Lab 1, but you should edit it and make sure it flows into your report well!\nShould contain some references\nShould include a sentence that states your research question (but NOT using a question). For example: “This study investigates the association between food insecurity and age.”\n\n\n\n2.3 Statistical Methods\n\nLength: 3-5 paragraphs\nPurpose: Describe the analyses that were conducted and methods used to select variables and check diagnostics\nImportant to keep in mind: methods typically describe your approach and process, not the results of that process\n\nFor example: I might say “We investigated the linearity of each continuous covariate visually. If continuous variables were not linear, then we divided the variable into categories using existing guidelines from &lt;insert reference here&gt; or creating quartiles.”\n\nIn the methods section, I would NOT say: “We investigated the linearity of each continuous covariate visually. We found that age was not linearly related to IAT scores. Thus, we categorized age into the following groups: ___, ____, ____, ____, and ____.”\n\nThe last two sentences about age would be more appropriate in the Results section\n\n\n\nSome important methods to discuss (You may divide these into your sections, not necessarily with these names)\n\nGeneral approach to the dataset\n\n3-5 sentences\nDid you need to do any quality control?\nMissing data: we performed complete case analysis\n\n1 sentence\nCan be included in the Exploratory data analysis section\n\n\nVariables and variable creation\n\nThis includes a description of analyses for Table 1 and what statistics were used to summarize the variables\n\nMore on creation of Table 1, not discussing the results of Table 1\n\nIncludes (not required)\n\nIndicators for gender identity or race\nCreating BMI\nCategorizing a continuous variable (even if performed in model selection)\nUsing scoring for an ordered categorical variable (that is not your explanatory variable)\n\n1-2 sentences per variable\n\nModel building: we performed purposeful selection\n\n3-5 sentences\nIncludes\n\nDescribe purposeful selection: combining existing literature, clinical significance, and analysis\nHow did you build the model? Describe the process in ONE SENTENCE\nDid you consider confounders and effect modifiers?\n\n\nModel diagnostics\n\n2-5 sentences\nIncludes\n\nProcess of investigating model diagnostics\nBy the time you build the model, LINE assumptions should be met\nIf assumptions were not met, what process did you use to fix it?\n\n\n\n\n\n\n2.4 Results\n\nLength: ~3 paragraphs\nPurpose: Relay the results from our sample’s analysis typically focusing on the numbers and interpretations\n\nThe goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions.\nFocus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nSome important results to discuss (also could be sections)\n\nSample data set statistics (Table 1)\n\n3-5 sentences\nInclude a brief description of the sample’s characteristics\nTable 1 should be referenced and appear here!\n\nFinal model\n\n1-2 sentences\nDescribe final model (or models if comparing a few)\n\nWhat variables were included in your final model?\nWhat interactions with your explanatory variable did you include?\n\n\nInterpret the model coefficients in the context of the research question\n\n1-2 paragraphs\nInterpreting the explanatory variable’s relationship with IAT score is the most important thing to report!!\n\nWhen doing this, make sure you account for ALL interactions: If your explanatory variable has multiple interactions and you are trying to interpret one, then what does that mean about the other variables involved in the other interactions? If this is confusing, please make an appointment with me!!\n\n\nResults of model diagnostics if there is anything worth noting\n\nTables & figures\n\nThe following are required tables or figures\n\nTable 1 summarizing participant characteristics both overall and stratified by your primary independent variable\nTable or figure with regression results\n\nCan be a forest plot\nIf you have A LOT of coefficient estimates, the forest plot may not work well!\n\n\n1-3 figures that you think are helpful in understanding the results, for example\n\nDAG explaining connection between variables (if you did this)\nTable or figure to compare model fit statistics (if you did this)\nTable or figure for unadjusted relationship between outcome and explanatory variables\n\n\n\n\n\n2.5 Discussion\n\nLength: 2-3 paragraphs\nPurpose: Discuss the results and give them context outside of the sample and its analysis\nSome important things to include\n\nInclude a paragraph on the limitations of the results\n\nYou don’t need to hit all the limitations, but think about the big ones (generalizability? independence of samples? large sample size vs. clinical significance? the way we handled variables?)\n\nAfter limitations, discuss the positive parts of the results\n\nWhat can we do with these results? What impact can it have?\n\nAny overarching trends that are worth noting? [@Giebel2024]\n\nShould contain some references\n\n\n\n2.6 Reflection\n\n\n2.7 References\n\nInclude your references here!\nYou introduction should have references, especially when discussing the social science behind the analysis\nYou must reference the IAT data source!!"
  },
  {
    "objectID": "project/Lab_02_instructions.html",
    "href": "project/Lab_02_instructions.html",
    "title": "Lab 2 Instructions",
    "section": "",
    "text": "You can download the .qmd file for this lab here.\nThe above link will take you to your editing file. Please do not remove anything from this editing file!! You will only add your code and work to this file.\n\n\nThe purpose of this lab is to explore our data further, set up the unadjusted odds ratio, and create code to later help us present our final model.\n\n\n\nThis lab is graded out of 12 points. The TAs will go through and grade your lab. They will make sure each section is complete and will follow the rubric below. I have instructed them that completion and clear effort is all that is needed to receive 100%. Nicky will go through the labs to give you feedback.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\n\n\nFormatting\nLab submitted on Sakai with .html file. Answers are written in complete sentences with no major grammatical nor spelling errors. With little editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with grammatical or spelling errors. With editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with major grammatical or spelling errors. With major editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are bulletted or do not use complete sentences.\nLab not submitted on Sakai with .html file.\n\n\nCode/Work\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMost tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nSome tasks are directly followed or answered.This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMore than a quarter of the tasks are not completed properly.\n\n\nReasoning*\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful and can be easily integrated into the final report.\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful, but lack the clarity needed to easily integrate into the final report.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers are fairly thoughtful, but lack connection to the research.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers seem rushed and with minimal thought.\nAnswers lack understanding of research context and investigation of the data. Answers seem rushed and without thought.\n\n\n\n*Applies to questions with reasoning"
  },
  {
    "objectID": "project/Lab_02_instructions.html#directions",
    "href": "project/Lab_02_instructions.html#directions",
    "title": "Lab 2 Instructions",
    "section": "",
    "text": "You can download the .qmd file for this lab here.\nThe above link will take you to your editing file. Please do not remove anything from this editing file!! You will only add your code and work to this file.\n\n\nThe purpose of this lab is to explore our data further, set up the unadjusted odds ratio, and create code to later help us present our final model.\n\n\n\nThis lab is graded out of 12 points. The TAs will go through and grade your lab. They will make sure each section is complete and will follow the rubric below. I have instructed them that completion and clear effort is all that is needed to receive 100%. Nicky will go through the labs to give you feedback.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\n\n\nFormatting\nLab submitted on Sakai with .html file. Answers are written in complete sentences with no major grammatical nor spelling errors. With little editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with grammatical or spelling errors. With editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with major grammatical or spelling errors. With major editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are bulletted or do not use complete sentences.\nLab not submitted on Sakai with .html file.\n\n\nCode/Work\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMost tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nSome tasks are directly followed or answered.This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMore than a quarter of the tasks are not completed properly.\n\n\nReasoning*\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful and can be easily integrated into the final report.\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful, but lack the clarity needed to easily integrate into the final report.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers are fairly thoughtful, but lack connection to the research.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers seem rushed and with minimal thought.\nAnswers lack understanding of research context and investigation of the data. Answers seem rushed and without thought.\n\n\n\n*Applies to questions with reasoning"
  },
  {
    "objectID": "project/Lab_02_instructions.html#lab-activities",
    "href": "project/Lab_02_instructions.html#lab-activities",
    "title": "Lab 2 Instructions",
    "section": "2 Lab activities",
    "text": "2 Lab activities\n\n\n\n\n\n\nNote\n\n\n\nI have left it up to you to load the needed packages for this lab.\n\n\n\n2.1 Restate research question\n\n\n\n\n\n\nTask\n\n\n\nPlease restate your research question below using the provided format (1 sentence). You can change the wording if you’d like, but please make sure it is still clear. It’s repetitive, but it helps me contextualize my feedback as I look through your lab.\n\n\nIn this study, we will investigate the association between food insecurity and ________.\n\n\n2.2 Make sure variables are coded correctly\nUse class() to determine the class of each of the 11 variables you selected from Lab 1 (including the outcome). A tidyverse equivalent to the apply() function that we learned last quarter is map(). Please take a look at the description of the map() function.\nMake sure the class that R recognizes is the class that you expect the variable to be. Categorical variables should be factors amd numeric variables should be numeric. It is very important that your outcome, food insecurity, is a factor with the reference level set to “No.” For example, if I am using age, but the class is character, I will need to convert age to a numeric variable. If I have a categorical covariate that is recognized as a character, I should convert it to a factor with a specific reference level.\n\ndf_name %&gt;% map(class)\n\n\n\n\n\n\n\nTask\n\n\n\n\nUse class() to determine the class of each of the 11 variables you selected from Lab 1 (including the outcome).\nChange the variable type to the appropriate type.\n\n\n\n\n\n2.3 Consider potential confounders and effect modifiers\nFor each of the 10 predictor variables, fill out the below table. Determine whether you think each variable will be a confounder, effect modifier, or nothing in relation to your main variable and food insecurity. This does not need to be extensive reasoning. If you would like to present this information in another way, you may.\n\n\n\n\n\n\nTask\n\n\n\nFill in the below table (or any other way you wish to present the same information).\n\n\n\n\n\n\n\n\n\n\nVariable name\nConfounder, Effect modifier, or nothing?\nReasoning (1-2 sentences)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4 Create contingency tables for categorical predictors\nFor each categorical covariate, create a contingency table between it and food insecurity. You can create a data frame with only categorical covariattes, then use lapply() to make a table for each column. Take note of any cells that have less than 10 observations. No need to make these tables pretty.\n\n# You need to replace df_cat_only with your data frame that \n#     only has categorical predictors\nlapply(df_cat_only, function(x) table(df_cat_only$FOOD_INSEC, x))\n\n\n\n\n\n\n\nTask\n\n\n\n\nCreate contingency tables for all categorical covariates with food insecurity.\nTake note of any cell counts that are less than 10\n\n\n\n\n\n2.5 Bivariate exploratory data analysis\nUse ggpairs() (introduced in BSTA 512 Lesson 13) to quickly look at the relationship between variables. If you have trouble seeing or interpreting the individual plots, try recreating them in ggplot().\n\n\n\n\n\n\nTask\n\n\n\n\nUse ggpairs() (introduced in BSTA 512 Lesson 13) to quickly look at the relationship between variables.\nList predictors with which there is a clear trend with food insecurity.\n\n\n\n\n\n2.6 Fit simple logistic regression\n\n\n\n\n\n\nTask\n\n\n\n\nUsing glm(), run a logistic regression with food insecurity and your main variable of interest.\nDisplay the unadjusted odds ratio of the regression. You can use logistic.display()\nInterpret the unadjusted odds ratio (with 95% confidence interval). If you’re main variable is multi-level, then you will need to interpret multiple odds ratios.\n\n\n\n\n\n2.7 Plot the predicted probability\nI want us to plot the predicted probability across our main independent variable. If your main variable of interest (from your research question) is continuous, then you can follow the code from Lesson 7 to construct a plot of the predicted probability. If your main variable of interest in categorical, then you can try plotting the predicted probability in the same way as Lesson 7. You may prefer to present the predicted probabilities for each group as a table.\nThis plot will serve as a good foundation if we have any interactions in the model!\n\n\n\n\n\n\nTask\n\n\n\nPlot or make a table of your predicted probabilities."
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#ive-never-explicitly-said-this",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#ive-never-explicitly-said-this",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "I’ve never explicitly said this…",
    "text": "I’ve never explicitly said this…\n\nBecause we are in a public health class, we are often analyzing data with sensitive outcomes\n\n \n\nIf you ever need a moment in class because of our topic, feel free to just step out or leave and privately view the lecture\n\n \n\nIf you need extra time on your assignments because you have an emotional response to lectures/homework/lab, just let me know! Extenuating circumstance!"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#connection-between-tests-in-linear-models-and-glms",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#connection-between-tests-in-linear-models-and-glms",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Connection between tests in linear models and GLMs",
    "text": "Connection between tests in linear models and GLMs\n\nIn linear regression, we used ordinary least squares (OLS) to find the best fit model, so we could use the following tests:\n\nt-test for single coefficients\nF-test for single coefficients or groups of coefficients\n\nThese tests hinge on the Mean Squared Error (MSE) which we minimized in OLS and the LINE assumptions\n\n \n\nIn GLMs, when we use maximum likelihood estimation (MLE), we cannot use t-tests or F-tests\n\nBecause we are now using likelihood to find our estimates (not OLS)\n\nBut we have parallel tests in MLE!!\n\nt-test ⟶ Wald test\nF-test ⟶ Likelihood ratio test"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#revisit-the-likelihood-function",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#revisit-the-likelihood-function",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Revisit the likelihood function",
    "text": "Revisit the likelihood function\n\n\n\nLikelihood function: expresses the probability of the observed data as a function of the unknown parameters\n\nFunction that enumerates the likelihood (similar to probability) that we observe the data across the range of potential values of our coefficients\n\nWe often compare likelihoods to see what estimates are more likely given our data\nPlot to right is a simplistic view of likelihood\n\nI have flattened the likelihood that would be a function of \\(\\beta_0\\) and \\(\\beta_1\\) into a 2D plot (instead of 3D: \\(\\beta_0\\) vs. \\(\\beta_1\\) vs. \\(L(\\beta_0, \\beta_1)\\))\n\nI use \\(L\\) to represent the log-likelihood and \\(l\\) to represent the likelihood"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#introduction-to-three-tests-in-glm",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#introduction-to-three-tests-in-glm",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Introduction to three tests in GLM",
    "text": "Introduction to three tests in GLM\n\nTo introduce these three tests, we will work on a single coefficient\n\nTo be clear: the Likelihood ratio test can be extended to more coefficients\n\nLet’s say we fit a GLM using MLE\n\nWe will continue to use logistic regression as our working example\n\n\n \n\nNow we want to run a hypothesis test for an individual coefficient \\(j\\):\n\n\\(H_0: \\beta_j = 0\\)\n\\(H_1: \\beta_j \\neq 0\\)\n\nThree potential tests that we use with a Likelihood function are:\n\nWald test\nScore test\nLikelihood ratio test (LRT)"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-1",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-1",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Poll Everywhere Question 1",
    "text": "Poll Everywhere Question 1"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#revisit-previous-model-with-late-stage-bc-diagnosis-and-age",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#revisit-previous-model-with-late-stage-bc-diagnosis-and-age",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Revisit previous model with late stage BC diagnosis and age",
    "text": "Revisit previous model with late stage BC diagnosis and age\n\n\n\nSimple logistic regression model: \\[\\text{logit}(\\pi(Age)) = \\beta_0 + \\beta_1 \\cdot Age\\]\n\n\n \nDon’t forget: \\(\\pi(Age) = P(Y=1 | Age)\\)\n\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nsummary(bc_reg)\n\n\nCall:\nglm(formula = Late_stage_diag ~ Age_c, family = binomial, data = bc)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.989422   0.023205  -42.64   &lt;2e-16 ***\nAge_c        0.056965   0.003204   17.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 11861  on 9999  degrees of freedom\nResidual deviance: 11510  on 9998  degrees of freedom\nAIC: 11514\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#wald-test-13",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#wald-test-13",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Wald test (1/3)",
    "text": "Wald test (1/3)\n\nVery similar to a t-test!\n\nBut slightly different because it based in our likelihood function\n\nAssumes test statistic W follows a standard normal distribution under the null hypothesis\nTest statistic: \\[W=\\frac{{\\hat{\\beta}}_j}{se({\\hat{\\beta}}_j)}\\sim N(0,1)\\]\n\nwhere \\(\\widehat{\\beta}_j\\) is a MLE of coefficient \\(j\\)\n\n95% Wald confidence interval: \\[{\\hat{\\beta}}_1\\pm1.96 \\cdot SE_{{\\hat{\\beta}}_j}\\]\nThe Wald test is a routine output in R (summary() of glm() output)\n\nIncludes \\(SE_{{\\hat{\\beta}}_j}\\) and can easily find confidence interval with tidy()"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#wald-test-23",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#wald-test-23",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Wald test (2/3)",
    "text": "Wald test (2/3)"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#wald-test-33",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#wald-test-33",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Wald test (3/3)",
    "text": "Wald test (3/3)"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#wald-test-procedure-with-confidence-intervals",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#wald-test-procedure-with-confidence-intervals",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Wald test procedure with confidence intervals",
    "text": "Wald test procedure with confidence intervals\n\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the confidence interval and determine if it overlaps with null\n\nOverlap with null (usually 0 for coefficient) = fail to reject null\nNo overlap with null (usually 0 for coefficient) = reject null\n\nWrite a conclusion to the hypothesis test\n\nWhat is the estimate and its confidence interval?\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\nRemember this from last class?\n\n\nWald test for age coefficient\n\n\nInterpret the coefficient for age in our model of late stage breast cancer diagnosis.\n\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\ntidy(bc_reg, conf.int=T) %&gt;% gt() %&gt;% tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n−0.989\n0.023\n−42.637\n0.000\n−1.035\n−0.944\n    Age_c\n0.057\n0.003\n17.780\n0.000\n0.051\n0.063\n  \n  \n  \n\n\n\n\n\nWrite a conclusion to the hypothesis test\n\nFor every one year increase in age, the log-odds of late stage breast cancer diagnosis increases 0.057 (95% CI: 0.051, 0.063)."
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-1",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-1",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nWald test for age coefficient\n\n\nInterpret the coefficient for age in our model of late stage breast cancer diagnosis.\n\n\n\nSet the level of significance \\(\\alpha\\) \\[\\alpha=0.05\\]\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\n\\[\\begin{aligned}\nH_0 &: \\beta_{Age} = 0 \\\\\nH_1 &: \\beta_{Age} \\neq 0 \\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-2",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-2",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nWald test for age coefficient\n\n\nInterpret the coefficient for age in our model of late stage breast cancer diagnosis.\n\n\n\nCalculate the confidence interval and determine if it overlaps with null\n\n\nlibrary(epiDisplay)\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\ntidy(bc_reg, conf.int=T) %&gt;% gt() %&gt;% tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n−0.989\n0.023\n−42.637\n0.000\n−1.035\n−0.944\n    Age_c\n0.057\n0.003\n17.780\n0.000\n0.051\n0.063"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-3",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-3",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nWald test for age coefficient\n\n\nInterpret the coefficient for age in our model of late stage breast cancer diagnosis.\n\n\n\n\n\nWrite a conclusion to the hypothesis test\n\nFor every one year increase in age, the log-odds of late stage breast cancer diagnosis increases 0.057 (95% CI: 0.051, 0.063).\nThere is sufficient evidence that age an breast cancer diagnosis are associated.\n\n\n\nNote\n\n\nI don’t want us to get fixated on this interpretation. This is more to introduce the process, BUT it’s MUCH better to interpret the coefficient in terms of OR (next class)."
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-2",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-2",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Poll Everywhere Question 2",
    "text": "Poll Everywhere Question 2"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#score-test",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#score-test",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Score test",
    "text": "Score test\n\nScore test does not require the computation of MLE for \\(\\beta_1\\), while both likelihood test and Wald test does\n\nOnly need to know \\(\\beta_1\\) under the null\n\nScore test is based on the first and second derivatives of the log-likelihood under the null hypothesis: \\[S=\\frac{\\sum_{i=1}^{n}{x_i(y_i-\\bar{y})}}{\\sqrt{\\bar{y}(1-\\bar{y})\\sum_{i=1}^{n}\\left(x_i-\\bar{x}\\right)^2}} \\sim N(0,1)\\]"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#score-test-1",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#score-test-1",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Score test",
    "text": "Score test"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#likelihood-ratio-test-13",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#likelihood-ratio-test-13",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Likelihood ratio test (1/3)",
    "text": "Likelihood ratio test (1/3)\n\nLikelihood ratio test answers the question:\n\nFor a specific covariate, which model tell us more about the outcome variable: the model including the covariate or the model omitting the covariate?\nAka: Which model is more likely given our data: model including the covariate or the model omitting the covariate?\n\n\n \n\nTest a single coefficient by comparing different models\n\nVery similar to the F-test\n\n\n \n\nImportant: LRT can be used conduct hypothesis tests for multiple coefficients\n\nJust like F-test, we can test a single coefficient, continuous/binary covariate, multi-level covariate, or multiple covariates"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#likelihood-ratio-test-23",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#likelihood-ratio-test-23",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Likelihood ratio test (2/3)",
    "text": "Likelihood ratio test (2/3)\n\nTo assess the significance of a continuous/binary covariate’s coefficient in the simple logistic regression, we compare the deviance (D) with and without the covariate \\[G=D\\left(\\text{model without } x\\right)-D\\left(\\text{model with } x\\right)\\]\n\n \n\nFor a continuous or binary variable, this is equivalent to test: \\(H_0: \\beta_j = 0\\) vs. \\(H_1: \\beta_j \\neq 0\\)\nTest statistic for LRT: \\[G=-2ln\\left[\\frac{\\text{likelihood without } x}{\\text{likelihood with } x}\\right]=2ln\\left[\\frac{l\\left({\\hat{\\beta}}_0,{\\hat{\\beta}}_1\\right)}{l({\\hat{\\beta}}_0)}\\right]\\]"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#likelihood-ratio-test-23-1",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#likelihood-ratio-test-23-1",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Likelihood ratio test (2/3)",
    "text": "Likelihood ratio test (2/3)\n\nTo assess the significance of a continuous/binary covariate’s coefficient in the simple logistic regression, we compare the deviance (D) with and without the covariate \\[G=D\\left(\\text{model without } x\\right)-D\\left(\\text{model with } x\\right)\\]\n\n \n\nFor a continuous or binary variable, this is equivalent to test: \\(H_0: \\beta_j = 0\\) vs. \\(H_1: \\beta_j \\neq 0\\)\nTest statistic for LRT: \\[G=-2ln\\left[\\frac{\\text{likelihood without } x}{\\text{likelihood with } x}\\right]=2ln\\left[\\frac{l\\left({\\hat{\\beta}}_0,{\\hat{\\beta}}_1\\right)}{l({\\hat{\\beta}}_0)}\\right]\\]"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#lrt-what-is-deviance",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#lrt-what-is-deviance",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "LRT: what is Deviance?",
    "text": "LRT: what is Deviance?\n\nDeviance: quantifies the difference in likelihoods between a fitted and saturated model\n\nFitted model:\n\nYour proposed fitted model\n\nSaturated model:\n\nA model that contains as many parameters as there are data points = perfect fit\n\nBasically every individual has their own covariate\n\nPerfect fit = maximum possible likelihood\n\n\n\n \n\nAll fitted models will have likelihood less than saturated model"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#lrt-what-is-deviance-1",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#lrt-what-is-deviance-1",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "LRT: what is Deviance?",
    "text": "LRT: what is Deviance?\n\nThe deviance is mathematically defined as: \\[D=-2[L_{\\text{fitted}}-L_{\\text{saturated}}]\\]\nAn alternative way to write it is: \\[D=-2ln\\left[\\frac{\\text{likelihood of the fitted model}}{\\text{likelihood of the saturated model}}\\right]\\]\nUsing ‘-2’ is to make the deviance follow a chi-square distribution"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#deviance-to-likelihood-ratio-test",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#deviance-to-likelihood-ratio-test",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Deviance to Likelihood Ratio Test",
    "text": "Deviance to Likelihood Ratio Test\n\nIn the LRT, we are NOT comparing the likelihood of saturated model to the fitted model\n\n \n\nWe ARE comparing the Deviance of the model with x and the model without x\n\nWe just use the saturated model to calculate Deviance\nBoth are considered fitted models with their own respective Deviance\n\n\n \n\nSo our LRT is: \\[G=D\\left(\\text{model without } x\\right)-D\\left(\\text{model with } x\\right)\\]"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#for-reference",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#for-reference",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "For reference",
    "text": "For reference\n\\[ \\begin{aligned}\nG&=D\\left(\\text{model without } x\\right)-D\\left(\\text{model with }x\\right) \\\\\nG&=-2ln\\left[\\frac{\\text{likelihood of model without } x}{\\text{likelihood of saturated model}}\\right]-\\left(-2ln\\left[\\frac{\\text{likelihood of model with } x}{\\text{likelihood of saturated model}}\\right]\\right) \\\\\nG&=-2ln\\left[\\frac{\\text{likelihood of model without } x}{\\text{likelihood of saturated model}}\\times\\frac{\\text{likelihood of saturated model}}{\\text{likelihood of model with } x}\\right] \\\\\nG&=-2ln\\left[\\frac{\\text{likelihood of model without } x}{\\text{likelihood of model with }}\\right] \\\\\nG&=2ln\\left[\\frac{l\\left({\\hat{\\beta}}_0,{\\hat{\\beta}}_1\\right)}{l({\\hat{\\beta}}_0)}\\right]\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-3",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-3",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Poll Everywhere Question 3",
    "text": "Poll Everywhere Question 3"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#likelihood-ratio-test-23-2",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#likelihood-ratio-test-23-2",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Likelihood ratio test (2/3)",
    "text": "Likelihood ratio test (2/3)\n\nTo assess the significance of a continuous/binary covariate’s coefficient in the simple logistic regression, we compare the deviance (D) with and without the covariate \\[G=D\\left(\\text{model without } x\\right)-D\\left(\\text{model with } x\\right)\\]\n\n \n\nFor a continuous or binary variable, this is equivalent to test: \\(H_0: \\beta_j = 0\\) vs. \\(H_1: \\beta_j \\neq 0\\)\nTest statistic for LRT: \\[G=-2ln\\left[\\frac{\\text{likelihood without } x}{\\text{likelihood with } x}\\right]=2ln\\left[\\frac{l\\left({\\hat{\\beta}}_0,{\\hat{\\beta}}_1\\right)}{l({\\hat{\\beta}}_0)}\\right]\\]"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#likelihood-ratio-test-33",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#likelihood-ratio-test-33",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Likelihood ratio test (3/3)",
    "text": "Likelihood ratio test (3/3)\n\nUnder the null hypothesis, with adequate sample size, LRT statistic follows a chi-square distribution: \\[G \\sim \\chi^2(df)\\]\n\n\\(df = (\\# \\text{coefficients in larger model}) − (\\# \\text{coefficients in smaller model})\\)\n\n\n \n\nIf we are testing a single coefficient, like age, then \\(df=1\\)"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#likelihood-ratio-test",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#likelihood-ratio-test",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Likelihood ratio test",
    "text": "Likelihood ratio test"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#lrt-procedure",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#lrt-procedure",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "LRT procedure",
    "text": "LRT procedure\n\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\nIn symbols\nIn words\nAlternative: one- or two-sided?\n\nCalculate the test statistic and p-value\nWrite a conclusion to the hypothesis test\n\nDo we reject or fail to reject \\(H_0\\)?\nWrite a conclusion in the context of the problem"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-4",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-4",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nLRT\n\n\nDetermine if the model including age is more likely than model without age. Aka: Is age associated with late stage breast cancer diagnosis?\n\n\nNeeded steps:\n\nSet the level of significance \\(\\alpha\\)\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\nCalculate the test statistic and p-value\nWrite a conclusion to the hypothesis test"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-5",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-5",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nLRT\n\n\nDetermine if the model including age is more likely than model without age. Aka: Is age associated with late stage breast cancer diagnosis?\n\n\n\nSet the level of significance \\(\\alpha\\) \\[\\alpha=0.05\\]\nSpecify the null ( \\(H_0\\) ) and alternative ( \\(H_A\\) ) hypotheses\n\n\\[\\begin{aligned}\nH_0 &: \\beta_{Age} = 0 \\\\\nH_1 &: \\beta_{Age} \\neq 0 \\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-6",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-6",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nLRT\n\n\nDetermine if the model including age is more likely than model without age. Aka: Is age associated with late stage breast cancer diagnosis?\n\n\n\nCalculate the test statistic and p-value\n\n\nlibrary(lmtest)\nbc_age = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nbc_int = glm(Late_stage_diag ~ 1, data = bc, family = binomial)\nlmtest::lrtest(bc_age, bc_int)\n\nLikelihood ratio test\n\nModel 1: Late_stage_diag ~ Age_c\nModel 2: Late_stage_diag ~ 1\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   2 -5754.8                         \n2   1 -5930.5 -1 351.27  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-7",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-bc-diagnosis-and-age-7",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: BC diagnosis and age",
    "text": "Example: BC diagnosis and age\n\n\nLRT\n\n\nDetermine if the model including age is more likely than model without age. Aka: Is age associated with late stage breast cancer diagnosis?\n\n\n\nWrite a conclusion to the hypothesis test\n\nWe reject the null hypothesis that the coefficient corresponding to age is 0 (\\(p-value &lt;&lt; 0.05\\)). There is sufficient evidence that there is an association between age and late stage breast cancer diagnosis."
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#all-three-tests-together",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#all-three-tests-together",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "All three tests together",
    "text": "All three tests together\n\nUCLA FAQ on Tests"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#which-test-to-use",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#which-test-to-use",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Which test to use?",
    "text": "Which test to use?\n\nAll three tests are asymptotically equivalent\n\nAs sample approaches infinity\n\nFor testing significance of single covariate coefficient:\n\nLRT\n\nWald and score are only approximations of LRT\nFor smaller samples, LRT better\n\nWald test is very convenient\n\nAutomatically performed in R\nDoes not need to estimate two models (LRT does)\nGood for constructing confidence intervals of coefficients and odds ratios\n\nScore test\n\nDoes not need to estimate two models (LRT does)\nI don’t really see people use this…"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-4",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-4",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Poll Everywhere Question 4",
    "text": "Poll Everywhere Question 4"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-5",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-5",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Poll Everywhere Question 5",
    "text": "Poll Everywhere Question 5"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-6",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-6",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Poll Everywhere Question 6",
    "text": "Poll Everywhere Question 6"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-7",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-7",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Poll Everywhere Question 7",
    "text": "Poll Everywhere Question 7"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-8",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#poll-everywhere-question-8",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Poll Everywhere Question 8",
    "text": "Poll Everywhere Question 8"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#tests-and-what-theyre-used-for",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#tests-and-what-theyre-used-for",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Tests and what they’re used for",
    "text": "Tests and what they’re used for\n\n\n\n\n\n\n\n\n\n\nWald test\nScore test\nLRT\n\n\n\n\nUsed to test significance of single coefficient\n\n\n\n\n\nCan be used to report confidence interval for a single coefficient\n\n\n\n\n\nConfidence interval reported by R for a single coefficient (and most commonly used)\n\n\n\n\n\nUse to test significance/contribution to outcome prediction of multi-level categorical covariate\n\n\n\n\n\nUsed for comparing two models with different (but nested) covariates"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#so-how-would-the-wald-test-and-lrt-show-up-in-research",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#so-how-would-the-wald-test-and-lrt-show-up-in-research",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "So how would the Wald test and LRT show up in research?",
    "text": "So how would the Wald test and LRT show up in research?\n\nWald test\n\nOften used when reporting estimates\nGenerally presented using a forest plot or table of ORs or RRs\n\nThen we highlight the specific variable of interest in text\nWill include the OR/RR estimate (not the coefficient like we saw today) with the 95% CI and proper interpretation of result\n\n\n\n \n\nLRT\n\nOften when performing model selection and comparing two models\n\nReporting model selection Cross Validated post\n\nOften does not show up explicitly in our reports, but is essential to get to our final model!!\n\n\n\n\nLesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#last-time-to-this-time",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#last-time-to-this-time",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Last time to this time",
    "text": "Last time to this time\n\nUsed the Wald test and Wald 95% confidence interval to interpret coefficients in a fitted model\nThis time: Interpret using odds ratio"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#we-typically-interpret-our-results-using-odds-ratios",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#we-typically-interpret-our-results-using-odds-ratios",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "We typically interpret our results using odds ratios",
    "text": "We typically interpret our results using odds ratios\nFor our fitted simple logistic regression model with a continuous predictor \\[\\text{logit}(\\widehat{\\pi}(X)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X\\]\n\nHow do we go from interpretations of \\(\\widehat{\\beta}_0\\) and \\(\\widehat{\\beta}_1\\) using log odds to odds ratios?\nWe will need to take the exponential of our model:\n\n\\(\\text{exp}(\\widehat{\\beta}_0)\\): expected odds that \\(Y=1\\) when X is 0.\n\\(\\text{exp}(\\widehat{\\beta}_1)\\): expected odds ratio that \\(Y=1\\) for every 1 unit increase in X"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#we-typically-interpret-our-results-using-odds-ratios-1",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#we-typically-interpret-our-results-using-odds-ratios-1",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "We typically interpret our results using odds ratios",
    "text": "We typically interpret our results using odds ratios\nFor our fitted simple logistic regression model with a continuous predictor \\[\\text{logit}(\\widehat{\\pi}(X)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X\\]\n\nHow do we go from interpretations of \\(\\widehat{\\beta}_0\\) and \\(\\widehat{\\beta}_1\\) using log odds to odds ratios?\nWe will need to take the exponential of our model:\n\n\\(\\text{exp}(\\widehat{\\beta}_0)\\): expected odds that \\(Y=1\\) when X is 0.\n\\(\\text{exp}(\\widehat{\\beta}_1)\\): expected odds ratio that \\(Y=1\\) for every 1 unit increase in X"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example",
    "text": "Example\n\nHow do we do this in R?\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\ntidy(bc_reg, conf.int=T, exponentiate=T) %&gt;% gt() %&gt;% \n  tab_options(table.font.size = 35) %&gt;% fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n0.372\n0.023\n−42.637\n0.000\n0.355\n0.389\n    Age_c\n1.059\n0.003\n17.780\n0.000\n1.052\n1.065\n  \n  \n  \n\n\n\nlogistic.display(bc_reg, decimal = 3)\n\n\nLogistic regression predicting Late_stage_diag : 1 vs 0 \n \n                   OR(95%CI)            P(Wald's test) P(LR-test)\nAge_c (cont. var.) 1.059 (1.052,1.065)  &lt; 0.001        &lt; 0.001   \n                                                                 \nLog-likelihood = -5754.84419\nNo. of observations = 10000\nAIC value = 11513.68837"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#transformations-of-continuous-variable-to-make-more-interpretable",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#transformations-of-continuous-variable-to-make-more-interpretable",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Transformations of continuous variable to make more interpretable",
    "text": "Transformations of continuous variable to make more interpretable\n\nSometimes a change in “1” unit may not be considered clinically interesting\n\nFor example, a 1 year increase in age or a 1 mm Hg increase in systolic blood pressure may be too small for a meaningful change in log odds\nInstead, we may be interested to find out the log odds change for a increase of 10 years in age or 10 mm Hg in systolic blood pressure\nOn the other hand, if the range of x is small (say 0-1), than a change in 1 unit of 𝑥 is too large to be meaningful\n\nWe should be able to compute and interpret coefficients for a continuous independent covariate 𝑥 for an arbitrary change of “c” units in 𝑥"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#how-do-we-get-the-odds-and-odds-ratio",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#how-do-we-get-the-odds-and-odds-ratio",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "How do we get the odds and odds ratio?",
    "text": "How do we get the odds and odds ratio?\n\n\nFor \\(\\text{exp}(\\widehat{\\beta}_0)\\)\n\nWhen \\(X=0\\), we have \\[\\text{logit}(\\widehat{\\pi}(X=0)) = \\widehat{\\beta}_0\\]\nThus, \\[\\begin{aligned} \\widehat{\\beta}_0 & = \\text{logit}(\\widehat{\\pi}(X)) \\\\\n\\text{exp}\\big[\\widehat{\\beta}_0\\big] & = \\text{exp}\\big[\\text{logit}(\\widehat{\\pi}(X))\\big] \\\\\n\\text{exp}\\big[\\widehat{\\beta}_0\\big] & = \\text{exp}\\Bigg[\\text{log}\\Bigg(\\dfrac{\\widehat{\\pi}(X)}{1-\\widehat{\\pi}(X)}\\Bigg)\\Bigg] \\\\\n\\text{exp}\\big[\\widehat{\\beta}_0\\big] & = \\dfrac{\\widehat{\\pi}(X)}{1-\\widehat{\\pi}(X)} \\\\\n\\end{aligned}\\]\n\n\n\n\nFor \\(\\text{exp}(\\widehat{\\beta}_1)\\)\n\nWe compare \\(X=x\\) and \\(X=x+1\\), and we have \\(\\text{logit}(\\widehat{\\pi}(X = x)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot x\\) and \\(\\text{logit}(\\widehat{\\pi}(X = x+1)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot (x+1)\\)\nThus, \\[\\begin{aligned} \\widehat{\\beta}_0 & = \\text{logit}(\\widehat{\\pi}(X)) \\\\\n\\text{exp}\\big[\\widehat{\\beta}_0\\big] & = \\text{exp}\\big[\\text{logit}(\\widehat{\\pi}(X))\\big] \\\\\n\\text{exp}\\big[\\widehat{\\beta}_0\\big] & = \\text{exp}\\Bigg[\\text{log}\\Bigg(\\dfrac{\\widehat{\\pi}(X)}{1-\\widehat{\\pi}(X)}\\Bigg)\\Bigg] \\\\\n\\text{exp}\\big[\\widehat{\\beta}_0\\big] & = \\dfrac{\\widehat{\\pi}(X)}{1-\\widehat{\\pi}(X)} \\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#how-do-we-get-the-odds-for-the-intercept",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#how-do-we-get-the-odds-for-the-intercept",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "How do we get the odds for the intercept?",
    "text": "How do we get the odds for the intercept?\nFor \\(\\text{exp}(\\widehat{\\beta}_0)\\)\n\nWhen \\(X=0\\), we have \\[\\text{logit}(\\widehat{\\pi}(X=0)) = \\widehat{\\beta}_0\\]\nThus, \\[\\begin{aligned} \\widehat{\\beta}_0 & = \\text{logit}(\\widehat{\\pi}(X)) \\\\\n\\text{exp}\\big[\\widehat{\\beta}_0\\big] & = \\text{exp}\\big[\\text{logit}(\\widehat{\\pi}(X))\\big] \\\\\n\\text{exp}\\big[\\widehat{\\beta}_0\\big] & = \\text{exp}\\Bigg[\\text{log}\\Bigg(\\dfrac{\\widehat{\\pi}(X)}{1-\\widehat{\\pi}(X)}\\Bigg)\\Bigg] \\\\\n\\text{exp}\\big[\\widehat{\\beta}_0\\big] & = \\dfrac{\\widehat{\\pi}(X)}{1-\\widehat{\\pi}(X)} \\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#how-do-we-get-the-odds-ratio-for-xs-coefficient",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#how-do-we-get-the-odds-ratio-for-xs-coefficient",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "How do we get the odds ratio for X’s coefficient?",
    "text": "How do we get the odds ratio for X’s coefficient?\n\n\nFor \\(\\text{exp}(\\widehat{\\beta}_1)\\)\n\nWe compare \\(X=x\\) and \\(X=x+1\\),\nSo we have \\[\\text{logit}(\\widehat{\\pi}(X = x)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot x\\] and \\[\\text{logit}(\\widehat{\\pi}(X = x+1)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot (x+1)\\]\nAnd… \\[\\begin{aligned} & \\text{logit}(\\widehat{\\pi}(X = x+1)) - \\text{logit}(\\widehat{\\pi}(X = x)) \\\\ & =  \n\\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot (x+1) - \\big[\\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot x \\big] \\\\ &= \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot x + \\widehat{\\beta}_1 - \\widehat{\\beta}_0 - \\widehat{\\beta}_1 \\cdot x \\\\ & =\n\\widehat{\\beta}_1 \\end{aligned}\\]\n\n\n\nThus, \\[\\begin{aligned} \\widehat{\\beta}_1 & =  \\text{logit}(\\widehat{\\pi}(X = x+1)) - \\text{logit}(\\widehat{\\pi}(X = x)) \\\\\n\\widehat{\\beta}_1 & =  \\text{log}\\Bigg(\\dfrac{\\widehat{\\pi}(X=x+1)}{1-\\widehat{\\pi}(X=x+1)}\\Bigg) - \\text{log}\\Bigg(\\dfrac{\\widehat{\\pi}(X=x)}{1-\\widehat{\\pi}(X=x)}\\Bigg) \\\\\n\\widehat{\\beta}_1 & =  \\text{log}\\left(\\frac{\\dfrac{\\widehat{\\pi}(X=x+1)}{1-\\widehat{\\pi}(X=x+1)}} {\\dfrac{\\widehat{\\pi}(X=x)}{1-\\widehat{\\pi}(X=x)}}\\right) \\\\\n\\text{exp}\\big[\\widehat{\\beta}_1\\big] & =  \\text{exp}\\left[\\text{log}\\left(\\frac{\\text{odds}_{X=x+1}} {\\text{odds}_{X=x}}\\right) \\right] \\\\\n\\text{exp}\\big[\\widehat{\\beta}_1\\big] & =  \\frac{\\text{odds}_{X=x+1}} {\\text{odds}_{X=x}} \\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-1",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-1",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example",
    "text": "Example\nFor our fitted simple logistic regression model with age as a predictor \\[\\text{logit}(\\widehat{\\pi}(Age)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot Age\\]\n\n\\(\\widehat{\\beta}_0\\): estimated log-odds when age is 61.71 years\n\\(\\widehat{\\beta}_1\\): estimated increase in log-odds for every 1 year increase in age\n\n\n\nLesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-2",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-2",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example",
    "text": "Example\nFor our fitted simple logistic regression model with age as a predictor \\[\\text{logit}(\\widehat{\\pi}(Age)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot Age\\]\n\n\\(\\widehat{\\beta}_0\\): estimated log-odds when age is 61.71 years\n\\(\\widehat{\\beta}_1\\): estimated increase in log-odds for every 1 year increase in age\n\n\n\nLesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-from-last-class",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#example-from-last-class",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: From last class",
    "text": "Example: From last class\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\ntidy(bc_reg, conf.int=T) %&gt;% gt() %&gt;% tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n−0.989\n0.023\n−42.637\n0.000\n−1.035\n−0.944\n    Age_c\n0.057\n0.003\n17.780\n0.000\n0.051\n0.063\n  \n  \n  \n\n\n\n\n\nFor our fitted simple logistic regression model with age as a predictor \\[\\text{logit}(\\widehat{\\pi}(Age^c)) = −0.989  + 0.057     \\cdot Age^c\\]\n\\(\\widehat{\\beta}_0\\): The estimated log-odds is -0.989 when age is 61.71 years (95% CI: -1.035, -0.944)\n\\(\\widehat{\\beta}_1\\): The estimated increase in log-odds is 0.057 for every 1 year increase in age (95% CI: 0.051, 0.063)."
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#so-far-weve-looked-at-the-association-using-the-log-odds-scale",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html#so-far-weve-looked-at-the-association-using-the-log-odds-scale",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "So far we’ve looked at the association using the log-odds scale",
    "text": "So far we’ve looked at the association using the log-odds scale\n\n\nFor a population simple logistic regression model with a continuous predictor \\[\\text{logit}(\\pi(X)) = \\beta_0 + \\beta_1 \\cdot X\\]\n\n\\(\\beta_0\\): log-odds when X is 0\n\\(\\beta_1\\): increase in log-odds for every 1 unit increase in X\n\n\n\n\nFor our fitted simple logistic regression model with a continuous predictor \\[\\text{logit}(\\widehat{\\pi}(X)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X\\]\n\n\\(\\widehat{\\beta}_0\\): estimated log-odds of \\(Y=1\\) when X is 0.\n\\(\\widehat{\\beta}_1\\): estimated increase in log-odds of \\(Y=1\\) for every 1 unit increase in X\nCan use expected instead of estimated"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#predicted-probability",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#predicted-probability",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Predicted Probability",
    "text": "Predicted Probability\n\nWe may be interested in predicting probability of having a late stage breast cancer diagnosis for a specific age.\nThe predicted probability is the estimated probability of having the event for given values of covariate(s)\nIn simple logistic regression, the fitted model is:\\[\\text{logit}(\\widehat{\\pi}(X)) = \\hat{\\beta}_0 +{\\hat{\\beta}}_1X \\]\nWe can convert it to the predicted probability: \\[\\hat{\\pi}\\left(X\\right)=\\frac{\\exp({\\hat{\\beta}}_0+{\\hat{\\beta}}_1X)}{1+\\exp({\\hat{\\beta}}_0+{\\hat{\\beta}}_1X)}\\]\n\nThis is an inverse logit calculation\n\nWe can calculate this using the the predict() function like in BSTA 512\n\nAnother option: taking inverse logit of fitted values from augment() function"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#example",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#example",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Example:",
    "text": "Example:\n\n\nPredicting probability of late stage breast cancer diagnosis\n\n\nFor someone 50 years old, what is the predicted probability for late stage breast cancer diagnosis (with confidence intervals)?\n\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\n\nnewdata = data.frame(Age_c = 60 - mean_age)\n\npred = predict(bc_reg, newdata = newdata, se.fit = T, type = \"response\")\n\nLL_CI = pred$fit - qnorm(1-0.05/2) * pred$se.fit\nUL_CI = pred$fit + qnorm(1-0.05/2) * pred$se.fit\n\nc(Pred = pred$fit, LL_CI, UL_CI) %&gt;% round(digits=3)\n\nPred.1      1      1 \n 0.252  0.243  0.261"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#visualization",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#visualization",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Visualization",
    "text": "Visualization\n\n\n\n\n\\[\\text{logit}(\\widehat{\\pi}(Age)) = -0.989 + 0.057 \\cdot Age\\]\n\n\\[\\widehat{\\pi}(Age) = \\dfrac{ \\exp \\left[-0.989 + 0.057 \\cdot Age \\right]}{1+\\exp \\left[-0.989 + 0.057 \\cdot Age \\right]}\\]"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-late-stage-breast-cancer-diagnosis",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-late-stage-breast-cancer-diagnosis",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Example: Late stage breast cancer diagnosis",
    "text": "Example: Late stage breast cancer diagnosis\n\n\nPredicting probability of late stage breast cancer diagnosis\n\n\nFor someone 50 years old, what is the predicted probability for late stage breast cancer diagnosis (with confidence intervals)?\n\n\nNeeded steps:\n\nCalculate probability prediction\nCheck if we can use Normal approximation\nCalculate confidence interval\n\nUsing logit scale then converting\nUsing Normal approximation\n\nInterpret results"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-late-stage-breast-cancer-diagnosis-1",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-late-stage-breast-cancer-diagnosis-1",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Example: Late stage breast cancer diagnosis",
    "text": "Example: Late stage breast cancer diagnosis\n\n\nPredicting probability of late stage breast cancer diagnosis\n\n\nFor someone 50 years old, what is the predicted probability for late stage breast cancer diagnosis (with confidence intervals)?\n\n\n\nCalculate probability prediction\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nnewdata = data.frame(Age_c = 60 - mean_age)\npred1 = predict(bc_reg, newdata = newdata, se.fit = T, type = \"response\")\npred1\n\n$fit\n        1 \n0.2522616 \n\n$se.fit\n          1 \n0.004709743 \n\n$residual.scale\n[1] 1"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-late-stage-breast-cancer-diagnosis-2",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-late-stage-breast-cancer-diagnosis-2",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Example: Late stage breast cancer diagnosis",
    "text": "Example: Late stage breast cancer diagnosis\n\n\nPredicting probability of late stage breast cancer diagnosis\n\n\nFor someone 50 years old, what is the predicted probability for late stage breast cancer diagnosis (with confidence intervals)?\n\n\n\nCheck if we can use Normal approximation\n\nWe can use the Normal approximation if: \\(\\widehat{p}n = \\widehat{\\pi}(X)\\cdot n &gt; 10\\) and \\((1-\\widehat{p})n = (1-\\widehat{\\pi}(X))\\cdot n &gt; 10\\).\n\nn = nobs(bc_reg)\np = pred1$fit\nn*p\n\n       1 \n2522.616 \n\nn*(1-p)\n\n       1 \n7477.384 \n\n\nWe can use the Normal approximation!"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#predicted-probability-1",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#predicted-probability-1",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Predicted Probability",
    "text": "Predicted Probability\n\nPredicted probability is NOT our predicted outcome\n\nWe cannot interpret it as the predicted \\(Y\\) for individuals with certain covariate values\nExample: our predicted probability does not tell us that one individual is or is not diagnosed with late stage breast cancer\n\nThe predicted probability is the estimate of the mean (i.e., proportion) of individuals at a certain age who are diagnosed with late stage breast cancer"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#predicted-outcome",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#predicted-outcome",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Predicted outcome",
    "text": "Predicted outcome\n\nTypically, the predicted probability is the most important thing to use in a clinical setting\n\n \n\nIf you ever need to predict the outcome itself (from logistic regression with binary outcome):\n\nRemember that the predicted probability can be used in a Bernoulli (or Binomial with \\(n=1\\)) distribution to find the predicted outcome\n\nIf outcome is something like counts, then we would use a Poisson distribution\n\n \n\nBy putting it back through a Bernoulli/binomial distribution, we are re-introducing the random component of our observed outcome\n\n\nset.seed(8392)\nrbinom(n=1, size=1, prob = pred$fit)\n\n[1] 0\n\nrbinom(n=10, size=1, prob = pred$fit)\n\n [1] 0 0 0 0 1 0 0 0 1 0"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-also-make-a-plot-of-all-the-predictions",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-also-make-a-plot-of-all-the-predictions",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "We can also make a plot of all the predictions",
    "text": "We can also make a plot of all the predictions"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#confidence-interval-of-predicted-probability",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#confidence-interval-of-predicted-probability",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Confidence Interval of Predicted Probability",
    "text": "Confidence Interval of Predicted Probability\n\nNot as easy to construct\nI have searched around for a function that does this for us, but I cannot find one\nSo we have to construct the confidence interval “by hand”\n\n \nThere are a two ways to do this:\n\nConstruct the 95% confidence interval in the logit scale, then convert to probability scale\nUse Normal approximation (if appropriate) to construct confidence interval in probability scale"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#confidence-interval-in-logit-scale",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#confidence-interval-in-logit-scale",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "95% confidence interval in logit scale",
    "text": "95% confidence interval in logit scale\n\nWe start by predicting the log-odds and forming"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#visualization-of-ors",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#visualization-of-ors",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Visualization of ORs?",
    "text": "Visualization of ORs?\n\n\nLesson 7: Prediction and Visualization in Simple Logistic Regression"
  },
  {
    "objectID": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html",
    "href": "lectures/07_Interpretations_SLR/07_Interpretations_SLR.html",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "",
    "text": "Used the Wald test and Wald 95% confidence interval to interpret coefficients in a fitted model\nThis time: Interpret using odds ratio"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#option-1-95-confidence-interval-in-logit-scale",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#option-1-95-confidence-interval-in-logit-scale",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Option 1: 95% confidence interval in logit scale",
    "text": "Option 1: 95% confidence interval in logit scale\n\nRecall our our fitted simple logistic regression model with a continuous predictor \\[\\text{logit}(\\widehat{\\pi}(X)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X\\]\nWe can first find the predicted \\(\\text{logit}(\\widehat{\\pi}(X))\\) and then find the 95% confidence interval around it: \\[\\text{logit}(\\widehat{\\pi}(X)) \\pm 1.96 \\cdot SE_{\\text{logit}(\\widehat{\\pi}(X))}\\]\nWe’ll call this 95% CI: \\[\\left(\\text{logit}(\\widehat{\\pi}(X)) - 1.96 \\cdot SE_{\\text{logit}(\\widehat{\\pi}(X))}, \\ \\text{logit}(\\widehat{\\pi}(X)) + 1.96 \\cdot SE_{\\text{logit}(\\widehat{\\pi}(X))} \\right)\\] \\[\\left(\\text{logit}_{L}, \\ \\text{logit}_{U} \\right)\\]"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#option-2-using-normal-approximation",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#option-2-using-normal-approximation",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Option 2: Using Normal approximation",
    "text": "Option 2: Using Normal approximation\n\nIf we meet the Normal approximation criteria, we can construct our confidence interval directly in the probability scale\n\nWe can use the Normal approximation if:\n\n\\(\\widehat{p}n = \\widehat{\\pi}(X)\\cdot n &gt; 10\\) and\n\\((1-\\widehat{p})n = (1-\\widehat{\\pi}(X))\\cdot n &gt; 10\\)\n\n\n\n \n\nWe can first find the predicted \\(\\widehat{\\pi}(X)\\) and then find the 95% confidence interval around it: \\[\\widehat{\\pi}(X) \\pm 1.96 \\cdot SE_{\\widehat{\\pi}(X)}\\]"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-late-stage-breast-cancer-diagnosis-3",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-late-stage-breast-cancer-diagnosis-3",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Example: Late stage breast cancer diagnosis",
    "text": "Example: Late stage breast cancer diagnosis\n\n\nPredicting probability of late stage breast cancer diagnosis\n\n\nFor someone 50 years old, what is the predicted probability for late stage breast cancer diagnosis (with confidence intervals)?\n\n\n3a. Calculate confidence interval (Option 1: logit scale, we could skip previous step)\n\npred1 = predict(bc_reg, newdata = newdata, se.fit = T, type = \"link\")\nLL_CI1 = pred1$fit - qnorm(1-0.05/2) * pred1$se.fit\nUL_CI1 = pred1$fit + qnorm(1-0.05/2) * pred1$se.fit\npred_link = c(Pred = pred1$fit, LL_CI1, UL_CI1)\n\n(exp(pred_link)/(1+exp(pred_link))) %&gt;% round(., digits=3)\n\nPred.1      1      1 \n 0.252  0.243  0.262 \n\ninv.logit(pred_link) %&gt;% round(., digits=3)\n\nPred.1      1      1 \n 0.252  0.243  0.262"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-late-stage-breast-cancer-diagnosis-4",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-late-stage-breast-cancer-diagnosis-4",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Example: Late stage breast cancer diagnosis",
    "text": "Example: Late stage breast cancer diagnosis\n\n\nPredicting probability of late stage breast cancer diagnosis\n\n\nFor someone 50 years old, what is the predicted probability for late stage breast cancer diagnosis (with confidence intervals)?\n\n\n3b. Calculate confidence interval (Option 2: with Normal approximation)\n\npred = predict(bc_reg, newdata = newdata, se.fit = T, type = \"response\")\n\nLL_CI = pred$fit - qnorm(1-0.05/2) * pred$se.fit\nUL_CI = pred$fit + qnorm(1-0.05/2) * pred$se.fit\n\nc(Pred = pred$fit, LL_CI, UL_CI) %&gt;% round(digits=3)\n\nPred.1      1      1 \n 0.252  0.243  0.261"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-late-stage-breast-cancer-diagnosis-5",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-late-stage-breast-cancer-diagnosis-5",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Example: Late stage breast cancer diagnosis",
    "text": "Example: Late stage breast cancer diagnosis\n\n\nPredicting probability of late stage breast cancer diagnosis\n\n\nFor someone 50 years old, what is the predicted probability for late stage breast cancer diagnosis (with confidence intervals)?\n\n\n\nInterpret results\n\nFor someone who is 60 years old, the predicted probability of late stage breast cancer diagnosis is 0.252 (95% CI: 0.243, 0.261)."
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-also-make-a-plot-of-all-the-predicted-probabilities",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-also-make-a-plot-of-all-the-predicted-probabilities",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "We can also make a plot of all the predicted probabilities",
    "text": "We can also make a plot of all the predicted probabilities\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nbc_aug = augment(bc_reg)\n\n\nlibrary(boot)\nprob_stage = ggplot(data = bc_aug, aes(x=Age_c, y = inv.logit(.fitted))) + \n  geom_point(size = 4, color = \"#70AD47\", shape = 1) +\n  labs(x = \"Age centered (yrs)\", \n       y = \"Probability of \\n Late stage BC diagnosis\")  + theme_classic() +\n    theme(axis.title = element_text(\n        size = 30), \n        axis.text = element_text(\n        size = 25), \n        title = element_text(\n        size = 30)) +\n  ylim(0, 1)"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#option-1-95-confidence-interval-in-logit-scale-12",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#option-1-95-confidence-interval-in-logit-scale-12",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Option 1: 95% confidence interval in logit scale (1/2)",
    "text": "Option 1: 95% confidence interval in logit scale (1/2)\n\nRecall our our fitted simple logistic regression model with a continuous predictor \\[\\text{logit}(\\widehat{\\pi}(X)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X\\]\nWe can first find the predicted \\(\\text{logit}(\\widehat{\\pi}(X))\\) and then find the 95% confidence interval around it: \\[\\text{logit}(\\widehat{\\pi}(X)) \\pm 1.96 \\cdot SE_{\\text{logit}(\\widehat{\\pi}(X))}\\]\nWe’ll call this 95% CI: \\[\\left(\\text{logit}(\\widehat{\\pi}(X)) - 1.96 \\cdot SE_{\\text{logit}(\\widehat{\\pi}(X))}, \\ \\text{logit}(\\widehat{\\pi}(X)) + 1.96 \\cdot SE_{\\text{logit}(\\widehat{\\pi}(X))} \\right)\\] \\[\\left(\\text{logit}_{L}, \\ \\text{logit}_{U} \\right)\\]"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#option-1-95-confidence-interval-in-logit-scale-12-1",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#option-1-95-confidence-interval-in-logit-scale-12-1",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Option 1: 95% confidence interval in logit scale (1/2)",
    "text": "Option 1: 95% confidence interval in logit scale (1/2)\n\nThen we need to convert to the probability scale\nTo convert from \\(\\text{logit}(\\widehat{\\pi}(X))\\) to \\(\\widehat{\\pi}(X)\\), we take the inverse logit\nThus, 95% CI in the probability scale is: \\[\\left(\\dfrac{\\exp\\left[\\text{logit}_{L}\\right]}{1 + \\exp\\left[\\text{logit}_{L}\\right]}, \\ \\dfrac{\\exp\\left[\\text{logit}_{U}\\right]}{1 + \\exp\\left[\\text{logit}_{U}\\right]} \\right)\\]"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#reference-inverse-logit",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#reference-inverse-logit",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Reference: Inverse logit",
    "text": "Reference: Inverse logit\n\nIf we have \\(\\text{logit}(a) = b\\), then \\[\\begin{aligned}\n\\text{logit}(a) & = b \\\\\n\\text{log}\\left(\\dfrac{a}{1-a}\\right) & = b \\\\\n\\exp \\left[ \\text{log}\\left(\\dfrac{a}{1-a}\\right) \\right] & = \\exp[b] \\\\\n\\dfrac{a}{1-a} & = \\exp[b] \\\\\na & = \\exp[b]\\cdot(1-a) \\\\\na & = \\exp[b] - a\\cdot \\exp[b] \\\\\na +  a\\cdot \\exp[b]& = \\exp[b] \\\\\na\\cdot ( 1 + \\exp[b] )& = \\exp[b] \\\\\na& = \\dfrac{\\exp[b]}{1 + \\exp[b]} \\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#option-1-95-confidence-interval-in-logit-scale-22",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#option-1-95-confidence-interval-in-logit-scale-22",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Option 1: 95% confidence interval in logit scale (2/2)",
    "text": "Option 1: 95% confidence interval in logit scale (2/2)\n\nThen we need to convert to the probability scale\nTo convert from \\(\\text{logit}(\\widehat{\\pi}(X))\\) to \\(\\widehat{\\pi}(X)\\), we take the inverse logit\nThus, 95% CI in the probability scale is: \\[\\left(\\dfrac{\\exp\\left[\\text{logit}_{L}\\right]}{1 + \\exp\\left[\\text{logit}_{L}\\right]}, \\ \\dfrac{\\exp\\left[\\text{logit}_{U}\\right]}{1 + \\exp\\left[\\text{logit}_{U}\\right]} \\right)\\]"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-also-make-a-plot-of-all-the-predicted-probabilities-12",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-also-make-a-plot-of-all-the-predicted-probabilities-12",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "We can also make a plot of all the predicted probabilities (1/2)",
    "text": "We can also make a plot of all the predicted probabilities (1/2)\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nbc_aug = augment(bc_reg)\n\n\nThen we plot the fitted values from the fitted model\n\n\nlibrary(boot) # for inv.logit()\nprob_stage = ggplot(data = bc_aug, aes(x=Age_c, y = inv.logit(.fitted))) + \n  # geom_point(size = 4, color = \"#70AD47\", shape = 1) +\n  geom_smooth(size = 4, color = \"#70AD47\") +\n  labs(x = \"Age centered (yrs)\", \n       y = \"Estimated probability of \\n Late stage BC diagnosis\")  + \n  theme_classic() +\n  theme(axis.title = element_text(size = 30), \n        axis.text = element_text(size = 25), \n        title = element_text(size = 30)) +\n  ylim(0, 1)"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-also-make-a-plot-of-all-the-predicted-probabilities-22",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-also-make-a-plot-of-all-the-predicted-probabilities-22",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "We can also make a plot of all the predicted probabilities (2/2)",
    "text": "We can also make a plot of all the predicted probabilities (2/2)\n\nIf we are interested in seeing all the predicted probabilities across the sample’s age range\nNote that the probabilities do not need to fill the full range of 0 to 1."
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-add-the-confidence-intervals",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-add-the-confidence-intervals",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "We can add the confidence intervals",
    "text": "We can add the confidence intervals\n\nnewdata2 = data.frame(Age_c = seq(min(bc$Age_c), max(bc$Age_c), by = 0.1))\npred2 = predict(bc_reg, newdata = newdata2, se.fit = T, type = \"link\")\nLL_CI1 = pred2$fit - qnorm(1-0.05/2) * pred2$se.fit\nUL_CI1 = pred2$fit + qnorm(1-0.05/2) * pred2$se.fit\n\nwith_CI = data.frame(Age_c = newdata2$Age_c, \n                     pred = inv.logit(pred2$fit), \n                     LL = inv.logit(LL_CI1), \n                     UL = inv.logit(UL_CI1))"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#section",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#section",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "",
    "text": "library(boot)\nprob_stage_CI = ggplot(data = with_CI, aes(x = Age_c)) +\n  geom_ribbon(aes(ymin = LL, ymax = UL), fill = \"grey\") +\n  geom_smooth(aes(x=Age_c, y = pred), size = 1, color = \"#70AD47\") +\n  labs(x = \"Age centered (yrs)\", \n       y = \"Probability of \\n Late stage BC diagnosis\")  + theme_classic() +\n    theme(axis.title = element_text(\n        size = 30), \n        axis.text = element_text(\n        size = 25), \n        title = element_text(\n        size = 30)) +\n  ylim(0, 0.6)"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#section-1",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#section-1",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "",
    "text": "prob_stage_CI"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-add-the-confidence-intervals-1",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-add-the-confidence-intervals-1",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "We can add the confidence intervals",
    "text": "We can add the confidence intervals\n\nlibrary(boot)\nprob_stage_CI = ggplot(data = with_CI, aes(x = Age_c)) +\n  geom_ribbon(aes(ymin = LL, ymax = UL), fill = \"grey\") +\n  geom_smooth(aes(x=Age_c, y = pred), size = 1, color = \"#70AD47\") +\n  labs(x = \"Age centered (yrs)\", \n       y = \"Probability of \\n Late stage BC diagnosis\")  + theme_classic() +\n    theme(axis.title = element_text(\n        size = 30), \n        axis.text = element_text(\n        size = 25), \n        title = element_text(\n        size = 30)) +\n  ylim(0, 0.6)"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-add-the-confidence-intervals-2",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-add-the-confidence-intervals-2",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "We can add the confidence intervals",
    "text": "We can add the confidence intervals"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-add-the-confidence-intervals-13",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-add-the-confidence-intervals-13",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "We can add the confidence intervals (1/3)",
    "text": "We can add the confidence intervals (1/3)\n\nnewdata2 = data.frame(Age_c = seq(min(bc$Age_c), max(bc$Age_c), by = 0.1))\npred2 = predict(bc_reg, newdata = newdata2, se.fit = T, type = \"link\")\nLL_CI1 = pred2$fit - qnorm(1-0.05/2) * pred2$se.fit\nUL_CI1 = pred2$fit + qnorm(1-0.05/2) * pred2$se.fit\n\nwith_CI = data.frame(Age_c = newdata2$Age_c, \n                     pred = inv.logit(pred2$fit), \n                     LL = inv.logit(LL_CI1), \n                     UL = inv.logit(UL_CI1))"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-add-the-confidence-intervals-23",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-add-the-confidence-intervals-23",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "We can add the confidence intervals (2/3)",
    "text": "We can add the confidence intervals (2/3)\n\nprob_stage_CI = ggplot(data = with_CI, aes(x = Age_c)) +\n  geom_ribbon(aes(ymin = LL, ymax = UL), fill = \"grey\") +\n  geom_smooth(aes(x=Age_c, y = pred), size = 1, color = \"#70AD47\") +\n  labs(x = \"Age centered (yrs)\", \n       y = \"Estimated probability of \\n Late stage BC diagnosis\")  + \n  theme_classic() +\n  theme(axis.title = element_text(size = 30), \n        axis.text = element_text(size = 25), \n        title = element_text(size = 30)) +\n  ylim(0, 0.6)"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-add-the-confidence-intervals-33",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#we-can-add-the-confidence-intervals-33",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "We can add the confidence intervals (3/3)",
    "text": "We can add the confidence intervals (3/3)"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#poll-everywhere-question",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#poll-everywhere-question",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Poll Everywhere Question",
    "text": "Poll Everywhere Question"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#visualization-of-odds-ratios",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#visualization-of-odds-ratios",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Visualization of odds ratios?",
    "text": "Visualization of odds ratios?\n\nWe will discuss this more on Wednesday when we look at interpretations of ORs"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-breast-cancer-diagnosis",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#example-breast-cancer-diagnosis",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Example: Breast cancer diagnosis",
    "text": "Example: Breast cancer diagnosis\n\nRecall that we fitted a simple logistic regression for late stage breast cancer diagnosis using the predictor, age:\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\ntidy(bc_reg, conf.int=T) %&gt;% gt() %&gt;% tab_options(table.font.size = 38) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n−0.989\n0.023\n−42.637\n0.000\n−1.035\n−0.944\n    Age_c\n0.057\n0.003\n17.780\n0.000\n0.051\n0.063\n  \n  \n  \n\n\n\n\n \n\nFitted logistic regression model: \\[\\text{logit}(\\widehat{\\pi}(Age)) = -0.989 + 0.057 \\cdot Age\\]"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#recall-our-example-late-stage-breast-cancer-diagnosis",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#recall-our-example-late-stage-breast-cancer-diagnosis",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Recall our example: Late stage breast cancer diagnosis",
    "text": "Recall our example: Late stage breast cancer diagnosis\n\nRecall that we fitted a simple logistic regression for late stage breast cancer diagnosis using the predictor, age:\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\ntidy(bc_reg, conf.int=T) %&gt;% gt() %&gt;% tab_options(table.font.size = 38) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n−0.989\n0.023\n−42.637\n0.000\n−1.035\n−0.944\n    Age_c\n0.057\n0.003\n17.780\n0.000\n0.051\n0.063\n  \n  \n  \n\n\n\n\n \n\nFitted logistic regression model: \\[\\text{logit}(\\widehat{\\pi}(Age)) = -0.989 + 0.057 \\cdot Age\\]"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#predictedestimated-probability",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#predictedestimated-probability",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Predicted/Estimated probability",
    "text": "Predicted/Estimated probability\n\nPredicted probability is NOT our predicted outcome\n\nWe cannot interpret it as the predicted \\(Y\\) for individuals with certain covariate values\nExample: our predicted probability does not tell us that one individual will or will not be diagnosed with late stage breast cancer\n\n\n \n\nThe predicted probability is the estimate of the mean (i.e., proportion) of individuals at a certain age who are diagnosed with late stage breast cancer\nWe can use the predicted/estimated probability to predict the outcome"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#recall-our-example-late-stage-breast-cancer-diagnosis-1",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#recall-our-example-late-stage-breast-cancer-diagnosis-1",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Recall our example: Late stage breast cancer diagnosis",
    "text": "Recall our example: Late stage breast cancer diagnosis\n\nFitted logistic regression model: \\[\\text{logit}(\\widehat{\\pi}(Age)) = -0.989 + 0.057 \\cdot Age\\]\n\n     \n\nNow we want to caclulate the predicted/estimated probability from the above fitted model\nWe will need to calculate the predicted probability and its confidence interval\n\nThen we will visualize the fitted probability"
  },
  {
    "objectID": "lectures/07_Pred_Viz/07_Pred_Viz.html#visualization-of-observed-outcome-and-fitted-model",
    "href": "lectures/07_Pred_Viz/07_Pred_Viz.html#visualization-of-observed-outcome-and-fitted-model",
    "title": "Lesson 7: Prediction and Visualization in Simple Logistic Regression",
    "section": "Visualization of observed outcome and fitted model",
    "text": "Visualization of observed outcome and fitted model\n\n\n\n\n\\[\\text{logit}(\\widehat{\\pi}(Age)) = -0.989 + 0.057 \\cdot Age\\]\n\n\\[\\widehat{\\pi}(Age) = \\dfrac{ \\exp \\left[-0.989 + 0.057 \\cdot Age \\right]}{1+\\exp \\left[-0.989 + 0.057 \\cdot Age \\right]}\\]"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html",
    "title": "Lesson 7: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "",
    "text": "Used the Wald test and Wald 95% confidence interval to interpret coefficients in a fitted model\nThis time: Interpret using odds ratio"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#last-time-to-this-time",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#last-time-to-this-time",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Last time to this time",
    "text": "Last time to this time\n\nUsed the Wald test and Wald 95% confidence interval to interpret coefficients in a fitted model\nThis time: Interpret using odds ratio"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#so-far-weve-looked-at-the-association-using-the-log-odds-scale",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#so-far-weve-looked-at-the-association-using-the-log-odds-scale",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "So far we’ve looked at the association using the log-odds scale",
    "text": "So far we’ve looked at the association using the log-odds scale\n\n\nFor a population simple logistic regression model with a continuous predictor \\[\\text{logit}(\\pi(X)) = \\beta_0 + \\beta_1 \\cdot X\\]\n\n\\(\\beta_0\\): log-odds when X is 0\n\\(\\beta_1\\): increase in log-odds for every 1 unit increase in X\n\n\n\n\nFor our fitted simple logistic regression model with a continuous predictor \\[\\text{logit}(\\widehat{\\pi}(X)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X\\]\n\n\\(\\widehat{\\beta}_0\\): estimated log-odds of \\(Y=1\\) when X is 0.\n\\(\\widehat{\\beta}_1\\): estimated increase in log-odds of \\(Y=1\\) for every 1 unit increase in X\nCan use expected instead of estimated"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-from-last-class",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-from-last-class",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: From last class",
    "text": "Example: From last class\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\ntidy(bc_reg, conf.int=T) %&gt;% gt() %&gt;% tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n−0.989\n0.023\n−42.637\n0.000\n−1.035\n−0.944\n    Age_c\n0.057\n0.003\n17.780\n0.000\n0.051\n0.063\n  \n  \n  \n\n\n\n\n\nFor our fitted simple logistic regression model with age as a predictor \\[\\text{logit}(\\widehat{\\pi}(Age^c)) = −0.989  + 0.057     \\cdot Age^c\\]\n\\(\\widehat{\\beta}_0\\): The estimated log-odds is -0.989 when age is 61.71 years (95% CI: -1.035, -0.944)\n\\(\\widehat{\\beta}_1\\): The estimated increase in log-odds is 0.057 for every 1 year increase in age (95% CI: 0.051, 0.063)."
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#we-typically-interpret-our-results-using-odds-ratios",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#we-typically-interpret-our-results-using-odds-ratios",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "We typically interpret our results using odds ratios",
    "text": "We typically interpret our results using odds ratios\nFor our fitted simple logistic regression model with a continuous predictor \\[\\text{logit}(\\widehat{\\pi}(X)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X\\]\n\nHow do we go from interpretations of \\(\\widehat{\\beta}_0\\) and \\(\\widehat{\\beta}_1\\) using log odds to odds ratios?\nWe will need to take the exponential of our model:\n\n\\(\\text{exp}(\\widehat{\\beta}_0)\\): expected odds that \\(Y=1\\) when X is 0.\n\\(\\text{exp}(\\widehat{\\beta}_1)\\): expected odds ratio that \\(Y=1\\) for every 1 unit increase in X\n\nImportant distinction:\n\nWe take the inverse logit to find our predicted probability\nWe take the exponential to interpret the odds/odds ratios"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-do-we-get-the-odds-for-the-intercept",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-do-we-get-the-odds-for-the-intercept",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "How do we get the odds for the intercept?",
    "text": "How do we get the odds for the intercept?\nFor \\(\\text{exp}(\\widehat{\\beta}_0)\\)\n\nWhen \\(X=0\\), we have \\[\\text{logit}(\\widehat{\\pi}(X=0)) = \\widehat{\\beta}_0\\]\nThus, \\[\\begin{aligned} \\widehat{\\beta}_0 & = \\text{logit}(\\widehat{\\pi}(X)) \\\\\n\\text{exp}\\big[\\widehat{\\beta}_0\\big] & = \\text{exp}\\big[\\text{logit}(\\widehat{\\pi}(X))\\big] \\\\\n\\text{exp}\\big[\\widehat{\\beta}_0\\big] & = \\text{exp}\\Bigg[\\text{log}\\Bigg(\\dfrac{\\widehat{\\pi}(X)}{1-\\widehat{\\pi}(X)}\\Bigg)\\Bigg] \\\\\n\\text{exp}\\big[\\widehat{\\beta}_0\\big] & = \\dfrac{\\widehat{\\pi}(X)}{1-\\widehat{\\pi}(X)} \\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-do-we-get-the-odds-ratio-for-xs-coefficient",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-do-we-get-the-odds-ratio-for-xs-coefficient",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "How do we get the odds ratio for X’s coefficient?",
    "text": "How do we get the odds ratio for X’s coefficient?\n\n\nFor \\(\\text{exp}(\\widehat{\\beta}_1)\\)\n\nWe compare \\(X=x\\) and \\(X=x+1\\),\nSo we have \\[\\text{logit}(\\widehat{\\pi}(X = x)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot x\\] and \\[\\text{logit}(\\widehat{\\pi}(X = x+1)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot (x+1)\\]\nAnd… \\[\\begin{aligned} & \\text{logit}(\\widehat{\\pi}(X = x+1)) - \\text{logit}(\\widehat{\\pi}(X = x)) \\\\ & =  \n\\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot (x+1) - \\big[\\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot x \\big] \\\\ &= \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot x + \\widehat{\\beta}_1 - \\widehat{\\beta}_0 - \\widehat{\\beta}_1 \\cdot x \\\\ & =\n\\widehat{\\beta}_1 \\end{aligned}\\]\n\n\n\nThus, \\[\\begin{aligned} \\widehat{\\beta}_1 & =  \\text{logit}(\\widehat{\\pi}(X = x+1)) - \\text{logit}(\\widehat{\\pi}(X = x)) \\\\\n\\widehat{\\beta}_1 & =  \\text{log}\\Bigg(\\dfrac{\\widehat{\\pi}(X=x+1)}{1-\\widehat{\\pi}(X=x+1)}\\Bigg) - \\text{log}\\Bigg(\\dfrac{\\widehat{\\pi}(X=x)}{1-\\widehat{\\pi}(X=x)}\\Bigg) \\\\\n\\widehat{\\beta}_1 & =  \\text{log}\\left(\\dfrac{\\dfrac{\\widehat{\\pi}(X=x+1)}{1-\\widehat{\\pi}(X=x+1)}} {\\dfrac{\\widehat{\\pi}(X=x)}{1-\\widehat{\\pi}(X=x)}}\\right) \\\\\n\\text{exp}\\big[\\widehat{\\beta}_1\\big] & =  \\text{exp}\\left[\\text{log}\\left(\\dfrac{\\text{odds}_{X=x+1}} {\\text{odds}_{X=x}}\\right) \\right] \\\\\n\\text{exp}\\big[\\widehat{\\beta}_1\\big] & =  \\dfrac{\\text{odds}_{X=x+1}} {\\text{odds}_{X=x}} \\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example",
    "text": "Example\n\nWhat if we are interested in learning the OR corresponding to 10-year increase in age?\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\ntidy(bc_reg, conf.int=T) %&gt;% gt() %&gt;% tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n−0.989\n0.023\n−42.637\n0.000\n−1.035\n−0.944\n    Age_c\n0.057\n0.003\n17.780\n0.000\n0.051\n0.063"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#transformations-of-continuous-variable-to-make-more-interpretable",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#transformations-of-continuous-variable-to-make-more-interpretable",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Transformations of continuous variable to make more interpretable",
    "text": "Transformations of continuous variable to make more interpretable\n\nSometimes a change in “1” unit may not be considered clinically interesting\n\nFor example, a 1 year increase in age or a 1 mm Hg increase in systolic blood pressure may be too small for a meaningful change in log odds\nInstead, we may be interested to find out the log odds change for a increase of 10 years in age or 10 mm Hg in systolic blood pressure\nOn the other hand, if the range of x is small (say 0-1), than a change in 1 unit of 𝑥 is too large to be meaningful\n\nWe should be able to compute and interpret coefficients for a continuous independent covariate \\(x\\) for an arbitrary change of “c” units in \\(x\\)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-1",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example",
    "text": "Example\n\nWhat if we are interested in learning the OR corresponding to 10-year increase in age?\n\n\\[ \\widehat{OR}\\left(10\\right)=\\exp{\\left(10\\cdot{\\hat{\\beta}}_1\\right)}=\\exp{\\left(0.56965\\right)}=\\mathrm{\\mathrm{1.767}}\\]\n\nThe 95% CI for \\(\\widehat{OR}\\left(10\\right)\\) is: \\[\\begin{aligned} \\widehat{OR}\\left(10\\right) &=\\exp{\\left(10\\cdot{\\hat{\\beta}}_1\\pm1.96\\cdot10\\cdot SE_{\\hat{\\beta}_1} \\right)} \\\\ &=\\exp{\\left(10\\cdot0.056965\\pm1.96\\cdot10\\cdot0.003204\\right)}\\\\\n&=(1.66,\\ 1.88) \\end{aligned}\\]"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#introrecap-of-interpreting-fitted-model",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#introrecap-of-interpreting-fitted-model",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Intro/Recap of Interpreting Fitted Model",
    "text": "Intro/Recap of Interpreting Fitted Model\n\nInterpret coefficients from fitted logistic regression model\n\nGoodness-of-fit of model should be assessed before summarizing findings (have not covered yet)\nIn this lecture: assume model fits data well\n\nThe interpretation of the coefficients involves two issues:\n\nThe functional relationship between the dependent variable and the independent variable (link function)\nUnit of change for the independent variable\n\nWe will learn the interpretation for\n\nBinary independent variable\nCategorical independent variable with multiple groups\n\nWe looked at this for our race and ethnicity variable\n\nContinuous independent variable"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-continuous-independent-variable-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-continuous-independent-variable-1",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Coefficient interpretation: Continuous Independent Variable 1",
    "text": "Coefficient interpretation: Continuous Independent Variable 1\n\nFor simplicity, we assume the linear relationship between logit and continuous variable 𝑥\nAgain using simple logistic regression model to illustrate the interpretation of \\(\\widehat{\\beta}\\) for a continuous variable \\(x\\) \\[\\text{logit}(\\widehat{\\pi}(X)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X\\]\nThe estimated slope coefficient, \\(\\widehat{\\beta}_1\\), is the expected change in the log odds for 1 unit increase in \\(x\\)\n\nAdditional attention should be paid to picking a meaningful units of change in \\(x\\)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-continuous-independent-variable-2",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-continuous-independent-variable-2",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Coefficient Interpretation: Continuous Independent Variable 2",
    "text": "Coefficient Interpretation: Continuous Independent Variable 2\n\nSometimes a change in “1” unit may not be considered clinically interesting\n\nFor example, a 1 year increase in age or a 1 mm Hg increase in systolic blood pressure may be too small for a meaningful change in log odds\nInstead, we may be interested to find out the log odds change for a increase of 10 years in age or 10 mm Hg in systolic blood pressure\nOn the other hand, if the range of x is small (say 0-1), than a change in 1 unit of 𝑥 is too large to be meaningful\n\nWe should be able to compute and interpret coefficients for a continuous independent covariate 𝑥 for an arbitrary change of “c” units in 𝑥"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-continuous-independent-variable-3",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-continuous-independent-variable-3",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Coefficient Interpretation: Continuous Independent Variable 3",
    "text": "Coefficient Interpretation: Continuous Independent Variable 3"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-i",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-i",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: Age and Late Stage Diagnosis (I)",
    "text": "Example: Age and Late Stage Diagnosis (I)\n\n\nOdds ratio from logistic regression\n\n\nCompute the estimate and 95% confidence interval for odds ratio for late stage breast cancer diagnosis for every 1 year increase in age.\n\n\nNeeded steps:\n\nFit the regression model\nTransform the coefficients into odds ratios\nInterpret the odds ratio"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-2",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-2",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: Age and Late Stage Diagnosis 2",
    "text": "Example: Age and Late Stage Diagnosis 2\n\n\nOdds ratio from logistic regression\n\n\nCompute the estimate and 95% confidence interval for odds ratio for late stage breast cancer diagnosis for every 1 year increase in age.\n\n\n\nInterpret the odds ratio\n\nFor every one year increase in age, there is an estimated 5.86% increase in the estimated odds of late stage breast cancer diagnosis (95% CI: 5.2%, 6.53%)."
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-interpretation-of-age-coefficientor-i",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-interpretation-of-age-coefficientor-i",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: Interpretation of Age Coefficient/OR (I)",
    "text": "Example: Interpretation of Age Coefficient/OR (I)\n\n\\(\\widehat{\\beta}_1\\) is 0.057, suggesting that one year increase in age is associated with 0.057 increase in log odds of receiving a late stage breast cancer diagnosis\n\\(\\exp\\left({\\widehat{\\beta}}_1\\right)\\) is 1.06, suggesting that one year increase in age is associated with 1.06 times the odds of receiving a late stage breast cancer diagnosis\nFor continuous covariates in logistic regression model, it is helpful to subtract 1 from the odds ratio and multiply by 100 to obtain the percentage change in odds for 1-unit increase.\n\nThe estimated OR for age is 1.06, suggesting that a 1-year increase in age is associated with a 6% increase in the predicted odds of late stage diagnosis in the patient population"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-interpretation-of-age-coefficientor-i-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-interpretation-of-age-coefficientor-i-1",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: Interpretation of Age Coefficient/OR (I)",
    "text": "Example: Interpretation of Age Coefficient/OR (I)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-interpretation-of-age-coefficientor-i-2",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-interpretation-of-age-coefficientor-i-2",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: Interpretation of Age Coefficient/OR (I)",
    "text": "Example: Interpretation of Age Coefficient/OR (I)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#last-note-about-continuous-independent-variable",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#last-note-about-continuous-independent-variable",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Last Note About Continuous Independent Variable",
    "text": "Last Note About Continuous Independent Variable\n\nNotice that the logistic regression model suggests that logit is linear in the covariate\nThe model implies the additional risk of late stage breast cancer diagnosis for a 40 year-old compared to a 30 year-old is the same as the additional risk of late stage breast cancer diagnosis for a 60 year-old compared to a 50-year-old\nThis assumption may not be realistic\nTo address this, we may consider using higher order terms (e.g., \\(x^2\\), \\(x^3\\),…) or other nonlinear transformation(e.g., \\(log(x)\\))\nCategorize the continuous variable may be another option"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-binary-independent-variable",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-binary-independent-variable",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Coefficient Interpretation: Binary Independent Variable",
    "text": "Coefficient Interpretation: Binary Independent Variable\n\nIndependent variable \\(x\\) is a binary variable (\\(x\\) can take values: 0 or 1)\nWe are fitting the simple logistic regression model: \\[\\text{logit}\\left(\\pi(X) \\right) = \\beta_0 + \\beta_1 \\cdot I(X=1)\\]\nThe logit difference is \\(\\beta_1\\) for binary independent variable\n\n\\(\\beta_1\\) represents the change/difference in the logit for \\(x=1\\) vs. \\(x=0\\)\n\nIt will be much easier to understand if we can interpret the coefficient using odds ratio (OR)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#binary-how-do-we-interpret-the-coefficient-i",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#binary-how-do-we-interpret-the-coefficient-i",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Binary: How do we interpret the coefficient? (I)",
    "text": "Binary: How do we interpret the coefficient? (I)\n\nFor individuals with \\(X=0\\): \\[\\text{logit}\\left(\\pi(X=0)\\right)=\\beta_0+\\beta_1\\times\\left(0\\right)=\\beta_0\\]\nFor individuals with \\(X=1\\): \\[\\text{logit}\\left(\\pi(X=1)\\right)=\\beta_0+\\beta_1\\times\\left(1\\right)=\\beta_0 + \\beta_1\\]\nTo solve for \\(\\beta_1\\), we take the difference of the logits: \\[ \\text{logit}\\left(\\pi(X=1)\\right) - \\text{logit}\\left(\\pi(X=0)\\right) = \\left( \\beta_0 + \\beta_1 \\right) - \\left( \\beta_0 \\right) = \\beta_1\\]"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#binary-how-do-we-interpret-the-coefficient-ii",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#binary-how-do-we-interpret-the-coefficient-ii",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Binary: How do we interpret the coefficient? (II)",
    "text": "Binary: How do we interpret the coefficient? (II)\n\\[ \\text{logit}\\left(\\pi(X=1)\\right) - \\text{logit}\\left(\\pi(X=0)\\right) = \\left( \\beta_0 + \\beta_1 \\right) - \\left( \\beta_0 \\right) = \\beta_1\\]\n\\[\\begin{aligned}\n\\beta_1&=l\\mathrm{ogit}\\left(\\pi(X=1)\\right)\\ -l\\mathrm{ogit}\\left(\\pi\\left(X=0\\right)\\right) \\\\  \\beta_1&=l\\mathrm{og}\\left(\\dfrac{\\pi(X=1)}{1-\\pi(X=1)}\\right)-l\\mathrm{og}\\left(\\dfrac{\\pi\\left(X=0\\right)}{1-\\pi\\left(X=0\\right)}\\right) \\\\\n\\beta_1&=\\log{\\left(\\dfrac{\\dfrac{\\pi(X=1)}{1-\\pi(X=1)}}{\\dfrac{\\pi(X=0)}{1-\\pi(X=0)}}\\right)} \\\\ \\exp{\\left(\\beta_1\\right)}&=\\dfrac{\\dfrac{\\pi(X=1)}{1-\\pi(X=1)}}{\\dfrac{\\pi(X=0)}{1-\\pi(X=0)}}\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#review-of-odds-ratio",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#review-of-odds-ratio",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Review of Odds Ratio",
    "text": "Review of Odds Ratio\n\nOdds for a subject with \\(X=1\\): \\[\\text{odds}_1 = \\dfrac{\\pi(X=1)}{1-\\pi(X=1)}\\]\nOdds for a subject with \\(X=0\\): \\[\\text{odds}_0 = \\dfrac{\\pi(X=0)}{1-\\pi(X=0)}\\]\nOdds Ratio for \\(X=1\\) vs. \\(X=0\\): \\[OR = \\dfrac{\\dfrac{\\pi(X=1)}{1-\\pi(X=1)}}{\\dfrac{\\pi(X=0)}{1-\\pi(X=0)}}\\]"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-does-this-relate-to-a-2x2-table",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-does-this-relate-to-a-2x2-table",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "How does this relate to a 2x2 table?",
    "text": "How does this relate to a 2x2 table?\n\n\n\n2x2 table with the respective logistic functions in each cell"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#poll-everywhere-question-3",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#poll-everywhere-question-3",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Poll Everywhere Question 3",
    "text": "Poll Everywhere Question 3"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-does-this-relate-to-a-2x2-table-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-does-this-relate-to-a-2x2-table-1",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "How does this relate to a 2x2 table?",
    "text": "How does this relate to a 2x2 table?\n\\[\nOR=\\dfrac{a/c}{b/d}=\\dfrac{\\dfrac{\\left(\\dfrac{\\exp{\\left(\\beta_0+\\beta_1\\right)}}{1+\\exp{\\left(\\beta_0+\\beta_1\\right)}}\\right)}{\\left(\\dfrac{1}{1+\\exp(\\beta_0+\\beta_1)}\\right)}}{\\dfrac{\\left(\\dfrac{\\exp(\\beta_0)}{1+\\exp(\\beta_0)}\\right)}{\\left(\\dfrac{1}{1+\\exp{\\left(\\beta_0\\right)}}\\right)}}=\\dfrac{\\exp(\\beta_0+\\beta_1)}{\\exp(\\beta_0)}=e^{\\beta_1}\n\\]\n\nSimple relationship between coefficient and odds ratio is a primary reason why we report OR for categorical data analysis.\nFor binary independent variable x, OR computed in logistic regression model is the same as OR computed using contingency table"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-binary-age-and-late-stage-diagnosis-i",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-binary-age-and-late-stage-diagnosis-i",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Binary age and Late Stage Diagnosis (I)",
    "text": "Example: Binary age and Late Stage Diagnosis (I)\n\n\nOdds ratio from logistic regression\n\n\nWhat is the odds ratio of late stage breast cancer diagnosis for older individuals (&gt;65 years old) compared to younger individuals (≤65 years old)?\n\n\n\nTwo options to calculate this value:\n\nOption 1: Calculate \\(\\widehat{OR}\\) from 2x2 contingency table\n\nRefer to Lesson 3 for this process\n\nOption 2: Calculate \\(\\widehat{OR}\\) from logistic regression\n\n\nNeeded steps for Option 2:\n\nFit the regression model\nTransform the coefficients into odds ratios\nInterpret the odds ratio"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#computing-or-from-𝛽-i",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#computing-or-from-𝛽-i",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Computing OR from 𝛽 (I)",
    "text": "Computing OR from 𝛽 (I)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-multi-group-categorical-variable",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-multi-group-categorical-variable",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Coefficient Interpretation: Multi-group Categorical Variable",
    "text": "Coefficient Interpretation: Multi-group Categorical Variable\n\nIndependent variable \\(x\\) is a multi-level categorical variable\nLet’s say \\(X\\) takes values: a, b, c, or d\nWe are fitting the simple logistic regression model: \\[\\text{logit}\\left(\\pi(X) \\right) = \\beta_0 + \\beta_1 \\cdot I(X=b) + \\beta_2 \\cdot I(X=c) + \\beta_3 \\cdot I(X=d)\\]\n\nWhere \\(a\\) is our reference group\n\nThe logit difference is \\(\\beta_1\\) for binary independent variable\n\n\\(\\beta_1\\) represents the change/difference in the logit for \\(x=b\\) vs. \\(x=a\\)\n\nIt will be much easier to understand if we can interpret the coefficient using odds ratio (OR)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-do-we-pick-the-reference-group",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-do-we-pick-the-reference-group",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "How do we pick the reference group?",
    "text": "How do we pick the reference group?\n\nThe choice can be more apparent for multi-group categorical independent variables within studies\nFor example, if we want to evaluate the association between clinical response and four treatments.\n\nThe treatment variable has 4 categories: “active treatment A”, “active treatment B”, “active treatment C” and “Placebo treatment”\nThe investigator is interested in comparing each of the three active treatment with the placebo treatment\nThen the placebo treatment should be picked as the reference group"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-late-stage-diagnosis-and-race-and-ethnicity",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-late-stage-diagnosis-and-race-and-ethnicity",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Late stage diagnosis and race and ethnicity",
    "text": "Example: Late stage diagnosis and race and ethnicity\n\n\n\nChose Non-Hispanic White individuals as reference group\nUnderlying health disparities linked to racism in healthcare and in clinical studies\nThere is evidence that white individuals receive a certain standard of care that is not paralleled for POC Mateo and Williams (2021)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#what-if-you-want-to-compare-other-groups",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#what-if-you-want-to-compare-other-groups",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "What if you want to compare other groups?",
    "text": "What if you want to compare other groups?\n\nWhat if we want to estimate OR comparing Non-Hispanic Asian Pacific Islander to Non-Hispanic Black individuals?\nOption 1: Change reference group and refit the model (maybe the easiest option)\nOption 2: Estimate OR using fitted coefficients (\\(\\widehat{\\beta}\\)’s) in the current model: \\[\\begin{aligned} \\text{log}\\left( OR (\\text{NH API}, \\text{NH B}) \\right) &= \\text{logit}\\left(\\pi \\left(X = \\text{NH API}\\right)\\right) - \\text{logit}\\left(\\pi \\left(X = \\text{NH B}\\right)\\right) \\\\\n& = \\left[\\beta_0 + \\beta_3 \\cdot 1\\right] - \\left[\\beta_0 + \\beta_4 \\cdot 1 \\right] \\\\\n\\text{log}\\left( \\widehat{OR} (\\text{NH API}, \\text{NH B}) \\right) &= \\widehat{\\beta}_3 - \\widehat{\\beta}_4 \\\\\n\\widehat{OR} (\\text{NH API}, \\text{NH B}) &= \\exp \\left( \\widehat{\\beta}_3 - \\widehat{\\beta}_4 \\right)\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#poll-everywhere-question-5",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#poll-everywhere-question-5",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Poll Everywhere Question 5",
    "text": "Poll Everywhere Question 5"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#transformations-of-continuous-variable-to-make-more-interpretable-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#transformations-of-continuous-variable-to-make-more-interpretable-1",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Transformations of continuous variable to make more interpretable",
    "text": "Transformations of continuous variable to make more interpretable\n\nThe estimated log odds ratio for a change of c units in x can be obtained from \\[\\hat{g}\\left(x+c\\right)-\\hat{g}\\left(x\\right)=c{\\hat{\\beta}}_1\\]\n\n\\(\\widehat{OR}\\left(c\\right)=\\exp\\left(c{\\hat{\\beta}}_1\\right)\\)\n\nThe 95% CI for \\(\\widehat{OR}(c)\\) is: \\[\\exp \\left( c \\hat{\\beta}_1 \\pm 1.96 \\cdot c \\cdot SE_{\\hat{\\beta}_1} \\right)\\]\nThe \\(c\\) is chosen to be a clinically meaningful unit change in \\(x\\)\nThe value of 𝑐 should be clearly specified in all tables and calculations\n\nBecause the estimated OR and the corresponding CI depends on the choice of 𝑐 value"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-2",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-2",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example",
    "text": "Example\n\nWhat if we are interested in learning the OR corresponding to 10-year increase in age?\n\n\nbc2 = bc %&gt;% mutate(Age_c_10 = Age_c/10)\nbc_reg_10 = glm(Late_stage_diag ~ Age_c_10, data = bc2, family = binomial)\ntidy(bc_reg_10, conf.int=T, exponentiate = T) %&gt;% gt() %&gt;% tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n0.372\n0.023\n−42.637\n0.000\n0.355\n0.389\n    Age_c_10\n1.768\n0.032\n17.780\n0.000\n1.661\n1.883"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-3",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-3",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example",
    "text": "Example\n\nHow do we do this in R?\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\ntidy(bc_reg, conf.int=T, exponentiate=T) %&gt;% gt() %&gt;% \n  tab_options(table.font.size = 35) %&gt;% fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n0.372\n0.023\n−42.637\n0.000\n0.355\n0.389\n    Age_c\n1.059\n0.003\n17.780\n0.000\n1.052\n1.065\n  \n  \n  \n\n\n\nlogistic.display(bc_reg, decimal = 3)\n\n\nLogistic regression predicting Late_stage_diag : 1 vs 0 \n \n                   OR(95%CI)            P(Wald's test) P(LR-test)\nAge_c (cont. var.) 1.059 (1.052,1.065)  &lt; 0.001        &lt; 0.001   \n                                                                 \nLog-likelihood = -5754.84419\nNo. of observations = 10000\nAIC value = 11513.68837"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-4",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-4",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example",
    "text": "Example\nFor our fitted simple logistic regression model with age as a predictor \\[\\text{logit}(\\widehat{\\pi}(Age)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot Age\\]\n\n\\(\\widehat{\\beta}_0\\): estimated log-odds when age is 61.71 years\n\\(\\widehat{\\beta}_1\\): estimated increase in log-odds for every 1 year increase in age"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-i-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-i-1",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: Age and Late Stage Diagnosis (I)",
    "text": "Example: Age and Late Stage Diagnosis (I)\n\n\nOdds ratio from logistic regression\n\n\nCompute the estimate and 95% confidence interval for odds ratio for late stage breast cancer diagnosis for every 1 year increase in age.\n\n\n\nFit the regression model\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nsummary(bc_reg)\n\n\nCall:\nglm(formula = Late_stage_diag ~ Age_c, family = binomial, data = bc)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.989422   0.023205  -42.64   &lt;2e-16 ***\nAge_c        0.056965   0.003204   17.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 11861  on 9999  degrees of freedom\nResidual deviance: 11510  on 9998  degrees of freedom\nAIC: 11514\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-i-2",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-i-2",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: Age and Late Stage Diagnosis (I)",
    "text": "Example: Age and Late Stage Diagnosis (I)\n\n\nOdds ratio from logistic regression\n\n\nCompute the estimate and 95% confidence interval for odds ratio for late stage breast cancer diagnosis for every 1 year increase in age.\n\n\n\nTransform the coefficients into odds ratios\n\n\nOption 1: tidy()\n\n\ntidy_bc_reg = tidy(bc_reg, conf.int=T, exponentiate = T) \ntidy_bc_reg %&gt;% gt() %&gt;% tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n0.372\n0.023\n−42.637\n0.000\n0.355\n0.389\n    Age_c\n1.059\n0.003\n17.780\n0.000\n1.052\n1.065\n  \n  \n  \n\n\n\ntidy_bc_reg$conf.low # I prefer tidy() bc now I can grab each component\n\n[1] 0.3551931 1.0520321"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-i-3",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-i-3",
    "title": "Lesson 8: Interpretations and Visualizations of Results in Simple Logistic Regression",
    "section": "Example: Age and Late Stage Diagnosis (I)",
    "text": "Example: Age and Late Stage Diagnosis (I)\n\n\nOdds ratio from logistic regression\n\n\nCompute the estimate and 95% confidence interval for odds ratio for late stage breast cancer diagnosis for every 1 year increase in age.\n\n\n\nTransform the coefficients into odds ratios\n\n\nOption 2: logistic.display()\n\n\nlogistic.display(bc_reg) # Cannot grab each component in this\n\n\nLogistic regression predicting Late_stage_diag : 1 vs 0 \n \n                   OR(95%CI)         P(Wald's test) P(LR-test)\nAge_c (cont. var.) 1.06 (1.05,1.07)  &lt; 0.001        &lt; 0.001   \n                                                              \nLog-likelihood = -5754.8442\nNo. of observations = 10000\nAIC value = 11513.6884"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-interpretation-of-age-coefficientor",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-interpretation-of-age-coefficientor",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Interpretation of Age Coefficient/OR",
    "text": "Example: Interpretation of Age Coefficient/OR\n\n\\(\\widehat{\\beta}_1\\) is 0.057, suggesting that one year increase in age is associated with 0.057 increase in log odds of receiving a late stage breast cancer diagnosis\n\\(\\exp\\left({\\widehat{\\beta}}_1\\right)\\) is 1.06, suggesting that one year increase in age is associated with 1.06 times the odds of receiving a late stage breast cancer diagnosis\nFor continuous covariates in logistic regression model, it is helpful to subtract 1 from the odds ratio and multiply by 100 to obtain the percentage change in odds for 1-unit increase.\n\nThe estimated OR for age is 1.06, suggesting that a 1-year increase in age is associated with a 6% increase in the predicted odds of late stage diagnosis in the patient population"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#poll-everywhere-question-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#poll-everywhere-question-1",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Poll Everywhere Question 1",
    "text": "Poll Everywhere Question 1"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#poll-everywhere-question-1-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#poll-everywhere-question-1-1",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Poll Everywhere Question 1",
    "text": "Poll Everywhere Question 1"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#poll-everywhere-question-2",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#poll-everywhere-question-2",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Poll Everywhere Question 2",
    "text": "Poll Everywhere Question 2"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-binary-age-and-late-stage-diagnosis-i-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-binary-age-and-late-stage-diagnosis-i-1",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Binary age and Late Stage Diagnosis (I)",
    "text": "Example: Binary age and Late Stage Diagnosis (I)\n\n\nOdds ratio from logistic regression\n\n\nWhat is the odds ratio of late stage breast cancer diagnosis for older individuals (&gt;65 years old) compared to younger individuals (≤65 years old)?\n\n\n\nFit the regression model\n\n\nbc3 = bc %&gt;% mutate(Age_binary = ifelse(Age &gt; 65, 1, 0))\nage_bin_glm = glm(Late_stage_diag ~ Age_binary, data = bc3, family = binomial)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-binary-age-and-late-stage-diagnosis-i-2",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-binary-age-and-late-stage-diagnosis-i-2",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Binary age and Late Stage Diagnosis (I)",
    "text": "Example: Binary age and Late Stage Diagnosis (I)\n\n\nOdds ratio from logistic regression\n\n\nWhat is the odds ratio of late stage breast cancer diagnosis for older individuals (&gt;65 years old) compared to younger individuals (≤65 years old)?\n\n\n\nTransform the coefficients into odds ratios\n\n\nage_bin_tidy = tidy(age_bin_glm, conf.int=T, exponentiate = T) \nage_bin_tidy %&gt;% gt() %&gt;%\n  tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n0.297\n0.031\n−39.608\n0.000\n0.280\n0.315\n    Age_binary\n1.875\n0.045\n13.928\n0.000\n1.716\n2.048"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-binary-age-and-late-stage-diagnosis-i-3",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-binary-age-and-late-stage-diagnosis-i-3",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Binary age and Late Stage Diagnosis (I)",
    "text": "Example: Binary age and Late Stage Diagnosis (I)\n\n\nOdds ratio from logistic regression\n\n\nWhat is the odds ratio of late stage breast cancer diagnosis for older individuals (&gt;65 years old) compared to younger individuals (≤65 years old)?\n\n\n\nInterpret the odds ratio\n\nThe estimated odds of late stage breast cancer among individuals over 65 years old is 1.87 (95% CI: (1.72, 2.05)) times that of individuals 65 years or younger."
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-multi-group-categorical-variable-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-multi-group-categorical-variable-1",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Coefficient Interpretation: Multi-group Categorical Variable",
    "text": "Coefficient Interpretation: Multi-group Categorical Variable\nWe are fitting the simple logistic regression model with reference group \\(a\\): \\[\\text{logit}\\left(\\pi(X) \\right) = \\beta_0 + \\beta_1 \\cdot I(X=b) + \\beta_2 \\cdot I(X=c) + \\beta_3 \\cdot I(X=d)\\]\n\n\\(\\beta_0\\): the log-odds of event \\(Y=1\\) for group \\(a\\)\n\\(\\beta_1\\): the difference in log-odds of event \\(Y=1\\) comparing group \\(b\\) to group \\(a\\)\n\\(\\beta_2\\): the difference in log-odds of event \\(Y=1\\) comparing group \\(c\\) to group \\(a\\)\n\\(\\beta_3\\): the difference in log-odds of event \\(Y=1\\) comparing group \\(d\\) to group \\(a\\)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#multi-level-categorical-how-do-we-interpret-the-coefficient-ii",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#multi-level-categorical-how-do-we-interpret-the-coefficient-ii",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Multi-level categorical: How do we interpret the coefficient? (II)",
    "text": "Multi-level categorical: How do we interpret the coefficient? (II)\n\\[ \\text{logit}\\left(\\pi(X=c)\\right) - \\text{logit}\\left(\\pi(X=a)\\right) = \\left( \\beta_0 + \\beta_1\\cdot 0 + \\beta_2\\cdot 1 + \\beta_3\\cdot 0  \\right) - \\left( \\beta_0 + \\beta_1\\cdot 0 + \\beta_2\\cdot 0 + \\beta_3\\cdot 0 \\right) = \\beta_2\\]\n\\[\\begin{aligned}\n\\beta_2&=l\\mathrm{ogit}\\left(\\pi(X=c)\\right)\\ -l\\mathrm{ogit}\\left(\\pi\\left(X=a\\right)\\right) \\\\  \\beta_2&=l\\mathrm{og}\\left(\\dfrac{\\pi(X=c)}{1-\\pi(X=c)}\\right)-l\\mathrm{og}\\left(\\dfrac{\\pi\\left(X=a\\right)}{1-\\pi\\left(X=a\\right)}\\right) \\\\\n\\beta_2&=\\log{\\left(\\dfrac{\\dfrac{\\pi(X=c)}{1-\\pi(X=c)}}{\\dfrac{\\pi(X=a)}{1-\\pi(X=a)}}\\right)} \\\\ \\exp{\\left(\\beta_2\\right)}&=\\dfrac{\\dfrac{\\pi(X=c)}{1-\\pi(X=c)}}{\\dfrac{\\pi(X=a)}{1-\\pi(X=a)}}\n\\end{aligned}\\]"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-multi-group-categorical-variable-2",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-multi-group-categorical-variable-2",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Coefficient Interpretation: Multi-group Categorical Variable",
    "text": "Coefficient Interpretation: Multi-group Categorical Variable\nWe are fitting the simple logistic regression model with reference group \\(a\\): \\[\\text{logit}\\left(\\pi(X) \\right) = \\beta_0 + \\beta_1 \\cdot I(X=b) + \\beta_2 \\cdot I(X=c) + \\beta_3 \\cdot I(X=d)\\]\n\n\\(\\exp\\left(\\beta_0\\right)\\): the odds of event \\(Y=1\\) for group \\(a\\)\n\\(\\exp\\left(\\beta_1\\right)\\): the odds of event \\(Y=1\\) for group \\(b\\) is \\(\\exp\\left(\\beta_1\\right)\\) times the odds of event \\(Y=1\\) for group \\(a\\)\n\\(\\exp\\left(\\beta_2\\right)\\): the odds of event \\(Y=1\\) for group \\(c\\) is \\(\\exp\\left(\\beta_2\\right)\\) times the odds of event \\(Y=1\\) for group \\(a\\)\n\\(\\exp\\left(\\beta_3\\right)\\): the odds of event \\(Y=1\\) for group \\(d\\) is \\(\\exp\\left(\\beta_3\\right)\\) times the odds of event \\(Y=1\\) for group \\(a\\)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#references",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#references",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "References",
    "text": "References\n\n\nLesson 8: Interpretations and Visualizations of Odds Ratios\n\n\n\nMateo, Camila M., and David R. Williams. 2021. “Racism: A Fundamental Driver of Racial Disparities in Health-Care Quality.” Nature Reviews Disease Primers 7 (1): 1–2. https://doi.org/10.1038/s41572-021-00258-1.\n\n\nYedjou, Clement G., Jennifer N. Sims, Lucio Miele, Felicite Noubissi, Leroy Lowe, Duber D. Fonseca, Richard A. Alo, Marinelle Payton, and Paul B. Tchounwou. 2019. “Health and Racial Disparity in Breast Cancer.” Advances in Experimental Medicine and Biology 1152: 31–49. https://doi.org/10.1007/978-3-030-20301-6_3."
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-late-stage-diagnosis-and-race-and-ethnicity-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-late-stage-diagnosis-and-race-and-ethnicity-1",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Late stage diagnosis and race and ethnicity",
    "text": "Example: Late stage diagnosis and race and ethnicity\n\n\nOdds ratio from logistic regression\n\n\nWhat is the odds ratio of late stage breast cancer diagnosis for Non-Hispanic Asian/Pacific Islander individuals compared to Non-Hispanic White individuals?\n\n\nNeeded steps:\n\nFit the regression model\nTransform the coefficients into odds ratios\nInterpret the odds ratio"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-late-stage-diagnosis-and-race-and-ethnicity-2",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-late-stage-diagnosis-and-race-and-ethnicity-2",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Late stage diagnosis and race and ethnicity",
    "text": "Example: Late stage diagnosis and race and ethnicity\n\n\nOdds ratio from logistic regression\n\n\nWhat is the odds ratio of late stage breast cancer diagnosis for Non-Hispanic Asian/Pacific Islander individuals compared to Non-Hispanic White individuals?\n\n\n\nFit the regression model\n\n\nRE_glm = glm(Late_stage_diag ~ Race_Ethnicity, data = bc,  \n               family = binomial)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-late-stage-diagnosis-and-race-and-ethnicity-3",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-late-stage-diagnosis-and-race-and-ethnicity-3",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Late stage diagnosis and race and ethnicity",
    "text": "Example: Late stage diagnosis and race and ethnicity\n\n\nOdds ratio from logistic regression\n\n\nWhat is the odds ratio of late stage breast cancer diagnosis for Non-Hispanic Asian/Pacific Islander individuals compared to Non-Hispanic White individuals?\n\n\n\nTransform the coefficients into odds ratios\n\n\nRE_tidy = tidy(RE_glm, conf.int=T, exponentiate = T) \nRE_tidy %&gt;% gt() %&gt;%\n  tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n0.372\n0.026\n−37.553\n0.000\n0.353\n0.392\n    Race_EthnicityHispanic-Latino\n0.968\n0.082\n−0.398\n0.691\n0.822\n1.135\n    Race_EthnicityNH American Indian/Alaskan Native\n0.948\n0.476\n−0.111\n0.911\n0.342\n2.287\n    Race_EthnicityNH Asian/Pacific Islander\n1.131\n0.082\n1.497\n0.134\n0.961\n1.327\n    Race_EthnicityNH Black\n1.405\n0.070\n4.826\n0.000\n1.223\n1.611"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-late-stage-diagnosis-and-race-and-ethnicity-4",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-late-stage-diagnosis-and-race-and-ethnicity-4",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Late stage diagnosis and race and ethnicity",
    "text": "Example: Late stage diagnosis and race and ethnicity\n\n\nOdds ratio from logistic regression\n\n\nWhat is the odds ratio of late stage breast cancer diagnosis for Non-Hispanic Asian/Pacific Islander individuals compared to Non-Hispanic White individuals?\n\n\n\nInterpret the odds ratio\n\nThe estimated odds of late stage breast cancer among Non-Hispanic Asian/Pacific Islander individuals is 1.13 (95% CI: (0.96, 1.33)) times that of Non-Hispanic White individuals."
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#what-if-you-want-to-compare-other-groups-option-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#what-if-you-want-to-compare-other-groups-option-1",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "What if you want to compare other groups? Option 1",
    "text": "What if you want to compare other groups? Option 1\n\nbc3 = bc %&gt;% \n  mutate(Race_Ethnicity = relevel(Race_Ethnicity, ref = \"NH Black\"))\nRE_glm2 = glm(Late_stage_diag ~ Race_Ethnicity, data = bc3, \n               family = binomial)\ntidy(RE_glm2, conf.int=T, exponentiate = T) %&gt;% gt() %&gt;%\n  tab_options(table.font.size = 38) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n0.523\n0.065\n−9.934\n0.000\n0.459\n0.594\n    Race_EthnicityNH White\n0.712\n0.070\n−4.826\n0.000\n0.621\n0.818\n    Race_EthnicityHispanic-Latino\n0.689\n0.102\n−3.664\n0.000\n0.564\n0.840\n    Race_EthnicityNH American Indian/Alaskan Native\n0.675\n0.479\n−0.819\n0.413\n0.242\n1.641\n    Race_EthnicityNH Asian/Pacific Islander\n0.805\n0.102\n−2.131\n0.033\n0.659\n0.982"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-to-present-odds-ratios-table",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-to-present-odds-ratios-table",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "How to present odds ratios: Table",
    "text": "How to present odds ratios: Table\n\ntbl_regression() in the gtsummary package is helpful for presenting the odds ratios in a clean way\n\n\nlibrary(gtsummary)\ntbl_regression(RE_glm, exponentiate = TRUE) %&gt;% \n  as_gt() %&gt;% # allows us to use tab_options()\n  tab_options(table.font.size = 38)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    Race_Ethnicity\n\n\n\n        NH White\n—\n—\n\n        Hispanic-Latino\n0.97\n0.82, 1.14\n0.7\n        NH American Indian/Alaskan Native\n0.95\n0.34, 2.29\n&gt;0.9\n        NH Asian/Pacific Islander\n1.13\n0.96, 1.33\n0.13\n        NH Black\n1.40\n1.22, 1.61\n&lt;0.001\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-to-present-odds-ratios-forest-plot",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-to-present-odds-ratios-forest-plot",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "How to present odds ratios: Forest Plot",
    "text": "How to present odds ratios: Forest Plot\n\nggplot(data=RE_tidy, aes(y=label, x=estimate, xmin=conf.low, xmax=conf.high)) + \n  geom_point(size = 3) +  geom_errorbarh(height=.2) + \n  geom_vline(xintercept=1, color='#C2352F', linetype='dashed', alpha=1) +\n  theme_classic() +\n  labs(x = \"OR (95% CI)\", y = \"Race and ethnicity\", \n       title = \"Odds ratios of Late Stage \\n Breast Cancer Diagnosis\") +\n  theme(axis.title = element_text(size = 25), axis.text = element_text(size = 25), title = element_text(size = 25))"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-to-present-odds-ratios-forest-plot-setup",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#how-to-present-odds-ratios-forest-plot-setup",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "How to present odds ratios: Forest Plot Setup",
    "text": "How to present odds ratios: Forest Plot Setup\n\nlibrary(broom.helpers)\nRE_tidy = tidy_and_attach(RE_glm, conf.int=T, exponentiate = T) %&gt;%\n  tidy_remove_intercept() %&gt;%\n  tidy_add_reference_rows() %&gt;% tidy_add_estimate_to_reference_rows() %&gt;%\n  tidy_add_term_labels()\nglimpse(RE_tidy)\n\nRows: 5\nColumns: 16\n$ term           &lt;chr&gt; \"Race_EthnicityNH White\", \"Race_EthnicityHispanic-Latin…\n$ variable       &lt;chr&gt; \"Race_Ethnicity\", \"Race_Ethnicity\", \"Race_Ethnicity\", \"…\n$ var_label      &lt;chr&gt; \"Race_Ethnicity\", \"Race_Ethnicity\", \"Race_Ethnicity\", \"…\n$ var_class      &lt;chr&gt; \"factor\", \"factor\", \"factor\", \"factor\", \"factor\"\n$ var_type       &lt;chr&gt; \"categorical\", \"categorical\", \"categorical\", \"categoric…\n$ var_nlevels    &lt;int&gt; 5, 5, 5, 5, 5\n$ contrasts      &lt;chr&gt; \"contr.treatment\", \"contr.treatment\", \"contr.treatment\"…\n$ contrasts_type &lt;chr&gt; \"treatment\", \"treatment\", \"treatment\", \"treatment\", \"tr…\n$ reference_row  &lt;lgl&gt; TRUE, FALSE, FALSE, FALSE, FALSE\n$ label          &lt;chr&gt; \"NH White\", \"Hispanic-Latino\", \"NH American Indian/Alas…\n$ estimate       &lt;dbl&gt; 1.0000000, 0.9678002, 0.9484848, 1.1310170, 1.4046741\n$ std.error      &lt;dbl&gt; NA, 0.08224948, 0.47558680, 0.08224988, 0.07041472\n$ statistic      &lt;dbl&gt; NA, -0.3979312, -0.1112089, 1.4968682, 4.8257715\n$ p.value        &lt;dbl&gt; NA, 6.906809e-01, 9.114507e-01, 1.344276e-01, 1.394623e…\n$ conf.low       &lt;dbl&gt; NA, 0.8223138, 0.3417844, 0.9612074, 1.2226824\n$ conf.high      &lt;dbl&gt; NA, 1.135332, 2.286596, 1.327092, 1.611466"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-continuous-independent-variable",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#coefficient-interpretation-continuous-independent-variable",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Coefficient interpretation: Continuous Independent Variable",
    "text": "Coefficient interpretation: Continuous Independent Variable\n\nFor simplicity, we assume the linear relationship between logit and continuous variable 𝑥\nAgain using simple logistic regression model to illustrate the interpretation of \\(\\widehat{\\beta}\\) for a continuous variable \\(x\\) \\[\\text{logit}(\\widehat{\\pi}(X)) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X\\]\nThe estimated slope coefficient, \\(\\widehat{\\beta}_1\\), is the expected change in the log odds for 1 unit increase in \\(x\\)\n\nAdditional attention should be paid to picking a meaningful units of change in \\(x\\)"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-15",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-15",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Age and Late Stage Diagnosis (1/5)",
    "text": "Example: Age and Late Stage Diagnosis (1/5)\n\n\nOdds ratio from logistic regression\n\n\nCompute the estimate and 95% confidence interval for odds ratio for late stage breast cancer diagnosis for every 1 year increase in age.\n\n\nNeeded steps:\n\nFit the regression model\nTransform the coefficients into odds ratios\nInterpret the odds ratio"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-25",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-25",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Age and Late Stage Diagnosis (2/5)",
    "text": "Example: Age and Late Stage Diagnosis (2/5)\n\n\nOdds ratio from logistic regression\n\n\nCompute the estimate and 95% confidence interval for odds ratio for late stage breast cancer diagnosis for every 1 year increase in age.\n\n\n\nFit the regression model\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\nsummary(bc_reg)\n\n\nCall:\nglm(formula = Late_stage_diag ~ Age_c, family = binomial, data = bc)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.989422   0.023205  -42.64   &lt;2e-16 ***\nAge_c        0.056965   0.003204   17.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 11861  on 9999  degrees of freedom\nResidual deviance: 11510  on 9998  degrees of freedom\nAIC: 11514\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-35",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-35",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Age and Late Stage Diagnosis (3/5)",
    "text": "Example: Age and Late Stage Diagnosis (3/5)\n\n\nOdds ratio from logistic regression\n\n\nCompute the estimate and 95% confidence interval for odds ratio for late stage breast cancer diagnosis for every 1 year increase in age.\n\n\n\nTransform the coefficients into odds ratios\n\n\nOption 1: tidy()\n\n\ntidy_bc_reg = tidy(bc_reg, conf.int=T, exponentiate = T) \ntidy_bc_reg %&gt;% gt() %&gt;% tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n0.372\n0.023\n−42.637\n0.000\n0.355\n0.389\n    Age_c\n1.059\n0.003\n17.780\n0.000\n1.052\n1.065\n  \n  \n  \n\n\n\ntidy_bc_reg$conf.low # I prefer tidy() bc now I can grab each component\n\n[1] 0.3551931 1.0520321"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-45",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-45",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Age and Late Stage Diagnosis (4/5)",
    "text": "Example: Age and Late Stage Diagnosis (4/5)\n\n\nOdds ratio from logistic regression\n\n\nCompute the estimate and 95% confidence interval for odds ratio for late stage breast cancer diagnosis for every 1 year increase in age.\n\n\n\nTransform the coefficients into odds ratios\n\n\nOption 2: logistic.display()\n\n\nlogistic.display(bc_reg) # Cannot grab each component in this\n\n\nLogistic regression predicting Late_stage_diag : 1 vs 0 \n \n                   OR(95%CI)         P(Wald's test) P(LR-test)\nAge_c (cont. var.) 1.06 (1.05,1.07)  &lt; 0.001        &lt; 0.001   \n                                                              \nLog-likelihood = -5754.8442\nNo. of observations = 10000\nAIC value = 11513.6884"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-55",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-age-and-late-stage-diagnosis-55",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: Age and Late Stage Diagnosis (5/5)",
    "text": "Example: Age and Late Stage Diagnosis (5/5)\n\n\nOdds ratio from logistic regression\n\n\nCompute the estimate and 95% confidence interval for odds ratio for late stage breast cancer diagnosis for every 1 year increase in age.\n\n\n\nInterpret the odds ratio\n\nFor every one year increase in age, there is an estimated 5.86% increase in the estimated odds of late stage breast cancer diagnosis (95% CI: 5.2%, 6.53%)."
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-10-year-increase-in-age-and-late-stage-diagnosis",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-10-year-increase-in-age-and-late-stage-diagnosis",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: 10 year increase in age and Late Stage Diagnosis",
    "text": "Example: 10 year increase in age and Late Stage Diagnosis\n\nWhat if we are interested in learning the OR corresponding to 10-year increase in age?\n\n\nbc_reg = glm(Late_stage_diag ~ Age_c, data = bc, family = binomial)\ntidy(bc_reg, conf.int=T) %&gt;% gt() %&gt;% tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n−0.989\n0.023\n−42.637\n0.000\n−1.035\n−0.944\n    Age_c\n0.057\n0.003\n17.780\n0.000\n0.051\n0.063"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-10-year-increase-in-age-and-late-stage-diagnosis-1",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-10-year-increase-in-age-and-late-stage-diagnosis-1",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: 10 year increase in age and Late Stage Diagnosis",
    "text": "Example: 10 year increase in age and Late Stage Diagnosis\n\nWhat if we are interested in learning the OR corresponding to 10-year increase in age?\n\n\\[ \\widehat{OR}\\left(10\\right)=\\exp{\\left(10\\cdot{\\hat{\\beta}}_1\\right)}=\\exp{\\left(0.56965\\right)}=\\mathrm{\\mathrm{1.767}}\\]\n\nThe 95% CI for \\(\\widehat{OR}\\left(10\\right)\\) is: \\[\\begin{aligned} \\widehat{OR}\\left(10\\right) &=\\exp{\\left(10\\cdot{\\hat{\\beta}}_1\\pm1.96\\cdot10\\cdot SE_{\\hat{\\beta}_1} \\right)} \\\\ &=\\exp{\\left(10\\cdot0.056965\\pm1.96\\cdot10\\cdot0.003204\\right)}\\\\\n&=(1.66,\\ 1.88) \\end{aligned}\\]"
  },
  {
    "objectID": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-10-year-increase-in-age-and-late-stage-diagnosis-2",
    "href": "lectures/08_Interpretations_SLR/08_Interpretations_SLR.html#example-10-year-increase-in-age-and-late-stage-diagnosis-2",
    "title": "Lesson 8: Interpretations and Visualizations of Odds Ratios",
    "section": "Example: 10 year increase in age and Late Stage Diagnosis",
    "text": "Example: 10 year increase in age and Late Stage Diagnosis\n\nWhat if we are interested in learning the OR corresponding to 10-year increase in age?\n\n\nbc2 = bc %&gt;% mutate(Age_c_10 = Age_c/10)\nbc_reg_10 = glm(Late_stage_diag ~ Age_c_10, data = bc2, family = binomial)\ntidy(bc_reg_10, conf.int=T, exponentiate = T) %&gt;% gt() %&gt;% tab_options(table.font.size = 35) %&gt;%\n  fmt_number(decimals = 3)\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n0.372\n0.023\n−42.637\n0.000\n0.355\n0.389\n    Age_c_10\n1.768\n0.032\n17.780\n0.000\n1.661\n1.883"
  },
  {
    "objectID": "project/Lab_03_instructions.html",
    "href": "project/Lab_03_instructions.html",
    "title": "Lab 2 Instructions",
    "section": "",
    "text": "You can download the .qmd file for this lab here.\nThe above link will take you to your editing file. Please do not remove anything from this editing file!! You will only add your code and work to this file.\n\n\nThe purpose of this lab is to\n\n\n\nThis lab is graded out of 12 points. The TAs will go through and grade your lab. They will make sure each section is complete and will follow the rubric below. I have instructed them that completion and clear effort is all that is needed to receive 100%. Nicky will go through the labs to give you feedback.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\n\n\nFormatting\nLab submitted on Sakai with .html file. Answers are written in complete sentences with no major grammatical nor spelling errors. With little editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with grammatical or spelling errors. With editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with major grammatical or spelling errors. With major editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are bulletted or do not use complete sentences.\nLab not submitted on Sakai with .html file.\n\n\nCode/Work\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMost tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nSome tasks are directly followed or answered.This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMore than a quarter of the tasks are not completed properly.\n\n\nReasoning*\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful and can be easily integrated into the final report.\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful, but lack the clarity needed to easily integrate into the final report.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers are fairly thoughtful, but lack connection to the research.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers seem rushed and with minimal thought.\nAnswers lack understanding of research context and investigation of the data. Answers seem rushed and without thought.\n\n\n\n*Applies to questions with reasoning"
  },
  {
    "objectID": "project/Lab_03_instructions.html#directions",
    "href": "project/Lab_03_instructions.html#directions",
    "title": "Lab 2 Instructions",
    "section": "",
    "text": "You can download the .qmd file for this lab here.\nThe above link will take you to your editing file. Please do not remove anything from this editing file!! You will only add your code and work to this file.\n\n\nThe purpose of this lab is to\n\n\n\nThis lab is graded out of 12 points. The TAs will go through and grade your lab. They will make sure each section is complete and will follow the rubric below. I have instructed them that completion and clear effort is all that is needed to receive 100%. Nicky will go through the labs to give you feedback.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\n\n\nFormatting\nLab submitted on Sakai with .html file. Answers are written in complete sentences with no major grammatical nor spelling errors. With little editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with grammatical or spelling errors. With editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are written in complete sentences with major grammatical or spelling errors. With major editing, the answer can be incorporated into the project report.\nLab submitted on Sakai with .html file. Answers are bulletted or do not use complete sentences.\nLab not submitted on Sakai with .html file.\n\n\nCode/Work\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nAll tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMost tasks are directly followed or answered. This includes all the needed code, in code chunks, with the requested output.\nSome tasks are directly followed or answered.This includes all the needed code, in code chunks, with the requested output. In a few tasks, the code syntax or output is not quite right.\nMore than a quarter of the tasks are not completed properly.\n\n\nReasoning*\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful and can be easily integrated into the final report.\nAnswers demonstrate understanding of research context and investigation of the data. Answers are thoughtful, but lack the clarity needed to easily integrate into the final report.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers are fairly thoughtful, but lack connection to the research.\nAnswers demonstrate some understanding of research context and investigation of the data. Answers seem rushed and with minimal thought.\nAnswers lack understanding of research context and investigation of the data. Answers seem rushed and without thought.\n\n\n\n*Applies to questions with reasoning"
  },
  {
    "objectID": "project/Lab_03_instructions.html#lab-activities",
    "href": "project/Lab_03_instructions.html#lab-activities",
    "title": "Lab 2 Instructions",
    "section": "2 Lab activities",
    "text": "2 Lab activities\n\n\n\n\n\n\nNote\n\n\n\nI have left it up to you to load the needed packages for this lab.\n\n\n\n2.1 Restate research question\n\n\n\n\n\n\nTask\n\n\n\nPlease restate your research question below using the provided format (1 sentence). You can change the wording if you’d like, but please make sure it is still clear. It’s repetitive, but it helps me contextualize my feedback as I look through your lab.\n\n\nIn this study, we will investigate the association between food insecurity and ________."
  },
  {
    "objectID": "project/LastName_FirstInit_Lab_03.html",
    "href": "project/LastName_FirstInit_Lab_03.html",
    "title": "Lab 2",
    "section": "",
    "text": "This is your editing file. Please do not remove anything from this editing file!! You will only add your code and work to this file.\n\n\nThe purpose of this lab is to explore our data further, set up the unadjusted odds ratio, and create code to later help us present our final model.\n\n\n\nThis lab is graded out of 12 points. The TAs will go through and grade your lab. They will make sure each section is complete and will follow the rubric below. I have instructed them that completion and clear effort is all that is needed to receive 100%. Nicky will go through the labs to give you feedback."
  },
  {
    "objectID": "project/LastName_FirstInit_Lab_03.html#directions",
    "href": "project/LastName_FirstInit_Lab_03.html#directions",
    "title": "Lab 2",
    "section": "",
    "text": "This is your editing file. Please do not remove anything from this editing file!! You will only add your code and work to this file.\n\n\nThe purpose of this lab is to explore our data further, set up the unadjusted odds ratio, and create code to later help us present our final model.\n\n\n\nThis lab is graded out of 12 points. The TAs will go through and grade your lab. They will make sure each section is complete and will follow the rubric below. I have instructed them that completion and clear effort is all that is needed to receive 100%. Nicky will go through the labs to give you feedback."
  },
  {
    "objectID": "project/LastName_FirstInit_Lab_03.html#lab-activities",
    "href": "project/LastName_FirstInit_Lab_03.html#lab-activities",
    "title": "Lab 2",
    "section": "2 Lab activities",
    "text": "2 Lab activities\n\n\n\n\n\n\nNote\n\n\n\nI have left it up to you to load the needed packages for this lab.\n\n\n\n2.1 Restate research question\n\n\n\n\n\n\nTask\n\n\n\nPlease restate your research question below using the provided format (1 sentence). You can change the wording if you’d like, but please make sure it is still clear. It’s repetitive, but it helps me contextualize my feedback as I look through your lab.\n\n\nIn this study, we will investigate the association between food insecurity and ________.\n\n\n2.2 Make sure variables are coded correctly\n\n\n\n\n\n\nTask\n\n\n\n\nUse class() to determine the class of each of the 11 variables you selected from Lab 1 (including the outcome).\nChange the variable type to the appropriate type.\n\n\n\n\n\n2.3 Consider potential confounders and effect modifiers\n\n\n\n\n\n\nTask\n\n\n\nFill in the below table (or any other way you wish to present the same information).\n\n\n\n\n\n\n\n\n\n\nVariable name\nConfounder, Effect modifier, or nothing?\nReasoning (1-2 sentences)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4 Create contingency tables for categorical predictors\n\n\n\n\n\n\nTask\n\n\n\n\nCreate contingency tables for all categorical covariates with food insecurity.\nTake note of any cell counts that are less than 10\n\n\n\n\n\n2.5 Bivariate exploratory data analysis\n\n\n\n\n\n\nTask\n\n\n\n\nUse ggpairs() (introduced in BSTA 512 Lesson 13) to quickly look at the relationship between variables.\nList predictors with which there is a clear trend with food insecurity.\n\n\n\n\n\n2.6 Fit simple logistic regression\n\n\n\n\n\n\nTask\n\n\n\n\nUsing glm(), run a logistic regression with food insecurity and your main variable of interest.\nDisplay the unadjusted odds ratio of the regression. You can use logistic.display()\nInterpret the unadjusted odds ratio (with 95% confidence interval). If you’re main variable is multi-level, then you will need to interpret multiple odds ratios.\n\n\n\n\n\n2.7 Plot the predicted probability\n\n\n\n\n\n\nTask\n\n\n\nPlot or make a table of your predicted probabilities."
  }
]